
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <!--pjax：防止跳转页面音乐暂停-->
    <script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script> 
    <meta charset="utf-8">
    

    

    
    <title>
        code:spikeBert_Sqy |
        
        あまのひな‘s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });   简要目录 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565">
<meta property="og:type" content="article">
<meta property="og:title" content="code:spikeBert_Sqy">
<meta property="og:url" content="https://abinzzz.github.io/2023/11/19/code-spikeBert-Sqy/index.html">
<meta property="og:site_name" content="あまのひな‘s Blog">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });   简要目录 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-11-19T05:19:11.000Z">
<meta property="article:modified_time" content="2023-11-20T08:17:43.672Z">
<meta property="article:author" content="あまのひな">
<meta property="article:tag" content="internship">
<meta property="article:tag" content="spikeBert">
<meta name="twitter:card" content="summary">
    
        <link rel="alternate" href="/atom.xml" title="あまのひな‘s Blog" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
        
<link rel="stylesheet" href="https://unpkg.com/katex@0.16.7/dist/katex.min.css">

    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
    
        <img data-src="https://singyesterday.com/cmn/images/gallery/l/pic_200325_22.jpg" data-sizes="auto" alt="code:spikeBert_Sqy" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>code:spikeBert_Sqy</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-code-spikeBert-Sqy" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2023/11/19/code-spikeBert-Sqy/" class="article-date-link">
        <time datetime="2023-11-19T05:19:11.000Z"
              itemprop="datePublished">2023-11-19</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/internship/">internship</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="简要目录"><a class="markdownIt-Anchor" href="#简要目录"></a> 简要目录</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── bert_base.sh</span><br><span class="line">├── bert-base-uncased</span><br><span class="line">│   ├── config.json</span><br><span class="line">│   ├── coreml</span><br><span class="line">│   ├── flax_model.msgpack</span><br><span class="line">│   ├── .git</span><br><span class="line">│   ├── .gitattributes</span><br><span class="line">│   ├── LICENSE</span><br><span class="line">│   ├── model.safetensors</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── rust_model.ot</span><br><span class="line">│   ├── tf_model.h5</span><br><span class="line">│   ├── tokenizer_config.json</span><br><span class="line">│   ├── tokenizer.json</span><br><span class="line">│   └── vocab.txt</span><br><span class="line">├── bert.py</span><br><span class="line">├── binary_bert_kqv_lora.py</span><br><span class="line">├── learner.py</span><br><span class="line">├── model_debug.py</span><br><span class="line">├── output</span><br><span class="line">│   ├── args.json</span><br><span class="line">│   ├── config.json</span><br><span class="line">│   ├── pytorch_model.bin</span><br><span class="line">│   ├── special_tokens_map.json</span><br><span class="line">│   ├── step_100000</span><br><span class="line">│   ├── step_150000</span><br><span class="line">│   ├── step_200000</span><br><span class="line">│   ├── step_250000</span><br><span class="line">│   ├── step_300000</span><br><span class="line">│   ├── step_350000</span><br><span class="line">│   ├── step_400000</span><br><span class="line">│   ├── step_450000</span><br><span class="line">│   ├── step_50000</span><br><span class="line">│   ├── step_500000</span><br><span class="line">│   ├── tokenizer_config.json</span><br><span class="line">│   ├── tokenizer.json</span><br><span class="line">│   └── vocab.txt</span><br><span class="line">├── __pycache__</span><br><span class="line">│   ├── binary_bert_kqv_lora.cpython-39.pyc</span><br><span class="line">│   ├── learner.cpython-39.pyc</span><br><span class="line">│   ├── model_debug.cpython-39.pyc</span><br><span class="line">│   ├── spike_bert.cpython-39.pyc</span><br><span class="line">│   ├── spike_lif.cpython-39.pyc</span><br><span class="line">│   └── utils_spike.cpython-39.pyc</span><br><span class="line">├── run_pretrain_binary.py</span><br><span class="line">├── snntorch</span><br><span class="line">│   ├── backprop.py</span><br><span class="line">│   ├── functional</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── _neurons</span><br><span class="line">│   ├── spikegen.py</span><br><span class="line">│   ├── spikeplot.py</span><br><span class="line">│   ├── spikevision</span><br><span class="line">│   ├── surrogate.py</span><br><span class="line">│   ├── utils.py</span><br><span class="line">│   └── _version.py</span><br><span class="line">├── spike_bert.py</span><br><span class="line">├── spike_lif.py</span><br><span class="line">├── spikingjelly1</span><br><span class="line">│   ├── activation_based</span><br><span class="line">│   ├── configure.py</span><br><span class="line">│   ├── datasets</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   ├── timing_based</span><br><span class="line">│   └── visualizing</span><br><span class="line">├── test.log</span><br><span class="line">├── test.py</span><br><span class="line">├── utils_quant.py</span><br><span class="line">├── utils_spike.py</span><br><span class="line">└── .vscode</span><br><span class="line">    └── launch.json</span><br></pre></td></tr></table></figure>
<br>
<h2 id="最简目录"><a class="markdownIt-Anchor" href="#最简目录"></a> 最简目录</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">├── bert_base.sh</span><br><span class="line">├── bert-base-uncased</span><br><span class="line">├── bert.py</span><br><span class="line">├── binary_bert_kqv_lora.py</span><br><span class="line">├── learner.py</span><br><span class="line">├── model_debug.py</span><br><span class="line">├── output</span><br><span class="line">├── __pycache__</span><br><span class="line">├── run_pretrain_binary.py</span><br><span class="line">├── snntorch</span><br><span class="line">├── spike_bert.py</span><br><span class="line">├── spike_lif.py</span><br><span class="line">├── spikingjelly1</span><br><span class="line">├── test.log</span><br><span class="line">├── test.py</span><br><span class="line">├── utils_quant.py</span><br><span class="line">├── utils_spike.py</span><br><span class="line">└── .vscode</span><br></pre></td></tr></table></figure>
<br>
<h2 id="1bert_basesh"><a class="markdownIt-Anchor" href="#1bert_basesh"></a> 1.bert_base.sh</h2>
<p>训练一个基于BERT架构的预训练模型的脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># schedule_str=&quot;--grow_time 5</span></span><br><span class="line"><span class="comment"># --hidden_size_start 30</span></span><br><span class="line"><span class="comment"># --layer_start 20</span></span><br><span class="line"><span class="comment"># --layer_start_2 50</span></span><br><span class="line"><span class="comment"># --head_start 40</span></span><br><span class="line"><span class="comment"># --intermediate_start 10</span></span><br><span class="line"><span class="comment"># &quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># target_str=&quot;--hidden_size_target 768</span></span><br><span class="line"><span class="comment"># --layer_target 6</span></span><br><span class="line"><span class="comment"># --layer_target_2 12</span></span><br><span class="line"><span class="comment"># --head_target 12</span></span><br><span class="line"><span class="comment"># --intermediate_target 3072</span></span><br><span class="line"><span class="comment"># &quot;</span></span><br><span class="line"><span class="comment"># CUDA_VISIBLE_DEVICES=0,1,2,3</span></span><br><span class="line">python -m torch.distributed.run \</span><br><span class="line">--nproc_per_node 8  --master_port 44144 \</span><br><span class="line">run_pretrain_binary.py \</span><br><span class="line"> \</span><br><span class="line">--dataset_name /data10/static_10000 \</span><br><span class="line">--model_name_or_path bert-base-uncased \</span><br><span class="line">--per_device_train_batch_size 32 \</span><br><span class="line">--per_device_eval_batch_size 32 \</span><br><span class="line">--learning_rate 2e-4 \</span><br><span class="line">--max_train_steps 500000 \</span><br><span class="line">--num_warmup_steps 5000 \</span><br><span class="line">--output_dir /data10/sqy/spikeBert_Sqy/output \</span><br><span class="line">--max_seq_length 128 \</span><br><span class="line">--checkpointing_steps 50000 </span><br><span class="line"><span class="comment"># --with_tracking True</span></span><br><span class="line"><span class="comment"># --report_to wandb </span></span><br></pre></td></tr></table></figure>
<p><strong>参数设置（被注释掉的部分）</strong>:</p>
<ul>
<li><code>schedule_str</code> 和 <code>target_str</code> 部分包含了一些被注释掉的参数，它们似乎用于定义模型训练过程中的一些动态调整。这些参数包括隐藏层的大小（<code>hidden_size</code>）、网络层的数量（<code>layer</code>）、头的数量（<code>head</code>）和中间层的尺寸（<code>intermediate</code>）。</li>
</ul>
<p><strong>CUDA环境(被注释的部分)</strong>:</p>
<ul>
<li><code>CUDA_VISIBLE_DEVICES=0,1,2,3</code> 这行设置了CUDA环境变量，指定了哪些GPU将被用于训练。这里指定了四个GPU（编号为0, 1, 2, 3）。</li>
</ul>
<p><strong>PyTorch分布式运行设置</strong>:</p>
<ul>
<li><code>python -m torch.distributed.run</code> 是启动PyTorch分布式训练的命令。</li>
<li><code>--nproc_per_node 8</code> 指定了每个节点（在这个情况下是每个GPU）将运行的进程数。</li>
<li><code>--master_port 44144</code> 设置了主节点监听的端口号。</li>
</ul>
<p><strong>模型训练脚本及其参数</strong>:</p>
<ul>
<li><code>run_pretrain_binary.py</code> 是实际运行的Python脚本，用于预训练BERT模型。</li>
<li>参数如下：
<ul>
<li><code>--dataset_name /data10/static_10000</code> 指定了数据集的路径。</li>
<li><code>--model_name_or_path bert-base-uncased</code> 表明使用的是“bert-base-uncased”模型。</li>
<li><code>--per_device_train_batch_size 32</code> 和 <code>--per_device_eval_batch_size 32</code> 分别设置了每个设备的训练和评估批量大小。</li>
<li><code>--learning_rate 2e-4</code> 设置了学习率。</li>
<li><code>--max_train_steps 500000</code> 设置了最大训练步数。</li>
<li><code>--num_warmup_steps 5000</code> 设置了预热步数。</li>
<li><code>--output_dir /data10/sqy/spikeBert_Sqy/output</code> 指定了输出目录。</li>
<li><code>--max_seq_length 128</code> 设置了序列的最大长度。</li>
<li><code>--checkpointing_steps 50000</code> 指定了检查点保存的步数间隔。</li>
</ul>
</li>
</ul>
<p><strong>额外的可选设置（被注释掉的部分）</strong>:</p>
<ul>
<li><code>--with_tracking True</code> 和 <code>--report_to wandb</code> 这两个参数被注释掉了，但它们似乎用于跟踪训练进度和报告到Weights &amp; Biases（wandb）平台。</li>
</ul>
<br>
<br>
<h2 id="2bert-base-uncased文件夹"><a class="markdownIt-Anchor" href="#2bert-base-uncased文件夹"></a> 2.bert-base-uncased文件夹</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">├── bert-base-uncased</span><br><span class="line">│   ├── config.json</span><br><span class="line">│   ├── coreml</span><br><span class="line">│   ├── flax_model.msgpack</span><br><span class="line">│   ├── .git</span><br><span class="line">│   ├── .gitattributes</span><br><span class="line">│   ├── LICENSE</span><br><span class="line">│   ├── model.safetensors</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── rust_model.ot</span><br><span class="line">│   ├── tf_model.h5</span><br><span class="line">│   ├── tokenizer_config.json</span><br><span class="line">│   ├── tokenizer.json</span><br><span class="line">│   └── vocab.txt</span><br></pre></td></tr></table></figure>
<br>
<h2 id="21-configjson"><a class="markdownIt-Anchor" href="#21-configjson"></a> 2.1 config.json</h2>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;architectures&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;BertForMaskedLM&quot;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;attention_probs_dropout_prob&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;gradient_checkpointing&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;hidden_act&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gelu&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;hidden_dropout_prob&quot;</span><span class="punctuation">:</span> <span class="number">0.1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;hidden_size&quot;</span><span class="punctuation">:</span> <span class="number">768</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;initializer_range&quot;</span><span class="punctuation">:</span> <span class="number">0.02</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;intermediate_size&quot;</span><span class="punctuation">:</span> <span class="number">3072</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;layer_norm_eps&quot;</span><span class="punctuation">:</span> <span class="number">1e-12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;max_position_embeddings&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;model_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bert&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;num_attention_heads&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;num_hidden_layers&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;pad_token_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;position_embedding_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;absolute&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;transformers_version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4.6.0.dev0&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;type_vocab_size&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;use_cache&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;vocab_size&quot;</span><span class="punctuation">:</span> <span class="number">30522</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>-------------- <strong>JSON·解释·BEGIN</strong> --------------</p>
<p><strong>什么是json文件</strong>：JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，它易于人类阅读和编写，同时也易于机器解析和生成。JSON源自JavaScript，但它是独立于语言的，因此在很多编程环境中都得到了广泛的应用。JSON格式的主要用途是在网络上传输数据，比如在客户端和服务器之间</p>
<p><strong>json的关键特点</strong>：</p>
<ul>
<li><strong>文本格式</strong>：JSON是基于文本的，可以被任何编程语言读取。</li>
<li><strong>键值对</strong>：JSON数据是由键值对组成的。键是一个字符串，值可以是字符串、数值、布尔值、数组或者另一个JSON对象。</li>
<li><strong>对象和数组</strong>：
<ul>
<li><strong>对象</strong>：用花括号 {} 括起来的一组无序的键值对，类似于Python中的字典或者JavaScript中的对象。</li>
<li><strong>数组</strong>：用方括号 [] 括起来的一组有序的值，类似于Python中的列表或者JavaScript中的数组。</li>
</ul>
</li>
<li><strong>可读性</strong>：虽然JSON主要用于数据交换，但其格式简洁明了，易于人类阅读和编写。</li>
<li><strong>语言独立性</strong>：JSON与任何特定的编程语言无关，这使得JSON成为不同语言和平台之间传输数据的理想格式。</li>
</ul>
<p>-------------- <strong>JSON·解释·END</strong> --------------</p>
<p>参数的解释：<br />
<strong><code>architectures</code>: [“BertForMaskedLM”]</strong>：指定了模型的架构，这里使用的是“BertForMaskedLM”，即用于掩码语言模型任务的BERT版本。</p>
<p><strong><code>attention_probs_dropout_prob</code>: 0.1</strong>：设置了注意力机制中的dropout概率为0.1，用于减少过拟合。</p>
<p><strong><code>gradient_checkpointing</code>: false</strong>：指示是否使用梯度检查点技术，这里设置为<code>false</code>，意味着不使用。</p>
<p><strong><code>hidden_act</code>: “gelu”</strong>：指定隐藏层使用的激活函数，这里使用的是GELU（Gaussian Error Linear Unit）。</p>
<p><strong><code>hidden_dropout_prob</code>: 0.1</strong>：设置隐藏层的dropout概率为0.1。</p>
<p><strong><code>hidden_size</code>: 768</strong>：表示隐藏层的维度大小，这里是768。</p>
<p><strong><code>initializer_range</code>: 0.02</strong>：指定模型参数初始化时的范围，这里是0.02。</p>
<p><strong><code>intermediate_size</code>: 3072</strong>：表示前馈网络中间层的大小，这里是3072。</p>
<p><strong><code>layer_norm_eps</code>: 1e-12</strong>：设置层归一化（Layer Normalization）中的一个小的常数，以防止除以零。</p>
<p><strong><code>max_position_embeddings</code>: 512</strong>：设置位置嵌入的最大数量，这里是512，这限制了模型能够处理的最大序列长度。</p>
<p><strong><code>model_type</code>: “bert”</strong>：指定模型类型，这里是BERT。</p>
<p><strong><code>num_attention_heads</code>: 12</strong>：设置每个注意力层的头数，这里是12。</p>
<p><strong><code>num_hidden_layers</code>: 12</strong>：指定隐藏层的数量，这里是12。</p>
<p><strong><code>pad_token_id</code>: 0</strong>：设置用于填充序列的标记的ID，通常是0。</p>
<p><strong><code>position_embedding_type</code>: “absolute”</strong>：指定位置嵌入的类型，这里使用的是绝对位置嵌入。</p>
<p><strong><code>transformers_version</code>: “4.6.0.dev0”</strong>：指定使用的Transformers库的版本。</p>
<p><strong><code>type_vocab_size</code>: 2</strong>：设置句子类型词汇的大小，通常用于区分两个不同的句子，这里是2。</p>
<p><strong><code>use_cache</code>: true</strong>：指示是否使用缓存来提高模型在生成文本时的效率，这里设置为<code>true</code>。</p>
<p><strong><code>vocab_size</code>: 30522</strong>：指定词汇表的大小，这里是30522。</p>
<br>
<h2 id="22-coreml"><a class="markdownIt-Anchor" href="#22-coreml"></a> 2.2 coreml</h2>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;fileFormatVersion&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.0.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;itemInfoEntries&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;9D749A46-ADA0-43CA-B5C2-8E722B91F41E&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;com.apple.CoreML&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;CoreML Model Specification&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;model.mlmodel&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;com.apple.CoreML/model.mlmodel&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;D545B13F-2D5E-4CFB-BFF1-C10E9EFD70DA&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;com.apple.CoreML&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;CoreML Model Weights&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;weights&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;com.apple.CoreML/weights&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rootModelIdentifier&quot;</span><span class="punctuation">:</span> <span class="string">&quot;9D749A46-ADA0-43CA-B5C2-8E722B91F41E&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="23-flax_modelmsgpack"><a class="markdownIt-Anchor" href="#23-flax_modelmsgpack"></a> 2.3 flax_model.msgpack</h2>
<p>没什么用的文件</p>
<br>
<br>
<h2 id="3-bertpy"><a class="markdownIt-Anchor" href="#3-bertpy"></a> 3. <a target="_blank" rel="noopener" href="http://bert.py">bert.py</a></h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="comment"># Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.</span></span><br><span class="line"><span class="comment"># Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;PyTorch BERT model.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span>, <span class="type">Tuple</span>, <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.checkpoint</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> BCEWithLogitsLoss, CrossEntropyLoss, MSELoss</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers.activations <span class="keyword">import</span> ACT2FN</span><br><span class="line"><span class="keyword">from</span> transformers.modeling_outputs <span class="keyword">import</span> (</span><br><span class="line">    BaseModelOutputWithPastAndCrossAttentions,</span><br><span class="line">    BaseModelOutputWithPoolingAndCrossAttentions,</span><br><span class="line">    CausalLMOutputWithCrossAttentions,</span><br><span class="line">    MaskedLMOutput,</span><br><span class="line">    MultipleChoiceModelOutput,</span><br><span class="line">    NextSentencePredictorOutput,</span><br><span class="line">    QuestionAnsweringModelOutput,</span><br><span class="line">    SequenceClassifierOutput,</span><br><span class="line">    TokenClassifierOutput,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> transformers.modeling_utils <span class="keyword">import</span> PreTrainedModel</span><br><span class="line"><span class="keyword">from</span> transformers.pytorch_utils <span class="keyword">import</span> apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer</span><br><span class="line"><span class="keyword">from</span> transformers.utils <span class="keyword">import</span> (</span><br><span class="line">    ModelOutput,</span><br><span class="line">    add_code_sample_docstrings,</span><br><span class="line">    add_start_docstrings,</span><br><span class="line">    add_start_docstrings_to_model_forward,</span><br><span class="line">    logging,</span><br><span class="line">    replace_return_docstrings,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> transformers.models.bert.configuration_bert <span class="keyword">import</span> BertConfig</span><br></pre></td></tr></table></figure>
<p>导入所需的库，模块和配置</p>
<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">logger = logging.get_logger(__name__)</span><br><span class="line"></span><br><span class="line">_CHECKPOINT_FOR_DOC = <span class="string">&quot;bert-base-uncased&quot;</span></span><br><span class="line">_CONFIG_FOR_DOC = <span class="string">&quot;BertConfig&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TokenClassification docstring</span></span><br><span class="line">_CHECKPOINT_FOR_TOKEN_CLASSIFICATION = <span class="string">&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;</span></span><br><span class="line">_TOKEN_CLASS_EXPECTED_OUTPUT = (</span><br><span class="line">    <span class="string">&quot;[&#x27;O&#x27;, &#x27;I-ORG&#x27;, &#x27;I-ORG&#x27;, &#x27;I-ORG&#x27;, &#x27;O&#x27;, &#x27;O&#x27;, &#x27;O&#x27;, &#x27;O&#x27;, &#x27;O&#x27;, &#x27;I-LOC&#x27;, &#x27;O&#x27;, &#x27;I-LOC&#x27;, &#x27;I-LOC&#x27;] &quot;</span></span><br><span class="line">)</span><br><span class="line">_TOKEN_CLASS_EXPECTED_LOSS = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># QuestionAnswering docstring</span></span><br><span class="line">_CHECKPOINT_FOR_QA = <span class="string">&quot;deepset/bert-base-cased-squad2&quot;</span></span><br><span class="line">_QA_EXPECTED_OUTPUT = <span class="string">&quot;&#x27;a nice puppet&#x27;&quot;</span></span><br><span class="line">_QA_EXPECTED_LOSS = <span class="number">7.41</span></span><br><span class="line">_QA_TARGET_START_INDEX = <span class="number">14</span></span><br><span class="line">_QA_TARGET_END_INDEX = <span class="number">15</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SequenceClassification docstring</span></span><br><span class="line">_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION = <span class="string">&quot;textattack/bert-base-uncased-yelp-polarity&quot;</span></span><br><span class="line">_SEQ_CLASS_EXPECTED_OUTPUT = <span class="string">&quot;&#x27;LABEL_1&#x27;&quot;</span></span><br><span class="line">_SEQ_CLASS_EXPECTED_LOSS = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 预训练BERT模型列表</span></span><br><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_LIST = [</span><br><span class="line">    <span class="string">&quot;bert-base-uncased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-large-uncased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-cased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-large-cased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-multilingual-uncased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-multilingual-cased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-chinese&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-german-cased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-large-uncased-whole-word-masking&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-large-cased-whole-word-masking&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-large-uncased-whole-word-masking-finetuned-squad&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-large-cased-whole-word-masking-finetuned-squad&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-cased-finetuned-mrpc&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-german-dbmdz-cased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;bert-base-german-dbmdz-uncased&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cl-tohoku/bert-base-japanese&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cl-tohoku/bert-base-japanese-whole-word-masking&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cl-tohoku/bert-base-japanese-char&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cl-tohoku/bert-base-japanese-char-whole-word-masking&quot;</span>,</span><br><span class="line">    <span class="string">&quot;TurkuNLP/bert-base-finnish-cased-v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;TurkuNLP/bert-base-finnish-uncased-v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;wietsedv/bert-base-dutch-cased&quot;</span>,</span><br><span class="line">    <span class="comment"># See all BERT models at https://huggingface.co/models?filter=bert</span></span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>日志记录器的配置</li>
<li>特定任务的预期输出和损失</li>
<li>预训练BERT模型的列表</li>
</ul>
<br>
<h2 id="31-bertembeddings"><a class="markdownIt-Anchor" href="#31-bertembeddings"></a> 3.1 BertEmbeddings</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BertEmbeddings</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Construct the embeddings from word, position and token_type embeddings.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 词嵌入，将词汇表中的每个单词映射到一个高维空间</span></span><br><span class="line">        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 位置嵌入，给每个单词在句子中的位置编码</span></span><br><span class="line">        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 令牌类型嵌入，用于区分两个句子</span></span><br><span class="line">        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load</span></span><br><span class="line">        <span class="comment"># any TensorFlow checkpoint file</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## 层归一化</span></span><br><span class="line">        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## dropout操作</span></span><br><span class="line">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</span><br><span class="line">        <span class="comment"># position_ids (1, len position emb) is contiguous in memory and exported when serialized</span></span><br><span class="line"></span><br><span class="line">        self.position_embedding_type = <span class="built_in">getattr</span>(config, <span class="string">&quot;position_embedding_type&quot;</span>, <span class="string">&quot;absolute&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## 缓冲区</span></span><br><span class="line">        self.register_buffer(<span class="string">&quot;position_ids&quot;</span>, torch.arange(config.max_position_embeddings).expand((<span class="number">1</span>, -<span class="number">1</span>)))</span><br><span class="line">        self.register_buffer(</span><br><span class="line">            <span class="string">&quot;token_type_ids&quot;</span>, torch.zeros(self.position_ids.size(), dtype=torch.long), persistent=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        input_ids: <span class="type">Optional</span>[torch.LongTensor] = <span class="literal">None</span>, <span class="comment">## 单词在词汇表中的索引</span></span></span><br><span class="line"><span class="params">        token_type_ids: <span class="type">Optional</span>[torch.LongTensor] = <span class="literal">None</span>, <span class="comment">## 用于区分两个句子</span></span></span><br><span class="line"><span class="params">        position_ids: <span class="type">Optional</span>[torch.LongTensor] = <span class="literal">None</span>, <span class="comment">## 单词在句子中的位置</span></span></span><br><span class="line"><span class="params">        inputs_embeds: <span class="type">Optional</span>[torch.FloatTensor] = <span class="literal">None</span>,  <span class="comment">## 如果提供，将使用这些嵌入而不是从input_ids生成的嵌入。</span></span></span><br><span class="line"><span class="params">        past_key_values_length: <span class="built_in">int</span> = <span class="number">0</span>, <span class="comment">##用于处理序列化数据</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; torch.Tensor:</span><br><span class="line"></span><br><span class="line"><span class="comment">## 首先，代码检查input_ids是否为None。input_ids是一个包含输入令牌ID的张量。</span></span><br><span class="line"><span class="comment">## 如果input_ids不为None，则使用input_ids.size()来确定输入的形状（即维度）。否则，如果提供了inputs_embeds（直接嵌入而非令牌ID），则使用inputs_embeds.size()[:-1]来确定输入形状。[:-1]表示除了最后一个维度之外的所有维度，因为最后一个维度通常是嵌入的维度。</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> input_ids <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            input_shape = input_ids.size()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            input_shape = inputs_embeds.size()[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取输入的第二个维度作为序列长度（假设第一个维度是批次大小）</span></span><br><span class="line">        seq_length = input_shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 如果没有提供position_ids，则从预先注册的position_ids缓冲区中截取与当前序列长度相匹配的部分</span></span><br><span class="line">        <span class="keyword">if</span> position_ids <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Setting the token_type_ids to the registered buffer in constructor where it is all zeros, which usually occurs</span></span><br><span class="line">        <span class="comment"># when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves</span></span><br><span class="line">        <span class="comment"># issue #5664</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 如果没有提供token_type_ids，则检查类实例是否有token_type_ids属性。如果有，使用这个属性（一个预先设定好的全零张量）并根据输入的序列长度调整其形状。</span></span><br><span class="line">        <span class="keyword">if</span> token_type_ids <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(self, <span class="string">&quot;token_type_ids&quot;</span>):</span><br><span class="line">                buffered_token_type_ids = self.token_type_ids[:, :seq_length]</span><br><span class="line">                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[<span class="number">0</span>], seq_length)</span><br><span class="line">                token_type_ids = buffered_token_type_ids_expanded</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> inputs_embeds <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            inputs_embeds = self.word_embeddings(input_ids)</span><br><span class="line">        token_type_embeddings = self.token_type_embeddings(token_type_ids)</span><br><span class="line"></span><br><span class="line">        embeddings = inputs_embeds + token_type_embeddings</span><br><span class="line">        <span class="keyword">if</span> self.position_embedding_type == <span class="string">&quot;absolute&quot;</span>:</span><br><span class="line">            position_embeddings = self.position_embeddings(position_ids)</span><br><span class="line">            embeddings += position_embeddings</span><br><span class="line">        embeddings = self.LayerNorm(embeddings)</span><br><span class="line">        embeddings = self.dropout(embeddings)</span><br><span class="line">        <span class="keyword">return</span> embeddings</span><br></pre></td></tr></table></figure>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── bert_base.sh</span><br><span class="line">├── bert-base-uncased</span><br><span class="line">│   ├── config.json</span><br><span class="line">│   ├── coreml</span><br><span class="line">│   │   └── fill-mask</span><br><span class="line">│   │       └── float32_model.mlpackage</span><br><span class="line">│   │           ├── Data</span><br><span class="line">│   │           │   └── com.apple.CoreML</span><br><span class="line">│   │           │       ├── model.mlmodel</span><br><span class="line">│   │           │       └── weights</span><br><span class="line">│   │           │           └── weight.bin</span><br><span class="line">│   │           └── Manifest.json</span><br><span class="line">│   ├── flax_model.msgpack</span><br><span class="line">│   ├── .git</span><br><span class="line">│   │   ├── branches</span><br><span class="line">│   │   ├── config</span><br><span class="line">│   │   ├── description</span><br><span class="line">│   │   ├── HEAD</span><br><span class="line">│   │   ├── hooks</span><br><span class="line">│   │   │   ├── applypatch-msg.sample</span><br><span class="line">│   │   │   ├── commit-msg.sample</span><br><span class="line">│   │   │   ├── fsmonitor-watchman.sample</span><br><span class="line">│   │   │   ├── post-update.sample</span><br><span class="line">│   │   │   ├── pre-applypatch.sample</span><br><span class="line">│   │   │   ├── pre-commit.sample</span><br><span class="line">│   │   │   ├── pre-merge-commit.sample</span><br><span class="line">│   │   │   ├── prepare-commit-msg.sample</span><br><span class="line">│   │   │   ├── pre-push.sample</span><br><span class="line">│   │   │   ├── pre-rebase.sample</span><br><span class="line">│   │   │   ├── pre-receive.sample</span><br><span class="line">│   │   │   └── update.sample</span><br><span class="line">│   │   ├── index</span><br><span class="line">│   │   ├── info</span><br><span class="line">│   │   │   └── exclude</span><br><span class="line">│   │   ├── logs</span><br><span class="line">│   │   │   ├── HEAD</span><br><span class="line">│   │   │   └── refs</span><br><span class="line">│   │   │       ├── heads</span><br><span class="line">│   │   │       │   └── main</span><br><span class="line">│   │   │       └── remotes</span><br><span class="line">│   │   │           └── origin</span><br><span class="line">│   │   │               └── HEAD</span><br><span class="line">│   │   ├── objects</span><br><span class="line">│   │   │   ├── 03</span><br><span class="line">│   │   │   │   └── 874f0a9a51110f92770262847f7ac2efdb8ec7</span><br><span class="line">│   │   │   ├── 0a</span><br><span class="line">│   │   │   │   └── 6aa9128b6194f4f3c4db429b6cb4891cdb421b</span><br><span class="line">│   │   │   ├── 0b</span><br><span class="line">│   │   │   │   └── 72f895ac9d935f87f9845e02915c8851e124de</span><br><span class="line">│   │   │   ├── 0e</span><br><span class="line">│   │   │   │   └── 9f43ffc3afb401b28131d3443a63cb98e5deb8</span><br><span class="line">│   │   │   ├── 1a</span><br><span class="line">│   │   │   │   ├── 30f9711976fc1bd9879517ef1075cd161924fa</span><br><span class="line">│   │   │   │   └── 7dd4986e3dab699c24ca19b2afd0f5e1a80f37</span><br><span class="line">│   │   │   ├── 2d</span><br><span class="line">│   │   │   │   └── b44799aecfc24f6b5c6f5b4943766da5bcbe4f</span><br><span class="line">│   │   │   ├── 2f</span><br><span class="line">│   │   │   │   ├── 07d813ca87c8c709147704c87210359ccf2309</span><br><span class="line">│   │   │   │   └── 8677524bcd13c4384ca89d93bdcc00adef251c</span><br><span class="line">│   │   │   ├── 30</span><br><span class="line">│   │   │   │   └── 3a292e7b3a4253bb7eeac44b1d4798a8c2b7c7</span><br><span class="line">│   │   │   ├── 34</span><br><span class="line">│   │   │   │   └── 5fd30026bc3003828be943882dda32ab48b908</span><br><span class="line">│   │   │   ├── 39</span><br><span class="line">│   │   │   │   └── a45f481139aa8f9abf129240714ea9da57b2e8</span><br><span class="line">│   │   │   ├── 3d</span><br><span class="line">│   │   │   │   └── 2477d72b675a999d1b13ca822aaaf4908634ad</span><br><span class="line">│   │   │   ├── 40</span><br><span class="line">│   │   │   │   └── a2aaca31dd005eb5f6ffad07b5ffed0a31d1f6</span><br><span class="line">│   │   │   ├── 41</span><br><span class="line">│   │   │   │   └── 8430c3b5df7ace92f2aede75700d22c78a0f95</span><br><span class="line">│   │   │   ├── 45</span><br><span class="line">│   │   │   │   └── a2321a7ecfdaaf60a6c1fd7f5463994cc8907d</span><br><span class="line">│   │   │   ├── 4d</span><br><span class="line">│   │   │   │   └── 564b466df31bf165495398c0d8ef51ddd2ee99</span><br><span class="line">│   │   │   ├── 50</span><br><span class="line">│   │   │   │   ├── 4939aa53e8ce310dba3dd2296dbe266c575de4</span><br><span class="line">│   │   │   │   └── 5a7adf8be9e5fdf06aabbfbe9046e6c811f91b</span><br><span class="line">│   │   │   ├── 52</span><br><span class="line">│   │   │   │   └── f4ab676bed7ba6912ae1d96b272ab82adb3ae9</span><br><span class="line">│   │   │   ├── 55</span><br><span class="line">│   │   │   │   └── 46055f03398095e385d7dc625e636cc8910bf2</span><br><span class="line">│   │   │   ├── 57</span><br><span class="line">│   │   │   │   └── b6e3cba54270c69fa5cfb99873236868dcc576</span><br><span class="line">│   │   │   ├── 5b</span><br><span class="line">│   │   │   │   └── 16e96ccd6a42974d9bb1761b6506b896b83537</span><br><span class="line">│   │   │   ├── 5c</span><br><span class="line">│   │   │   │   └── 510bab25b8829a74a5314b871c63b12a2abca3</span><br><span class="line">│   │   │   ├── 5d</span><br><span class="line">│   │   │   │   └── fe9adac0748dcecbb14ab068f6a9406d7348da</span><br><span class="line">│   │   │   ├── 5f</span><br><span class="line">│   │   │   │   └── 0832a907f01a78777c5fe109de7b1f3fa5941a</span><br><span class="line">│   │   │   ├── 69</span><br><span class="line">│   │   │   │   ├── 819c162b33712ab3912f6366a63d5cb914ab24</span><br><span class="line">│   │   │   │   └── 9826f54d2f6e82f6c941146a8010c978d94caa</span><br><span class="line">│   │   │   ├── 6b</span><br><span class="line">│   │   │   │   ├── 27a0389dbec35db8534fd27cf44cb5b8176c1f</span><br><span class="line">│   │   │   │   └── 2f2ab89b227603d839e1c3df8509e685d905a3</span><br><span class="line">│   │   │   ├── 71</span><br><span class="line">│   │   │   │   └── 2f843fe03a214b38b75710507139a3c9f597ee</span><br><span class="line">│   │   │   ├── 74</span><br><span class="line">│   │   │   │   └── 74f0559041a6973a91f268587c71a933c4421a</span><br><span class="line">│   │   │   ├── 79</span><br><span class="line">│   │   │   │   └── 276673252f15cea400800731e0d4e3d3cba64f</span><br><span class="line">│   │   │   ├── 7a</span><br><span class="line">│   │   │   │   └── 9371512e3b980992f29235d25ee4f7f747560e</span><br><span class="line">│   │   │   ├── 80</span><br><span class="line">│   │   │   │   └── 39186bf824d1496f1c030150149b1ab6c7295f</span><br><span class="line">│   │   │   ├── 81</span><br><span class="line">│   │   │   │   ├── 97097fe81e18c54a0aa78684cadc04ff7c09f2</span><br><span class="line">│   │   │   │   └── a1712b46a9fd3f5b1d64ef424207a1c22fbf44</span><br><span class="line">│   │   │   ├── 82</span><br><span class="line">│   │   │   │   └── 69c79876030587c90ad481ded8f3730f342384</span><br><span class="line">│   │   │   ├── 85</span><br><span class="line">│   │   │   │   └── 4104d6ebdb16bccfc0bd7518d2fdd0ce35e95f</span><br><span class="line">│   │   │   ├── 86</span><br><span class="line">│   │   │   │   ├── 2f60468333266bee84d73c13a301c24b12fe23</span><br><span class="line">│   │   │   │   └── f982b105d6091e7537b13d7b2a5e650f0d899e</span><br><span class="line">│   │   │   ├── 94</span><br><span class="line">│   │   │   │   ├── 1c1ed3859432b6399878f50a93a7afe8394b1a</span><br><span class="line">│   │   │   │   ├── 9a6f013d67eb8a5b4b5b46026217b888021b88</span><br><span class="line">│   │   │   │   └── af24044e0f1337edbadc03423090dfb4d8698a</span><br><span class="line">│   │   │   ├── 9b</span><br><span class="line">│   │   │   │   └── b39cce506bd8c9e1717d1ce2dd02402c8bd667</span><br><span class="line">│   │   │   ├── 9e</span><br><span class="line">│   │   │   │   └── b98c817f04b051b3bcca591bcd4e03cec88018</span><br><span class="line">│   │   │   ├── a0</span><br><span class="line">│   │   │   │   └── 90ee7d80c0e00eca57c5aaaa54d136d58c5218</span><br><span class="line">│   │   │   ├── a2</span><br><span class="line">│   │   │   │   └── 65f773a47193eed794233aa2a0f0bb6d3eaa63</span><br><span class="line">│   │   │   ├── a6</span><br><span class="line">│   │   │   │   └── 61b1a138dac6dc5590367402d100765010ffd6</span><br><span class="line">│   │   │   ├── a8</span><br><span class="line">│   │   │   │   └── 86295655f51659368757f79135fb2ffa664141</span><br><span class="line">│   │   │   ├── ae</span><br><span class="line">│   │   │   │   └── 8c63daedbd4206d7d40126955d4e6ab1c80f8f</span><br><span class="line">│   │   │   ├── b0</span><br><span class="line">│   │   │   │   └── e67f4070874a51359949d8efcb2e36c9926d18</span><br><span class="line">│   │   │   ├── b3</span><br><span class="line">│   │   │   │   └── 409d9fba88a0d2a4a2a3c08bd5f33dd324cf38</span><br><span class="line">│   │   │   ├── b9</span><br><span class="line">│   │   │   │   └── 6743c503420c0858ad23fca994e670844c6c05</span><br><span class="line">│   │   │   ├── ba</span><br><span class="line">│   │   │   │   └── 5d19791be1dd7992e33bd61f20207b0f7f50a5</span><br><span class="line">│   │   │   ├── bb</span><br><span class="line">│   │   │   │   ├── 0c238a6903e404f3e0cdb1599183f81f04d26e</span><br><span class="line">│   │   │   │   └── 3c1c3256d2598217df9889a14a2e811587891d</span><br><span class="line">│   │   │   ├── bd</span><br><span class="line">│   │   │   │   ├── 3e35c1681371542bd98f96b299be1832d89dbf</span><br><span class="line">│   │   │   │   └── b420bf56ef3f72ee07cd75ab6df1b765b6012a</span><br><span class="line">│   │   │   ├── c1</span><br><span class="line">│   │   │   │   ├── 07dbb7dd275528552514945214f40b3b49ab16</span><br><span class="line">│   │   │   │   └── c37cd58b9eb000ddbb7ca90f04b893a33e50c8</span><br><span class="line">│   │   │   ├── cd</span><br><span class="line">│   │   │   │   └── 4b30943e4245a5dff3747c24686b81728553d3</span><br><span class="line">│   │   │   ├── cf</span><br><span class="line">│   │   │   │   └── 6afbfea8cc1dd02941af7f43ba5f2bd6c8cd5c</span><br><span class="line">│   │   │   ├── d1</span><br><span class="line">│   │   │   │   └── b8f934ac1bedc2fcf995972bd5d35f6df43814</span><br><span class="line">│   │   │   ├── d4</span><br><span class="line">│   │   │   │   └── 59802a5b4ae7eb402ce274f4f2d60d17263fa3</span><br><span class="line">│   │   │   ├── d5</span><br><span class="line">│   │   │   │   └── 793d257adc4d23c2e25f86f62b5ad5930f609b</span><br><span class="line">│   │   │   ├── dc</span><br><span class="line">│   │   │   │   ├── 08351d4dc0732d9c8af04070ced089b201ce2f</span><br><span class="line">│   │   │   │   └── 400b5d53726ec4912a77a961b6c36b3c0ab030</span><br><span class="line">│   │   │   ├── dd</span><br><span class="line">│   │   │   │   └── 4bc8b21efa05ec961e3efc4ee5e3832a3679c7</span><br><span class="line">│   │   │   ├── eb</span><br><span class="line">│   │   │   │   └── 456931f19c1dad278aa899be5033b4b548fac3</span><br><span class="line">│   │   │   ├── ed</span><br><span class="line">│   │   │   │   └── ffe1f3942125a11cc9c5ac907b950c52baff07</span><br><span class="line">│   │   │   ├── f2</span><br><span class="line">│   │   │   │   └── fc38bea01c8a48c2c4d5f3941e35562a8b3ee5</span><br><span class="line">│   │   │   ├── f4</span><br><span class="line">│   │   │   │   ├── 9a4e16e68b128803cc2dcea614603632b04eac</span><br><span class="line">│   │   │   │   └── f508084297b355a3a4a834a51fd9e159c551b1</span><br><span class="line">│   │   │   ├── f8</span><br><span class="line">│   │   │   │   └── 7d7e158e66321d831f6690559da0155b43a095</span><br><span class="line">│   │   │   ├── fb</span><br><span class="line">│   │   │   │   └── 140275c155a9c7c5a3b3e0e77a9e839594a938</span><br><span class="line">│   │   │   ├── fc</span><br><span class="line">│   │   │   │   └── a794a5f07ff8f963fe8b61e3694b0fb7f955df</span><br><span class="line">│   │   │   ├── fd</span><br><span class="line">│   │   │   │   └── 6476efe1918e9235d895507b9cb08030107954</span><br><span class="line">│   │   │   ├── fe</span><br><span class="line">│   │   │   │   └── 23aa0e428c9dc5195f16374d2b3d3dca64a901</span><br><span class="line">│   │   │   ├── info</span><br><span class="line">│   │   │   └── pack</span><br><span class="line">│   │   ├── packed-refs</span><br><span class="line">│   │   └── refs</span><br><span class="line">│   │       ├── heads</span><br><span class="line">│   │       │   └── main</span><br><span class="line">│   │       ├── remotes</span><br><span class="line">│   │       │   └── origin</span><br><span class="line">│   │       │       └── HEAD</span><br><span class="line">│   │       └── tags</span><br><span class="line">│   ├── .gitattributes</span><br><span class="line">│   ├── LICENSE</span><br><span class="line">│   ├── model.safetensors</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── rust_model.ot</span><br><span class="line">│   ├── tf_model.h5</span><br><span class="line">│   ├── tokenizer_config.json</span><br><span class="line">│   ├── tokenizer.json</span><br><span class="line">│   └── vocab.txt</span><br><span class="line">├── bert.py</span><br><span class="line">├── binary_bert_kqv_lora.py</span><br><span class="line">├── learner.py</span><br><span class="line">├── model_debug.py</span><br><span class="line">├── output</span><br><span class="line">│   ├── args.json</span><br><span class="line">│   ├── config.json</span><br><span class="line">│   ├── pytorch_model.bin</span><br><span class="line">│   ├── special_tokens_map.json</span><br><span class="line">│   ├── step_100000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_150000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_200000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_250000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_300000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_350000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_400000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_450000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_50000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── step_500000</span><br><span class="line">│   │   ├── optimizer.bin</span><br><span class="line">│   │   ├── pytorch_model.bin</span><br><span class="line">│   │   ├── random_states_0.pkl</span><br><span class="line">│   │   ├── random_states_1.pkl</span><br><span class="line">│   │   ├── random_states_2.pkl</span><br><span class="line">│   │   ├── random_states_3.pkl</span><br><span class="line">│   │   └── scheduler.bin</span><br><span class="line">│   ├── tokenizer_config.json</span><br><span class="line">│   ├── tokenizer.json</span><br><span class="line">│   └── vocab.txt</span><br><span class="line">├── __pycache__</span><br><span class="line">│   ├── binary_bert_kqv_lora.cpython-39.pyc</span><br><span class="line">│   ├── learner.cpython-39.pyc</span><br><span class="line">│   ├── model_debug.cpython-39.pyc</span><br><span class="line">│   ├── spike_bert.cpython-39.pyc</span><br><span class="line">│   ├── spike_lif.cpython-39.pyc</span><br><span class="line">│   └── utils_spike.cpython-39.pyc</span><br><span class="line">├── run_pretrain_binary.py</span><br><span class="line">├── snntorch</span><br><span class="line">│   ├── backprop.py</span><br><span class="line">│   ├── functional</span><br><span class="line">│   │   ├── acc.py</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   ├── loss.py</span><br><span class="line">│   │   ├── __pycache__</span><br><span class="line">│   │   │   ├── acc.cpython-37.pyc</span><br><span class="line">│   │   │   ├── __init__.cpython-37.pyc</span><br><span class="line">│   │   │   ├── loss.cpython-37.pyc</span><br><span class="line">│   │   │   └── reg.cpython-37.pyc</span><br><span class="line">│   │   ├── quant.py</span><br><span class="line">│   │   └── reg.py</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── _neurons</span><br><span class="line">│   │   ├── alpha.py</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   ├── lapicque.py</span><br><span class="line">│   │   ├── leaky.py</span><br><span class="line">│   │   ├── neurons.py</span><br><span class="line">│   │   ├── __pycache__</span><br><span class="line">│   │   │   ├── alpha.cpython-37.pyc</span><br><span class="line">│   │   │   ├── alpha.cpython-39.pyc</span><br><span class="line">│   │   │   ├── __init__.cpython-37.pyc</span><br><span class="line">│   │   │   ├── __init__.cpython-39.pyc</span><br><span class="line">│   │   │   ├── lapicque.cpython-37.pyc</span><br><span class="line">│   │   │   ├── lapicque.cpython-39.pyc</span><br><span class="line">│   │   │   ├── leaky.cpython-37.pyc</span><br><span class="line">│   │   │   ├── leaky.cpython-39.pyc</span><br><span class="line">│   │   │   ├── neurons.cpython-37.pyc</span><br><span class="line">│   │   │   ├── neurons.cpython-39.pyc</span><br><span class="line">│   │   │   ├── rleaky.cpython-37.pyc</span><br><span class="line">│   │   │   ├── rleaky.cpython-39.pyc</span><br><span class="line">│   │   │   ├── rsynaptic.cpython-37.pyc</span><br><span class="line">│   │   │   ├── rsynaptic.cpython-39.pyc</span><br><span class="line">│   │   │   ├── sconv2dlstm.cpython-37.pyc</span><br><span class="line">│   │   │   ├── sconv2dlstm.cpython-39.pyc</span><br><span class="line">│   │   │   ├── slstm.cpython-37.pyc</span><br><span class="line">│   │   │   ├── slstm.cpython-39.pyc</span><br><span class="line">│   │   │   ├── synaptic.cpython-37.pyc</span><br><span class="line">│   │   │   └── synaptic.cpython-39.pyc</span><br><span class="line">│   │   ├── rleaky.py</span><br><span class="line">│   │   ├── rsynaptic.py</span><br><span class="line">│   │   ├── sconv2dlstm.py</span><br><span class="line">│   │   ├── slstm.py</span><br><span class="line">│   │   └── synaptic.py</span><br><span class="line">│   ├── spikegen.py</span><br><span class="line">│   ├── spikeplot.py</span><br><span class="line">│   ├── spikevision</span><br><span class="line">│   │   ├── events_timeslices.py</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   ├── neuromorphic_dataset.py</span><br><span class="line">│   │   ├── spikedata</span><br><span class="line">│   │   │   ├── dvs_gesture.py</span><br><span class="line">│   │   │   ├── __init__.py</span><br><span class="line">│   │   │   ├── nmnist.py</span><br><span class="line">│   │   │   └── shd.py</span><br><span class="line">│   │   ├── _transforms.py</span><br><span class="line">│   │   └── _utils.py</span><br><span class="line">│   ├── surrogate.py</span><br><span class="line">│   ├── utils.py</span><br><span class="line">│   └── _version.py</span><br><span class="line">├── spike_bert.py</span><br><span class="line">├── spike_lif.py</span><br><span class="line">├── spikingjelly1</span><br><span class="line">│   ├── activation_based</span><br><span class="line">│   │   ├── ann2snn</span><br><span class="line">│   │   │   ├── converter.py</span><br><span class="line">│   │   │   ├── examples</span><br><span class="line">│   │   │   │   ├── cnn_mnist.py</span><br><span class="line">│   │   │   │   ├── __init__.py</span><br><span class="line">│   │   │   │   └── resnet18_cifar10.py</span><br><span class="line">│   │   │   ├── __init__.py</span><br><span class="line">│   │   │   ├── modules.py</span><br><span class="line">│   │   │   ├── sample_models</span><br><span class="line">│   │   │   │   ├── cifar10_resnet.py</span><br><span class="line">│   │   │   │   └── mnist_cnn.py</span><br><span class="line">│   │   │   └── utils.py</span><br><span class="line">│   │   ├── auto_cuda</span><br><span class="line">│   │   │   ├── base.py</span><br><span class="line">│   │   │   ├── cfunction.py</span><br><span class="line">│   │   │   ├── example.py</span><br><span class="line">│   │   │   ├── generator.py</span><br><span class="line">│   │   │   ├── __init__.py</span><br><span class="line">│   │   │   ├── neuron_kernel.py</span><br><span class="line">│   │   │   ├── __pycache__</span><br><span class="line">│   │   │   │   ├── base.cpython-38.pyc</span><br><span class="line">│   │   │   │   ├── base.cpython-39.pyc</span><br><span class="line">│   │   │   │   ├── cfunction.cpython-38.pyc</span><br><span class="line">│   │   │   │   ├── cfunction.cpython-39.pyc</span><br><span class="line">│   │   │   │   ├── __init__.cpython-38.pyc</span><br><span class="line">│   │   │   │   ├── __init__.cpython-39.pyc</span><br><span class="line">│   │   │   │   ├── neuron_kernel.cpython-38.pyc</span><br><span class="line">│   │   │   │   ├── neuron_kernel.cpython-39.pyc</span><br><span class="line">│   │   │   │   ├── ss_neuron_kernel.cpython-38.pyc</span><br><span class="line">│   │   │   │   └── ss_neuron_kernel.cpython-39.pyc</span><br><span class="line">│   │   │   ├── readme.md</span><br><span class="line">│   │   │   └── ss_neuron_kernel.py</span><br><span class="line">│   │   ├── base.py</span><br><span class="line">│   │   ├── cuda_utils.py</span><br><span class="line">│   │   ├── encoding.py</span><br><span class="line">│   │   ├── examples</span><br><span class="line">│   │   │   ├── A2C.py</span><br><span class="line">│   │   │   ├── cifar10_r11_enabling_spikebased_backpropagation.py</span><br><span class="line">│   │   │   ├── classify_dvsg.py</span><br><span class="line">│   │   │   ├── common</span><br><span class="line">│   │   │   │   ├── __init__.py</span><br><span class="line">│   │   │   │   └── multiprocessing_env.py</span><br><span class="line">│   │   │   ├── conv_fashion_mnist.py</span><br><span class="line">│   │   │   ├── DQN_state.py</span><br><span class="line">│   │   │   ├── __init__.py</span><br><span class="line">│   │   │   ├── lava_mnist.py</span><br><span class="line">│   │   │   ├── lif_fc_mnist.py</span><br><span class="line">│   │   │   ├── lynxi_fmnist_inference.py</span><br><span class="line">│   │   │   ├── mstdpet.py</span><br><span class="line">│   │   │   ├── mstdp.py</span><br><span class="line">│   │   │   ├── PPO.py</span><br><span class="line">│   │   │   ├── rsnn_sequential_fmnist.py</span><br><span class="line">│   │   │   ├── speechcommands.py</span><br><span class="line">│   │   │   ├── Spiking_A2C.py</span><br><span class="line">│   │   │   ├── Spiking_DQN_state.py</span><br><span class="line">│   │   │   ├── spiking_lstm_sequential_mnist.py</span><br><span class="line">│   │   │   ├── spiking_lstm_text.py</span><br><span class="line">│   │   │   ├── Spiking_PPO.py</span><br><span class="line">│   │   │   └── stdp_trace.py</span><br><span class="line">│   │   ├── functional.py</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   ├── lava_exchange.py</span><br><span class="line">│   │   ├── layer.py</span><br><span class="line">│   │   ├── learning.py</span><br><span class="line">│   │   ├── lynxi_exchange.py</span><br><span class="line">│   │   ├── model</span><br><span class="line">│   │   │   ├── __init__.py</span><br><span class="line">│   │   │   ├── parametric_lif_net.py</span><br><span class="line">│   │   │   ├── sew_resnet.py</span><br><span class="line">│   │   │   ├── snas_net.py</span><br><span class="line">│   │   │   ├── spike_dhs.py</span><br><span class="line">│   │   │   ├── spiking_resnet.py</span><br><span class="line">│   │   │   ├── spiking_vgg.py</span><br><span class="line">│   │   │   ├── train_classify.py</span><br><span class="line">│   │   │   ├── train_imagenet_example.py</span><br><span class="line">│   │   │   └── tv_ref_classify</span><br><span class="line">│   │   │       ├── __init__.py</span><br><span class="line">│   │   │       ├── presets.py</span><br><span class="line">│   │   │       ├── sampler.py</span><br><span class="line">│   │   │       ├── transforms.py</span><br><span class="line">│   │   │       └── utils.py</span><br><span class="line">│   │   ├── monitor.py</span><br><span class="line">│   │   ├── neuron_kernel.md</span><br><span class="line">│   │   ├── neuron_kernel.py</span><br><span class="line">│   │   ├── neuron_kernel_sample.cu</span><br><span class="line">│   │   ├── neuron.py</span><br><span class="line">│   │   ├── __pycache__</span><br><span class="line">│   │   │   ├── base.cpython-38.pyc</span><br><span class="line">│   │   │   ├── base.cpython-39.pyc</span><br><span class="line">│   │   │   ├── cuda_utils.cpython-38.pyc</span><br><span class="line">│   │   │   ├── cuda_utils.cpython-39.pyc</span><br><span class="line">│   │   │   ├── functional.cpython-39.pyc</span><br><span class="line">│   │   │   ├── __init__.cpython-38.pyc</span><br><span class="line">│   │   │   ├── __init__.cpython-39.pyc</span><br><span class="line">│   │   │   ├── neuron.cpython-38.pyc</span><br><span class="line">│   │   │   ├── neuron.cpython-39.pyc</span><br><span class="line">│   │   │   ├── neuron_kernel.cpython-38.pyc</span><br><span class="line">│   │   │   ├── surrogate.cpython-38.pyc</span><br><span class="line">│   │   │   ├── surrogate.cpython-39.pyc</span><br><span class="line">│   │   │   └── tensor_cache.cpython-38.pyc</span><br><span class="line">│   │   ├── quantize.py</span><br><span class="line">│   │   ├── rnn.py</span><br><span class="line">│   │   ├── spike_op.py</span><br><span class="line">│   │   ├── surrogate.py</span><br><span class="line">│   │   └── tensor_cache.py</span><br><span class="line">│   ├── configure.py</span><br><span class="line">│   ├── datasets</span><br><span class="line">│   │   ├── asl_dvs.py</span><br><span class="line">│   │   ├── bullying10k.py</span><br><span class="line">│   │   ├── cifar10_dvs.py</span><br><span class="line">│   │   ├── dvs128_gesture.py</span><br><span class="line">│   │   ├── es_imagenet.py</span><br><span class="line">│   │   ├── hardvs.py</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   ├── nav_gesture.py</span><br><span class="line">│   │   ├── n_caltech101.py</span><br><span class="line">│   │   ├── n_mnist.py</span><br><span class="line">│   │   ├── shd.py</span><br><span class="line">│   │   ├── speechcommands.py</span><br><span class="line">│   │   └── to_x_rep.py</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   │   ├── configure.cpython-38.pyc</span><br><span class="line">│   │   ├── configure.cpython-39.pyc</span><br><span class="line">│   │   ├── __init__.cpython-38.pyc</span><br><span class="line">│   │   └── __init__.cpython-39.pyc</span><br><span class="line">│   ├── timing_based</span><br><span class="line">│   │   ├── encoding.py</span><br><span class="line">│   │   ├── examples</span><br><span class="line">│   │   │   ├── __init__.py</span><br><span class="line">│   │   │   └── tempotron_mnist.py</span><br><span class="line">│   │   ├── __init__.py</span><br><span class="line">│   │   └── neuron.py</span><br><span class="line">│   └── visualizing</span><br><span class="line">│       └── __init__.py</span><br><span class="line">├── test.log</span><br><span class="line">├── test.py</span><br><span class="line">├── utils_quant.py</span><br><span class="line">├── utils_spike.py</span><br><span class="line">└── .vscode</span><br><span class="line">    └── launch.json</span><br></pre></td></tr></table></figure>
<br>
            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2023/11/19/code-spikeBert-Sqy/" data-id="clp515mes00014a695maf6xae" data-title="code:spikeBert_Sqy"
               class="article-share-link">分享</a>
            
            
            
            
    <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/internship/" rel="tag">internship</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spikeBert/" rel="tag">spikeBert</a></li></ul>


        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
            <div class="article-nav-link-wrap article-nav-link-left">
                
                    <img data-src="https://singyesterday.com/cmn/images/gallery/l/pic_200325_22.jpg" data-sizes="auto" alt="Database:Lab3"
                         class="lazyload">
                
                <a href="/2023/11/20/Database-Lab3/"></a>
                <div class="article-nav-caption">前一篇</div>
                <h3 class="article-nav-title">
                    
                        Database:Lab3
                    
                </h3>
            </div>
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://singyesterday.com/cmn/images/gallery/l/pic_200325_22.jpg" data-sizes="auto" alt="intern-04"
                         class="lazyload">
                
                <a href="/2023/11/19/intern-04/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        intern-04
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="あまのひな" class="lazyload">
            <div class="sidebar-author-name">あまのひな</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">233</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">23</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">293</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=28854246&auto=1&height=66"></iframe>

    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accumulate/">Accumulate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AimGraduate/">AimGraduate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bug/">bug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/internship/SNN/">SNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/spikeBERT/">spikeBERT</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/spikingjelly/">spikingjelly</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/reading/">reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/Database/">Database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/Databse/">Databse</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/">ML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/Missing-Semester-of-CS/">Missing Semester of CS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/NNDL/">NNDL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/OS/">OS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/SE/">SE</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/d2l/">d2l</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/">智能计算系统</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/0/" style="font-size: 10px;">0</a> <a href="/tags/1/" style="font-size: 10px;">1</a> <a href="/tags/11-11/" style="font-size: 10px;">11.11</a> <a href="/tags/2/" style="font-size: 10px;">2</a> <a href="/tags/2-2/" style="font-size: 10px;">2-2</a> <a href="/tags/3/" style="font-size: 10px;">3</a> <a href="/tags/3-1/" style="font-size: 10px;">3-1</a> <a href="/tags/4/" style="font-size: 10px;">4</a> <a href="/tags/A4/" style="font-size: 10px;">A4</a> <a href="/tags/A6/" style="font-size: 10px;">A6</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/AI-Ethics/" style="font-size: 10px;">AI Ethics</a> <a href="/tags/Accumulate/" style="font-size: 13.08px;">Accumulate</a> <a href="/tags/Advanced-SQL/" style="font-size: 10px;">Advanced SQL</a> <a href="/tags/Advancing-Spiking-Neural-Networks-towards-Deep-Residual-Learning/" style="font-size: 11.54px;">Advancing Spiking Neural Networks towards Deep Residual Learning</a> <a href="/tags/Ai-Ethics/" style="font-size: 10px;">Ai Ethics</a> <a href="/tags/AimGraduate/" style="font-size: 11.54px;">AimGraduate</a> <a href="/tags/An-Overview-of-the-BLITZ-Computer-Hardware/" style="font-size: 10px;">An Overview of the BLITZ Computer Hardware</a> <a href="/tags/An-Overview-of-the-BLITZ-System/" style="font-size: 10px;">An Overview of the BLITZ System</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/Artificial-neural-networks/" style="font-size: 10px;">Artificial neural networks</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/BLIP/" style="font-size: 10px;">BLIP</a> <a href="/tags/BLIP-2/" style="font-size: 10px;">BLIP-2</a> <a href="/tags/BasciConception/" style="font-size: 10px;">BasciConception</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/Blitz/" style="font-size: 12.31px;">Blitz</a> <a href="/tags/CAS/" style="font-size: 10px;">CAS</a> <a href="/tags/CMU15-445/" style="font-size: 10px;">CMU15-445</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CV/" style="font-size: 10.77px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 13.85px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/Chapter01/" style="font-size: 10px;">Chapter01</a> <a href="/tags/Container/" style="font-size: 10px;">Container</a> <a href="/tags/Convolutional-SNN-to-Classify-FMNIST/" style="font-size: 10px;">Convolutional SNN to Classify FMNIST</a> <a href="/tags/Cover-Letter/" style="font-size: 10px;">Cover Letter</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Database/" style="font-size: 13.85px;">Database</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 10.77px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Fine-Tuning/" style="font-size: 10px;">Fine-Tuning</a> <a href="/tags/GNN/" style="font-size: 10px;">GNN</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/Git/" style="font-size: 10.77px;">Git</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoAbroad/" style="font-size: 16.92px;">GoAbroad</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/IC/" style="font-size: 10px;">IC</a> <a href="/tags/IELTS/" style="font-size: 10.77px;">IELTS</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 10px;">IntelliJ IDEA</a> <a href="/tags/Intermediate-SQL/" style="font-size: 10px;">Intermediate SQL</a> <a href="/tags/Introduction/" style="font-size: 10px;">Introduction</a> <a href="/tags/Introduction-to-SQL/" style="font-size: 10px;">Introduction to SQL</a> <a href="/tags/Introduction-to-the-Relational-Model/" style="font-size: 10px;">Introduction to the Relational Model</a> <a href="/tags/Jianfei-Chen/" style="font-size: 10px;">Jianfei Chen</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/LMUFORMER/" style="font-size: 10px;">LMUFORMER</a> <a href="/tags/Lab1/" style="font-size: 10px;">Lab1</a> <a href="/tags/Lab3/" style="font-size: 10px;">Lab3</a> <a href="/tags/Lab4/" style="font-size: 10px;">Lab4</a> <a href="/tags/Lec01/" style="font-size: 11.54px;">Lec01</a> <a href="/tags/Lec01s/" style="font-size: 10.77px;">Lec01s</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/Linux/" style="font-size: 11.54px;">Linux</a> <a href="/tags/M2/" style="font-size: 10.77px;">M2</a> <a href="/tags/MIT6-S081/" style="font-size: 13.08px;">MIT6.S081</a> <a href="/tags/ML/" style="font-size: 13.08px;">ML</a> <a href="/tags/MS-ResNet/" style="font-size: 10px;">MS-ResNet</a> <a href="/tags/Mac/" style="font-size: 10.77px;">Mac</a> <a href="/tags/Missing-Semester/" style="font-size: 10px;">Missing Semester</a> <a href="/tags/Monitor/" style="font-size: 10px;">Monitor</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/NNDL/" style="font-size: 16.15px;">NNDL</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Neural-Network-from-Shallow-to-Deep/" style="font-size: 10px;">Neural Network from Shallow to Deep</a> <a href="/tags/Neuromorphic-computing/" style="font-size: 10px;">Neuromorphic computing</a> <a href="/tags/Neuron/" style="font-size: 10px;">Neuron</a> <a href="/tags/OS/" style="font-size: 11.54px;">OS</a> <a href="/tags/PSN/" style="font-size: 10px;">PSN</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Qingyao-Ai/" style="font-size: 10.77px;">Qingyao Ai</a> <a href="/tags/RISC-V/" style="font-size: 10px;">RISC-V</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/Readme/" style="font-size: 10px;">Readme</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" style="font-size: 10px;">Rethinking the performance comparison between SNNS and ANNS</a> <a href="/tags/SE/" style="font-size: 11.54px;">SE</a> <a href="/tags/SE-3-0/" style="font-size: 10px;">SE-3.0</a> <a href="/tags/SNN/" style="font-size: 13.08px;">SNN</a> <a href="/tags/SNN-vs-RNN/" style="font-size: 10px;">SNN vs RNN</a> <a href="/tags/SPIKEBERT/" style="font-size: 10px;">SPIKEBERT</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/Single-Fully-Connected-Layer-SNN-to-Classify-MNIST/" style="font-size: 10px;">Single Fully Connected Layer SNN to Classify MNIST</a> <a href="/tags/Spiking-neural-network/" style="font-size: 10.77px;">Spiking neural network</a> <a href="/tags/Spiking-neural-networks/" style="font-size: 10px;">Spiking neural networks</a> <a href="/tags/SpikingBERT/" style="font-size: 10px;">SpikingBERT</a> <a href="/tags/Surrogate-Gradient-Method/" style="font-size: 10px;">Surrogate Gradient Method</a> <a href="/tags/T1-fighting/" style="font-size: 10.77px;">T1 fighting</a> <a href="/tags/THU/" style="font-size: 10px;">THU</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/The-Thread-Scheduler-and-Concurrency-Control-Primitives/" style="font-size: 10px;">The Thread Scheduler and Concurrency Control Primitives</a> <a href="/tags/University/" style="font-size: 13.85px;">University</a> <a href="/tags/VSCode/" style="font-size: 10px;">VSCode</a> <a href="/tags/ViT/" style="font-size: 10.77px;">ViT</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 10.77px;">Yuxiao Dong</a> <a href="/tags/Zero/" style="font-size: 10px;">Zero</a> <a href="/tags/ai-ethics/" style="font-size: 10px;">ai ethics</a> <a href="/tags/arxiv/" style="font-size: 10px;">arxiv</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/bert/" style="font-size: 12.31px;">bert</a> <a href="/tags/blitz/" style="font-size: 10px;">blitz</a> <a href="/tags/bug/" style="font-size: 14.62px;">bug</a> <a href="/tags/chapter00/" style="font-size: 10px;">chapter00</a> <a href="/tags/chapter01/" style="font-size: 11.54px;">chapter01</a> <a href="/tags/chapter02/" style="font-size: 10.77px;">chapter02</a> <a href="/tags/chapter03/" style="font-size: 10px;">chapter03</a> <a href="/tags/chapter04/" style="font-size: 10.77px;">chapter04</a> <a href="/tags/chapter05/" style="font-size: 10.77px;">chapter05</a> <a href="/tags/chatgpt/" style="font-size: 10px;">chatgpt</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/code/" style="font-size: 11.54px;">code</a> <a href="/tags/coding/" style="font-size: 10px;">coding</a> <a href="/tags/conv2d/" style="font-size: 10px;">conv2d</a> <a href="/tags/courseinfo/" style="font-size: 10px;">courseinfo</a> <a href="/tags/cpu/" style="font-size: 10px;">cpu</a> <a href="/tags/cuda/" style="font-size: 10px;">cuda</a> <a href="/tags/d2l/" style="font-size: 13.85px;">d2l</a> <a href="/tags/database/" style="font-size: 14.62px;">database</a> <a href="/tags/dataloader/" style="font-size: 10px;">dataloader</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/deep-neural-network/" style="font-size: 10.77px;">deep neural network</a> <a href="/tags/discussion/" style="font-size: 10px;">discussion</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/dowhy/" style="font-size: 10.77px;">dowhy</a> <a href="/tags/dp/" style="font-size: 10px;">dp</a> <a href="/tags/echo/" style="font-size: 10px;">echo</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/explainer/" style="font-size: 10.77px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/file/" style="font-size: 10px;">file</a> <a href="/tags/github/" style="font-size: 10.77px;">github</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gpu/" style="font-size: 10.77px;">gpu</a> <a href="/tags/hacker/" style="font-size: 10px;">hacker</a> <a href="/tags/handout/" style="font-size: 10px;">handout</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/instructor/" style="font-size: 12.31px;">instructor</a> <a href="/tags/intern-00/" style="font-size: 10px;">intern-00</a> <a href="/tags/intern00/" style="font-size: 12.31px;">intern00</a> <a href="/tags/internship/" style="font-size: 18.46px;">internship</a> <a href="/tags/introduction/" style="font-size: 11.54px;">introduction</a> <a href="/tags/iterm2/" style="font-size: 10px;">iterm2</a> <a href="/tags/knowledge-distillaion/" style="font-size: 10px;">knowledge distillaion</a> <a href="/tags/l1/" style="font-size: 10px;">l1</a> <a href="/tags/l2/" style="font-size: 10px;">l2</a> <a href="/tags/l3/" style="font-size: 10px;">l3</a> <a href="/tags/lab1/" style="font-size: 10px;">lab1</a> <a href="/tags/lab2/" style="font-size: 10.77px;">lab2</a> <a href="/tags/lec01/" style="font-size: 10px;">lec01</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/llava/" style="font-size: 10px;">llava</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/loss/" style="font-size: 10px;">loss</a> <a href="/tags/lstm/" style="font-size: 10px;">lstm</a> <a href="/tags/mac/" style="font-size: 11.54px;">mac</a> <a href="/tags/mid/" style="font-size: 10.77px;">mid</a> <a href="/tags/ml/" style="font-size: 10px;">ml</a> <a href="/tags/mlp/" style="font-size: 10px;">mlp</a> <a href="/tags/mnist/" style="font-size: 10px;">mnist</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/mysqlclient/" style="font-size: 10px;">mysqlclient</a> <a href="/tags/neuromorphic-computing/" style="font-size: 10.77px;">neuromorphic computing</a> <a href="/tags/nndl/" style="font-size: 10.77px;">nndl</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/nvidia/" style="font-size: 10px;">nvidia</a> <a href="/tags/ohmyzsh/" style="font-size: 10px;">ohmyzsh</a> <a href="/tags/os/" style="font-size: 15.38px;">os</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/overview/" style="font-size: 10px;">overview</a> <a href="/tags/p1/" style="font-size: 10px;">p1</a> <a href="/tags/p2/" style="font-size: 11.54px;">p2</a> <a href="/tags/p3/" style="font-size: 10px;">p3</a> <a href="/tags/paper/" style="font-size: 19.23px;">paper</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/pku/" style="font-size: 10px;">pku</a> <a href="/tags/player/" style="font-size: 10px;">player</a> <a href="/tags/preparation/" style="font-size: 10px;">preparation</a> <a href="/tags/prml/" style="font-size: 12.31px;">prml</a> <a href="/tags/pytorch/" style="font-size: 12.31px;">pytorch</a> <a href="/tags/qemu/" style="font-size: 10px;">qemu</a> <a href="/tags/question/" style="font-size: 10px;">question</a> <a href="/tags/reading/" style="font-size: 10px;">reading</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/review/" style="font-size: 11.54px;">review</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/rsa/" style="font-size: 10px;">rsa</a> <a href="/tags/se/" style="font-size: 15.38px;">se</a> <a href="/tags/self-attention/" style="font-size: 10px;">self-attention</a> <a href="/tags/shap/" style="font-size: 10px;">shap</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/shell-vs-terminal/" style="font-size: 10px;">shell vs terminal</a> <a href="/tags/simple/" style="font-size: 10px;">simple</a> <a href="/tags/solution/" style="font-size: 10px;">solution</a> <a href="/tags/spike/" style="font-size: 10.77px;">spike</a> <a href="/tags/spikeBERT/" style="font-size: 10.77px;">spikeBERT</a> <a href="/tags/spikeBert/" style="font-size: 10px;">spikeBert</a> <a href="/tags/spikingjelly/" style="font-size: 13.08px;">spikingjelly</a> <a href="/tags/spikngjelly/" style="font-size: 10.77px;">spikngjelly</a> <a href="/tags/ssh/" style="font-size: 10.77px;">ssh</a> <a href="/tags/test/" style="font-size: 10px;">test</a> <a href="/tags/thu/" style="font-size: 10px;">thu</a> <a href="/tags/tips/" style="font-size: 10.77px;">tips</a> <a href="/tags/tool/" style="font-size: 17.69px;">tool</a> <a href="/tags/transformer/" style="font-size: 12.31px;">transformer</a> <a href="/tags/uml/" style="font-size: 10px;">uml</a> <a href="/tags/vit/" style="font-size: 10px;">vit</a> <a href="/tags/vscode/" style="font-size: 10px;">vscode</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/xv6/" style="font-size: 10px;">xv6</a> <a href="/tags/zero/" style="font-size: 10px;">zero</a> <a href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" style="font-size: 20px;">专业知识</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E4%B8%AD%E7%A7%91%E9%99%A2/" style="font-size: 10px;">中科院</a> <a href="/tags/%E5%86%85%E5%AD%98/" style="font-size: 10.77px;">内存</a> <a href="/tags/%E5%86%99%E4%BD%9C%E5%BF%83%E5%BE%97/" style="font-size: 10px;">写作心得</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" style="font-size: 10px;">分布式训练</a> <a href="/tags/%E5%8A%A0%E5%88%86/" style="font-size: 10px;">加分</a> <a href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">动手学深度学习</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0%E7%94%9F%E6%88%90/" style="font-size: 10px;">图像描述生成</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" style="font-size: 10px;">基础优化方法</a> <a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">复习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 10px;">多模态</a> <a href="/tags/%E5%A4%A7%E4%B8%89%E4%B8%8A/" style="font-size: 10px;">大三上</a> <a href="/tags/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/" style="font-size: 10.77px;">审稿意见</a> <a href="/tags/%E5%BC%BA%E5%BC%B1com/" style="font-size: 10px;">强弱com</a> <a href="/tags/%E5%BD%A2%E5%8A%BF%E4%B8%8E%E6%94%BF%E7%AD%96/" style="font-size: 10px;">形势与政策</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%80%80%E6%8F%A3%E7%9D%80%E4%B8%80%E5%AE%9A%E5%8F%AF%E4%BB%A5%E5%81%9A%E5%A5%BD%E7%9A%84%E7%A1%AE%E4%BF%A1/" style="font-size: 10px;">怀揣着一定可以做好的确信</a> <a href="/tags/%E6%83%85%E7%BB%AA%E7%9A%84%E7%A7%98%E5%AF%86/" style="font-size: 10px;">情绪的秘密</a> <a href="/tags/%E6%8F%90%E9%97%AE/" style="font-size: 10px;">提问</a> <a href="/tags/%E6%94%B9%E7%BB%B4%E5%BA%A6/" style="font-size: 10px;">改维度</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 10px;">数据操作+预处理</a> <a href="/tags/%E6%98%BE%E5%8D%A1/" style="font-size: 10px;">显卡</a> <a href="/tags/%E6%98%BE%E5%AD%98/" style="font-size: 10.77px;">显存</a> <a href="/tags/%E6%99%BA%E6%85%A7%E6%A0%91/" style="font-size: 10px;">智慧树</a> <a href="/tags/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" style="font-size: 13.08px;">智能计算系统</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 10.77px;">服务器</a> <a href="/tags/%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">期中复习</a> <a href="/tags/%E6%9C%9F%E6%9C%AB/" style="font-size: 10px;">期末</a> <a href="/tags/%E6%9C%B1%E8%80%81%E5%B8%88/" style="font-size: 10px;">朱老师</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9D%82%E9%A1%B9/" style="font-size: 10px;">杂项</a> <a href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" style="font-size: 10.77px;">李宏毅</a> <a href="/tags/%E6%A6%82%E8%AE%BA/" style="font-size: 10px;">概论</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/" style="font-size: 10px;">模型训练流程</a> <a href="/tags/%E6%AF%9B%E6%A6%82/" style="font-size: 13.85px;">毛概</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0/" style="font-size: 10.77px;">特征学习</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">环境搭建</a> <a href="/tags/%E7%94%A8%E4%BE%8B%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">用例模型</a> <a href="/tags/%E7%9F%A5%E8%A1%8C%E5%90%88%E4%B8%80/" style="font-size: 10px;">知行合一</a> <a href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">矩阵计算</a> <a href="/tags/%E7%AC%AC%E4%B8%89%E7%AB%A0/" style="font-size: 10px;">第三章</a> <a href="/tags/%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%BB%BA%E8%AE%AE%E4%B9%A6/" style="font-size: 10px;">系统开发建议书</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 10px;">线性代数</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 10px;">脑机接口信号处理</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">自动求导</a> <a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" style="font-size: 10px;">虚拟机</a> <a href="/tags/%E8%A7%84%E5%88%99/" style="font-size: 10px;">规则</a> <a href="/tags/%E8%A7%A3%E5%8E%8B%E7%BC%A9/" style="font-size: 10px;">解压缩</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87/" style="font-size: 10px;">评测指标</a> <a href="/tags/%E8%AF%BE%E5%A0%82%E8%AE%A8%E8%AE%BA/" style="font-size: 10px;">课堂讨论</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E6%A6%82%E8%A7%88/" style="font-size: 10px;">课程概览</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E8%A1%A8/" style="font-size: 10px;">课程表</a> <a href="/tags/%E8%AF%BE%E8%AE%BE/" style="font-size: 10px;">课设</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 11.54px;">调研</a> <a href="/tags/%E8%B4%A1%E7%8C%AE%E8%80%85/" style="font-size: 10px;">贡献者</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%A6%82%E8%A6%81%E8%AE%BE%E8%AE%A1/" style="font-size: 10px;">软件概要设计</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">软件生命周期模型</a> <a href="/tags/%E8%BE%93%E5%85%A5%E6%B3%95/" style="font-size: 10px;">输入法</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a> <a href="/tags/%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/" style="font-size: 10px;">需求分析</a> <a href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">面向对象的需求分析建模</a> <a href="/tags/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">领域模型</a>
        </div>
    </div>


    
        

    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">十一月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    

    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2023
                <span class="footer-info-sep"></span>
                あまのひな
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    488.6k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    31:10
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="あまのひな" class="lazyload">
            <div class="sidebar-author-name">あまのひな</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">233</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">23</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">293</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

