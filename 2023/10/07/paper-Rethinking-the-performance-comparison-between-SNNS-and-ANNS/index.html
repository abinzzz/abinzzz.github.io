
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <meta charset="utf-8">
    

    

    
    <title>
        paper:Rethinking the performance comparison between SNNS and ANNS |
        
        Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });   需要知道的问题  1.要了解深入，一个模型为什么好？ 2.以前的模型为什么不好？  除了脉冲驱动处理带来的低功耗属性优势之外，SNN 的性能通常比 ANN 差，尤其是在应用准确性方面  3.哪个关键点对性能提升最大？">
<meta property="og:type" content="article">
<meta property="og:title" content="paper:Rethinking the performance comparison between SNNS and ANNS">
<meta property="og:url" content="https://abinzzz.github.io/2023/10/07/paper-Rethinking-the-performance-comparison-between-SNNS-and-ANNS/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });   需要知道的问题  1.要了解深入，一个模型为什么好？ 2.以前的模型为什么不好？  除了脉冲驱动处理带来的低功耗属性优势之外，SNN 的性能通常比 ANN 差，尤其是在应用准确性方面  3.哪个关键点对性能提升最大？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pbs.twimg.com/media/F764_nYaAAACjk9?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F765BOSbwAAKfYs?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F77HNRjbIAAMsJI?format=png&amp;name=900x900">
<meta property="og:image" content="https://pbs.twimg.com/media/F77Ip2bb0AArpRt?format=png&amp;name=900x900">
<meta property="og:image" content="https://pbs.twimg.com/media/F79sUbjbQAA6-G7?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F79sWVZaMAA2fcK?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F79sXL3akAAbd4m?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F79sYAXbYAAR8tS?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F79107jbkAAD-gn?format=png&amp;name=360x360">
<meta property="og:image" content="https://pbs.twimg.com/media/F79112QbQAAauUO?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F79120taQAA9VNR?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F796zcSaEAAnVwQ?format=png&amp;name=small">
<meta property="og:image" content="https://pbs.twimg.com/media/F7960SpbIAAjaHj?format=png&amp;name=360x360">
<meta property="article:published_time" content="2023-10-07T14:11:25.000Z">
<meta property="article:modified_time" content="2023-10-09T03:55:44.807Z">
<meta property="article:author" content="野中晴">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="intern00">
<meta property="article:tag" content="Spiking neural networks">
<meta property="article:tag" content="Artificial neural networks">
<meta property="article:tag" content="Deep learning">
<meta property="article:tag" content="Neuromorphic computing">
<meta property="article:tag" content="Benchmark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pbs.twimg.com/media/F764_nYaAAACjk9?format=png&amp;name=small">
    
        <link rel="alternate" href="/atom.xml" title="Blog" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
        
<link rel="stylesheet" href="https://unpkg.com/katex@0.16.7/dist/katex.min.css">

    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
        <img data-src="https://singyesterday.com/cmn/images/gallery/l/pic_200325_22.jpg" data-sizes="auto" alt="paper:Rethinking the performance comparison between SNNS and ANNS" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>paper:Rethinking the performance comparison between SNNS and ANNS</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-paper-Rethinking-the-performance-comparison-between-SNNS-and-ANNS" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2023/10/07/paper-Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" class="article-date-link">
        <time datetime="2023-10-07T14:11:25.000Z"
              itemprop="datePublished">2023-10-07</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/paper/">paper</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="需要知道的问题"><a class="markdownIt-Anchor" href="#需要知道的问题"></a> 需要知道的问题</h2>
<ul>
<li>1.要了解深入，一个模型为什么好？</li>
<li>2.以前的模型为什么不好？</li>
</ul>
<p>除了脉冲驱动处理带来的低功耗属性优势之外，SNN 的性能通常比 ANN 差，尤其是在应用准确性方面</p>
<ul>
<li>3.哪个关键点对性能提升最大？</li>
<li>4.编程怎么实现？</li>
<li>5.论文源代码和paper匹配度怎么样、都覆盖了吗</li>
<li>6.哪些数学运算是关键的？</li>
<li>7.整个全流程是怎么走的？</li>
<li>8.数据是怎样流动的？其中是怎样变换的？各个变换有什么实际意义？</li>
<li>9.既要关注具体实现思路、也要关注上层抽象意义。作者灵感从何而来？</li>
<li>10.作者思考路线如何？</li>
</ul>
<h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> abstract</h2>
<p>脉冲神经网络（SNN）:一类模拟大脑神经元动力学的有前景的模型</p>
<p>长期以来，对于 SNN 在实际应用中的价值一直存在争论和怀疑。除了脉冲驱动处理带来的低功耗属性优势之外，SNN 的性能通常比 ANN 差，尤其是在应用准确性方面。</p>
<p>最近，研究人员试图<strong>通过借鉴 ANN 的学习方法（例如反向传播）来训练高精度 SNN 模型来解决这个问题</strong>。该领域的快速进步不断产生令人惊叹的结果，网络规模不断扩大，其成长路径似乎与深度学习的发展相似。尽管这些方法赋予 SNN 接近 ANN 准确性的能力，但由于使用面向 ANN 的工作负载和简单化的评估指标，SNN 的天然优势和超越 ANN 的方式可能会丢失。</p>
<p>在本文中，我们以<strong>视觉识别任务</strong>作为案例研究，回答“<strong>什么工作负载对于 SNN 来说是理想的以及如何评估 SNN 是否有意义</strong>”的问题。我们使用不同类型的数据集（面向 ANN 和 SNN）、不同的处理模型、信号转换方法和学习算法设计了一系列对比测试。我们提出了关于应用程序准确性和内存计算成本的综合指标来评估这些模型，并进行广泛的实验。我们证明了这样一个事实：<strong>在面向 ANN 的工作负载上，SNN 无法击败其 ANN 同行；而在面向 SNN 的工作负载上，SNN 完全可以表现得更好。我们进一步证明，在 SNN 中，应用程序准确性和执行成本之间存在权衡，这将受到模拟时间窗口和触发阈值的影响。</strong><br />
<Br></p>
<h2 id="1introduction"><a class="markdownIt-Anchor" href="#1introduction"></a> 1.Introduction</h2>
<p>人工神经网络(ANNs)能够通过深度层次从大量输入数据中学习高级特征。例如：</p>
<ul>
<li>MLP/CNN：图像识别，语音识别，语言处理，目标检测，医疗诊断，游戏等</li>
<li>RNN：语音识别，语言处理，状态控制等</li>
<li>CNN x RNNs</li>
<li><strong>大数据资源(如图像识别的ImageNet数据集(Deng et al.， 2009))和高性能计算平台(如GPU)</strong></li>
</ul>
<br>
<p><strong>脉冲神经网络（SNN）密切模仿生物神经回路的行为。它们以连续的时空动态和事件驱动的发射活动（0-无或1-脉冲事件）进行操作</strong>。由于异步脉冲机制，SNN 在基于事件的场景中表现出了优势，也有望解决一些有趣的问题。此外，SNN 广泛部署在用于类脑计算的神经形态设备中。然而，长期以来，<strong>关于 SNN 作为计算工具的实际价值在人工智能和神经形态计算社区中一直存在争论，特别是与 ANN 相比时。这些怀疑减缓了过去几年神经​​形态计算的发展，而神经形态计算又被深度学习的快速进步抢了风头。研究人员试图通过训练算法设计等手段强化 SNN，从根本上缓解这一问题</strong>。</p>
<Br>
<p>SNN 研究的最大<strong>困难</strong>之一：<strong>复杂的动态和不可微的脉冲活动导致的训练难度</strong>。</p>
<p><strong>SNN 在视觉识别任务中正在逐渐接近 ANN 级别的应用精度</strong>：</p>
<ul>
<li><strong>改进传统的脉冲时间依赖可塑性 (STDP) 无监督学习规则</strong>：例如通过添加横向抑制和自适应阈值  或奖励机制。</li>
<li>预训练了<strong>适应的 ANN 并将其转换为 SNN</strong>：ANN 中的适应通常包括消除偏差、使用 ReLU 激活函数（或其变体）、将最大池化更改为平均池化等，以增强与 SNN 模型的兼容性。从 ANN 到 SNN 的转换通常会引入权重/激活归一化、阈值调整、采样误差补偿等，以保持准确性。</li>
<li>借用人工神经网络中的<strong>有监督BP学习来直接训练准确的SNN</strong>：执行 BP 时，梯度可以通过聚合时间维度上的脉冲来仅沿空间方向传播，也可以通过直接计算每个时间步的膜电位和脉冲活动的导数来沿时间和空间维度传播。</li>
<li><strong>BP 和 STDP 学习的结合</strong>：例如在每次训练迭代的 BP 更新后应用 STDP 更新或在 STDP 预训练后应用 BP 微调。</li>
</ul>
<br>
<p><strong>由于缺乏专门的 SNN 基准测试工作负载，大量工作直接从 ANN 领域移植测试工作负载来验证 SNN 模型</strong>。用于 ANN 验证的图像数据集只需转换为用于 SNN 训练和测试的脉冲版本:这似乎是合理的，因为当 SNN 运行时，输入数据被编码为脉冲。然而，ANN 的原始数据集只是静态图像，即使将其转换为脉冲模式，也无法充分利用 SNN 的时空优势。</p>
<p><strong>由于工作负载和评估指标不合适，当前的 SNN 无法击败 ANN</strong></p>
<p>出现了两个悬而未决的问题：</p>
<ul>
<li>“<strong>什么工作负载对于 SNN 来说是理想的</strong></li>
<li><strong>如何评估 SNN 才有意义</strong>”。</li>
</ul>
<br>
<p><strong>所做工作</strong> ：</p>
<ul>
<li>通过使用不同领域的数据集、不同的处理模型、信号转换方法和学习算法设计一系列对比测试，我们比较了 ANN 和 SNN（带有速率编码）的性能。</li>
<li>提出了关于应用程序准确性、内存成本和计算成本的综合指标，以评估这些模型并进行广泛的分析。</li>
<li>证明了一个事实：<strong>在面向 ANN 的工作负载上，在相同网络规模下，SNN 在准确性方面无法击败 ANN，但具有高效处理的潜力；而在面向 SNN 的工作负载上，SNN 完全可以表现得更好</strong></li>
<li>进一步证明:<strong>模拟时间窗口和触发阈值的变化将在应用程序准确性和执行成本之间产生权衡</strong>。</li>
</ul>
<Br>
<p><strong>主要贡献</strong>：</p>
<ul>
<li><strong>考虑应用准确性和执行成本之间的权衡，提出了急需的SNN 和ANN 综合评估指标</strong>。使用不同的基准数据集、处理模型、信号转换和学习算法进行广泛的实验和分析，演示了各种比较方法和可视化手段。</li>
<li>为每个工作负载<strong>推荐最佳模型</strong></li>
<li><strong>直接将工作负载从 ANN 移植到 SNN 是不合适的</strong>，至少是不明智的，尽管许多工作正在这样做。创建更多面向 SNN 的数据集并构建具有<strong>更广泛任务的基准框架对于 SNN 社区来说是紧迫的</strong>。</li>
</ul>
<br>
<p>本文<strong>其余部分的</strong>组织如下：</p>
<ul>
<li>第 2 节介绍了 ANN 和 SNN 的一些预备知识，以及典型的网络拓扑和基准数据集；</li>
<li>第 3 节系统地提出了信号转换方法、测试工作负载、训练算法和评估指标；</li>
<li>第 4 节提供了实验设置、结果分析以及可视化；</li>
<li>最后，第 5 节总结并讨论了本文</li>
</ul>
<br>
<h2 id="2preliminaries"><a class="markdownIt-Anchor" href="#2preliminaries"></a> 2.Preliminaries</h2>
<p>视觉识别的 ANN 和 SNN 的<strong>初步知识</strong>:</p>
<ul>
<li>神经元模型</li>
<li>网络拓扑</li>
<li>基准数据集</li>
</ul>
<br>
<p><strong>神经元是基本的计算单元，由丰富的突触连接形成神经网络</strong>。如果我们将神经网络视为图，则每个神经元和突触可以分别视为节点和边。</p>
<br>
<p>神经网络<strong>分类</strong>：</p>
<ul>
<li>ANN</li>
<li>SNN</li>
</ul>
<br>
<h2 id="21-artificial-neural-networks"><a class="markdownIt-Anchor" href="#21-artificial-neural-networks"></a> 2.1 Artificial neural networks</h2>
<p><img src="https://pbs.twimg.com/media/F764_nYaAAACjk9?format=png&amp;name=small" alt="" /></p>
<p>图(a)描绘了典型的人工神经元的模型。计算过程由：y=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span></span></span></span>(b + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\sum_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">x_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>) <strong>(1)</strong></p>
<ul>
<li>x：输入激活</li>
<li>y：输出激活</li>
<li>w：突触权重</li>
<li>b：偏差</li>
<li>j：输入神经元的索引</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span></span></span></span>：非线性激活函数</li>
</ul>
<p>人工神经网络中的神经元使用以高精度和连续值编码的激活相互通信，并且仅在空间域（即逐层）传播信息。</p>
<br>
<h2 id="22-spiking-neural-networks"><a class="markdownIt-Anchor" href="#22-spiking-neural-networks"></a> 2.2 Spiking neural networks</h2>
<p><img src="https://pbs.twimg.com/media/F765BOSbwAAKfYs?format=png&amp;name=small" alt="" /></p>
<p>(b)展示了一个典型的脉冲神经元，与ANN神经元相比，它具有相似的结构，但行为不同。相比之下，脉冲神经元通过<strong>二进制事件编码的脉冲序列</strong>进行通信，而不是人工神经网络中的连续激活。树突整合输入脉冲，<strong>soma</strong>进而进行非线性变换，产生输出脉冲序列。</p>
<p>行为通常由流行的 <strong>LIF 模型</strong>建模，描述为:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>d</mi><mi>u</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{du(t)}{dt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">u</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> = - [u(t) - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>r</mi><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">u_{r1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>] + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\sum_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\omega_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mrow><msubsup><mi>t</mi><mi>j</mi><mi>k</mi></msubsup><mo>∈</mo><msubsup><mi>S</mi><mi>j</mi><msub><mi>T</mi><mi>w</mi></msub></msubsup></mrow></msub></mrow><annotation encoding="application/x-tex">\sum_{t_{j}^{k} \in S_j^{T_w}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.411045em;vertical-align:-0.661045em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3447999999999999em;"><span style="top:-2.361775em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8408285714285714em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.97575em;"><span style="top:-2.177714285714286em;margin-left:-0.05764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-2.987657142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:-0.13889em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.661045em;"><span></span></span></span></span></span></span></span></span></span>K(t - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mi>j</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">t_j^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>)  <strong>(2)</strong></p>
<p>s(t)=1 &amp; u(t)=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>r</mi><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">u_{r2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> , if u(t) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">\geq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">u_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>s(t)=0 , if u(t) &lt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">u_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>(t):时间步长</li>
<li>τ:时间常数</li>
<li>u:膜电位</li>
<li>s:输出脉冲</li>
<li>ur1：静息电位</li>
<li>ur2：复位电位</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>: 第 j 个输入神经元的突触权重</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mi>j</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">t^k_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>:第 j 个输入神经元的第 k 个脉冲在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">T_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的积分时间窗口内激发的时间（总共 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>S</mi><mi>j</mi><mrow><mi>T</mi><mi>w</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">S^{Tw}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>脉冲序列）</li>
<li>K():描述时间衰减效应的核函数</li>
<li>u:决定是否发射脉冲的发射阈值</li>
</ul>
<br>
<p>SNN 通常可以实现<strong>更低的功耗</strong>：</p>
<ul>
<li>与 ANN 不同，<strong>SNN 以脉冲模式表示信息</strong>，每个脉冲神经元都会经历丰富的动态行为</li>
<li>具体来说，除了<strong>空间域</strong>中的信息传播之外，当前状态还受到<strong>时间域</strong>中过去历史的紧密影响</li>
<li>与<strong>主要通过空间传播和连续激活的 ANN 相比，SNN 通常具有更多的时间多功能性，但精度较低</strong>。</li>
<li><strong>脉冲仅在膜电位超过阈值时触发</strong>，因此整个脉冲信号通常是<strong>稀疏</strong>的，并且计算可以是事件驱动的（仅在脉冲输入到达时启用）。</li>
<li>脉冲是<strong>二进制</strong>的，即 0 或 1</li>
</ul>
<br>
<h2 id="23-typical-network-topologies"><a class="markdownIt-Anchor" href="#23-typical-network-topologies"></a> 2.3 Typical network topologies</h2>
<p><img src="https://pbs.twimg.com/media/F77HNRjbIAAMsJI?format=png&amp;name=900x900" alt="" /></p>
<p>构建神经网络的基本层拓扑</p>
<ul>
<li>全连接（FC）层:<strong>多层感知器（MLP）</strong></li>
<li>循环层:<strong>RNN</strong></li>
<li>卷积（Conv）层（以及池化层）:<strong>CNN</strong></li>
</ul>
<p>MLP 和 RNN 仅包含堆叠的 FC 层，每层中带有或不带有循环连接，分别如图 2(a) 和 (b) 所示。对于图 2（c）所示的 CNN，它们直接针对 2D 特征的处理，而不是 MLP 和 RNN 中的 1D 特征。</p>
<p>卷积 (Conv) 层中的每个神经元仅接收来自上一层中所有特征图 (FM) 的局部感受野 (RF) 的输入。每个神经元的基本计算与式（1）或（2）相同。此外，CNN还使用池化层通过输出每个RF的最大值（即最大池化）或平均值（即平均池化）来单独对每个FM的大小进行下采样，并使用FC层进行最终分类。</p>
<br>
<h2 id="24-benchmark-datasets"><a class="markdownIt-Anchor" href="#24-benchmark-datasets"></a> 2.4 Benchmark datasets</h2>
<p><img src="https://pbs.twimg.com/media/F77Ip2bb0AArpRt?format=png&amp;name=900x900" alt="" /></p>
<p>图3展示了我们用于视觉识别的两种不同类型的基准数据集:</p>
<ul>
<li><strong>MNIST和CIFAR10</strong>:基于帧的静态图像，并被广泛用于人工神经网络，我们称它们为面向人工神经网络的数据集</li>
<li><strong>N-MNIST和dvs-cifar10</strong>:数据格式是spike事件，通过使用动态视觉传感器(DVS)扫描每个图像从上述静态数据集转换而来。除了与面向神经网络的数据集相似的空间信息外，它还包含更多的动态时间信息，并且脉冲事件与snn中的信号格式自然兼容，因此称为面向snn的数据集。</li>
</ul>
<Br>
<p><strong>MNIST</strong>:</p>
<ul>
<li>60,000 个标记手写数字的<strong>训练集</strong></li>
<li>10,000 个标记数字的<strong>测试集</strong></li>
<li>每个数字样本都是一个 28 × 28 的灰度图像。</li>
</ul>
<br>
<p><strong>CIFAR10</strong>：</p>
<ul>
<li>训练集：包含 50,000 张带标签的训练图像以及环境中的自然和人造物体</li>
<li>其他 10,000 个测试图像</li>
<li>每个样本都是 32 × 32 × 3 RGB 图像</li>
</ul>
<br>
<p><strong>DVS</strong>:</p>
<ul>
<li>9000张图像用于训练</li>
<li>1000张用于测试</li>
<li>可以沿着给定的方向扫描原始静态图像，并收集由每个像素的强度变化触发的脉冲序列。</li>
<li>由于它有两种改变方式(增加或减少)，DVS产生两个脉冲事件通道，分别称为On和Off事件(图3中的红色和蓝色)</li>
<li>将每个图像转换为行×深× 2 × T的脉冲模式，其中T是记录时间长度</li>
<li>从原始CIFAR10数据集转换10 000幅图像，其中每个类有1000个脉冲模式，大小为128 × 128 × 2 × T</li>
</ul>
<br>
<p><strong>N-MNIST</strong>:</p>
<ul>
<li><strong>将原始MNIST转换为spike版本</strong>。</li>
<li>60,000个训练样本</li>
<li>10,000个测试样本</li>
<li>每个样本都是一个大小为34 × 34 × 2 × T的时空脉冲模式</li>
</ul>
<br>
<h2 id="3benchmarking-methodology"><a class="markdownIt-Anchor" href="#3benchmarking-methodology"></a> 3.Benchmarking methodology</h2>
<ul>
<li>ANN和SNN域之间的信号转换</li>
<li>设计了六个基准模型以及用于对比测试的训练算法</li>
<li>提出了三个评估指标以供后续模型评估和比较</li>
</ul>
<br>
<h2 id="31-data-signal-conversion"><a class="markdownIt-Anchor" href="#31-data-signal-conversion"></a> 3.1 Data signal conversion</h2>
<p>ANN 接收实际值的基于帧的图像，而 SNN 接收事件驱动的脉冲信号。因此，有时需要将相同的数据资源转换成不同的形式以便在另一个域中进行处理。这里我们以视觉识别任务为例，主要介绍如下四种信号转换方法。</p>
<br>
<h2 id="311-image-to-spike-pattern"><a class="markdownIt-Anchor" href="#311-image-to-spike-pattern"></a> 3.1.1 Image to spike pattern</h2>
<p><img src="https://pbs.twimg.com/media/F79sUbjbQAA6-G7?format=png&amp;name=small" alt="" /></p>
<p><strong>图像到脉冲模式</strong>：由于像素强度的实值信号不适合基于脉冲的 SNN，因此在面向 ANN 的数据集上测试 SNN 模型时需要转换为脉冲序列。普遍的策略之一是<strong>概率抽样</strong>。在每个时间步长，它<strong>将原始像素强度（通常标准化为 [0, 1]）采样为二进制值</strong>，其中 1（发射脉冲）的概率等于强度值。采样遵循特定的概率分布，例如伯努利分布或泊松分布。例如，图 4(a) 中的 i1 神经元对应于归一化强度为 0.8 的左上角像素，产生一个二进制脉冲序列，遵循伯努利分布 B(0.8,T)，这里T是给定的采样时间窗口。</p>
<br>
<p><img src="https://pbs.twimg.com/media/F79sWVZaMAA2fcK?format=png&amp;name=small" alt="" /></p>
<p>在短时间窗的情况下，上述元素采样通常会遭受精度损失(参见第4.2节)。为了规避这个问题，modern works (Esser等人，2016)添加了一个编码层来全局产生脉冲信号，如图4(b)所示。该层中的<strong>每个神经元接收多个像素的强度值作为输入</strong>(即树突以正常输入权重MAC操作的ANN模式工作)，同时产生脉冲作为输出(即soma以LIF动力学的SNN模式工作)。尽管编码层是ANN-SNN混合层，而不是像网络中的后续层那样的完整SNN层，但其权重是可训练的，因为本文对SNN的训练方法对ANNs也是bp兼容的(见第3.4节)。由于神经元数量可灵活定制，且参数可训练，因此可以适应全局优化问题，获得更好的精度</p>
<br>
<h2 id="312-spike-pattern-to-image"><a class="markdownIt-Anchor" href="#312-spike-pattern-to-image"></a> 3.1.2 Spike pattern to image</h2>
<p><strong>脉冲模式到图像</strong>：为了在面向 SNN 的数据集上测试 ANN 模型，我们需要将脉冲模式转换为基于帧的图像。</p>
<p>存在两种可能的输出格式：</p>
<ul>
<li>(i)具有 0/1 像素的二值图像；</li>
<li>(ii) 具有实值像素的强度图像。</li>
</ul>
<br>
<p><img src="https://pbs.twimg.com/media/F79sXL3akAAbd4m?format=png&amp;name=small" alt="" /></p>
<br>
<p>将<strong>脉冲模式转换为二值图像</strong>的直观策略是首先沿着时间维度从所有神经元位置扩展脉冲序列。然后，如图4（c）所示，扩展的2D脉冲模式（位置索引与时间）可以直接视为二值图像（每个脉冲事件代表像素强度为1，否则像素强度为0）。原始记录时间长度T通常较长，这可能会导致图像尺寸过大。因此，沿时间方向的尖峰事件需要以适度的滑动时间窗口（例如每 1 ms）定期聚合或采样。这里，聚合意味着如果窗口中存在脉冲，则所得尖峰事件为 1，否则为 0。即使如此，2D 位置（图 4© 中的左侧）也将展开为 1D 位置向量（图4©）右侧的Y轴也产生大图像尺寸</p>
<br>
<p><img src="https://pbs.twimg.com/media/F79sYAXbYAAR8tS?format=png&amp;name=small" alt="" /></p>
<p>为了<strong>转换成强度图像</strong>，需要脉冲事件的时间累积（计算脉冲数量）。图4（d）描绘了100毫秒内脉冲序列的累积过程。累积的尖峰数将被标准化为具有适当强度值的像素。由于 DVS 的相对运动和固有噪声，所得图像常常模糊且边缘特征模糊。这种转换只有在强有力的假设下才允许，即每个脉冲位置不应随着 t 的演变而移开其起始位置，否则将严重损害所得图像的质量。</p>
<Br>
<h2 id="32-ann-oriented-workloads"><a class="markdownIt-Anchor" href="#32-ann-oriented-workloads"></a> 3.2 ANN-oriented workloads</h2>
<p><strong>目标</strong>:识别基于<strong>帧的数据集</strong>（例如 MNIST 和 CIFAR10）中的图像</p>
<p>为了处理此类工作负载，我们引入了三个基准模型:</p>
<ul>
<li>Model-1: <strong>具有 ANN 训练和 ANN 推理的自然 ANN</strong></li>
<li>Model-2: <strong>经过 ANN 训练和 SNN 推理转换后的 SNN</strong></li>
<li>Model-3: <strong>通过 SNN 训练和 SNN 推理强制执行 SNN</strong></li>
</ul>
<br>
<h2 id="321-model-1-natural-ann-with-ann-training-and-ann-inference"><a class="markdownIt-Anchor" href="#321-model-1-natural-ann-with-ann-training-and-ann-inference"></a> 3.2.1 Model-1: natural ANN with ANN training and ANN inference</h2>
<p><img src="https://pbs.twimg.com/media/F79107jbkAAD-gn?format=png&amp;name=360x360" alt="" /></p>
<p>如 <strong>5(a)</strong> 所示，<strong>具有“ANN 训练 ANN 推理”的自然 ANN</strong>: 使用强度图像以 ANN 模式(参考式1)充分训练网络，然后在同一域中进行后续推理。训练遵循ANN领域最广泛使用的BP算法。</p>
<br>
<h2 id="322-model-2-converted-snn-with-ann-training-and-snn-inference"><a class="markdownIt-Anchor" href="#322-model-2-converted-snn-with-ann-training-and-snn-inference"></a> 3.2.2 Model-2: converted SNN with ANN training and SNN inference</h2>
<p><img src="https://pbs.twimg.com/media/F79112QbQAAauUO?format=png&amp;name=small" alt="" /></p>
<p>此外，SNN 社区的许多工作也使用这些数据集来测试 SNN 的性能。由于在这些情况下网络工作在 SNN 模式下，因此输入数据需要从基于帧的图像转换为脉冲事件，如图 4(a) 或 (b) 所示。信号转换后，我们进一步提供两个建模分支。</p>
<p>如图 5（b）所示，<strong>首先使用 BP 算法在原始图像数据集上训练 ANN，然后将预训练的 ANN 适应具有相同结构但不同神经元模型的 SNN 对应部分。此转换后的 SNN 在推理阶段接收具有脉冲事件的数据集变体。</strong></p>
<br>
<h2 id="323-model-3-enforced-snn-with-snn-training-and-snn-inference"><a class="markdownIt-Anchor" href="#323-model-3-enforced-snn-with-snn-training-and-snn-inference"></a> 3.2.3 Model-3: enforced SNN with SNN training and SNN inference.</h2>
<p><img src="https://pbs.twimg.com/media/F79120taQAA9VNR?format=png&amp;name=small" alt="" /></p>
<p>如图 5© 所示的<strong>强制 SNN</strong>，其中 <strong>SNN 模型直接在转换后的脉冲数据集上从头开始训练，并在同一域中进行测试</strong>。考虑到Pytorch的开源性，我们选择STBP作为snn的直接训练模型。</p>
<Br>
<h2 id="33-snn-oriented-workloads"><a class="markdownIt-Anchor" href="#33-snn-oriented-workloads"></a> 3.3 SNN-oriented workloads</h2>
<p><strong>目标</strong>:识别无帧脉冲数据集中的图像（例如N-MNIST和DVS-CIFAR10）</p>
<br>
<p>三个基准模型:</p>
<ul>
<li>Model-4：<strong>使用转换后的二进制或强度图像的强制二元 ANN</strong></li>
<li>Model-5: <strong>强制强度 ANN，用于 ANN 训练和 ANN 推理</strong></li>
<li>Model-6: <strong>具有 SNN 训练和 SNN 推理的自然 SNN</strong></li>
</ul>
<Br>
<h2 id="331-model-4-or-model5-enforced-binary-ann-or-enforced-intensity-ann-using-converted-binary-or-intensity-images-respectively-for-ann-training-and-ann-inference"><a class="markdownIt-Anchor" href="#331-model-4-or-model5-enforced-binary-ann-or-enforced-intensity-ann-using-converted-binary-or-intensity-images-respectively-for-ann-training-and-ann-inference"></a> 3.3.1 Model-4 or Model5: enforced binary ANN or enforced intensity ANN using converted binary or intensity images, respectively, for ANN training and ANN inference</h2>
<p><img src="https://pbs.twimg.com/media/F796zcSaEAAnVwQ?format=png&amp;name=small" alt="" /></p>
<p>前两个工作在 <strong>ANN 模式</strong>下（见图 6（a）），其中<strong>输入数据被转换为图像</strong>。这些模型<strong>使用 ANN 的常规 BP 算法进行训练，并在 ANN 领域进行测试</strong>。</p>
<br>
<p>从<strong>脉冲事件到图像的数据转换</strong>有两种方法，分别如图 4© 和 (d) 所示：</p>
<ul>
<li>(i) 直接接收展开的脉冲模式的二值图像；</li>
<li>(ii) 通过沿时间维度压缩脉冲模式来获得强度图像</li>
</ul>
<br>
<h2 id="332-model-6l-natural-snn-with-snn-training-and-snn-inference"><a class="markdownIt-Anchor" href="#332-model-6l-natural-snn-with-snn-training-and-snn-inference"></a> 3.3.2 Model-6L: natural SNN with SNN training and SNN inference</h2>
<p><img src="https://pbs.twimg.com/media/F7960SpbIAAjaHj?format=png&amp;name=360x360" alt="" /></p>
<p>图6(b)给出了另一个在<strong>自然 SNN 模式</strong>下工作的基准模型。该网络直接<strong>使用原始脉冲数据集进行训练和测试，学习算法仍然是如上面 Model-3 中的 BP 启发</strong>。</p>
<br>
<h2 id="34-training-algorithms"><a class="markdownIt-Anchor" href="#34-training-algorithms"></a> 3.4 Training algorithms</h2>

            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2023/10/07/paper-Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" data-id="clng47s3g00003k699v2abj5p" data-title="paper:Rethinking the performance comparison between SNNS and ANNS"
               class="article-share-link">分享</a>
            
            
            
            
    <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Artificial-neural-networks/" rel="tag">Artificial neural networks</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Benchmark/" rel="tag">Benchmark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-learning/" rel="tag">Deep learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Neuromorphic-computing/" rel="tag">Neuromorphic computing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spiking-neural-networks/" rel="tag">Spiking neural networks</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/intern00/" rel="tag">intern00</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paper/" rel="tag">paper</a></li></ul>


        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://singyesterday.com/cmn/images/gallery/l/pic_200325_22.jpg" data-sizes="auto" alt="SNN"
                         class="lazyload">
                
                <a href="/2023/10/07/SNN/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        SNN
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="野中晴" class="lazyload">
            <div class="sidebar-author-name">野中晴</div>
            <div class="sidebar-description">Love is selfish.</div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">132</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">8</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">163</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/">Essay</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/reading/">reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/0/" style="font-size: 10px;">0</a> <a href="/tags/3-1/" style="font-size: 10px;">3-1</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/AI-Ethics/" style="font-size: 10px;">AI Ethics</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/Artificial-neural-networks/" style="font-size: 10px;">Artificial neural networks</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/CAS/" style="font-size: 10px;">CAS</a> <a href="/tags/CAS%E5%AE%9E%E4%B9%A0offer/" style="font-size: 10px;">CAS实习offer</a> <a href="/tags/CMU15-445/" style="font-size: 10px;">CMU15-445</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 14.55px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/Cover-Letter/" style="font-size: 10px;">Cover Letter</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 10.91px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Essay/" style="font-size: 20px;">Essay</a> <a href="/tags/GEAR-5/" style="font-size: 10px;">GEAR-5</a> <a href="/tags/Git/" style="font-size: 10.91px;">Git</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoAbroad/" style="font-size: 16.36px;">GoAbroad</a> <a href="/tags/Gumayusi/" style="font-size: 10px;">Gumayusi</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/IC/" style="font-size: 10px;">IC</a> <a href="/tags/IELTS/" style="font-size: 11.82px;">IELTS</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 10px;">IntelliJ IDEA</a> <a href="/tags/Jianfei-Chen/" style="font-size: 10px;">Jianfei Chen</a> <a href="/tags/Lec01/" style="font-size: 11.82px;">Lec01</a> <a href="/tags/Lec01s/" style="font-size: 10.91px;">Lec01s</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/MIT6-S081/" style="font-size: 13.64px;">MIT6.S081</a> <a href="/tags/MS-ResNet/" style="font-size: 10px;">MS-ResNet</a> <a href="/tags/Missing-Semester/" style="font-size: 10px;">Missing Semester</a> <a href="/tags/NNDL/" style="font-size: 10px;">NNDL</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/Neuromorphic-computing/" style="font-size: 10px;">Neuromorphic computing</a> <a href="/tags/Qingyao-Ai/" style="font-size: 10.91px;">Qingyao Ai</a> <a href="/tags/RISC-V/" style="font-size: 10px;">RISC-V</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/SE/" style="font-size: 13.64px;">SE</a> <a href="/tags/SE-3-0/" style="font-size: 10px;">SE-3.0</a> <a href="/tags/SNN/" style="font-size: 10.91px;">SNN</a> <a href="/tags/SNN-vs-RNN/" style="font-size: 10px;">SNN vs RNN</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/Spiking-neural-networks/" style="font-size: 10px;">Spiking neural networks</a> <a href="/tags/StarBucks/" style="font-size: 12.73px;">StarBucks</a> <a href="/tags/T1/" style="font-size: 13.64px;">T1</a> <a href="/tags/THU/" style="font-size: 10px;">THU</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/University/" style="font-size: 14.55px;">University</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 10.91px;">Yuxiao Dong</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/bing/" style="font-size: 10px;">bing</a> <a href="/tags/bug/" style="font-size: 10px;">bug</a> <a href="/tags/causal-churn-word/" style="font-size: 10px;">causal churn word</a> <a href="/tags/chapter00/" style="font-size: 10px;">chapter00</a> <a href="/tags/chapter01/" style="font-size: 10px;">chapter01</a> <a href="/tags/chapter02/" style="font-size: 10px;">chapter02</a> <a href="/tags/chapter03/" style="font-size: 10px;">chapter03</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/coding/" style="font-size: 17.27px;">coding</a> <a href="/tags/cold%F0%9F%98%B7/" style="font-size: 10px;">cold😷</a> <a href="/tags/dalle3/" style="font-size: 10px;">dalle3</a> <a href="/tags/database/" style="font-size: 12.73px;">database</a> <a href="/tags/debug/" style="font-size: 11.82px;">debug</a> <a href="/tags/discussion/" style="font-size: 10px;">discussion</a> <a href="/tags/dowhy/" style="font-size: 10.91px;">dowhy</a> <a href="/tags/echo/" style="font-size: 10px;">echo</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/explainer/" style="font-size: 10.91px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/game/" style="font-size: 10px;">game</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gym/" style="font-size: 11.82px;">gym</a> <a href="/tags/hacker/" style="font-size: 10px;">hacker</a> <a href="/tags/handout/" style="font-size: 10px;">handout</a> <a href="/tags/happy/" style="font-size: 10px;">happy</a> <a href="/tags/homework/" style="font-size: 10px;">homework</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/instructor/" style="font-size: 12.73px;">instructor</a> <a href="/tags/intern-00/" style="font-size: 10px;">intern-00</a> <a href="/tags/intern00/" style="font-size: 10px;">intern00</a> <a href="/tags/internship/" style="font-size: 15.45px;">internship</a> <a href="/tags/introduction/" style="font-size: 11.82px;">introduction</a> <a href="/tags/kfc/" style="font-size: 10px;">kfc</a> <a href="/tags/l1/" style="font-size: 10px;">l1</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/m/" style="font-size: 10px;">m</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/one-piece/" style="font-size: 10px;">one piece</a> <a href="/tags/openai/" style="font-size: 10px;">openai</a> <a href="/tags/os/" style="font-size: 13.64px;">os</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/paper/" style="font-size: 19.09px;">paper</a> <a href="/tags/pku/" style="font-size: 10px;">pku</a> <a href="/tags/preparation/" style="font-size: 10px;">preparation</a> <a href="/tags/prml/" style="font-size: 12.73px;">prml</a> <a href="/tags/pytorch/" style="font-size: 10px;">pytorch</a> <a href="/tags/qemu/" style="font-size: 10px;">qemu</a> <a href="/tags/reading/" style="font-size: 10px;">reading</a> <a href="/tags/redemption/" style="font-size: 10px;">redemption</a> <a href="/tags/research-vs-coursework/" style="font-size: 10px;">research vs coursework</a> <a href="/tags/shap/" style="font-size: 11.82px;">shap</a> <a href="/tags/shell-vs-terminal/" style="font-size: 10px;">shell vs terminal</a> <a href="/tags/starbucks/" style="font-size: 10px;">starbucks</a> <a href="/tags/tensor-vs-ndarray/" style="font-size: 10px;">tensor vs ndarray</a> <a href="/tags/third-place/" style="font-size: 10px;">third place</a> <a href="/tags/tips/" style="font-size: 10px;">tips</a> <a href="/tags/tool/" style="font-size: 13.64px;">tool</a> <a href="/tags/wbg%E8%AF%AD%E9%9F%B3-uzi/" style="font-size: 10px;">wbg语音-uzi</a> <a href="/tags/word/" style="font-size: 10px;">word</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/xv6/" style="font-size: 10px;">xv6</a> <a href="/tags/youth/" style="font-size: 10px;">youth</a> <a href="/tags/zeus/" style="font-size: 10px;">zeus</a> <a href="/tags/%E4%B8%83%E5%A4%95/" style="font-size: 10px;">七夕</a> <a href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" style="font-size: 18.18px;">专业知识</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E4%B8%AD%E7%A7%91%E9%99%A2/" style="font-size: 10px;">中科院</a> <a href="/tags/%E5%86%8D%E4%B9%9F%E4%B8%8D%E7%94%A8%E8%A2%AB%E7%BA%A6%E5%AE%9A%E6%9D%9F%E7%BC%9A%E4%BA%86/" style="font-size: 10px;">再也不用被约定束缚了</a> <a href="/tags/%E5%86%8D%E8%A7%81%E7%BB%98%E6%A2%A8/" style="font-size: 10px;">再见绘梨</a> <a href="/tags/%E5%86%99%E4%BD%9C%E5%BF%83%E5%BE%97/" style="font-size: 10px;">写作心得</a> <a href="/tags/%E5%8D%9A%E4%BA%BA%E4%BC%A0/" style="font-size: 10px;">博人传</a> <a href="/tags/%E5%8F%AA%E8%A6%81%E6%9C%89%E7%9C%9F%E5%BF%83%E5%96%9C%E6%AC%A2%E7%9A%84%E4%B8%9C%E8%A5%BF-%E5%B0%B1%E8%83%BD%E5%8F%91%E5%87%BA%E5%85%89%E6%9D%A5/" style="font-size: 10px;">只要有真心喜欢的东西,就能发出光来</a> <a href="/tags/%E5%93%88%E5%B8%8C%E5%80%BC/" style="font-size: 10px;">哈希值</a> <a href="/tags/%E5%9C%A3%E5%A2%83/" style="font-size: 10px;">圣境</a> <a href="/tags/%E5%A4%A7%E4%B8%89%E4%B8%8A/" style="font-size: 10px;">大三上</a> <a href="/tags/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/" style="font-size: 10.91px;">审稿意见</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%83%85%E7%BB%AA%E7%9A%84%E7%A7%98%E5%AF%86/" style="font-size: 10px;">情绪的秘密</a> <a href="/tags/%E6%84%9F%E5%86%92/" style="font-size: 10px;">感冒</a> <a href="/tags/%E6%84%9F%E5%86%92%E7%97%8A%E6%84%88/" style="font-size: 10px;">感冒痊愈</a> <a href="/tags/%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84/" style="font-size: 10px;">拓扑结构</a> <a href="/tags/%E6%8F%90%E9%97%AE/" style="font-size: 10px;">提问</a> <a href="/tags/%E6%90%AC%E5%AE%B6/" style="font-size: 10px;">搬家</a> <a href="/tags/%E6%94%BE%E4%B8%8B/" style="font-size: 10px;">放下</a> <a href="/tags/%E6%95%99%E5%B8%88%E8%8A%82/" style="font-size: 10px;">教师节</a> <a href="/tags/%E6%9C%80%E9%95%BF%E7%9A%84%E7%94%B5%E5%BD%B1/" style="font-size: 10.91px;">最长的电影</a> <a href="/tags/%E6%A6%82%E8%AE%BA/" style="font-size: 10px;">概论</a> <a href="/tags/%E6%AF%9B%E6%A6%82/" style="font-size: 14.55px;">毛概</a> <a href="/tags/%E6%B2%88%E6%9C%88/" style="font-size: 10px;">沈月</a> <a href="/tags/%E6%B2%A1%E9%82%A3%E4%B9%88%E7%AE%80%E5%8D%95/" style="font-size: 10px;">没那么简单</a> <a href="/tags/%E7%81%AB%E9%BE%99%E5%A4%A7%E7%82%AC/" style="font-size: 10px;">火龙大炬</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">环境搭建</a> <a href="/tags/%E7%9F%A5%E8%A1%8C%E5%90%88%E4%B8%80/" style="font-size: 10px;">知行合一</a> <a href="/tags/%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%BB%BA%E8%AE%AE%E4%B9%A6/" style="font-size: 10px;">系统开发建议书</a> <a href="/tags/%E8%8E%93/" style="font-size: 10px;">莓</a> <a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" style="font-size: 10px;">虚拟机</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E8%A1%A8/" style="font-size: 10px;">课程表</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 10px;">调研</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">软件生命周期模型</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a> <a href="/tags/%F0%9F%93%A6/" style="font-size: 10px;">📦</a> <a href="/tags/%F0%9F%9B%80/" style="font-size: 10px;">🛀</a>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2023
                <span class="footer-info-sep"></span>
                野中晴
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    227.3k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    14:07
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="野中晴" class="lazyload">
            <div class="sidebar-author-name">野中晴</div>
            <div class="sidebar-description">Love is selfish.</div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">132</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">8</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">163</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

