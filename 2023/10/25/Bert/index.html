<!DOCTYPE html>

<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <!--
        hexo-theme-suka © SukkaW
        GitHub: https://github.com/SukkaW/hexo-theme-suka
    -->

    <!-- ### Resource Hint ### -->

    <!-- ## DNS Prefetch ## -->
    <meta http-equiv="x-dns-prefetch-control" content="on">

<!-- busuanzi -->

    <link rel="dns-prefetch" href="//busuanzi.ibruce.info">


<!-- comment -->







<!-- analytics -->







    <!-- ## Preload ## -->
    
    <!-- Busuanzi -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" as="script">







    <!-- ### Meta & Title & Info ### -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <meta name="renderer" content="webkit">

    <!-- Title -->
    <title>ML:Bert | blog</title>

    <!-- Favicons -->
    <link rel="icon" type="image&#x2F;ico" href="/img/bot.ico">

    <!-- ### Import File ### -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spectre.css@0.5.3"><style>
    body {
        background-color: #f8f9fa;
    }

    a, a:visited {
        color: #0070ff;
    }

    a:active, a:focus, a:hover {
        color: #0070ff;
        opacity: .75;
    }

    #post-content a,
    #post-content a:hover,
    #post-content a:focus,
    #post-content a:visited {
        color: #005eb9;
        opacity: 1;
    }

    

    .post-entry .card-body a {
        color: #0070ff;
    }

    .avatar {
        background: #444;
    }

    .navbar-link,
    .navbar-link:visited,
    .timeline .timeline-item .timeline-icon.icon-lg {
        color: #0070ff;
    }

    .navbar-link:hover {
        color: #0070ff;
        opacity: .8;
    }

    #search-input .btn,
    #disqus_click_btn,
    #disqus-switch-to-direct,
    #disqus-loadmore-button {
        background: #727e96;
        border-color: #727e96;
        color: #fff;
    }

    #post-toc a.post-toc-link,
    #post-toc a.post-toc-link:visited,
    .share-menu.menu .menu-item>a {
        color: #727e96;
    }

    .share-menu.menu .menu-item>a:hover,
    .share-menu.menu .menu-item>a:focus,
    .share-menu.menu .menu-item>a:visited {
        color: #50596c;
        background: #f8f9fa;
        opacity: .85;
    }
</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.4.0/source/css/style.min.css">








    <!-- Prettify Theme -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.4.0/source/css/highlight/[theme-name].min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.4.0/source/css/highlight/[theme-name].min.css"></noscript>





<script>
/*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
!function(t){"use strict";t.loadCSS||(t.loadCSS=function(){});var e=loadCSS.relpreload={};if(e.support=function(){var e;try{e=t.document.createElement("link").relList.supports("preload")}catch(t){e=!1}return function(){return e}}(),e.bindMediaToggle=function(t){var e=t.media||"all";function a(){t.addEventListener?t.removeEventListener("load",a):t.attachEvent&&t.detachEvent("onload",a),t.setAttribute("onload",null),t.media=e}t.addEventListener?t.addEventListener("load",a):t.attachEvent&&t.attachEvent("onload",a),setTimeout(function(){t.rel="stylesheet",t.media="only x"}),setTimeout(a,3e3)},e.poly=function(){if(!e.support())for(var a=t.document.getElementsByTagName("link"),n=0;n<a.length;n++){var o=a[n];"preload"!==o.rel||"style"!==o.getAttribute("as")||o.getAttribute("data-loadcss")||(o.setAttribute("data-loadcss",!0),e.bindMediaToggle(o))}},!e.support()){e.poly();var a=t.setInterval(e.poly,500);t.addEventListener?t.addEventListener("load",function(){e.poly(),t.clearInterval(a)}):t.attachEvent&&t.attachEvent("onload",function(){e.poly(),t.clearInterval(a)})}"undefined"!=typeof exports?exports.loadCSS=loadCSS:t.loadCSS=loadCSS}("undefined"!=typeof global?global:this);
</script>

    <!-- ### Site Verification ### -->
    


    <meta name="mobile-web-app-capable" content="yes"><meta name="application-name" content="blog"><meta name="msapplication-starturl" content="https://abinzzz.github.io"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><link rel="search" type="application/opensearchdescription+xml" href="opensearch.xml" title="blog">

    <!-- ### The Open Graph & Twitter Card Protocol ### -->
    <meta property="og:title" content="ML:Bert | blog"><meta property="og:site_name" content="blog"><meta property="og:type" content="article"><meta property="og:url" content="https://abinzzz.github.io/2023/10/25/Bert/"><meta property="og:locale" content="zh-CN"><meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&amp;apos;$&amp;apos;, &amp;apos;$&amp;apos;]]}, messageStyle: &quot;none&quot; });   参考链接： 🔗：李宏毅-ELMO, BERT, GPT讲解   一.Review  1.1 1-of-N Encoding 最早采用的方法，显然一个词用一个向量表示不合理 apple&#x3D;[1 0 0 0 0] bag&#x3D;[0 1 0 - ab - blog"><meta name="keywords" content="专业知识, ML, bert, 李宏毅"><meta property="og:image" content="https://pbs.twimg.com/media/F9QBk3BbAAAbtmX?format=png&amp;name=small"><meta property="og:image" content="https://pbs.twimg.com/media/F9QB7xQbAAAizwg?format=png&amp;name=small"><meta property="og:image" content="https://pbs.twimg.com/media/F9QX_OoacAA0dP4?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QYYFvaYAAoswZ?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QYaCJbQAACqFg?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QYcYXagAAKXeD?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QaYRAacAA5Z6k?format=jpg&amp;name=medium"><meta property="og:image" content="https://img-blog.csdnimg.cn/2021031611423652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODk3ODAw,size_16,color_FFFFFF,t_70#pic_center"><meta property="og:image" content="https://pbs.twimg.com/media/F9QaciNbQAAbgkM?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QammOasAA9R7V?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QapUPakAElWOT?format=jpg&amp;name=medium"><meta property="og:image" content="https://img-blog.csdnimg.cn/20210316115419587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODk3ODAw,size_16,color_FFFFFF,t_70#pic_center"><meta property="og:image" content="https://pbs.twimg.com/media/F9Qa8g6bQAEVlm5?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QbE1DacAA83hV?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QbCZ2akAAr9Q-?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QbJk2aIAAflVu?format=jpg&amp;name=medium"><meta property="og:image" content="https://pbs.twimg.com/media/F9QbOHcagAAcOuk?format=jpg&amp;name=medium"><meta property="article:published_time" content="2023-10-25T01:58:26.000Z"><meta property="article:modified_time" content="2023-11-23T14:43:09.839Z"><meta property="og:updated_time" content="2023-11-23T14:43:09.839Z"><meta property="article:author" content="ab"><meta property="article:tag" content="专业知识, ML, bert, 李宏毅"><meta name="twitter:card" content="summary">

    

    <!-- ### Canonical link ### -->
    <link rel="canonical" href="https://abinzzz.github.io/2023/10/25/Bert/">

    <meta name="generator" content="Hexo 5.4.2">

    <!-- ### Analytics ### -->
    







    <!-- ### Structured Data ### -->
    



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "https://abinzzz.github.io/2023/10/25/Bert/",
    "@type": "BlogPosting",
    "logo": "https://abinzzz.github.io/img/bot.ico",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://abinzzz.github.io/2023/10/25/Bert/"
    },
    "headline": "ML:Bert | blog",
    
    "image": {
        "@type": "ImageObject",
        "url": "https://abinzzz.github.io/img/bot.ico"
    },
    
    "datePublished": "2023-10-25T01:58:26.000Z",
    "dateModified": "2023-11-23T14:43:09.839Z",
    "author": {
        "@type": "Person",
        "name": "ab",
        "image": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/default_avatar.png"
        },
        "description": "Hi, nice to meet you."
    },
    "publisher": {
        "@type": "Organization",
        "name": "blog",
        "logo": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/bot.ico"
        }
    },
    
    "potentialAction": {
        "@type": "SearchAction",
        "target": "https://abinzzz.github.io/search?s={search_term_string}",
        "query-input": "required name=search_term_string"
    },
    
    "keywords": "专业知识, ML, bert, 李宏毅",
    "description": "MathJax.Hub.Config({ tex2jax: {inlineMath: [[&amp;apos;$&amp;apos;, &amp;apos;$&amp;apos;]]}, messageStyle: &amp;quot;none&amp;quot; });   参考链接： 🔗：李宏毅-ELMO, BERT, GPT讲解   一.Review  1.1 1-of-N Encoding 最早采用的方法，显然一个词用一个向量表示不合理 apple=[1 0 0 0 0] bag=[0 1 0 - ab - blog"
}
</script>



    <!-- ### Custom Head ### -->
    
</head>

    <body>
            

            <!-- ### Main content ### -->
            <!-- ## Header ##-->
<header>
    <h1 class="header-title text-center"><a href="/">blog</a></h1>

    <p class="text-center header-slogan">
        
            
                Hi, nice to meet you.
            
        
    </p>

    <nav class="navbar-section text-center">
    
        <a href="/" class="navbar-link">首页</a>
    
    
        <a href="/archives/" class="navbar-link">归档</a>
    
    
        <a href="/search" class="navbar-link">搜索</a>
    
    
    
        <div class="dropdown dropdown-right">
    <a class="navbar-link dropdown-toggle" tabindex="0">分享</a>
    <ul class="menu share-menu">

        <!-- Share Weibo -->
        
        <li class="menu-item">
            <a href="http://service.weibo.com/share/share.php?appkey=&title=blog&url=https://abinzzz.github.io&pic=https://abinzzz.github.io/img/bot.ico&searchPic=false&style=simple" target="_blank" rel="external noopener noreferrer nofollow">分享到微博</a>
        </li>
        

        <!-- Share Twitter -->
        
        <li class="menu-item">
            <a href="https://twitter.com/intent/tweet?text=blog&url=https://abinzzz.github.io&via=ab" target="_blank" rel="external noopener noreferrer nofollow">分享到 Twitter</a>
        </li>
        

        <!-- Share Facebook -->
        
        <li class="menu-item">
            <a href="https://www.facebook.com/sharer/sharer.php?u=https://abinzzz.github.io" target="_blank" rel="external noopener noreferrer nofollow">分享到 Facebook</a>
        </li>
        

        <!-- Share Google+ -->
        
        <li class="menu-item">
            <a href="https://plus.google.com/share?url=https://abinzzz.github.io" target="_blank" rel="external noopener noreferrer nofollow">分享到 Google+</a>
        </li>
        

        <!-- Share LinkedIn -->
        
        <li class="menu-item">
            <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://abinzzz.github.io&title=ML:Bert" target="_blank" rel="external noopener noreferrer nofollow">分享到 LinkedIn</a>
        </li>
        

        <!-- Share QQ -->
        
        <li class="menu-item">
            <a href="http://connect.qq.com/widget/shareqq/index.html?site=blog&title=ML:Bert&summary=&pics=https://abinzzz.github.io/img/bot.ico&url=https://abinzzz.github.io" target="_blank" rel="external noopener noreferrer nofollow"> 分享到 QQ</a>
        </li>
        

        <!-- Share Telegram -->
        
        <li class="menu-item">
            <a href="https://t.me/share/url?url=https://abinzzz.github.io&text=ML:Bert" target="_blank" rel="external noopener noreferrer nofollow">分享到 Telegram</a>
        </li>
        

        <!-- QRCode -->
        
        <li class="menu-item">
            <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIQAAACECAAAAAB0L9x7AAABeUlEQVR42u3aQQ7CMAxE0d7/0rCvmvG4RGVc/W5ALYS3sLAd5/gEXAcIECBGIA5xLb98enb1HWddELmI6ocO46qgl+uCiEacFzzfX72/euasC+IdiNUflApMEO9HuCAQ8xFVYK2ere5tzaIgHkeoQuWX123VNohHEWXTKgoXpzHa0pWDeBShAslpgJ0Cd1n4gBiFcJOZKmrUWiByESr5uA3xKnBb/5ggYhCyOTGK3CpQ1WdBZCKqDVS1saruOYEKIhPhbnrJRLQri4KIQKjNjm4TXDXZVhYFEYVwhq5V89sZzoGYhagG9tVGWzuLgohBuJsinaB0i10QuQinmK0a4k4xA2IG4k4iWwWzapxAzEG4A9gqODsBCyIT4QzinIM8twY0ICIR7kHPanPdPdhTFrogIhDdgz3VoQ1ngxZEPsI9KOwe9LidRUGMQ7ibJ9VAH8R8hFvctpIiiGiEU7C6CU8VPiBmIDqNrBrKOkM8EPmIf14gQICIRnwBSd2ZmUOp8K4AAAAASUVORK5CYII=" alr="QRCode">
        </li>
        

    </ul>
</div>
    
    
</nav>
</header>

            
    <!-- ## Post ## -->
    <div class="post-container">
    <div id="post-card" class="card">
        
        <div class="card-item-container">
            <div class="card-inner-cell">
                <!-- # Post Header Info # -->
                <div class="card-header">
                    
    <h1 class="card-title h3 mb-2">ML:Bert</h1>




<div class="post-header-info">
    <p class="post-header-info-left text-gray">
        <img class="author-thumb lazyload" data-src="/img/default_avatar.png" src="/img/suka-lazyload.gif" alt="ab's Avatar">
        <span>2023-10-25</span>
        
            <span class="suka-devide-dot"></span>
            <a class="category-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><span class="suka-devide-dot"></span><a class="category-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/">ML</a>
        
        
            <!-- Busuanzi Post Views -->
<span id="busuanzi_container_page_pv" hidden>
    <span class="suka-devide-dot"></span>
    <span></span>
    <span id="busuanzi_value_page_pv"></span>
    <span>Views</span>
</span>
        
        
    </p>
    <div class="post-header-info-right">
        
            <div class="dropdown dropdown-right">
<a class="dropdown-toggle" tabindex="0">分享本文</a>
<ul class="menu share-menu">
    <!-- Share Weibo -->
    
    <li class="menu-item">
        <a href="http://service.weibo.com/share/share.php?appkey=&title=ML:Bert&url=https://abinzzz.github.io/2023/10/25/Bert/&pic=https://abinzzz.github.io/img/bot.ico&searchPic=false&style=simple" target="_blank" rel="external noopener noreferrer nofollow">分享到微博</a>
    </li>
    

    <!-- Share Twitter -->
    
    <li class="menu-item">
        <a href="https://twitter.com/intent/tweet?text=ML:Bert&url=https://abinzzz.github.io/2023/10/25/Bert/&via=ab" target="_blank" rel="external noopener noreferrer nofollow">分享到 Twitter</a>
    </li>
    

    <!-- Share Facebook -->
    
    <li class="menu-item">
        <a href="https://www.facebook.com/sharer/sharer.php?u=https://abinzzz.github.io/2023/10/25/Bert/" target="_blank" rel="external noopener noreferrer nofollow">分享到 Facebook</a>
    </li>
    

    <!-- Share Google+ -->
    
    <li class="menu-item">
        <a href="https://plus.google.com/share?url=https://abinzzz.github.io/2023/10/25/Bert/" target="_blank" rel="external noopener noreferrer nofollow">分享到 Google+</a>
    </li>
    

    <!-- Share LinkedIn -->
    
    <li class="menu-item">
        <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://abinzzz.github.io/2023/10/25/Bert/&title=blog" target="_blank" rel="external noopener noreferrer nofollow">分享到 LinkedIn</a>
    </li>
    

    <!-- Share QQ -->
    
    <li class="menu-item">
        <a href="http://connect.qq.com/widget/shareqq/index.html?site=blog&title=blog&summary=&pics=https://abinzzz.github.io/img/bot.ico&url=https://abinzzz.github.io/2023/10/25/Bert/" target="_blank" rel="external noopener noreferrer nofollow"> 分享到 QQ</a>
    </li>
    

    <!-- Share Telegram -->
    
    <li class="menu-item">
        <a href="https://t.me/share/url?url=https://abinzzz.github.io/2023/10/25/Bert/&text=blog" target="_blank" rel="external noopener noreferrer nofollow">分享到 Telegram</a>
    </li>
    

    <!-- QRCode -->
    
    <li class="menu-item">
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIQAAACECAAAAAB0L9x7AAABeUlEQVR42u3aQQ7CMAxE0d7/0rCvmvG4RGVc/W5ALYS3sLAd5/gEXAcIECBGIA5xLb98enb1HWddELmI6ocO46qgl+uCiEacFzzfX72/euasC+IdiNUflApMEO9HuCAQ8xFVYK2ere5tzaIgHkeoQuWX123VNohHEWXTKgoXpzHa0pWDeBShAslpgJ0Cd1n4gBiFcJOZKmrUWiByESr5uA3xKnBb/5ggYhCyOTGK3CpQ1WdBZCKqDVS1saruOYEKIhPhbnrJRLQri4KIQKjNjm4TXDXZVhYFEYVwhq5V89sZzoGYhagG9tVGWzuLgohBuJsinaB0i10QuQinmK0a4k4xA2IG4k4iWwWzapxAzEG4A9gqODsBCyIT4QzinIM8twY0ICIR7kHPanPdPdhTFrogIhDdgz3VoQ1ngxZEPsI9KOwe9LidRUGMQ7ibJ9VAH8R8hFvctpIiiGiEU7C6CU8VPiBmIDqNrBrKOkM8EPmIf14gQICIRnwBSd2ZmUOp8K4AAAAASUVORK5CYII=" alt="QRCode">
    </li>
    

</ul>
</div>
        
    </div>
</div>
                </div>
                <div class="card-body">
                    
                        
                        
                            <div id="post-toc"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="post-toc-number">1.</span> <span class="post-toc-text"> 参考链接：</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E4%B8%80review"><span class="post-toc-number">2.</span> <span class="post-toc-text"> 一.Review</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#11-1-of-n-encoding"><span class="post-toc-number">3.</span> <span class="post-toc-text"> 1.1 1-of-N Encoding</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#12-word-class"><span class="post-toc-number">4.</span> <span class="post-toc-text"> 1.2 Word Class</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#13-word-embedding"><span class="post-toc-number">5.</span> <span class="post-toc-text"> 1.3 Word Embedding</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#14-contextualized-word-embedding"><span class="post-toc-number">6.</span> <span class="post-toc-text"> 1.4 Contextualized Word Embedding</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E4%BA%8Celmoembeddings-from-language-model"><span class="post-toc-number">7.</span> <span class="post-toc-text"> 二.ELMO&#x3D;Embeddings from Language Model</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E4%B8%89bertbidirectional-encoder-representations-from-transformers"><span class="post-toc-number">8.</span> <span class="post-toc-text"> 三.BERT&#x3D;Bidirectional Encoder Representations from Transformers</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#31-train-approach"><span class="post-toc-number">9.</span> <span class="post-toc-text"> 3.1 train approach</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#311-train-approachmasked-lm"><span class="post-toc-number">10.</span> <span class="post-toc-text"> 3.1.1 train approach：Masked LM</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#312-train-approachnext-sentence-prediction"><span class="post-toc-number">11.</span> <span class="post-toc-text"> 3.1.2 train approach：Next Sentence Prediction</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#32-pre-train%E4%B8%8Efine-tune"><span class="post-toc-number">12.</span> <span class="post-toc-text"> 3.2 Pre-Train与fine-tune</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#33-how-to-use-bert"><span class="post-toc-number">13.</span> <span class="post-toc-text"> 3.3 How to use BERT</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#331-case-1"><span class="post-toc-number">14.</span> <span class="post-toc-text"> 3.3.1 Case 1</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#332-case-2"><span class="post-toc-number">15.</span> <span class="post-toc-text"> 3.3.2 Case 2</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#333-case-3"><span class="post-toc-number">16.</span> <span class="post-toc-text"> 3.3.3 Case 3</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#334-case-4"><span class="post-toc-number">17.</span> <span class="post-toc-text"> 3.3.4 Case 4</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#34-ernieenhanced-representation-through-knowledge-integration"><span class="post-toc-number">18.</span> <span class="post-toc-text"> 3.4 ERNIE&#x3D;Enhanced Representation through Knowledge Integration</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#35-multilingual-bert"><span class="post-toc-number">19.</span> <span class="post-toc-text"> 3.5 Multilingual BERT</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4gptgenerative-pre-traininggpt"><span class="post-toc-number">20.</span> <span class="post-toc-text"> 4.GPT&#x3D;Generative Pre-Training(GPT)</span></a></li></ol></div>
                        
                    
                    <article id="post-content">
                        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接：</h2>
<p>🔗：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV17441137fa/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">李宏毅-ELMO, BERT, GPT讲解</a></p>
<br>
<h2 id="一review"><a class="markdownIt-Anchor" href="#一review"></a> 一.Review</h2>
<h2 id="11-1-of-n-encoding"><a class="markdownIt-Anchor" href="#11-1-of-n-encoding"></a> 1.1 <code>1-of-N Encoding</code></h2>
<p>最早采用的方法，显然一个词用一个向量表示不合理<br />
apple=[1 0 0 0 0]</p>
<p>bag=[0 1 0 0 0]</p>
<p>cat=[0 0 1 0 0]</p>
<p>dog=[0 0  0 1 0]</p>
<p>elephant=[0 0 0 0 1]</p>
<br>
<h2 id="12-word-class"><a class="markdownIt-Anchor" href="#12-word-class"></a> 1.2 <code>Word Class</code></h2>
<p>之后才用WOrd CLass，但是这种分类还是太粗糙了</p>
<p><img src="https://pbs.twimg.com/media/F9QBk3BbAAAbtmX?format=png&amp;name=small" alt="" /></p>
<Br>
<h2 id="13-word-embedding"><a class="markdownIt-Anchor" href="#13-word-embedding"></a> 1.3 <code>Word Embedding</code></h2>
<p>每一个词映射到一个连续的向量空间，语义相似的词语在向量空间中距离较近</p>
<p><img src="https://pbs.twimg.com/media/F9QB7xQbAAAizwg?format=png&amp;name=small" alt="" /></p>
<br>
<h2 id="14-contextualized-word-embedding"><a class="markdownIt-Anchor" href="#14-contextualized-word-embedding"></a> 1.4 <code>Contextualized Word Embedding</code></h2>
<p>但是同一个词汇可能有不同的意思，比如：</p>
<ul>
<li>Have you paid that money to the bank yet ?(银行)</li>
<li>It is safest to deposit your money in the bank.(银行)</li>
<li>The victim was found lying dead on the river bank.(河堤)</li>
<li>They stood on the river bank to fish.(河堤)</li>
</ul>
<br>
<p>期待：</p>
<ul>
<li>过去，word type对应一种embedding；现在，word tokens对应一种的embdding</li>
<li>但同时word tokens也取决于其语境</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QX_OoacAA0dP4?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="二elmoembeddings-from-language-model"><a class="markdownIt-Anchor" href="#二elmoembeddings-from-language-model"></a> 二.ELMO=Embeddings from Language Model</h2>
<ul>
<li>RNN-based language models</li>
</ul>
<p>给很多句子去预测下一个句子的token是什么,不仅仅有正向的还有反向的</p>
<p><img src="https://pbs.twimg.com/media/F9QYYFvaYAAoswZ?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>但是深层LSTM的每一层都可以生成一个潜伏的表示，我们该用哪个呢？</p>
<p><img src="https://pbs.twimg.com/media/F9QYaCJbQAACqFg?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>ELMO的思想那个就是我全部都要，不同的Task抽不同层的权重不一样：</p>
<p><img src="https://pbs.twimg.com/media/F9QYcYXagAAKXeD?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="三bertbidirectional-encoder-representations-from-transformers"><a class="markdownIt-Anchor" href="#三bertbidirectional-encoder-representations-from-transformers"></a> 三.BERT=Bidirectional Encoder Representations from Transformers</h2>
<p><img src="https://pbs.twimg.com/media/F9QaYRAacAA5Z6k?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="31-train-approach"><a class="markdownIt-Anchor" href="#31-train-approach"></a> 3.1 train approach</h2>
<p>两种方法要同时使用</p>
<h2 id="311-train-approachmasked-lm"><a class="markdownIt-Anchor" href="#311-train-approachmasked-lm"></a> 3.1.1 train approach：Masked LM</h2>
<p>BERT模型本身就是Transformer的Encoder，输入输出长度一样，BERT会对输入随机mask一些token，然后让机器来填空。Mask有两种处理方法，一是将其标记为一个特殊的符号，二是随机填上一个文字。在下图的例子中，第二个output vector经过Linear transform和softmax之后，得到所有文字在第二个位置出现的概率，选择概率最大的文字为答案。训练目标就是最小化 预测结果与已知的ground truth之间的交叉熵</p>
<p><img src="https://img-blog.csdnimg.cn/2021031611423652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODk3ODAw,size_16,color_FFFFFF,t_70#pic_center" alt="" /></p>
<br>
<h2 id="312-train-approachnext-sentence-prediction"><a class="markdownIt-Anchor" href="#312-train-approachnext-sentence-prediction"></a> 3.1.2 train approach：Next Sentence Prediction</h2>
<p>BERT在做填空的同时，同时也在做NSP任务。对于输入的句子得做两个处理，首先在开始位置加上一个特殊的classification token(CLS)，在两个句子之间加上一个分隔符(SEP)。然后将处理好的向量表示丢给BERT，只取出(CLS)token对应的输出向量，进行线性变换和softmax，来判断Sentence1的下一句是否为Sentence2，但是NSP任务对BERT的下游任务没有什么帮助</p>
<ul>
<li>(CLS):输出分类结果的位置</li>
<li>(SEP):两个句子的边界</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QaciNbQAAbgkM?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="32-pre-train与fine-tune"><a class="markdownIt-Anchor" href="#32-pre-train与fine-tune"></a> 3.2 Pre-Train与fine-tune</h2>
<p>BERT做填空题和NSP对于我们很关心的其他任务来说非常有用，并且这些任务只有少量带标签的数据，我们称训练BERT的过程称为预训练（pre-train），称我们关心的其他任务为下游任务(downstream tasks)。</p>
<p>BERT模型预训练之后，经过微调(fine-tune)之后，可以应用于各式各样的下游任务中。</p>
<Br>
<h2 id="33-how-to-use-bert"><a class="markdownIt-Anchor" href="#33-how-to-use-bert"></a> 3.3 How to use BERT</h2>
<h2 id="331-case-1"><a class="markdownIt-Anchor" href="#331-case-1"></a> 3.3.1 Case 1</h2>
<ul>
<li>输入：stence</li>
<li>输出：class</li>
<li>例如：情感分析，文件分类…</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QammOasAA9R7V?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="332-case-2"><a class="markdownIt-Anchor" href="#332-case-2"></a> 3.3.2 Case 2</h2>
<ul>
<li>输入：sentence</li>
<li>输出：每个词的class</li>
<li>例如：槽位填充</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QapUPakAElWOT?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="333-case-3"><a class="markdownIt-Anchor" href="#333-case-3"></a> 3.3.3 Case 3</h2>
<ul>
<li>输入：两个sentence</li>
<li>输出：class</li>
<li>例如：给定一个假设，判断推理是否正确</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20210316115419587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODk3ODAw,size_16,color_FFFFFF,t_70#pic_center" alt="" /></p>
<br>
<h2 id="334-case-4"><a class="markdownIt-Anchor" href="#334-case-4"></a> 3.3.4 Case 4</h2>
<ul>
<li>输入：Document和Query</li>
<li>输出：两个正数s，e(s决定开始，e决定结束)</li>
</ul>
<p>基于抽取的问答的限制是答案必须来自于文章。如下图，输入的document中有N个单词，输入的query或question中有M个单词，最后输出两个整数(s, e)，分别表示答案在document中的起始(start)位置和结束(end)位置。例如第三题&quot;within a cloud&quot;是document的第77到79个单词，所以输出为(77, 79)。</p>
<p><img src="https://pbs.twimg.com/media/F9Qa8g6bQAEVlm5?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>具体如何训练，就是有两组随机初始化的向量，第一组与document对应的输出向量表示(output vector representation)做内积(inner product)，其结果进行线性变换和softmax，选择最大概率0.5所在的位置为起始位置s=2；第二组做同样的操作，选择最大概率0.7所在的位置为结束位置e=3，所以 outpu=(2,3),answer=(d2,d3)</p>
<p><img src="https://pbs.twimg.com/media/F9QbE1DacAA83hV?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="34-ernieenhanced-representation-through-knowledge-integration"><a class="markdownIt-Anchor" href="#34-ernieenhanced-representation-through-knowledge-integration"></a> 3.4 ERNIE=Enhanced Representation through Knowledge Integration</h2>
<p>专门为中文设计的BERT</p>
<p>将Mask LM盖住的character改为盖住word</p>
<p><img src="https://pbs.twimg.com/media/F9QbCZ2akAAr9Q-?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="35-multilingual-bert"><a class="markdownIt-Anchor" href="#35-multilingual-bert"></a> 3.5 Multilingual BERT</h2>
<p>Multi-BERT就是使用多种语言对BERT进行预训练，Multi-BERT使用了104种语言做预训练，实验发现Multi-BERT在一种语言上做微调，在另一种语言上做测试</p>
<p><img src="https://pbs.twimg.com/media/F9QbJk2aIAAflVu?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="4gptgenerative-pre-traininggpt"><a class="markdownIt-Anchor" href="#4gptgenerative-pre-traininggpt"></a> 4.GPT=Generative Pre-Training(GPT)</h2>
<p>GPT是Generative Pre-trained Transformer的缩写。GPT做的事其实是Predict Next Token，顾名思义就是预测下一个token，模型示意如下:</p>
<p><img src="https://pbs.twimg.com/media/F9QbOHcagAAcOuk?format=jpg&amp;name=medium" alt="" /></p>

                    </article>
                    


    <blockquote id="date-expire-notification" class="post-expired-notify">本文最后更新于 <span id="date-expire-num"></span> 天前，文中所描述的信息可能已发生改变</blockquote>
    <script>
    (function() {
        var dateUpdate = Date.parse("2023-11-23");
        var nowDate = new Date();
        var a = nowDate.getTime();
        var b = a - dateUpdate;
        var daysUpdateExpire = Math.floor(b/(24*3600*1000));
        if (daysUpdateExpire >= 120) {
            document.getElementById('date-expire-num').innerHTML = daysUpdateExpire;
        } else {
            document.getElementById('date-expire-notification').style.display = 'none';
        }
    })();
    </script>


<p class="post-footer-info mb-0 pt-0">本文发表于&nbsp;<time datetime="2023-10-25T01:58:26.000Z" itemprop="datePublished">2023-10-25</time>

    , 最后修改于&nbsp;<time datetime="2023-11-23T14:43:09.839Z" itemprop="dateModified">2023-11-23</time>

</p>
<p class="post-footer-info mb-0 pt-2">

<span class="post-categories-list mt-2">

<a class="post-categories-list-item" href='/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/'>专业知识</a>

<a class="post-categories-list-item" href='/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/'>ML</a>

</span>



<span class="post-tags-list mt-2">

<a class="post-tags-list-item" href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" rel="tag">#&nbsp;专业知识</a>

<a class="post-tags-list-item" href="/tags/ML/" rel="tag">#&nbsp;ML</a>

<a class="post-tags-list-item" href="/tags/bert/" rel="tag">#&nbsp;bert</a>

<a class="post-tags-list-item" href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" rel="tag">#&nbsp;李宏毅</a>

</span>


</p>

                </div>
                <div class="post-nav px-2 bg-gray">
<ul class="pagination">
    <!-- Prev Nav -->
    
        <li class="page-item page-prev">
            <a href="/2023/10/27/github%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="prev">
                <div class="page-item-title"><i class="icon icon-back" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">github小技巧</div>
            </a>
        </li>
    

    <!-- Next Nav -->
    
        <li class="page-item page-next">
            <a href="/2023/10/19/%E5%BC%BAcom-VS-%E5%BC%B1com/" rel="next">
                <div class="page-item-title"><i class="icon icon-forward" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">强com VS 弱com</div>
            </a>
        </li>
    
</ul>
</div>

                
                    <!-- # Comment # -->
                    
                
            </div>
        </div>
    </div>
</div>

            <!-- ### Footer ### -->
            <footer class="text-center">
    <!-- footer copyright -->
    
        <p class="footer-copyright mb-0">Copyright&nbsp;©&nbsp;<span id="copyright-year"></span>
            <a class="footer-copyright-a" href="https://abinzzz.github.io">blog</a>
        </p>

    <!-- footer custom text -->
    <p class="footer-text mb-0">
    
    </p>
    <!-- footer develop info -->
    <p class="footer-develop mb-0">
        
    <!-- Busuanzi User Views -->
    <span id="busuanzi_container_site_uv" hidden>
        <span></span>
        <span id="busuanzi_value_site_uv"></span>
        <span>Viewers</span>
        
            <span>|</span>
        
    </span>




        
        Powered by&nbsp;<!--
         --><a href="https://hexo.io" target="_blank" class="footer-develop-a" rel="external nofollow noopener noreferrer">Hexo</a><span class="footer-develop-divider"></span>Theme&nbsp;-&nbsp;<!--
         --><a href="https://github.com/SukkaW/hexo-theme-suka" target="_blank" class="footer-develop-a" rel="external noopener">Suka</a>
    </p>
</footer>


        <!-- ### Import File ### -->
        <!-- ### Footer JS Import ### -->

<script>

    
window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 50
};
document.getElementById('copyright-year').textContent = new Date().getFullYear();
console.log('\n %c Suka Theme (hexo-theme-suka) | © SukkaW | Verision 1.3.3 %c https://github.com/SukkaW/hexo-theme-suka \n', 'color: #fff; background: #444; padding:5px 0;', 'background: #bbb; padding:5px 0;');

</script>

<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@8.9.0" async></script>
    <script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" async></script>


<!-- Offset -->




<!-- Comment -->


<!-- ### Custom Footer ### -->

    </body>

</html>