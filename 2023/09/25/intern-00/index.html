<!DOCTYPE html>

<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <!--
        hexo-theme-suka © SukkaW
        GitHub: https://github.com/SukkaW/hexo-theme-suka
    -->

    <!-- ### Resource Hint ### -->

    <!-- ## DNS Prefetch ## -->
    <meta http-equiv="x-dns-prefetch-control" content="on">

<!-- busuanzi -->

    <link rel="dns-prefetch" href="//busuanzi.ibruce.info">


<!-- comment -->


    <link rel="dns-prefetch" href="//disqus.com">
    <link rel="dns-prefetch" href="//robin02.disqus.com">






<!-- analytics -->







    <!-- ## Preload ## -->
    
    <!-- Busuanzi -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" as="script">







    <!-- ### Meta & Title & Info ### -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <meta name="renderer" content="webkit">

    <!-- Title -->
    <title>Intern:00 | blog</title>

    <!-- Favicons -->
    <link rel="icon" type="image&#x2F;ico" href="/img/bot.ico">

    <!-- ### Import File ### -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spectre.css@0.5.3"><style>
    body {
        background-color: #f8f9fa;
    }

    a, a:visited {
        color: blue;
    }

    a:active, a:focus, a:hover {
        color: blue;
        opacity: .75;
    }

    #post-content a,
    #post-content a:hover,
    #post-content a:focus,
    #post-content a:visited {
        color: blue;
        opacity: 1;
    }

    

    .post-entry .card-body a {
        color: red;
    }

    .avatar {
        background: red;
    }

    .navbar-link,
    .navbar-link:visited,
    .timeline .timeline-item .timeline-icon.icon-lg {
        color: red;
    }

    .navbar-link:hover {
        color: red;
        opacity: .8;
    }

    #search-input .btn,
    #disqus_click_btn,
    #disqus-switch-to-direct,
    #disqus-loadmore-button {
        background: red;
        border-color: red;
        color: #fff;
    }

    #post-toc a.post-toc-link,
    #post-toc a.post-toc-link:visited,
    .share-menu.menu .menu-item>a {
        color: red;
    }

    .share-menu.menu .menu-item>a:hover,
    .share-menu.menu .menu-item>a:focus,
    .share-menu.menu .menu-item>a:visited {
        color: #50596c;
        background: #f8f9fa;
        opacity: .85;
    }
</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/style.min.css">








    <!-- Prettify Theme -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css"></noscript>





<script>
/*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
!function(t){"use strict";t.loadCSS||(t.loadCSS=function(){});var e=loadCSS.relpreload={};if(e.support=function(){var e;try{e=t.document.createElement("link").relList.supports("preload")}catch(t){e=!1}return function(){return e}}(),e.bindMediaToggle=function(t){var e=t.media||"all";function a(){t.addEventListener?t.removeEventListener("load",a):t.attachEvent&&t.detachEvent("onload",a),t.setAttribute("onload",null),t.media=e}t.addEventListener?t.addEventListener("load",a):t.attachEvent&&t.attachEvent("onload",a),setTimeout(function(){t.rel="stylesheet",t.media="only x"}),setTimeout(a,3e3)},e.poly=function(){if(!e.support())for(var a=t.document.getElementsByTagName("link"),n=0;n<a.length;n++){var o=a[n];"preload"!==o.rel||"style"!==o.getAttribute("as")||o.getAttribute("data-loadcss")||(o.setAttribute("data-loadcss",!0),e.bindMediaToggle(o))}},!e.support()){e.poly();var a=t.setInterval(e.poly,500);t.addEventListener?t.addEventListener("load",function(){e.poly(),t.clearInterval(a)}):t.attachEvent&&t.attachEvent("onload",function(){e.poly(),t.clearInterval(a)})}"undefined"!=typeof exports?exports.loadCSS=loadCSS:t.loadCSS=loadCSS}("undefined"!=typeof global?global:this);
</script>

    <!-- ### Site Verification ### -->
    


    <meta name="mobile-web-app-capable" content="yes"><meta name="application-name" content="blog"><meta name="msapplication-starturl" content="https://abinzzz.github.io"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><link rel="search" type="application/opensearchdescription+xml" href="opensearch.xml" title="blog">

    <!-- ### The Open Graph & Twitter Card Protocol ### -->
    <meta property="og:title" content="Intern:00 | blog"><meta property="og:site_name" content="blog"><meta property="og:type" content="article"><meta property="og:url" content="https://abinzzz.github.io/2023/09/25/intern-00/"><meta property="og:locale" content="zh-CN"><meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&amp;apos;$&amp;apos;, &amp;apos;$&amp;apos;]]}, messageStyle: &quot;none&quot; });   TODO   [x] 1、了解什么是SNN(脉冲神经网络)   [x] 2、对比ANN和SNN区别 https:&#x2F;&#x2F;par.nsf.gov&#x2F;servlets&#x2F;purl&#x2F;10188417   [x] 3.学习MS-ResNet;（S - ab - blog"><meta name="keywords" content="internship, CAS, SNN, 0, SNN vs RNN, MS-ResNet, Attention, blog"><meta property="og:image" content="https://pic2.zhimg.com/80/v2-c0c3dbbb0febc5477f5551b2ddba85b1_1440w.webp"><meta property="og:image" content="https://pic1.zhimg.com/80/v2-2c1fd5e9f76a8ab215f74f8f5a0d7d08_1440w.webp"><meta property="og:image" content="https://pic1.zhimg.com/80/v2-50e800bc6ef8aa515193d5fb3a67a510_1440w.webp"><meta property="article:published_time" content="2023-09-25T08:51:31.000Z"><meta property="article:modified_time" content="2023-10-16T07:24:08.120Z"><meta property="og:updated_time" content="2023-10-16T07:24:08.120Z"><meta property="article:author" content="ab"><meta property="article:tag" content="internship, CAS, SNN, 0, SNN vs RNN, MS-ResNet, Attention, blog"><meta name="twitter:card" content="summary">

    

    <!-- ### Canonical link ### -->
    <link rel="canonical" href="https://abinzzz.github.io/2023/09/25/intern-00/">

    <meta name="generator" content="Hexo 5.4.2">

    <!-- ### Analytics ### -->
    







    <!-- ### Structured Data ### -->
    



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "https://abinzzz.github.io/2023/09/25/intern-00/",
    "@type": "BlogPosting",
    "logo": "https://abinzzz.github.io/img/bot.ico",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://abinzzz.github.io/2023/09/25/intern-00/"
    },
    "headline": "Intern:00 | blog",
    
    "image": {
        "@type": "ImageObject",
        "url": "https://abinzzz.github.io/img/bot.ico"
    },
    
    "datePublished": "2023-09-25T08:51:31.000Z",
    "dateModified": "2023-10-16T07:24:08.120Z",
    "author": {
        "@type": "Person",
        "name": "ab",
        "image": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/avatar.jpg"
        },
        "description": "Welcome to my blog!"
    },
    "publisher": {
        "@type": "Organization",
        "name": "blog",
        "logo": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/bot.ico"
        }
    },
    
    "potentialAction": {
        "@type": "SearchAction",
        "target": "https://abinzzz.github.io/search?s={search_term_string}",
        "query-input": "required name=search_term_string"
    },
    
    "keywords": "internship, CAS, SNN, 0, SNN vs RNN, MS-ResNet, Attention, blog",
    "description": "MathJax.Hub.Config({ tex2jax: {inlineMath: [[&amp;apos;$&amp;apos;, &amp;apos;$&amp;apos;]]}, messageStyle: &amp;quot;none&amp;quot; });   TODO   [x] 1、了解什么是SNN(脉冲神经网络)   [x] 2、对比ANN和SNN区别 https://par.nsf.gov/servlets/purl/10188417   [x] 3.学习MS-ResNet;（S - ab - blog"
}
</script>



    <!-- ### Custom Head ### -->
    
</head>

    <body>
            

            <!-- ### Main content ### -->
            <!-- ## Header ##-->
<header>
    <h1 class="header-title text-center"><a href="/">blog</a></h1>

    <p class="text-center header-slogan">
        
            
                Welcome to my blog!
            
        
    </p>

    <nav class="navbar-section text-center">
    
        <a href="/" class="navbar-link">首页</a>
    
    
        <a href="/archives/" class="navbar-link">归档</a>
    
    
        <a href="/search" class="navbar-link">搜索</a>
    
    
    
    
</nav>
</header>

            
    <!-- ## Post ## -->
    <div class="post-container">
    <div id="post-card" class="card">
        
        <div class="card-item-container">
            <div class="card-inner-cell">
                <!-- # Post Header Info # -->
                <div class="card-header">
                    
    <h1 class="card-title h3 mb-2">Intern:00</h1>




<div class="post-header-info">
    <p class="post-header-info-left text-gray">
        <img class="author-thumb lazyload" data-src="/img/avatar.jpg" src="/img/suka-lazyload.gif" alt="ab's Avatar">
        <span>2023-09-25</span>
        
            <span class="suka-devide-dot"></span>
            <a class="category-link" href="/categories/internship/">internship</a>
        
        
        
    </p>
    <div class="post-header-info-right">
        
            <div class="dropdown dropdown-right">
<a class="dropdown-toggle" tabindex="0">分享本文</a>
<ul class="menu share-menu">
    <!-- Share Weibo -->
    

    <!-- Share Twitter -->
    

    <!-- Share Facebook -->
    

    <!-- Share Google+ -->
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    

    <!-- QRCode -->
    
    <li class="menu-item">
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJQAAACUCAAAAABQV18IAAAB1klEQVR42u3a0Y6DMAxEUf7/p9tXRJOZMa2qxFxeVmppfFYKxHF8vBa8DlCgQIEaoA5xnb+/3jv6/fmzj4AmDqheqOGkm0BGg13xs3FUHFD9UKPgs+9H96nJnMQB9RzUbMKm+EocUM9AqYV29iJN0aB6o9RCOUr2ZglgJfED1ReVLqTf/v3pbgbUsqio8BBuVP9adQG1LCpN/N0LUC3gSbIHqh+qWrRw/0BSPLMTHdS2KJX4zyAuaFq4lVkCqG1RanKrRVgVWtNx7YIMajtUEnw2mJvwycsZVD9U8qMkcXMbi+jwCFQrlJugyYOQFkZA9Ue5DahK3JLg6YE3qB6oakKmXo7JhkMV10D1QKlBq80TSbGjXMkDtS2qGrxauFW/A9UTlSycaZNO2mgIqifqzgJcaXxWm1FZdQG1LepOAaxyEJAcVoLqjbIHhSJYummdFtVAtUUpnHsZVj4D1ReVLqrVJq5kk2qbJUBth0oGTg4p3cMQPVigWqCShua0icZtQOyhJ6g2qHSCVxI3t3kA1R/lDhcrjTpp0R/Uc1EpxBUzbCMPqEegXGGjUjyzCz2oVihVXHUNEsl9UfIIqg3qzkFQJaFTD8tXuxlQS6JWukCBAgXqdL0B9S/R0Sy3I/wAAAAASUVORK5CYII=" alt="QRCode">
    </li>
    

</ul>
</div>
        
    </div>
</div>
                </div>
                <div class="card-body">
                    
                        
                        
                            <div id="post-toc"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#todo"><span class="post-toc-number">1.</span> <span class="post-toc-text"> TODO</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1snn"><span class="post-toc-number">2.</span> <span class="post-toc-text"> 1.SNN</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#11-nn%E7%9A%84%E8%BF%9B%E5%8C%96"><span class="post-toc-number">3.</span> <span class="post-toc-text"> 1.1 NN的进化</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#12-snn%E7%9A%84%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F"><span class="post-toc-number">4.</span> <span class="post-toc-text"> 1.2 SNN的编码方式</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#13-snn%E6%A8%A1%E5%9E%8B"><span class="post-toc-number">5.</span> <span class="post-toc-text"> 1.3 SNN模型</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#14-snn%E7%9A%84%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F"><span class="post-toc-number">6.</span> <span class="post-toc-text"> 1.4 SNN的训练方式</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#15-%E5%B1%80%E9%99%90%E6%80%A7"><span class="post-toc-number">7.</span> <span class="post-toc-text"> 1.5 局限性</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-snn-vs-ann"><span class="post-toc-number">8.</span> <span class="post-toc-text"> 2. SNN vs ANN</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#21-snn"><span class="post-toc-number">9.</span> <span class="post-toc-text"> 2.1 SNN</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#22-%E5%A6%82%E4%BD%95%E8%AF%84%E4%BC%B0-snn-%E6%98%AF%E6%9C%89%E6%84%8F%E4%B9%89%E7%9A%84"><span class="post-toc-number">10.</span> <span class="post-toc-text"> 2.2 如何评估 SNN 是有意义的</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#23-%E8%84%89%E5%86%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%8E%9F%E7%90%86"><span class="post-toc-number">11.</span> <span class="post-toc-text"> 2.3 脉冲神经网络的原理</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3%E8%84%89%E5%86%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="post-toc-number">12.</span> <span class="post-toc-text"> 3.脉冲神经网络数据集</span></a></li></ol></div>
                        
                    
                    <article id="post-content">
                        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="todo"><a class="markdownIt-Anchor" href="#todo"></a> TODO</h2>
<ul>
<li>
<p>[x] 1、了解什么是SNN(脉冲神经网络)</p>
</li>
<li>
<p>[x] 2、对比ANN和SNN区别</p>
<p><a target="_blank" rel="noopener" href="https://par.nsf.gov/servlets/purl/10188417">https://par.nsf.gov/servlets/purl/10188417</a></p>
</li>
<li>
<p>[x] 3.学习MS-ResNet;（SNN）</p>
<p>论文：Advancing Residual Learning towards Powerful Deep Spiking Neural Networks</p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/BICLab/MS-ResNet">https://github.com/BICLab/MS-ResNet</a></p>
</li>
</ul>
<br>
<h2 id="1snn"><a class="markdownIt-Anchor" href="#1snn"></a> 1.SNN</h2>
<h2 id="11-nn的进化"><a class="markdownIt-Anchor" href="#11-nn的进化"></a> 1.1 NN的进化</h2>
<p>第一代nn：感知器，一个简单的神经元只能处理二进制数据。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><msub><mi>I</mi><mi>n</mi></msub><msub><mi>W</mi><mi>n</mi></msub><mo>→</mo></mrow><annotation encoding="application/x-tex">\sum I_nW_n \rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span></span></span></span> Perceptron</p>
<p>第二代nn：通常是全连接的神经网络，它们输入连续的值，然后输出连续的值 ，也就是目前我们一直在使用各种神经网络，BP，CNN，RNN等，本质来讲，这些神经网络都是基于神经脉冲的频率进行编码( rate coded）。</p>
<p>第三代nn：脉冲神经网络（spiking neural networks），其模拟神经元更加接近实际，把时间信息的影响也考虑其中 。旨在弥合神经科学与机器学习之间的鸿沟，使用接近真实的生物神经模型来进行计算。SNN可以归类为类脑计算，是认为生物智能是人工智能想要达到的目标和方向，标榜自然智进行改进与深化。</p>
<br>
<h2 id="12-snn的编码方式"><a class="markdownIt-Anchor" href="#12-snn的编码方式"></a> 1.2 SNN的编码方式</h2>
<h2 id="13-snn模型"><a class="markdownIt-Anchor" href="#13-snn模型"></a> 1.3 SNN模型</h2>
<h2 id="14-snn的训练方式"><a class="markdownIt-Anchor" href="#14-snn的训练方式"></a> 1.4 SNN的训练方式</h2>
<h2 id="15-局限性"><a class="markdownIt-Anchor" href="#15-局限性"></a> 1.5 局限性</h2>
<br>
<h2 id="2-snn-vs-ann"><a class="markdownIt-Anchor" href="#2-snn-vs-ann"></a> 2. SNN vs ANN</h2>
<h2 id="21-snn"><a class="markdownIt-Anchor" href="#21-snn"></a> 2.1 SNN</h2>
<p>SNN 作为人工智能和神经形态计算机群体中的计算工具的实用价值，长期以来一直存在争论。尤其是和人工神经网络 (ANN) 相比。在过去的几年里，这些怀疑减缓了神经形态计算 (neuromorphic computing ) 的发展，而随着深度学习的快速进步，研究人员试图从根本上缓解这个问题，人们想要通过加强 SNN 的手段，如改善训练算法，来缓解这个问题。</p>
<p>与成熟有效的人工神经网络 (ANN) 训练算法：误差反向传播算法 (Back Propagation) 不同，神经网络研究中最困难的问题之一是由于<strong>复杂的动力学和脉冲的不可微性质</strong>导致的训练困难。</p>
<p>为了提升脉冲神经网络的精度，已有一些前人的工作做出了探索，如：</p>
<ul>
<li><strong>Spike timing dependent plasticity (STDP)</strong> ：无监督学习方法</li>
<li><strong>添加奖励机制</strong></li>
<li><strong>把预训练好的 ANN 转化为 SNN</strong>：为了提升 ANN 与 SNN 的兼容性，通常把 bias 去掉，使用 ReLU 激活函数，把 max-pool 换成 average-pool 等。把 ANN 转化成 SNN 时，通常包括 weight/activation normalization，threshold tuning, sampling error compensation 等操作以维持精度。</li>
<li><strong>脉冲神经网络使用 BP 算法训练</strong>：在执行反向传播时，梯度可以沿着空间维度通过聚合脉冲传播，也可以沿着时间和空间2个维度通过计算膜电势的梯度传播</li>
</ul>
<br>
<p>由于 SNN 缺乏专门的benchmark，许多工作直接使用 ANN 的 benchmark 来验证 SNN 模型。例如，用于 ANN 验证的图像数据集被简单地转换为 Spike 版本，用于 SNN 训练和测试。 此外，网络的准确性仍然是主要的评估指标，但众所周知，我们的大脑在绝对识别准确性方面，通常比现有的人工智能机器表现得差。这反映了我们需要更全面和公平的衡量标准来评估和模拟生物大脑工作方式的 SNN。简而言之，由于不适当的评估指标，目前的 SNN 无法击败 ANN。因此，出现了1个开放的问题</p>
<h2 id="22-如何评估-snn-是有意义的"><a class="markdownIt-Anchor" href="#22-如何评估-snn-是有意义的"></a> 2.2 如何评估 SNN 是有意义的</h2>
<p>这篇文章将预训练好的 ANN 转化成 SNN，在这个工作里面作者考虑到了 SNN 网络的 Efficiency，而不仅仅是 Accuracy。评价一个 SNN 时要从多个角度考量，比如：application accuracy，memory cost, compute cost 。</p>
<p>在以 ANN 主导的评价指标和任务中，相同大小的 SNN 无法打败 ANN。但是在以 SNN 主导的评价指标和任务中，SNN 的表现会更好。</p>
<h2 id="23-脉冲神经网络的原理"><a class="markdownIt-Anchor" href="#23-脉冲神经网络的原理"></a> 2.3 脉冲神经网络的原理</h2>
<p>如下图1所示是ANN 和 SNN 的单个基本神经元：</p>
<p><img src="https://pic2.zhimg.com/80/v2-c0c3dbbb0febc5477f5551b2ddba85b1_1440w.webp" alt="" /></p>
<br>
<p>(a) 图是典型的单个 ANN 神经元，ANN 的计算方法是：</p>
<p>y=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span></span></span></span>(b + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\sum_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">x_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>) <strong>(1)</strong></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ψ</mi></mrow><annotation encoding="application/x-tex">\psi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span></span></span></span>:非线性的激活函数</li>
<li>X代表上个神经元过来的连续的激活值 (Pre-activation)，通过突触 (Synapse) 传递到树突的位置 (Dendrite)，并且最终由细胞体 (Soma) 来处理这个激活值 (具体处理方法就是1式)</li>
<li>ANN 中的神经元使用高精度和连续值编码的激活值进行相互通信，并且只在空间域 (spatial domain，即 layer by layer) 传播信息。从上述方程可以看出，输入和权重的相乘和累加 (MAC) 是网络的主要操作</li>
</ul>
<br>
<p>(b) 图是典型的单个 SNN 神经元，它的结构与 ANN 神经元相似，但行为不同。脉冲神经元之间的交流通过 <strong>binary 的 events</strong>，而不是<strong>连续的激活值</strong></p>
<p>S代表上个神经元过来的一个一个的脉冲 (Spike)，通过突触 (Synapse) 传递到树突的位置 (Dendrite)，并且最终由细胞体 (Soma) 来处理这些脉冲 (具体处理方法就是2式)</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>d</mi><mi>u</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{du(t)}{dt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">u</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">t</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> = - [u(t) - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>r</mi><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">u_{r1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>] + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\sum_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185818em;vertical-align:-0.43581800000000004em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16195399999999993em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\omega_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>∑</mo><mrow><msubsup><mi>t</mi><mi>j</mi><mi>k</mi></msubsup><mo>∈</mo><msubsup><mi>S</mi><mi>j</mi><msub><mi>T</mi><mi>w</mi></msub></msubsup></mrow></msub></mrow><annotation encoding="application/x-tex">\sum_{t_{j}^{k} \in S_j^{T_w}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.411045em;vertical-align:-0.661045em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3447999999999999em;"><span style="top:-2.361775em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8408285714285714em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-2.8448em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.97575em;"><span style="top:-2.177714285714286em;margin-left:-0.05764em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-2.987657142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.23056em;"><span style="top:-2.3em;margin-left:-0.13889em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46117142857142857em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.661045em;"><span></span></span></span></span></span></span></span></span></span>K(t - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mi>j</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">t_j^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>)  <strong>(2)</strong></p>
<p>s(t)=1 &amp; u(t)=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>r</mi><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">u_{r2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> , if u(t) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≥</mo></mrow><annotation encoding="application/x-tex">\geq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mrel">≥</span></span></span></span> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">u_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>s(t)=0 , if u(t) &lt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">u_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<ul>
<li>t:时间步长，时间离散化单位，模型中的微分方程会根据t进行更新</li>
<li>τ:时间常数</li>
<li>u:膜电位</li>
<li>s:输出脉冲</li>
<li>ur1：静息电位，指神经元在没有接收到任何突触输入时的电位水平。它通常被设置为一个负值,比如-70mV。这个负值意味着当神经元不被激活时,内部是趋向稳定的状态。</li>
<li>ur2：复位电位，当神经元放电产生脉冲后,为了准备下一次积分放电,需要将电位重新设置到一个复位值。这个值通常接近甚至等于静息电位,比如也设为-70mV。它使得神经元在放电后快速返回静息,准备下一次信息编码。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">w_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>: 第 j 个输入神经元的突触权重</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>t</mi><mi>j</mi><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">t^k_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>:第 j 个输入神经元的第 k 个脉冲在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">T_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的积分时间窗口内激发的时间（总共 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>S</mi><mi>j</mi><mrow><mi>T</mi><mi>w</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex">S^{Tw}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>脉冲序列），发放脉冲的时刻</li>
<li>K():描述时间衰减效应的核函数</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">u_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>:决定是否发射脉冲的发射阈值</li>
</ul>
<br>
<p>接下来用人话即使一下2是什么意思：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.当膜电位  ut(也就是细胞体 Soma 这个隐含电位) 高于阈值  uth时，脉冲神经元看做一次点火，此时输出电位 st 置为1，同时膜电位 ut 回归到重置电位 ur2 。</span><br><span class="line">2.当膜电位 ut (也就是细胞体 Soma 这个隐含电位) 低于阈值uth  时，不点火，此时输出电位 st 保持为0。</span><br><span class="line">3.在每个 time step，膜电位ut 的更新过程满足一个微分方程，即2.1式。</span><br><span class="line">4.在每个 time step，膜电位 ut 值应下降 ut - ur1 这么大的值，其中 ur1 是静息电位。</span><br><span class="line">5.同时在每个 time step，膜电位 ut 值应上升一个值，这个值来的大小与这个神经元的 j个输入突触有关，每个输入突触的权值是wj  ，这个突触对膜电位上升的贡献值是 \sigma ，即在S  个脉冲中，如果 tkj 时刻的输入脉冲是点火状态 (即1状态)，那么计算一次K(t-tkj)  并累积起来。</span><br></pre></td></tr></table></figure>
<p>与 ANN 不同的是，SNN 使用脉冲的序列来传递信息，每个脉冲神经元都经历着丰富的动态行为。 具体而言，除了空间域中的信息传播外，时间域中的过去历史也会对当前状态产生紧密的影响。 因此，与主要通过空间传播和连续激活的神经网络相比，神经网络通常具有更多的时间通用性，但精度较低。 由于只有当膜电位超过一个阈值时才会激发尖峰信号，因此整个尖峰信号通常很稀疏。 此外，由于尖峰值 (Spike) 是二进制的，即0或1，如果积分时间窗口  调整为1，输入和权重之间的乘法运算就可以消除。由于上述原因，与计算量较大的 ANN 网络相比，SNN 网络通常可以获得较低的功耗</p>
<h2 id="3脉冲神经网络数据集"><a class="markdownIt-Anchor" href="#3脉冲神经网络数据集"></a> 3.脉冲神经网络数据集</h2>
<p>这一节介绍下脉冲神经网络的基本数据集。</p>
<p>像 MNIST，CIFAR10 这类基于帧的静态图像，广泛应用于 ANN 中，我们称之为 ANN-oriented dataset，如下图2的前2行所示。</p>
<p>CIFAR-10：32×32×3 RGB image，Training set：50000，Testing set：10000</p>
<p>MNIST：28×28×1 grayscale image，Training set：60000，Testing set：10000</p>
<p><img src="https://pic1.zhimg.com/80/v2-2c1fd5e9f76a8ab215f74f8f5a0d7d08_1440w.webp" alt="" /></p>
<p>图2的后2行 N-MNIST 和 DVS-CIFAR10 叫做 SNN-oriented dataset。这里的 DVS 叫做 dynamic vision sensor，代表使用了动态视觉传感器扫描每张 images 得到的 spike 数据。它除了具有与 ANN-oriented dataset 相似的空间信息外，还包含更多的动态时间信息，而且尖峰事件与神经网络中的信号格式自然兼容，因此我们称之为 SNN-oriented dataset。</p>
<p>DVS 产生两个通道的脉冲事件，命名为 On 和Off 事件 (分别如图2中红色和蓝色所示)。因此，DVS 将每个图像转换为  的脉冲模式。</p>
<p>N-MNIST：34×34×2×T spatio-temporal spike pattern，Training set：60000，Testing set：10000</p>
<p>DVS-CIFAR-10：128×128×2×T spatio-temporal spike pattern，Training set：9000，Testing set：1000</p>
<br>
<p>一般来说，ANN 接收帧为基础的图像，而 SNN 接收事件驱动的脉冲信号。因此，有时需要将相同的数据转换为另一个域中的不同形式来处理。本文以视觉识别任务为例，主要介绍了四种信号转换方法，如下图3所示:</p>
<p><img src="https://pic1.zhimg.com/80/v2-50e800bc6ef8aa515193d5fb3a67a510_1440w.webp" alt="" /></p>

                    </article>
                    


    <blockquote id="date-expire-notification" class="post-expired-notify">本文最后更新于 <span id="date-expire-num"></span> 天前，文中所描述的信息可能已发生改变</blockquote>
    <script>
    (function() {
        var dateUpdate = Date.parse("2023-10-16");
        var nowDate = new Date();
        var a = nowDate.getTime();
        var b = a - dateUpdate;
        var daysUpdateExpire = Math.floor(b/(24*3600*1000));
        if (daysUpdateExpire >= 120) {
            document.getElementById('date-expire-num').innerHTML = daysUpdateExpire;
        } else {
            document.getElementById('date-expire-notification').style.display = 'none';
        }
    })();
    </script>


<p class="post-footer-info mb-0 pt-0">本文发表于&nbsp;<time datetime="2023-09-25T08:51:31.000Z" itemprop="datePublished">2023-09-25</time>

    , 最后修改于&nbsp;<time datetime="2023-10-16T07:24:08.120Z" itemprop="dateModified">2023-10-16</time>

</p>
<p class="post-footer-info mb-0 pt-2">

<span class="post-categories-list mt-2">

<a class="post-categories-list-item" href='/categories/internship/'>internship</a>

</span>



<span class="post-tags-list mt-2">

<a class="post-tags-list-item" href="/tags/internship/" rel="tag">#&nbsp;internship</a>

<a class="post-tags-list-item" href="/tags/CAS/" rel="tag">#&nbsp;CAS</a>

<a class="post-tags-list-item" href="/tags/SNN/" rel="tag">#&nbsp;SNN</a>

<a class="post-tags-list-item" href="/tags/0/" rel="tag">#&nbsp;0</a>

<a class="post-tags-list-item" href="/tags/SNN-vs-RNN/" rel="tag">#&nbsp;SNN vs RNN</a>

<a class="post-tags-list-item" href="/tags/MS-ResNet/" rel="tag">#&nbsp;MS-ResNet</a>

<a class="post-tags-list-item" href="/tags/Attention/" rel="tag">#&nbsp;Attention</a>

</span>


</p>

                </div>
                <div class="post-nav px-2 bg-gray">
<ul class="pagination">
    <!-- Prev Nav -->
    
        <li class="page-item page-prev">
            <a href="/2023/10/07/Missing-Semester-of-CS/" rel="prev">
                <div class="page-item-title"><i class="icon icon-back" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">Missing Semester of CS:Lecture01-课程概览与shell</div>
            </a>
        </li>
    

    <!-- Next Nav -->
    
        <li class="page-item page-next">
            <a href="/2023/09/25/pytorch%E9%9D%A2%E7%BB%8F/" rel="next">
                <div class="page-item-title"><i class="icon icon-forward" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">pytorch面经</div>
            </a>
        </li>
    
</ul>
</div>

                
                    <!-- # Comment # -->
                    
                        <div class="card-footer post-comment">
                            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
        this.page.url = 'https://abinzzz.github.io/2023/09/25/intern-00/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://abinzzz.github.io/2023/09/25/intern-00/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>
<script id="disqus-thread-script">
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//robin02.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

                        </div>
                    
                
            </div>
        </div>
    </div>
</div>

            <!-- ### Footer ### -->
            <footer class="text-center">
    <!-- footer copyright -->
    
        <p class="footer-copyright mb-0">Copyright&nbsp;©&nbsp;<span id="copyright-year"></span>
            <a class="footer-copyright-a" href="https://abinzzz.github.io">blog</a>
        </p>

    <!-- footer custom text -->
    <p class="footer-text mb-0">
    
    </p>
    <!-- footer develop info -->
    <p class="footer-develop mb-0">
        
    <!-- Busuanzi User Views -->
    <span id="busuanzi_container_site_uv" hidden>
        <span></span>
        <span id="busuanzi_value_site_uv"></span>
        <span>Viewers</span>
        
            <span>|</span>
        
    </span>




        
        Powered by&nbsp;<!--
         --><a href="https://hexo.io" target="_blank" class="footer-develop-a" rel="external nofollow noopener noreferrer">Hexo</a><span class="footer-develop-divider"></span>Theme&nbsp;-&nbsp;<!--
         --><a href="https://github.com/SukkaW/hexo-theme-suka" target="_blank" class="footer-develop-a" rel="external noopener">Suka</a>
    </p>
</footer>


        <!-- ### Import File ### -->
        <!-- ### Footer JS Import ### -->

<script>

    
window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 50
};

(function() {
    var copyrightNow = new Date().getFullYear();
    var copyrightContent = document.getElementById('copyright-year');
    var copyrightSince = 2023;
    if (copyrightSince === copyrightNow) {
        copyrightContent.textContent = copyrightNow;
    } else {
        copyrightContent.textContent = copyrightSince + ' - ' + copyrightNow;
    }
})();
console.log('\n %c Suka Theme (hexo-theme-suka) | © SukkaW | Verision 1.3.3 %c https://github.com/SukkaW/hexo-theme-suka \n', 'color: #fff; background: #444; padding:5px 0;', 'background: #bbb; padding:5px 0;');

</script>

<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@8.9.0" async></script>
    <script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" async></script>


<!-- Offset -->




<!-- Comment -->

    
        <script id="dsq-count-scr" src="https://robin02.disqus.com/count.js" async></script>

    


<!-- ### Custom Footer ### -->

    </body>

</html>