
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <meta charset="utf-8">
    

    

    
    <title>
        code:causal analysis churn |
        
        Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="此篇文章是用来梳理”paper:Causal Analysis Churn”的代码    流程：  导入数据集  删掉重复行  找到分类特征列和数量特征列   删掉高相关性特征   预处理对分类特征进行one-hot编码  1.导入数据集123observation_window1 &#x3D; pd.read_csv(&amp;#x27;new_data&#x2F;features_201506.csv&amp;#x27;)obs">
<meta property="og:type" content="article">
<meta property="og:title" content="code:causal analysis churn">
<meta property="og:url" content="https://abinzzz.github.io/2023/08/21/code-causal-analysis-churn/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="此篇文章是用来梳理”paper:Causal Analysis Churn”的代码    流程：  导入数据集  删掉重复行  找到分类特征列和数量特征列   删掉高相关性特征   预处理对分类特征进行one-hot编码  1.导入数据集123observation_window1 &#x3D; pd.read_csv(&amp;#x27;new_data&#x2F;features_201506.csv&amp;#x27;)obs">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-21T05:50:30.000Z">
<meta property="article:modified_time" content="2023-08-21T17:05:33.126Z">
<meta property="article:author" content="晴">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="coding">
<meta property="article:tag" content="Causal Analysis Churn">
<meta name="twitter:card" content="summary">
    
        <link rel="alternate" href="/atom.xml" title="Blog" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
        <img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Code.org_logo.svg/1200px-Code.org_logo.svg.png" data-sizes="auto" alt="code:causal analysis churn" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>code:causal analysis churn</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-code-causal-analysis-churn" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2023/08/21/code-causal-analysis-churn/" class="article-date-link">
        <time datetime="2023-08-21T05:50:30.000Z"
              itemprop="datePublished">2023-08-21</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/paper/">paper</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <p>此篇文章是用来梳理”paper:Causal Analysis Churn”的代码  </p>
<p><br></p>
<p>流程：</p>
<ul>
<li>导入数据集 </li>
<li>删掉重复行 </li>
<li>找到分类特征列和数量特征列  </li>
<li>删掉高相关性特征  </li>
<li>预处理对分类特征进行one-hot编码</li>
</ul>
<h2 id="1-导入数据集"><a href="#1-导入数据集" class="headerlink" title="1.导入数据集"></a>1.导入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">observation_window1 = pd.read_csv(<span class="string">&#x27;new_data/features_201506.csv&#x27;</span>)</span><br><span class="line">observation_window2 = pd.read_csv(<span class="string">&#x27;new_data/features_201512.csv&#x27;</span>)</span><br><span class="line">outcome_window = pd.read_csv(<span class="string">&#x27;new_data/features_201606.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="2-将前两个数据集拼接在一起"><a href="#2-将前两个数据集拼接在一起" class="headerlink" title="2.将前两个数据集拼接在一起"></a>2.将前两个数据集拼接在一起</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将两个数据集拼接在一起</span></span><br><span class="line"><span class="comment">#参数axis表示拼接的方向，0表示垂直拼接，1表示水平拼接</span></span><br><span class="line"><span class="comment">#参数ignore_index表示忽略原来索引，使新的索引连续</span></span><br><span class="line">features = pd.concat([observation_window1, observation_window2], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3-特征工程"><a href="#3-特征工程" class="headerlink" title="3.特征工程"></a>3.特征工程</h2><h3 id="3-1创建副本-删掉重复行"><a href="#3-1创建副本-删掉重复行" class="headerlink" title="3.1创建副本 删掉重复行"></a>3.1创建副本 删掉重复行</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个之前数据集的副本，检查数据集中是否还有重复行</span></span><br><span class="line"><span class="comment">#df是原数据，finaldf是副本</span></span><br><span class="line">finalDF = df.copy()</span><br><span class="line">finalDF = finalDF.drop_duplicates()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of Combined Dataframe : &quot;</span>, finalDF.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#只考虑id来识别重复列，而不是所有属性</span></span><br><span class="line"><span class="comment">#参数keep=last是保留重复项的最后一个</span></span><br><span class="line"><span class="comment">#inplace=true将结果保存会原始数据框</span></span><br><span class="line">finalDF.drop_duplicates(subset=<span class="string">&#x27;new_id&#x27;</span>, keep=<span class="string">&#x27;last&#x27;</span>, inplace=<span class="literal">True</span>, ignore_index=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of Combined Dataframe : &quot;</span>, finalDF.shape)</span><br></pre></td></tr></table></figure>
<h3 id="3-2-找到分类列和数量列"><a href="#3-2-找到分类列和数量列" class="headerlink" title="3.2 找到分类列和数量列"></a>3.2 找到分类列和数量列</h3><p>Display uniqueness in each column<br>显示df每一列的唯一值和缺失值<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">summarize_categoricals</span>(<span class="params">df, show_levels=<span class="literal">False</span></span>):</span><br><span class="line"></span><br><span class="line">    data = [[df[c].unique(), <span class="built_in">len</span>(df[c].unique()), df[c].isnull().<span class="built_in">sum</span>()] <span class="keyword">for</span> c <span class="keyword">in</span> df.columns]</span><br><span class="line">    df_temp = pd.DataFrame(data, index=df.columns,</span><br><span class="line">                           columns=[<span class="string">&#x27;Levels&#x27;</span>, <span class="string">&#x27;No. of Levels&#x27;</span>, <span class="string">&#x27;No. of Missing Values&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> df_temp.iloc[:, <span class="number">0</span> <span class="keyword">if</span> show_levels <span class="keyword">else</span> <span class="number">1</span>:]<span class="comment"># df.iloc提供了非常灵活方便的整数位置索引方法</span></span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p><strong>cutoff</strong>是分类的阈值<br>如果说一个列的唯一值数量小于10,那么他就会被判别为一列分类数据,其列名将会加入到返回的分类列表中<br>一个好的分类列应该有较少的unique值  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_categorical</span>(<span class="params">df, cutoff=<span class="number">10</span></span>):</span><br><span class="line"></span><br><span class="line">    cat_cols = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(df[col].unique()) &lt;= cutoff:</span><br><span class="line">            cat_cols.append(col)</span><br><span class="line">    <span class="keyword">return</span> cat_cols</span><br></pre></td></tr></table></figure>
<p><br></p>
<p>将指定列转换为categorical类型<br>categorical类型在pandas中meaning表示分类的数据,比普通object类型会更加高效,尤其是在内存使用上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">to_categorical</span>(<span class="params">columns, df</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">        df[col] = df[col].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>
<p><br></p>
<p>💡<strong>总结</strong>：先用<strong>summarize_categoricals</strong>统计每个特征的唯一值和空值，然后根据统计好的唯一值和空值来自动判断是不是类别特征，然后将判断为类别特征的对象转化为类别特征类型  </p>
<p><br></p>
<p>执行：  </p>
<p>找到分类列<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">categoricals = find_categorical(finalDF, cutoff=<span class="number">12</span>)</span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>找到数量列<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numericals = <span class="built_in">list</span>(<span class="built_in">set</span>(finalDF.columns.tolist()) - <span class="built_in">set</span>(categoricals)) + <span class="built_in">list</span>(<span class="built_in">set</span>(categoricals) - <span class="built_in">set</span>(finalDF.columns.tolist()))</span><br></pre></td></tr></table></figure></p>
<h3 id="3-3-删掉高相关性特征"><a href="#3-3-删掉高相关性特征" class="headerlink" title="3.3 删掉高相关性特征"></a>3.3 删掉高相关性特征</h3><p>Objective:移除特征间相关性太高的特征列</p>
<p>Inputs: </p>
<ul>
<li>x: df</li>
<li>threshold: 相关性大于此值将被移除</li>
</ul>
<p>Output: df </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">remove_collinear_features</span>(<span class="params">x, threshold = <span class="number">0.99</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算特征间的相关系数矩阵</span></span><br><span class="line">    corr_matrix = x.corr() <span class="comment">#df</span></span><br><span class="line">    iters = <span class="built_in">range</span>(<span class="built_in">len</span>(corr_matrix.columns) - <span class="number">1</span>) <span class="comment">#列名数-1，也就是索引恰好是最大范围</span></span><br><span class="line">    drop_cols = [] <span class="comment">#需要drop的列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Iterate through the correlation matrix and compare correlations</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> iters:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>):</span><br><span class="line">            item = corr_matrix.iloc[j:(j+<span class="number">1</span>), (i+<span class="number">1</span>):(i+<span class="number">2</span>)] <span class="comment"># series,切片机制的区间是[j,j+1)所以区间中所包含的元素只有j，即item就是i和j的相关系数</span></span><br><span class="line">            col = item.columns <span class="comment">#此相关系数的列名 是index对象</span></span><br><span class="line">            row = item.index <span class="comment"># 此相关系数的行名 也是index对象</span></span><br><span class="line">            val = <span class="built_in">abs</span>(item.values) <span class="comment">#相关系数的值的绝对值，ndarray类型</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果相关性高于阈值</span></span><br><span class="line">            <span class="keyword">if</span> val &gt;= threshold:</span><br><span class="line">                </span><br><span class="line">                <span class="comment">#col.values虽然只有一个元素，但是他的数据类型是ndarray数组，所以必须加上索引[0]，得到字符串类型</span></span><br><span class="line">                <span class="comment">#将该列名加入到adrop_cols中</span></span><br><span class="line">                <span class="built_in">print</span>(col.values[<span class="number">0</span>], <span class="string">&quot;|&quot;</span>, row.values[<span class="number">0</span>], <span class="string">&quot;|&quot;</span>, <span class="built_in">round</span>(val[<span class="number">0</span>][<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line">                drop_cols.append(col.values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 移除</span></span><br><span class="line">    drops = <span class="built_in">set</span>(drop_cols)</span><br><span class="line">    x = x.drop(columns=drops)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><br></p>
<p>执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#移除特征相关性超过0.9的特征并print</span></span><br><span class="line">finalDF = remove_collinear_features(finalDF, threshold = <span class="number">0.9</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="3-4-预处理-对类别特征进行one-hot编码"><a href="#3-4-预处理-对类别特征进行one-hot编码" class="headerlink" title="3.4 预处理:对类别特征进行one-hot编码"></a>3.4 预处理:对类别特征进行one-hot编码</h3><p>one-hot编码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encoding</span>(<span class="params">df, cols</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @param df pandas DataFrame</span></span><br><span class="line"><span class="string">    @param cols a list of columns to encode</span></span><br><span class="line"><span class="string">    @return a DataFrame with one-hot encoding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> cols: <span class="comment">#遍历每一列</span></span><br><span class="line">        dummies = pd.get_dummies(df[each], prefix=each, drop_first=<span class="literal">False</span>) <span class="comment">#每一列都进行onehot编码</span></span><br><span class="line">        df = pd.concat([df, dummies], axis=<span class="number">1</span>) <span class="comment">#onehot-df和原df合并</span></span><br><span class="line">        df = df.drop(each, <span class="number">1</span>) <span class="comment">#删除原始列</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>规范化处理<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">df, cols</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @param df pandas DataFrame</span></span><br><span class="line"><span class="string">    @param cols a list of columns to encode</span></span><br><span class="line"><span class="string">    @return a DataFrame with normalized specified features</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = df.copy() <span class="comment"># 原始的df不会被修改</span></span><br><span class="line">    <span class="keyword">for</span> feature_name <span class="keyword">in</span> cols:</span><br><span class="line">        max_value = df[feature_name].<span class="built_in">max</span>()</span><br><span class="line">        min_value = df[feature_name].<span class="built_in">min</span>()</span><br><span class="line">        <span class="keyword">if</span> max_value &gt; min_value:</span><br><span class="line">            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>执行：<br>对类别特征进行one-hot编码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">finalDF = one_hot_encoding(finalDF, categoricals)</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 3.5 切分成特征和标签的数据框  </span></span><br><span class="line"></span><br><span class="line">标准化数量特征</span><br><span class="line">```python</span><br><span class="line">numeric_cols = <span class="built_in">list</span>(finalDF.dtypes[finalDF.dtypes != <span class="string">&#x27;object&#x27;</span>].index) <span class="comment">#将object类型以外的特征名称加入到numeric_cols中</span></span><br><span class="line">finalDF.loc[:,numeric_cols] = scaler.fit_transform(finalDF.loc[:,numeric_cols]) <span class="comment">#标准化后在放缩到E=0,D=1</span></span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>创建分类特征和数值特征的列表<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">categorical_columns = <span class="built_in">list</span>(x.select_dtypes(include=<span class="string">&#x27;category&#x27;</span>).columns)</span><br><span class="line">numeric_columns = <span class="built_in">list</span>(x.select_dtypes(exclude=<span class="string">&#x27;category&#x27;</span>).columns)</span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>切分数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_splits = train_test_split(x, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>,</span><br><span class="line">                               shuffle=<span class="literal">True</span>)</span><br><span class="line">x_train, x_test, y_train, y_test = data_splits</span><br></pre></td></tr></table></figure></p>
<h2 id="4-模型评估"><a href="#4-模型评估" class="headerlink" title="4.模型评估"></a>4.模型评估</h2><h3 id="4-1-对训练数据进行欠采样处理"><a href="#4-1-对训练数据进行欠采样处理" class="headerlink" title="4.1 对训练数据进行欠采样处理"></a>4.1 对训练数据进行欠采样处理</h3><p>进行欠采样处理，删除掉训练数据中的一部分，使得样本数量变得平衡<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, y_train = RandomUnderSampler().fit_resample(X_train, y_train)</span><br><span class="line">Y_train = y_train.copy()</span><br></pre></td></tr></table></figure></p>
<h3 id="4-2-评估指标"><a href="#4-2-评估指标" class="headerlink" title="4.2 评估指标"></a>4.2 评估指标</h3><p>定义多个列表来存储不同评估指标<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_accuracy = [] <span class="comment">#训练集精度</span></span><br><span class="line">test_accuracy = [] <span class="comment">#测试集精度</span></span><br><span class="line">precision = [] <span class="comment">#精确率</span></span><br><span class="line">recall = [] <span class="comment">#召回率</span></span><br><span class="line">f1 = [] <span class="comment">#F1指标</span></span><br><span class="line">cohen_kappa = [] <span class="comment">#系数</span></span><br><span class="line">models = [<span class="string">&quot;Naive Bayes&quot;</span>,<span class="string">&quot;Logistic Regression&quot;</span>,<span class="string">&quot;Decision Tree&quot;</span>,<span class="string">&quot;RandomForest&quot;</span>, <span class="string">&quot;AdaBoost&quot;</span>, <span class="string">&quot;ExtraTrees&quot;</span>,<span class="string">&quot;GradientBoosting&quot;</span>,<span class="string">&quot;XGboost&quot;</span>]</span><br><span class="line">roc = [] <span class="comment">#roc曲线下的auc值</span></span><br><span class="line">mathew = [] <span class="comment">#mathew系数</span></span><br><span class="line">random_state = <span class="number">2</span> <span class="comment">#随机指数</span></span><br><span class="line">classifiers = []</span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>添加分类器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">classifiers.append(BernoulliNB())</span><br><span class="line">classifiers.append(LogisticRegression())</span><br><span class="line">classifiers.append(DecisionTreeClassifier())</span><br><span class="line">classifiers.append(RandomForestClassifier(random_state=random_state, max_depth = <span class="number">10</span>, max_features = <span class="string">&#x27;sqrt&#x27;</span>, n_estimators=  <span class="number">300</span>))</span><br><span class="line">classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=<span class="number">0.5</span>))</span><br><span class="line">classifiers.append(ExtraTreesClassifier(random_state=random_state, criterion =<span class="string">&#x27;entropy&#x27;</span>, max_features = <span class="string">&#x27;sqrt&#x27;</span>, min_samples_leaf = <span class="number">20</span>, min_samples_split = <span class="number">15</span>))</span><br><span class="line">classifiers.append(GradientBoostingClassifier(random_state=random_state, learning_rate = <span class="number">0.2</span>, max_depth = <span class="number">10</span>, n_estimators = <span class="number">200</span>))</span><br><span class="line">classifiers.append(XGBClassifier(random_state = random_state))</span><br></pre></td></tr></table></figure></p>
<p><br></p>
<p>训练不同的分类模型,并计算各种重要的评价指标<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> classifier,model <span class="keyword">in</span> <span class="built_in">zip</span>(classifiers, models):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line">    classifier.fit(X_train, y_train) <span class="comment">#训练分类模型</span></span><br><span class="line">    trainprediction = classifier.predict(X_train)</span><br><span class="line">    prediction = classifier.predict(X_test) <span class="comment">#对新数据进行预测</span></span><br><span class="line"></span><br><span class="line">    trainaccuracy = accuracy_score(y_train, trainprediction) <span class="comment">#acc</span></span><br><span class="line">    testaccuracy = accuracy_score(y_test, prediction)</span><br><span class="line">    train_accuracy.append(trainaccuracy)</span><br><span class="line">    test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">    precision.append(precision_score(y_test, prediction, average=<span class="string">&#x27;macro&#x27;</span>))<span class="comment"># precision</span></span><br><span class="line">    recall.append(recall_score(y_test, prediction, average=<span class="string">&#x27;macro&#x27;</span>))<span class="comment">#recall</span></span><br><span class="line">    cohen_kappa.append(cohen_kappa_score(y_test, prediction))<span class="comment">#kappa</span></span><br><span class="line">    f1.append(f1_score(y_test, prediction, average=<span class="string">&#x27;macro&#x27;</span>))<span class="comment">#f1</span></span><br><span class="line">    roc.append(metrics.roc_auc_score(y_test, prediction))<span class="comment">#roc</span></span><br><span class="line"></span><br><span class="line">    mathew.append(metrics.matthews_corrcoef(y_test, prediction)) <span class="comment">#mathew</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n confussion matrix:\n&#x27;</span>,confusion_matrix(y_test, prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="5-集成学习"><a href="#5-集成学习" class="headerlink" title="5.集成学习"></a>5.集成学习</h2><p>建立集成学习器(硬投票)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ensemble = VotingClassifier(estimators=[(<span class="string">&#x27;Logistic Regression&#x27;</span>, LogisticRegression(random_state = random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;Naive Bayes&#x27;</span>, GaussianNB()),</span><br><span class="line">                                              (<span class="string">&#x27;RF&#x27;</span>, RandomForestClassifier(random_state=random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;KNN&#x27;</span>, KNeighborsClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;Decision Tree&#x27;</span>, DecisionTreeClassifier(random_state=random_state))], </span><br><span class="line">                                               voting=<span class="string">&#x27;hard&#x27;</span>).fit(X_train,y_train)</span><br></pre></td></tr></table></figure></p>
<p>训练集成学习模型，并将指标存入  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_train_ensemble = ensemble.predict(X_train)</span><br><span class="line">y_pred_ensemble = ensemble.predict(X_test)</span><br><span class="line"></span><br><span class="line">trainaccuracy = accuracy_score(y_train, y_train_ensemble)</span><br><span class="line">testaccuracy = accuracy_score(y_test, y_pred_ensemble)</span><br><span class="line">train_accuracy.append(trainaccuracy)</span><br><span class="line">test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">precision.append(precision_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">recall.append(recall_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">cohen_kappa.append(cohen_kappa_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">f1.append(f1_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">roc.append(metrics.roc_auc_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">mathew.append(metrics.matthews_corrcoef(y_test, y_pred_ensemble))</span><br></pre></td></tr></table></figure>

            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2023/08/21/code-causal-analysis-churn/" data-id="cllkhxdro0000p8696xl69abr" data-title="code:causal analysis churn"
               class="article-share-link">分享</a>
            
            
            
            
    <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Causal-Analysis-Churn/" rel="tag">Causal Analysis Churn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/coding/" rel="tag">coding</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paper/" rel="tag">paper</a></li></ul>


        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
            <div class="article-nav-link-wrap article-nav-link-left">
                
                    <img data-src="https://pbs.twimg.com/media/F4GCk_yXEAA_OR2?format=jpg&amp;name=small" data-sizes="auto" alt="2023.08.22"
                         class="lazyload">
                
                <a href="/2023/08/22/2023-08-22/"></a>
                <div class="article-nav-caption">前一篇</div>
                <h3 class="article-nav-title">
                    
                        2023.08.22
                    
                </h3>
            </div>
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://pbs.twimg.com/media/F3U-edyaQAA4XIR?format=jpg&amp;name=large" data-sizes="auto" alt="2023.08.21"
                         class="lazyload">
                
                <a href="/2023/08/21/2023-08-21/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        2023.08.21
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="晴" class="lazyload">
            <div class="sidebar-author-name">晴</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">66</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">8</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">64</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
                <div class=icon-google>
                    <a href= itemprop="url" target="_blank"></a>
                </div>
            
                <div class=icon-twitter>
                    <a href=https://twitter.com/abinzzz183328 itemprop="url" target="_blank"></a>
                </div>
            
                <div class=icon-facebook>
                    <a href=https://www.facebook.com/profile.php?id=100092835102953 itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/">Essay</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/reading/">reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 16.25px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/Cover-Letter/" style="font-size: 10px;">Cover Letter</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 11.25px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Essay/" style="font-size: 20px;">Essay</a> <a href="/tags/GEAR-5/" style="font-size: 10px;">GEAR-5</a> <a href="/tags/GoAbroad/" style="font-size: 17.5px;">GoAbroad</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/IC/" style="font-size: 10px;">IC</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/T1/" style="font-size: 15px;">T1</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/University/" style="font-size: 16.25px;">University</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 11.25px;">Yuxiao Dong</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/causal-churn-word/" style="font-size: 10px;">causal churn word</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/coding/" style="font-size: 18.75px;">coding</a> <a href="/tags/dowhy/" style="font-size: 11.25px;">dowhy</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/explainer/" style="font-size: 11.25px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gym/" style="font-size: 12.5px;">gym</a> <a href="/tags/hacker/" style="font-size: 10px;">hacker</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/instructor/" style="font-size: 13.75px;">instructor</a> <a href="/tags/internship/" style="font-size: 15px;">internship</a> <a href="/tags/introduction/" style="font-size: 10px;">introduction</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/m/" style="font-size: 10px;">m</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/paper/" style="font-size: 17.5px;">paper</a> <a href="/tags/prml/" style="font-size: 13.75px;">prml</a> <a href="/tags/reading/" style="font-size: 10px;">reading</a> <a href="/tags/shap/" style="font-size: 12.5px;">shap</a> <a href="/tags/third-place/" style="font-size: 10px;">third place</a> <a href="/tags/tool/" style="font-size: 11.25px;">tool</a> <a href="/tags/wbg%E8%AF%AD%E9%9F%B3-uzi/" style="font-size: 10px;">wbg语音-uzi</a> <a href="/tags/youth/" style="font-size: 10px;">youth</a> <a href="/tags/%E4%B8%83%E5%A4%95/" style="font-size: 10px;">七夕</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E5%8D%9A%E4%BA%BA%E4%BC%A0/" style="font-size: 10px;">博人传</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%83%85%E7%BB%AA%E7%9A%84%E7%A7%98%E5%AF%86/" style="font-size: 10px;">情绪的秘密</a> <a href="/tags/%E6%8F%90%E9%97%AE/" style="font-size: 10px;">提问</a> <a href="/tags/%E6%9C%80%E9%95%BF%E7%9A%84%E7%94%B5%E5%BD%B1/" style="font-size: 10px;">最长的电影</a> <a href="/tags/%E6%AF%9B%E6%A6%82/" style="font-size: 16.25px;">毛概</a> <a href="/tags/%E7%9F%A5%E8%A1%8C%E5%90%88%E4%B8%80/" style="font-size: 10px;">知行合一</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 10px;">调研</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2023
                <span class="footer-info-sep"></span>
                晴
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    92.5k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    05:47
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="晴" class="lazyload">
            <div class="sidebar-author-name">晴</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">66</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">8</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">64</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
                <div class=icon-google>
                    <a href= itemprop="url" target="_blank"></a>
                </div>
            
                <div class=icon-twitter>
                    <a href=https://twitter.com/abinzzz183328 itemprop="url" target="_blank"></a>
                </div>
            
                <div class=icon-facebook>
                    <a href=https://www.facebook.com/profile.php?id=100092835102953 itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

