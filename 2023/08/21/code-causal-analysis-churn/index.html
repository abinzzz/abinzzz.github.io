
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <!--pjax：防止跳转页面音乐暂停-->
    <script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script> 
    <meta charset="utf-8">
    

    

    
    <title>
        code:causal analysis churn |
        
        Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="此篇文章是用来梳理&quot;paper:Causal Analysis Churn&quot;的代码  流程：  1.导入数据集 2.将前两个数据集拼接在一起 3.特征工程：  3.1创建副本 删掉重复行 3.2找到分类列和数量列 3.3删掉高相关性特征 3.4预处理：对类别特征进行one-hot编码   4.模型评估  4.1对训练数据进行欠采样处理 4.2评估指标   5.集成学习  5.1">
<meta property="og:type" content="article">
<meta property="og:title" content="code:causal analysis churn">
<meta property="og:url" content="https://abinzzz.github.io/2023/08/21/code-causal-analysis-churn/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="此篇文章是用来梳理&quot;paper:Causal Analysis Churn&quot;的代码  流程：  1.导入数据集 2.将前两个数据集拼接在一起 3.特征工程：  3.1创建副本 删掉重复行 3.2找到分类列和数量列 3.3删掉高相关性特征 3.4预处理：对类别特征进行one-hot编码   4.模型评估  4.1对训练数据进行欠采样处理 4.2评估指标   5.集成学习  5.1">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-21T05:50:30.000Z">
<meta property="article:modified_time" content="2023-08-22T13:12:39.439Z">
<meta property="article:author" content="ab">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="Causal Analysis Churn">
<meta property="article:tag" content="coding">
<meta name="twitter:card" content="summary">
    
        <link rel="alternate" href="/atom.xml" title="Blog" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
        
<link rel="stylesheet" href="https://unpkg.com/katex@0.16.7/dist/katex.min.css">

    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
    
        <img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Code.org_logo.svg/1200px-Code.org_logo.svg.png" data-sizes="auto" alt="code:causal analysis churn" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>code:causal analysis churn</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-code-causal-analysis-churn" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2023/08/21/code-causal-analysis-churn/" class="article-date-link">
        <time datetime="2023-08-21T05:50:30.000Z"
              itemprop="datePublished">2023-08-21</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/paper/">paper</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <p>此篇文章是用来梳理&quot;paper:Causal Analysis Churn&quot;的代码</p>
<br>
<p>流程：</p>
<ul>
<li>1.导入数据集</li>
<li>2.将前两个数据集拼接在一起</li>
<li>3.特征工程：
<ul>
<li>3.1创建副本 删掉重复行</li>
<li>3.2找到分类列和数量列</li>
<li>3.3删掉高相关性特征</li>
<li>3.4预处理：对类别特征进行one-hot编码</li>
</ul>
</li>
<li>4.模型评估
<ul>
<li>4.1对训练数据进行欠采样处理</li>
<li>4.2评估指标</li>
</ul>
</li>
<li>5.集成学习
<ul>
<li>5.1建立集成学习分类器-hard</li>
<li>5.2建立集成学习分类器-soft</li>
</ul>
</li>
<li>6.特征选择-随机森林变量的重要性
<ul>
<li>6.1训练随机森林分类器</li>
<li>6.2显示重要性最大的前180个</li>
<li>6.3将重要性前100个存入列表，然后将训练数据只保存前100个</li>
<li>6.4将修改后的数据集用于训练，并添加模型评价指标</li>
</ul>
</li>
<li>7.特征挑选方法-递归特征消除
<ul>
<li>7.1过采样处理，平衡样本量</li>
<li>7.2定义特征选择器，进行特征选择</li>
<li>7.3保留选择后的特征</li>
<li>7.4创建评价指标列表，并将分类器加入到model列表中</li>
<li>7.5训练模型</li>
</ul>
</li>
<li>8.在简单模型上的集成
<ul>
<li>8.1simple voting</li>
<li>8.2weight voting</li>
<li>8.3weight voting2</li>
</ul>
</li>
<li>9.基于深度学习的集成
<ul>
<li>9.1对训练数据和测试数据进行特征缩放</li>
<li>9.2定义深度学习模型：ANN1，ANN2</li>
<li>9.3进行模型训练</li>
</ul>
</li>
<li>10.ROC AUC曲线
<ul>
<li>10.1定义模型</li>
<li>10.2训练模型</li>
<li>10.3定义roc auc函数</li>
<li>10.4展示图像</li>
</ul>
</li>
<li>11.precision-recall曲线
<ul>
<li>11.1定义函数</li>
<li>11.2绘图</li>
</ul>
</li>
<li>12.dowhy归因分析</li>
<li>13.模型可解释性
<ul>
<li>13.1eli5展示特征重要性</li>
<li>13.2pdp图(部分依赖图)</li>
<li>13.3shap</li>
</ul>
</li>
</ul>
<h2 id="1导入数据集"><a class="markdownIt-Anchor" href="#1导入数据集"></a> 1.导入数据集</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">observation_window1 = pd.read_csv(<span class="string">&#x27;new_data/features_201506.csv&#x27;</span>)</span><br><span class="line">observation_window2 = pd.read_csv(<span class="string">&#x27;new_data/features_201512.csv&#x27;</span>)</span><br><span class="line">outcome_window = pd.read_csv(<span class="string">&#x27;new_data/features_201606.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="2将前两个数据集拼接在一起将observation的churn列去掉换上outcome的churn列"><a class="markdownIt-Anchor" href="#2将前两个数据集拼接在一起将observation的churn列去掉换上outcome的churn列"></a> 2.将前两个数据集拼接在一起，将observation的churn列去掉换上outcome的churn列</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将两个数据集拼接在一起</span></span><br><span class="line"><span class="comment">#参数axis表示拼接的方向，0表示垂直拼接，1表示水平拼接</span></span><br><span class="line"><span class="comment">#参数ignore_index表示忽略原来索引，使新的索引连续</span></span><br><span class="line">features = pd.concat([observation_window1, observation_window2], axis=<span class="number">0</span>, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>去掉churn列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去除数据中存款低于1500和任期低于6个月的客户数据，这样能增加预测的正确性  </span></span><br><span class="line">features = features[features[<span class="string">&#x27;acc_balance&#x27;</span>]&gt;<span class="number">1500</span>]</span><br><span class="line">features = features[features[<span class="string">&#x27;acc_tenure&#x27;</span>]&gt;<span class="number">6</span>]</span><br><span class="line">features = features.reset_index(drop = <span class="literal">True</span>) <span class="comment">#重置索引</span></span><br><span class="line">features.drop([<span class="string">&#x27;churn&#x27;</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>) <span class="comment">#删除数据中的churn列，88-1=87</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Shape of Features : &#x27;</span>, features.shape)</span><br></pre></td></tr></table></figure>
<p>添加上outcome的churn列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#outcome_window中只要id列和churn列</span></span><br><span class="line"><span class="comment">#outcome_window数据集和前两个数据集合并</span></span><br><span class="line"><span class="comment">#两个数据集不同的是feature里面的id数量更少，而且没有churn列，合并之后就会把outcome_window的churn列加入到feature中</span></span><br><span class="line">outcome_window = outcome_window[[<span class="string">&#x27;new_id&#x27;</span>, <span class="string">&#x27;churn&#x27;</span>]]</span><br><span class="line">df = pd.merge(features, outcome_window, on = <span class="string">&#x27;new_id&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3特征工程"><a class="markdownIt-Anchor" href="#3特征工程"></a> 3.特征工程</h2>
<h3 id="31创建副本-删掉重复行"><a class="markdownIt-Anchor" href="#31创建副本-删掉重复行"></a> 3.1创建副本 删掉重复行</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个之前数据集的副本，检查数据集中是否还有重复行</span></span><br><span class="line"><span class="comment">#df是原数据，finaldf是副本</span></span><br><span class="line">finalDF = df.copy()</span><br><span class="line">finalDF = finalDF.drop_duplicates()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of Combined Dataframe : &quot;</span>, finalDF.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#只考虑id来识别重复列，而不是所有属性</span></span><br><span class="line"><span class="comment">#参数keep=last是保留重复项的最后一个</span></span><br><span class="line"><span class="comment">#inplace=true将结果保存会原始数据框</span></span><br><span class="line">finalDF.drop_duplicates(subset=<span class="string">&#x27;new_id&#x27;</span>, keep=<span class="string">&#x27;last&#x27;</span>, inplace=<span class="literal">True</span>, ignore_index=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of Combined Dataframe : &quot;</span>, finalDF.shape)</span><br></pre></td></tr></table></figure>
<h3 id="32-找到分类列和数量列"><a class="markdownIt-Anchor" href="#32-找到分类列和数量列"></a> 3.2 找到分类列和数量列</h3>
<p>Display uniqueness in each column<br />
显示df每一列的唯一值和缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">summarize_categoricals</span>(<span class="params">df, show_levels=<span class="literal">False</span></span>):</span><br><span class="line"></span><br><span class="line">    data = [[df[c].unique(), <span class="built_in">len</span>(df[c].unique()), df[c].isnull().<span class="built_in">sum</span>()] <span class="keyword">for</span> c <span class="keyword">in</span> df.columns]</span><br><span class="line">    df_temp = pd.DataFrame(data, index=df.columns,</span><br><span class="line">                           columns=[<span class="string">&#x27;Levels&#x27;</span>, <span class="string">&#x27;No. of Levels&#x27;</span>, <span class="string">&#x27;No. of Missing Values&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> df_temp.iloc[:, <span class="number">0</span> <span class="keyword">if</span> show_levels <span class="keyword">else</span> <span class="number">1</span>:]<span class="comment"># df.iloc提供了非常灵活方便的整数位置索引方法</span></span><br></pre></td></tr></table></figure>
<br>
<p><strong>cutoff</strong>是分类的阈值<br />
如果说一个列的唯一值数量小于10,那么他就会被判别为一列分类数据,其列名将会加入到返回的分类列表中<br />
一个好的分类列应该有较少的unique值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_categorical</span>(<span class="params">df, cutoff=<span class="number">10</span></span>):</span><br><span class="line"></span><br><span class="line">    cat_cols = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(df[col].unique()) &lt;= cutoff:</span><br><span class="line">            cat_cols.append(col)</span><br><span class="line">    <span class="keyword">return</span> cat_cols</span><br></pre></td></tr></table></figure>
<br>
<p>将指定列转换为categorical类型<br />
categorical类型在pandas中meaning表示分类的数据,比普通object类型会更加高效,尤其是在内存使用上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">to_categorical</span>(<span class="params">columns, df</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> columns:</span><br><span class="line">        df[col] = df[col].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>
<br>
<p>💡<strong>总结</strong>：先用<strong>summarize_categoricals</strong>统计每个特征的唯一值和空值，然后根据统计好的唯一值和空值来自动判断是不是类别特征，然后将判断为类别特征的对象转化为类别特征类型</p>
<br>
<p>执行：</p>
<p>找到分类列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">categoricals = find_categorical(finalDF, cutoff=<span class="number">12</span>)</span><br></pre></td></tr></table></figure>
<br>
<p>找到数量列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numericals = <span class="built_in">list</span>(<span class="built_in">set</span>(finalDF.columns.tolist()) - <span class="built_in">set</span>(categoricals)) + <span class="built_in">list</span>(<span class="built_in">set</span>(categoricals) - <span class="built_in">set</span>(finalDF.columns.tolist()))</span><br></pre></td></tr></table></figure>
<h3 id="33-删掉高相关性特征"><a class="markdownIt-Anchor" href="#33-删掉高相关性特征"></a> 3.3 删掉高相关性特征</h3>
<p>Objective:移除特征间相关性太高的特征列</p>
<p>Inputs:</p>
<ul>
<li>x: df</li>
<li>threshold: 相关性大于此值将被移除</li>
</ul>
<p>Output: df</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">remove_collinear_features</span>(<span class="params">x, threshold = <span class="number">0.99</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算特征间的相关系数矩阵</span></span><br><span class="line">    corr_matrix = x.corr() <span class="comment">#df</span></span><br><span class="line">    iters = <span class="built_in">range</span>(<span class="built_in">len</span>(corr_matrix.columns) - <span class="number">1</span>) <span class="comment">#列名数-1，也就是索引恰好是最大范围</span></span><br><span class="line">    drop_cols = [] <span class="comment">#需要drop的列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Iterate through the correlation matrix and compare correlations</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> iters:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>):</span><br><span class="line">            item = corr_matrix.iloc[j:(j+<span class="number">1</span>), (i+<span class="number">1</span>):(i+<span class="number">2</span>)] <span class="comment"># series,切片机制的区间是[j,j+1)所以区间中所包含的元素只有j，即item就是i和j的相关系数</span></span><br><span class="line">            col = item.columns <span class="comment">#此相关系数的列名 是index对象</span></span><br><span class="line">            row = item.index <span class="comment"># 此相关系数的行名 也是index对象</span></span><br><span class="line">            val = <span class="built_in">abs</span>(item.values) <span class="comment">#相关系数的值的绝对值，ndarray类型</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果相关性高于阈值</span></span><br><span class="line">            <span class="keyword">if</span> val &gt;= threshold:</span><br><span class="line">                </span><br><span class="line">                <span class="comment">#col.values虽然只有一个元素，但是他的数据类型是ndarray数组，所以必须加上索引[0]，得到字符串类型</span></span><br><span class="line">                <span class="comment">#将该列名加入到adrop_cols中</span></span><br><span class="line">                <span class="built_in">print</span>(col.values[<span class="number">0</span>], <span class="string">&quot;|&quot;</span>, row.values[<span class="number">0</span>], <span class="string">&quot;|&quot;</span>, <span class="built_in">round</span>(val[<span class="number">0</span>][<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line">                drop_cols.append(col.values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 移除</span></span><br><span class="line">    drops = <span class="built_in">set</span>(drop_cols)</span><br><span class="line">    x = x.drop(columns=drops)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<br>
<p>执行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#移除特征相关性超过0.9的特征并print</span></span><br><span class="line">finalDF = remove_collinear_features(finalDF, threshold = <span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<h3 id="34-预处理对类别特征进行one-hot编码"><a class="markdownIt-Anchor" href="#34-预处理对类别特征进行one-hot编码"></a> 3.4 预处理:对类别特征进行one-hot编码</h3>
<p>one-hot编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encoding</span>(<span class="params">df, cols</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @param df pandas DataFrame</span></span><br><span class="line"><span class="string">    @param cols a list of columns to encode</span></span><br><span class="line"><span class="string">    @return a DataFrame with one-hot encoding</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> cols: <span class="comment">#遍历每一列</span></span><br><span class="line">        dummies = pd.get_dummies(df[each], prefix=each, drop_first=<span class="literal">False</span>) <span class="comment">#每一列都进行onehot编码</span></span><br><span class="line">        df = pd.concat([df, dummies], axis=<span class="number">1</span>) <span class="comment">#onehot-df和原df合并</span></span><br><span class="line">        df = df.drop(each, <span class="number">1</span>) <span class="comment">#删除原始列</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>
<br>
<p>规范化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">df, cols</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    @param df pandas DataFrame</span></span><br><span class="line"><span class="string">    @param cols a list of columns to encode</span></span><br><span class="line"><span class="string">    @return a DataFrame with normalized specified features</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = df.copy() <span class="comment"># 原始的df不会被修改</span></span><br><span class="line">    <span class="keyword">for</span> feature_name <span class="keyword">in</span> cols:</span><br><span class="line">        max_value = df[feature_name].<span class="built_in">max</span>()</span><br><span class="line">        min_value = df[feature_name].<span class="built_in">min</span>()</span><br><span class="line">        <span class="keyword">if</span> max_value &gt; min_value:</span><br><span class="line">            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<br>
<p>执行：<br />
对类别特征进行one-hot编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">finalDF = one_hot_encoding(finalDF, categoricals)</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 3.5 切分成特征和标签的数据框  </span></span><br><span class="line"></span><br><span class="line">标准化数量特征</span><br><span class="line">```python</span><br><span class="line">numeric_cols = <span class="built_in">list</span>(finalDF.dtypes[finalDF.dtypes != <span class="string">&#x27;object&#x27;</span>].index) <span class="comment">#将object类型以外的特征名称加入到numeric_cols中</span></span><br><span class="line">finalDF.loc[:,numeric_cols] = scaler.fit_transform(finalDF.loc[:,numeric_cols]) <span class="comment">#标准化后在放缩到E=0,D=1</span></span><br></pre></td></tr></table></figure>
<br>
<p>创建分类特征和数值特征的列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">categorical_columns = <span class="built_in">list</span>(x.select_dtypes(include=<span class="string">&#x27;category&#x27;</span>).columns)</span><br><span class="line">numeric_columns = <span class="built_in">list</span>(x.select_dtypes(exclude=<span class="string">&#x27;category&#x27;</span>).columns)</span><br></pre></td></tr></table></figure>
<br>
<p>切分数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_splits = train_test_split(x, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>,</span><br><span class="line">                               shuffle=<span class="literal">True</span>)</span><br><span class="line">x_train, x_test, y_train, y_test = data_splits</span><br></pre></td></tr></table></figure>
<h2 id="4模型评估"><a class="markdownIt-Anchor" href="#4模型评估"></a> 4.模型评估</h2>
<h3 id="41-对训练数据进行欠采样处理"><a class="markdownIt-Anchor" href="#41-对训练数据进行欠采样处理"></a> 4.1 对训练数据进行欠采样处理</h3>
<p>进行欠采样处理，删除掉训练数据中的一部分，使得样本数量变得平衡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train, y_train = RandomUnderSampler().fit_resample(X_train, y_train)</span><br><span class="line">Y_train = y_train.copy()</span><br></pre></td></tr></table></figure>
<h3 id="42-评估指标"><a class="markdownIt-Anchor" href="#42-评估指标"></a> 4.2 评估指标</h3>
<p>定义多个列表来存储不同评估指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_accuracy = [] <span class="comment">#训练集精度</span></span><br><span class="line">test_accuracy = [] <span class="comment">#测试集精度</span></span><br><span class="line">precision = [] <span class="comment">#精确率</span></span><br><span class="line">recall = [] <span class="comment">#召回率</span></span><br><span class="line">f1 = [] <span class="comment">#F1指标</span></span><br><span class="line">cohen_kappa = [] <span class="comment">#系数</span></span><br><span class="line">models = [<span class="string">&quot;Naive Bayes&quot;</span>,<span class="string">&quot;Logistic Regression&quot;</span>,<span class="string">&quot;Decision Tree&quot;</span>,<span class="string">&quot;RandomForest&quot;</span>, <span class="string">&quot;AdaBoost&quot;</span>, <span class="string">&quot;ExtraTrees&quot;</span>,<span class="string">&quot;GradientBoosting&quot;</span>,<span class="string">&quot;XGboost&quot;</span>]</span><br><span class="line">roc = [] <span class="comment">#roc曲线下的auc值</span></span><br><span class="line">mathew = [] <span class="comment">#mathew系数</span></span><br><span class="line">random_state = <span class="number">2</span> <span class="comment">#随机指数</span></span><br><span class="line">classifiers = []</span><br></pre></td></tr></table></figure>
<br>
<p>添加分类器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">classifiers.append(BernoulliNB())</span><br><span class="line">classifiers.append(LogisticRegression())</span><br><span class="line">classifiers.append(DecisionTreeClassifier())</span><br><span class="line">classifiers.append(RandomForestClassifier(random_state=random_state, max_depth = <span class="number">10</span>, max_features = <span class="string">&#x27;sqrt&#x27;</span>, n_estimators=  <span class="number">300</span>))</span><br><span class="line">classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=<span class="number">0.5</span>))</span><br><span class="line">classifiers.append(ExtraTreesClassifier(random_state=random_state, criterion =<span class="string">&#x27;entropy&#x27;</span>, max_features = <span class="string">&#x27;sqrt&#x27;</span>, min_samples_leaf = <span class="number">20</span>, min_samples_split = <span class="number">15</span>))</span><br><span class="line">classifiers.append(GradientBoostingClassifier(random_state=random_state, learning_rate = <span class="number">0.2</span>, max_depth = <span class="number">10</span>, n_estimators = <span class="number">200</span>))</span><br><span class="line">classifiers.append(XGBClassifier(random_state = random_state))</span><br></pre></td></tr></table></figure>
<br>
<p>训练不同的分类模型,并计算各种重要的评价指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> classifier,model <span class="keyword">in</span> <span class="built_in">zip</span>(classifiers, models):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line">    classifier.fit(X_train, y_train) <span class="comment">#训练分类模型</span></span><br><span class="line">    trainprediction = classifier.predict(X_train)</span><br><span class="line">    prediction = classifier.predict(X_test) <span class="comment">#对新数据进行预测</span></span><br><span class="line"></span><br><span class="line">    trainaccuracy = accuracy_score(y_train, trainprediction) <span class="comment">#acc</span></span><br><span class="line">    testaccuracy = accuracy_score(y_test, prediction)</span><br><span class="line">    train_accuracy.append(trainaccuracy)</span><br><span class="line">    test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">    precision.append(precision_score(y_test, prediction, average=<span class="string">&#x27;macro&#x27;</span>))<span class="comment"># precision</span></span><br><span class="line">    recall.append(recall_score(y_test, prediction, average=<span class="string">&#x27;macro&#x27;</span>))<span class="comment">#recall</span></span><br><span class="line">    cohen_kappa.append(cohen_kappa_score(y_test, prediction))<span class="comment">#kappa</span></span><br><span class="line">    f1.append(f1_score(y_test, prediction, average=<span class="string">&#x27;macro&#x27;</span>))<span class="comment">#f1</span></span><br><span class="line">    roc.append(metrics.roc_auc_score(y_test, prediction))<span class="comment">#roc</span></span><br><span class="line"></span><br><span class="line">    mathew.append(metrics.matthews_corrcoef(y_test, prediction)) <span class="comment">#mathew</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n confussion matrix:\n&#x27;</span>,confusion_matrix(y_test, prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="5集成学习"><a class="markdownIt-Anchor" href="#5集成学习"></a> 5.集成学习</h2>
<h3 id="51-建立集成学习器硬投票-并将指标存入"><a class="markdownIt-Anchor" href="#51-建立集成学习器硬投票-并将指标存入"></a> 5.1 建立集成学习器(硬投票)  ，并将指标存入</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nsemble = VotingClassifier(estimators=[(<span class="string">&#x27;Logistic Regression&#x27;</span>, LogisticRegression(random_state = random_state)),  </span><br><span class="line">                                       (<span class="string">&#x27;Naive Bayes&#x27;</span>, GaussianNB()),    </span><br><span class="line">                                       (<span class="string">&#x27;RF&#x27;</span>, RandomForestClassifier(random_state=random_state)),     </span><br><span class="line">                                       (<span class="string">&#x27;KNN&#x27;</span>, KNeighborsClassifier()),    </span><br><span class="line">                                       (<span class="string">&#x27;Decision Tree&#x27;</span>, DecisionTreeClassifier(random_state=random_state))],      </span><br><span class="line">                                       voting=<span class="string">&#x27;hard&#x27;</span>).fit(X_train,y_train)</span><br></pre></td></tr></table></figure>
<p>训练集成学习模型，并将指标存入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_train_ensemble = ensemble.predict(X_train)</span><br><span class="line">y_pred_ensemble = ensemble.predict(X_test)</span><br><span class="line"></span><br><span class="line">trainaccuracy = accuracy_score(y_train, y_train_ensemble)</span><br><span class="line">testaccuracy = accuracy_score(y_test, y_pred_ensemble)</span><br><span class="line">train_accuracy.append(trainaccuracy)</span><br><span class="line">test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">precision.append(precision_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">recall.append(recall_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">cohen_kappa.append(cohen_kappa_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">f1.append(f1_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">roc.append(metrics.roc_auc_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">mathew.append(metrics.matthews_corrcoef(y_test, y_pred_ensemble))</span><br></pre></td></tr></table></figure>
<h3 id="52-建立集成学习器软投票-并将指标存入"><a class="markdownIt-Anchor" href="#52-建立集成学习器软投票-并将指标存入"></a> 5.2 建立集成学习器(软投票)  ，并将指标存入</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#与ensemble1不同的是：这里是soft voting</span></span><br><span class="line">ensemble2 = VotingClassifier(estimators=[(<span class="string">&#x27;Logistic Regression&#x27;</span>, LogisticRegression(random_state = random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;Naive Bayes&#x27;</span>, GaussianNB()),</span><br><span class="line">                                              (<span class="string">&#x27;RF&#x27;</span>, RandomForestClassifier(random_state=random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;KNN&#x27;</span>, KNeighborsClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;Decision Tree&#x27;</span>, DecisionTreeClassifier(random_state=random_state))], </span><br><span class="line">                                               voting=<span class="string">&#x27;soft&#x27;</span>).fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line">y_train_ensemble2 = ensemble2.predict(X_train)</span><br><span class="line">y_pred_ensemble2 = ensemble2.predict(X_test)</span><br><span class="line"></span><br><span class="line">trainaccuracy = accuracy_score(y_train, y_train_ensemble2)</span><br><span class="line">testaccuracy = accuracy_score(y_test, y_pred_ensemble2)</span><br><span class="line">train_accuracy.append(trainaccuracy)</span><br><span class="line">test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">precision.append(precision_score(y_test, y_pred_ensemble2, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">recall.append(recall_score(y_test, y_pred_ensemble2, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">cohen_kappa.append(cohen_kappa_score(y_test, y_pred_ensemble2))</span><br><span class="line"></span><br><span class="line">f1.append(f1_score(y_test, y_pred_ensemble2, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">roc.append(metrics.roc_auc_score(y_test, y_pred_ensemble2))</span><br><span class="line"></span><br><span class="line">mathew.append(metrics.matthews_corrcoef(y_test, y_pred_ensemble2))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Accuracy Score:\n&#x27;</span>, np.<span class="built_in">round</span>(accuracy_score(y_test, y_pred_ensemble2), <span class="number">3</span>))</span><br><span class="line">sns.heatmap(confusion_matrix(y_test,y_pred_ensemble2),annot=<span class="literal">True</span>,fmt=<span class="string">&#x27;2.0f&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,y_pred_ensemble2))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Cohen Kappa Score:\n&#x27;</span>, metrics.cohen_kappa_score(y_test, y_pred_ensemble2))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="6特征选择-随机森林变量重要性"><a class="markdownIt-Anchor" href="#6特征选择-随机森林变量重要性"></a> 6.特征选择-随机森林变量重要性</h2>
<h3 id="61-训练随机森林分类器"><a class="markdownIt-Anchor" href="#61-训练随机森林分类器"></a> 6.1 训练随机森林分类器</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化随机森林分类器，并将🌲的个数设置为500</span></span><br><span class="line">clf = RandomForestClassifier(n_estimators=<span class="number">500</span>, max_depth = <span class="number">15</span>, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 用训练集拟合模型</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对测试集进行预测</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br></pre></td></tr></table></figure>
<h3 id="62-显示重要性最大的前180个"><a class="markdownIt-Anchor" href="#62-显示重要性最大的前180个"></a> 6.2 显示重要性最大的前180个</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建series对象，内容包含随机森林分类器的重要性得分</span></span><br><span class="line">feat_importances = pd.Series(clf.feature_importances_, index= X_train.columns)</span><br><span class="line"></span><br><span class="line"><span class="comment">#显示重要性最大的前180个</span></span><br><span class="line">feat_importances.nlargest(<span class="number">180</span>).plot(kind=<span class="string">&#x27;barh&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Correlation by Weights&#x27;</span>)</span><br><span class="line">plt.yticks(fontsize = <span class="number">12</span>)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<h3 id="63将重要性最高的前100个存入列表然后将训练数据中的特征只保存前100个"><a class="markdownIt-Anchor" href="#63将重要性最高的前100个存入列表然后将训练数据中的特征只保存前100个"></a> 6.3将重要性最高的前100个存入列表，然后将训练数据中的特征只保存前100个</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将重要性最高的前一百个特征存入到列表中</span></span><br><span class="line">features_to_select = feat_importances.nlargest(<span class="number">100</span>).index.tolist()</span><br><span class="line"></span><br><span class="line">X_train = X_train[features_to_select]</span><br><span class="line">X_test = X_test[features_to_select]</span><br></pre></td></tr></table></figure>
<h3 id="64将修改后的数据集用于训练并添加评价指标"><a class="markdownIt-Anchor" href="#64将修改后的数据集用于训练并添加评价指标"></a> 6.4将修改后的数据集用于训练，并添加评价指标</h3>
<p>创建评价指标，将分类器加入到模型中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">train_accuracy = []</span><br><span class="line">test_accuracy = []</span><br><span class="line">precision = []</span><br><span class="line">recall = []</span><br><span class="line">f1 = []</span><br><span class="line">cohen_kappa = []</span><br><span class="line">models = [<span class="string">&quot;Naive Bayes&quot;</span>,<span class="string">&quot;Logistic Regression&quot;</span>,<span class="string">&quot;Decision Tree&quot;</span>,<span class="string">&quot;RandomForest&quot;</span>, <span class="string">&quot;AdaBoost&quot;</span>, <span class="string">&quot;ExtraTrees&quot;</span>,<span class="string">&quot;GradientBoosting&quot;</span>,<span class="string">&quot;XGboost&quot;</span>]</span><br><span class="line">roc = []</span><br><span class="line">mathew = []</span><br><span class="line">random_state = <span class="number">2</span></span><br><span class="line">classifiers = []</span><br><span class="line">classifiers.append(BernoulliNB())</span><br><span class="line">classifiers.append(LogisticRegression())</span><br><span class="line">classifiers.append(DecisionTreeClassifier())</span><br><span class="line">classifiers.append(RandomForestClassifier(random_state=random_state, max_depth = <span class="number">15</span>, max_features = <span class="string">&#x27;auto&#x27;</span>, n_estimators=  <span class="number">500</span>))</span><br><span class="line">classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=<span class="number">0.5</span>))</span><br><span class="line">classifiers.append(ExtraTreesClassifier(random_state=random_state, criterion =<span class="string">&#x27;gini&#x27;</span>, max_features = <span class="string">&#x27;auto&#x27;</span>, min_samples_leaf = <span class="number">20</span>, min_samples_split = <span class="number">15</span>))</span><br><span class="line">classifiers.append(GradientBoostingClassifier(random_state=random_state, learning_rate = <span class="number">0.01</span>, max_depth = <span class="number">15</span>, n_estimators = <span class="number">500</span>))</span><br><span class="line">classifiers.append(XGBClassifier(random_state = random_state))</span><br></pre></td></tr></table></figure>
<p>训练模型并将指标存入列表中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> classifier,model <span class="keyword">in</span> <span class="built_in">zip</span>(classifiers, models):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line"></span><br><span class="line">    classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    trainprediction = classifier.predict(X_train)</span><br><span class="line">    prediction = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line">    trainaccuracy = accuracy_score(y_train, trainprediction)</span><br><span class="line">    testaccuracy = accuracy_score(y_test, prediction)</span><br><span class="line">    train_accuracy.append(trainaccuracy)</span><br><span class="line">    test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">    precision.append(precision_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    recall.append(recall_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    cohen_kappa.append(cohen_kappa_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    f1.append(f1_score(y_test, prediction))</span><br><span class="line">    </span><br><span class="line">    roc.append(metrics.roc_auc_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    mathew.append(metrics.matthews_corrcoef(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n confussion matrix:\n&#x27;</span>,confusion_matrix(y_test, prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scoreDF = pd.DataFrame(&#123;<span class="string">&#x27;Model&#x27;</span> : models&#125;)</span><br><span class="line">scoreDF[<span class="string">&#x27;Train Accuracy&#x27;</span>] = train_accuracy</span><br><span class="line">scoreDF[<span class="string">&#x27;Test Accuracy&#x27;</span>] = test_accuracy</span><br><span class="line">scoreDF[<span class="string">&#x27;Precision&#x27;</span>] =  precision</span><br><span class="line">scoreDF[<span class="string">&#x27;Recall&#x27;</span>] =  recall</span><br><span class="line">scoreDF[<span class="string">&#x27;F1 Score&#x27;</span>] = f1 </span><br><span class="line">scoreDF[<span class="string">&#x27;AUC Score&#x27;</span>] = roc </span><br><span class="line">scoreDF[<span class="string">&#x27;Matthew Correlation Coefficient&#x27;</span>] = mathew</span><br><span class="line">scoreDF[<span class="string">&#x27;Cohen Kappa Score&#x27;</span>] = cohen_kappa</span><br></pre></td></tr></table></figure>
<h2 id="7-特征挑选方法-递归特征消除这个方法和6是并列的关系"><a class="markdownIt-Anchor" href="#7-特征挑选方法-递归特征消除这个方法和6是并列的关系"></a> 7. 特征挑选方法-递归特征消除(这个方法和6是并列的关系)</h2>
<h3 id="71-过采样处理平衡样本量"><a class="markdownIt-Anchor" href="#71-过采样处理平衡样本量"></a> 7.1 过采样处理，平衡样本量</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line">X_train, y_train = SMOTE(<span class="string">&#x27;minority&#x27;</span>).fit_resample(X_train, y_train)</span><br><span class="line">Y_train = y_train.copy()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Train data shape: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(X_train.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test data shape: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(X_test.shape))</span><br></pre></td></tr></table></figure>
<h3 id="72-定义特征选择器进行特征选择"><a class="markdownIt-Anchor" href="#72-定义特征选择器进行特征选择"></a> 7.2 定义特征选择器，进行特征选择</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义特征选择器</span></span><br><span class="line">rfe_selector = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=<span class="number">100</span>, step=<span class="number">10</span>, verbose=<span class="number">3</span>)</span><br><span class="line">rfe_selector.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">rfe_support = rfe_selector.get_support() <span class="comment">#获取特征选择结果</span></span><br><span class="line">rfe_feature = X_train.loc[:,rfe_support].columns.tolist() <span class="comment">#将选择后的特征加入到列表中</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">str</span>(<span class="built_in">len</span>(rfe_feature)), <span class="string">&#x27;selected features&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="73-保留选择后的特征"><a class="markdownIt-Anchor" href="#73-保留选择后的特征"></a> 7.3 保留选择后的特征</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train = X_train[rfe_feature]</span><br><span class="line">X_test = X_test[rfe_feature]</span><br></pre></td></tr></table></figure>
<h3 id="74-创建评价指标列表并将分类器加入到models列表中"><a class="markdownIt-Anchor" href="#74-创建评价指标列表并将分类器加入到models列表中"></a> 7.4 创建评价指标列表，并将分类器加入到models列表中</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">train_accuracy = []</span><br><span class="line">test_accuracy = []</span><br><span class="line">precision = []</span><br><span class="line">recall = []</span><br><span class="line">f1 = []</span><br><span class="line">cohen_kappa = []</span><br><span class="line">models = [<span class="string">&quot;Naive Bayes&quot;</span>,<span class="string">&quot;Logistic Regression&quot;</span>,<span class="string">&quot;Decision Tree&quot;</span>,<span class="string">&quot;RandomForest&quot;</span>, <span class="string">&quot;AdaBoost&quot;</span>, <span class="string">&quot;ExtraTrees&quot;</span>,<span class="string">&quot;GradientBoosting&quot;</span>,<span class="string">&quot;XGboost&quot;</span>]</span><br><span class="line">roc = []</span><br><span class="line">mathew = []</span><br><span class="line">random_state = <span class="number">2</span></span><br><span class="line">classifiers = []</span><br><span class="line">classifiers.append(BernoulliNB())</span><br><span class="line">classifiers.append(LogisticRegression())</span><br><span class="line">classifiers.append(DecisionTreeClassifier())</span><br><span class="line">classifiers.append(RandomForestClassifier(random_state=random_state, max_depth = <span class="number">15</span>, max_features = <span class="string">&#x27;auto&#x27;</span>, n_estimators=  <span class="number">500</span>))</span><br><span class="line">classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=<span class="number">0.5</span>))</span><br><span class="line">classifiers.append(ExtraTreesClassifier(random_state=random_state, criterion =<span class="string">&#x27;gini&#x27;</span>, max_features = <span class="string">&#x27;auto&#x27;</span>, min_samples_leaf = <span class="number">20</span>, min_samples_split = <span class="number">15</span>))</span><br><span class="line">classifiers.append(GradientBoostingClassifier(random_state=random_state, learning_rate = <span class="number">0.01</span>, max_depth = <span class="number">15</span>, n_estimators = <span class="number">500</span>))</span><br><span class="line">classifiers.append(XGBClassifier(random_state = random_state))</span><br></pre></td></tr></table></figure>
<h3 id="75-训练模型"><a class="markdownIt-Anchor" href="#75-训练模型"></a> 7.5 训练模型</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> classifier,model <span class="keyword">in</span> <span class="built_in">zip</span>(classifiers, models):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="built_in">len</span>(model))</span><br><span class="line"></span><br><span class="line">    classifier.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    trainprediction = classifier.predict(X_train)</span><br><span class="line">    prediction = classifier.predict(X_test)</span><br><span class="line"></span><br><span class="line">    trainaccuracy = accuracy_score(y_train, trainprediction)</span><br><span class="line">    testaccuracy = accuracy_score(y_test, prediction)</span><br><span class="line">    train_accuracy.append(trainaccuracy)</span><br><span class="line">    test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">    precision.append(precision_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    recall.append(recall_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    cohen_kappa.append(cohen_kappa_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    f1.append(f1_score(y_test, prediction))</span><br><span class="line">    </span><br><span class="line">    roc.append(metrics.roc_auc_score(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    mathew.append(metrics.matthews_corrcoef(y_test, prediction))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n confussion matrix:\n&#x27;</span>,confusion_matrix(y_test, prediction))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">scoreDF = pd.DataFrame(&#123;<span class="string">&#x27;Model&#x27;</span> : models&#125;)</span><br><span class="line">scoreDF[<span class="string">&#x27;Train Accuracy&#x27;</span>] = train_accuracy</span><br><span class="line">scoreDF[<span class="string">&#x27;Test Accuracy&#x27;</span>] = test_accuracy</span><br><span class="line">scoreDF[<span class="string">&#x27;Precision&#x27;</span>] =  precision</span><br><span class="line">scoreDF[<span class="string">&#x27;Recall&#x27;</span>] =  recall</span><br><span class="line">scoreDF[<span class="string">&#x27;F1 Score&#x27;</span>] = f1 </span><br><span class="line">scoreDF[<span class="string">&#x27;AUC Score&#x27;</span>] = roc </span><br><span class="line">scoreDF[<span class="string">&#x27;Matthew Correlation Coefficient&#x27;</span>] = mathew</span><br><span class="line">scoreDF[<span class="string">&#x27;Cohen Kappa Score&#x27;</span>] = cohen_kappa</span><br></pre></td></tr></table></figure>
<h2 id="8在简单模型上的集成"><a class="markdownIt-Anchor" href="#8在简单模型上的集成"></a> 8.在简单模型上的集成</h2>
<h3 id="81-simple-voting"><a class="markdownIt-Anchor" href="#81-simple-voting"></a> 8.1 simple voting</h3>
<p>训练分类器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">LR = LogisticRegression(random_state = random_state, n_jobs=-<span class="number">1</span>)</span><br><span class="line">NB = BernoulliNB()</span><br><span class="line">KNN = KNeighborsClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">DT = DecisionTreeClassifier(random_state=random_state)</span><br><span class="line">RF = RandomForestClassifier(random_state=random_state)</span><br><span class="line">BG = BaggingClassifier()</span><br><span class="line">XGB = XGBClassifier()</span><br><span class="line">ADA = AdaBoostClassifier()</span><br><span class="line">GBM = GradientBoostingClassifier()</span><br><span class="line">ET = ExtraTreesClassifier()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LR.fit(X_train, y_train)</span><br><span class="line">NB.fit(X_train, y_train)</span><br><span class="line">RF.fit(X_train, y_train)</span><br><span class="line">KNN.fit(X_train, y_train)</span><br><span class="line">DT.fit(X_train, y_train)</span><br><span class="line">BG.fit(X_train, y_train)</span><br><span class="line">XGB.fit(X_train, y_train)</span><br><span class="line">ADA.fit(X_train, y_train)</span><br><span class="line">GBM.fit(X_train, y_train)</span><br><span class="line">ET.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<br>
<p>进行预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">LR_pred = LR.predict(X_test)</span><br><span class="line">NB_pred = NB.predict(X_test)</span><br><span class="line">RF_pred = RF.predict(X_test)</span><br><span class="line">KNN_pred = KNN.predict(X_test)</span><br><span class="line">DT_pred = DT.predict(X_test)</span><br><span class="line">BG_pred = BG.predict(X_test)</span><br><span class="line">ADA_pred = BG.predict(X_test)</span><br><span class="line">XGB_pred = BG.predict(X_test)</span><br><span class="line">ET_pred = BG.predict(X_test)</span><br><span class="line">GBM_pred = BG.predict(X_test)</span><br></pre></td></tr></table></figure>
<br>
<p>宏平均求得结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">averaged_preds = (LR_pred + NB_pred + RF_pred + KNN_pred + DT_pred + BG_pred + ADA_pred +XGB_pred + ET_pred + GBM_pred)//<span class="number">10</span></span><br><span class="line">acc = accuracy_score(y_test, averaged_preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Accuracy Score:\n&#x27;</span>, np.<span class="built_in">round</span>(acc, <span class="number">3</span>))</span><br><span class="line">                            </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,averaged_preds))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n confussion matrix:\n&#x27;</span>, metrics.confusion_matrix(y_test, averaged_preds))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Cohen Kappa Score:\n&#x27;</span>, metrics.cohen_kappa_score(y_test, averaged_preds))</span><br></pre></td></tr></table></figure>
<h3 id="82-weight-averaging"><a class="markdownIt-Anchor" href="#82-weight-averaging"></a> 8.2 weight averaging</h3>
<p>定义集成学习器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ensemble = VotingClassifier(estimators=[(<span class="string">&#x27;Logistic Regression&#x27;</span>, LogisticRegression(random_state = random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;Naive Bayes&#x27;</span>, GaussianNB()),</span><br><span class="line">                                              (<span class="string">&#x27;RF&#x27;</span>, RandomForestClassifier(random_state=random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;KNN&#x27;</span>, KNeighborsClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;Decision Tree&#x27;</span>, DecisionTreeClassifier(random_state=random_state)),</span><br><span class="line">                                       (<span class="string">&#x27;Bagging Classifier&#x27;</span>, BaggingClassifier(random_state = random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;GBM&#x27;</span>, GradientBoostingClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;ADA&#x27;</span>, AdaBoostClassifier(random_state=random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;ET&#x27;</span>, ExtraTreesClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;XGB&#x27;</span>, XGBClassifier(random_state=random_state))</span><br><span class="line">                                       </span><br><span class="line">                                       </span><br><span class="line">                                       </span><br><span class="line">                                       ], </span><br><span class="line">                                               voting=<span class="string">&#x27;hard&#x27;</span>).fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line">y_pred_ensemble = ensemble.predict(X_test)</span><br></pre></td></tr></table></figure>
<br>
<p>计算评价指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">y_train_ensemble = ensemble.predict(X_train)</span><br><span class="line">y_pred_ensemble = ensemble.predict(X_test)</span><br><span class="line"></span><br><span class="line">trainaccuracy = accuracy_score(y_train, y_train_ensemble)</span><br><span class="line">testaccuracy = accuracy_score(y_test, y_pred_ensemble)</span><br><span class="line">train_accuracy.append(trainaccuracy)</span><br><span class="line">test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">precision.append(precision_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">recall.append(recall_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">cohen_kappa.append(cohen_kappa_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">f1.append(f1_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">roc.append(metrics.roc_auc_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">mathew.append(metrics.matthews_corrcoef(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Accuracy Score:\n&#x27;</span>, np.<span class="built_in">round</span>(accuracy_score(y_test, y_pred_ensemble), <span class="number">3</span>))</span><br><span class="line">sns.heatmap(confusion_matrix(y_test,y_pred_ensemble),annot=<span class="literal">True</span>,fmt=<span class="string">&#x27;2.0f&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,y_pred_ensemble))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Cohen Kappa Score:\n&#x27;</span>, metrics.cohen_kappa_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="83-weight-averaging2"><a class="markdownIt-Anchor" href="#83-weight-averaging2"></a> 8.3 weight averaging2</h3>
<p>定义集成学习分类器并进行训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">ensemble = VotingClassifier(estimators=[(<span class="string">&#x27;Logistic Regression&#x27;</span>, LogisticRegression(random_state = random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;Naive Bayes&#x27;</span>, GaussianNB()),</span><br><span class="line">                                              (<span class="string">&#x27;RF&#x27;</span>, RandomForestClassifier(random_state=random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;KNN&#x27;</span>, KNeighborsClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;Decision Tree&#x27;</span>, DecisionTreeClassifier(random_state=random_state)),</span><br><span class="line">                                       (<span class="string">&#x27;Bagging Classifier&#x27;</span>, BaggingClassifier(random_state = random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;GBM&#x27;</span>, GradientBoostingClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;ADA&#x27;</span>, AdaBoostClassifier(random_state=random_state)),</span><br><span class="line">                                              (<span class="string">&#x27;ET&#x27;</span>, ExtraTreesClassifier()),</span><br><span class="line">                                              (<span class="string">&#x27;XGB&#x27;</span>, XGBClassifier(random_state=random_state))</span><br><span class="line">                                       </span><br><span class="line">                                       </span><br><span class="line">                                       </span><br><span class="line">                                       ], </span><br><span class="line">                                               voting=<span class="string">&#x27;soft&#x27;</span>).fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line">y_pred_ensemble = ensemble.predict(X_test)</span><br><span class="line"></span><br><span class="line">y_train_ensemble = ensemble.predict(X_train)</span><br><span class="line">y_pred_ensemble = ensemble.predict(X_test)</span><br></pre></td></tr></table></figure>
<br>
<p>计算评价指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">trainaccuracy = accuracy_score(y_train, y_train_ensemble)</span><br><span class="line">testaccuracy = accuracy_score(y_test, y_pred_ensemble)</span><br><span class="line">train_accuracy.append(trainaccuracy)</span><br><span class="line">test_accuracy.append(testaccuracy)</span><br><span class="line"></span><br><span class="line">precision.append(precision_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">recall.append(recall_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">cohen_kappa.append(cohen_kappa_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">f1.append(f1_score(y_test, y_pred_ensemble, average=<span class="string">&#x27;macro&#x27;</span>))</span><br><span class="line"></span><br><span class="line">roc.append(metrics.roc_auc_score(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line">mathew.append(metrics.matthews_corrcoef(y_test, y_pred_ensemble))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Accuracy Score:\n&#x27;</span>, np.<span class="built_in">round</span>(accuracy_score(y_test, y_pred_ensemble), <span class="number">3</span>))</span><br><span class="line">sns.heatmap(confusion_matrix(y_test,y_pred_ensemble),annot=<span class="literal">True</span>,fmt=<span class="string">&#x27;2.0f&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n clasification report:\n&#x27;</span>, classification_report(y_test,y_pred_ensemble))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n Cohen Kappa Score:\n&#x27;</span>, metrics.cohen_kappa_score(y_test, y_pred_ensemble))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="9基于深度学习的集成"><a class="markdownIt-Anchor" href="#9基于深度学习的集成"></a> 9.基于深度学习的集成</h2>
<h3 id="91对训练数据和测试数据进行特征缩放"><a class="markdownIt-Anchor" href="#91对训练数据和测试数据进行特征缩放"></a> 9.1对训练数据和测试数据进行特征缩放</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">X_train = scaler.fit_transform(X_train)<span class="comment"># 与下面那行代码不同的是：这里先进性fit，然后在将特征放缩到0，1之间</span></span><br><span class="line">X_test  = scaler.transform(X_test)</span><br></pre></td></tr></table></figure>
<h3 id="92-定义深度学习模型-ann1ann2"><a class="markdownIt-Anchor" href="#92-定义深度学习模型-ann1ann2"></a> 9.2 定义深度学习模型: ANN1,ANN2</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">model_ANN1</span>(<span class="params">input_shape=X_train.shape[<span class="number">1</span>], num_classes=<span class="number">2</span></span>):   </span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;tanh&#x27;</span>, input_dim=X_train.shape[<span class="number">1</span>]))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">8</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">    <span class="comment"># Lets add softmax activated neurons as much as number of classes</span></span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation = <span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line">    <span class="comment"># Compile the model with loss and metrics</span></span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer =  Adam(learning_rate = <span class="number">0.00001</span>, decay = <span class="number">1e-5</span>) , loss = <span class="string">&quot;binary_crossentropy&quot;</span>, metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_ANN2</span>(<span class="params">input_shape=X_train.shape[<span class="number">1</span>], num_classes=<span class="number">2</span></span>):   </span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;tanh&#x27;</span>,  input_dim=X_train.shape[<span class="number">1</span>]))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">    model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">    model.add(Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">    model.add(Dense(<span class="number">8</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">    model.add(Dense(<span class="number">4</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Lets add softmax activated neurons as much as number of classes</span></span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation = <span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line">    <span class="comment"># Compile the model with loss and metrics</span></span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer =  Adam(learning_rate = <span class="number">0.00001</span>, decay = <span class="number">1e-5</span>) , loss = <span class="string">&quot;binary_crossentropy&quot;</span>, metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h3 id="93-进行模型训练"><a class="markdownIt-Anchor" href="#93-进行模型训练"></a> 9.3 进行模型训练</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">models = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(model)):</span><br><span class="line">    model[i].fit(X_train,y_train, batch_size=<span class="number">512</span>,</span><br><span class="line">                                        epochs = <span class="number">100</span>,</span><br><span class="line">                                        validation_data = (X_test,y_test), </span><br><span class="line">                                        callbacks=[ReduceLROnPlateau(monitor=<span class="string">&#x27;loss&#x27;</span>, patience=<span class="number">3</span>, factor=<span class="number">0.1</span>)], </span><br><span class="line">                                        verbose=<span class="number">2</span>)</span><br><span class="line">    models.append(model[i])</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 9.4 打印模型指评价标  </span></span><br><span class="line">```python</span><br><span class="line">model_results =pd.DataFrame([[<span class="string">&#x27;ANN Ensemble Classifier&#x27;</span>,train_acc, acc, prec,rec, f1,roc,mathew, ck]],</span><br><span class="line">               columns = [<span class="string">&#x27;Model&#x27;</span>, <span class="string">&#x27;Train Accuracy&#x27;</span>, <span class="string">&#x27;Test Accuracy&#x27;</span>,<span class="string">&#x27;Precision&#x27;</span>, <span class="string">&#x27;Recall&#x27;</span>, <span class="string">&#x27;F1 Score&#x27;</span>,<span class="string">&#x27;AUC Score&#x27;</span>,<span class="string">&#x27;Matthew Correlation Coefficient&#x27;</span>, <span class="string">&#x27;Cohen Kappa Score&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_results = model_results.set_index(<span class="string">&#x27;Model&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model_results.index.name = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">model_results</span><br></pre></td></tr></table></figure>
<h2 id="10roc-auc曲线"><a class="markdownIt-Anchor" href="#10roc-auc曲线"></a> 10.ROC AUC曲线</h2>
<h3 id="101-定义模型"><a class="markdownIt-Anchor" href="#101-定义模型"></a> 10.1 定义模型</h3>
<p>同上</p>
<h3 id="102-训练模型"><a class="markdownIt-Anchor" href="#102-训练模型"></a> 10.2 训练模型</h3>
<p>同上</p>
<h3 id="103-定义roc-auc函数"><a class="markdownIt-Anchor" href="#103-定义roc-auc函数"></a> 10.3 定义roc auc函数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">roc_auc_plot</span>(<span class="params">y_true, y_proba, label=<span class="string">&#x27; &#x27;</span>, l=<span class="string">&#x27;-&#x27;</span>, lw=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, roc_auc_score</span><br><span class="line">    fpr, tpr, _ = roc_curve(y_true, y_proba[:,<span class="number">1</span>])</span><br><span class="line">    ax.plot(fpr, tpr, linestyle=l, linewidth=lw,</span><br><span class="line">            label=<span class="string">&quot;%s (area=%.3f)&quot;</span>%(label,roc_auc_score(y_true, y_proba[:,<span class="number">1</span>])))</span><br></pre></td></tr></table></figure>
<h3 id="104-展示图像"><a class="markdownIt-Anchor" href="#104-展示图像"></a> 10.4 展示图像</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">roc_auc_plot(y_test,LR.predict_proba(X_test),label=<span class="string">&#x27;Logsitic Regression Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,NB.predict_proba(X_test),label=<span class="string">&#x27;Naive Bayes Classifier&#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,DT.predict_proba(X_test),label=<span class="string">&#x27;Decision TreeClassifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,RF.predict_proba(X_test),label=<span class="string">&#x27;Random Forest Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,KNN.predict_proba(X_test),label=<span class="string">&#x27;KNN Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">                                               </span><br><span class="line">roc_auc_plot(y_test,BG.predict_proba(X_test),label=<span class="string">&#x27;Bagging Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,XGB.predict_proba(X_test),label=<span class="string">&#x27;XGboost&#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,ADA.predict_proba(X_test),label=<span class="string">&#x27;Adaooost Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,GBM.predict_proba(X_test),label=<span class="string">&#x27;Gradient Boosting Machine Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,ET.predict_proba(X_test),label=<span class="string">&#x27;Extra Trees Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,ensemble2.predict_proba(X_test),label=<span class="string">&#x27;Ensemble Classifier (Soft Voting) &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,ensemble2.predict_proba(X_test),label=<span class="string">&#x27;Ensemble Classifier (Hard Voting) &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">roc_auc_plot(y_test,model[<span class="number">0</span>].predict(X_test),label=<span class="string">&#x27;ANN Classifier&#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="11precision-recall曲线"><a class="markdownIt-Anchor" href="#11precision-recall曲线"></a> 11.precision-recall曲线</h2>
<h3 id="111定义函数"><a class="markdownIt-Anchor" href="#111定义函数"></a> 11.1定义函数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">precision_recall_plot</span>(<span class="params">y_true, y_proba, label=<span class="string">&#x27; &#x27;</span>, l=<span class="string">&#x27;-&#x27;</span>, lw=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve, average_precision_score</span><br><span class="line">    precision, recall, _ = precision_recall_curve(y_test,</span><br><span class="line">                                                  y_proba[:,<span class="number">1</span>])</span><br><span class="line">    average_precision = average_precision_score(y_test, y_proba[:,<span class="number">1</span>],</span><br><span class="line">                                                     average=<span class="string">&quot;micro&quot;</span>) <span class="comment">#计算微平均下的精确率</span></span><br><span class="line">    ax.plot(recall, precision, label=<span class="string">&#x27;%s (average=%.3f)&#x27;</span>%(label,average_precision),</span><br><span class="line">            linestyle=l, linewidth=lw)</span><br></pre></td></tr></table></figure>
<h3 id="112-绘图"><a class="markdownIt-Anchor" href="#112-绘图"></a> 11.2 绘图</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">precision_recall_plot(y_test,LR.predict_proba(X_test),label=<span class="string">&#x27;Logsitic Regression Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,NB.predict_proba(X_test),label=<span class="string">&#x27;Naive Bayes Classifier&#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,DT.predict_proba(X_test),label=<span class="string">&#x27;Decision TreeClassifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,RF.predict_proba(X_test),label=<span class="string">&#x27;Random Forest Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,KNN.predict_proba(X_test),label=<span class="string">&#x27;KNN Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">                                               </span><br><span class="line">precision_recall_plot(y_test,BG.predict_proba(X_test),label=<span class="string">&#x27;Bagging Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,XGB.predict_proba(X_test),label=<span class="string">&#x27;XGboost&#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,ADA.predict_proba(X_test),label=<span class="string">&#x27;Adaooost Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,GBM.predict_proba(X_test),label=<span class="string">&#x27;Gradient Boosting Machine Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,ET.predict_proba(X_test),label=<span class="string">&#x27;Extra Trees Classifier &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,ensemble2.predict_proba(X_test),label=<span class="string">&#x27;Ensemble Classifier (Soft Voting) &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,ensemble2.predict_proba(X_test),label=<span class="string">&#x27;Ensemble Classifier (Hard Voting) &#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">precision_recall_plot(y_test,model[<span class="number">0</span>].predict(X_test),label=<span class="string">&#x27;ANN Classifier&#x27;</span>,l=<span class="string">&#x27;-&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="12-dowhy-归因分析"><a class="markdownIt-Anchor" href="#12-dowhy-归因分析"></a> 12 dowhy 归因分析</h2>
<h2 id="13-模型可解释性"><a class="markdownIt-Anchor" href="#13-模型可解释性"></a> 13. 模型可解释性</h2>
<h3 id="131-eli5展示特征重要性"><a class="markdownIt-Anchor" href="#131-eli5展示特征重要性"></a> 13.1 eli5展示特征重要性</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> eli5</span><br><span class="line"><span class="keyword">from</span> eli5.sklearn <span class="keyword">import</span> PermutationImportance</span><br><span class="line"></span><br><span class="line">perm = PermutationImportance(final_model, random_state=<span class="number">1</span>).fit(X_test,y_test)</span><br><span class="line">eli5.show_weights(perm, feature_names = X_test.columns.tolist())</span><br></pre></td></tr></table></figure>
<h3 id="132-pdp图部分依赖图"><a class="markdownIt-Anchor" href="#132-pdp图部分依赖图"></a> 13.2 pdp图(部分依赖图)</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征名称</span></span><br><span class="line">features = [<span class="string">&#x27;acc_tenure&#x27;</span>,<span class="string">&#x27;cust_tenure&#x27;</span>, <span class="string">&#x27;acc_balance_change_amount&#x27;</span>,<span class="string">&#x27;fund_performance&#x27;</span>, <span class="string">&#x27;acc_balance_change_ratio&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;insurance_recency&#x27;</span>,<span class="string">&#x27;account_growth&#x27;</span>,<span class="string">&#x27;has_mobile_0&#x27;</span>,<span class="string">&#x27;num_contacts_0&#x27;</span>,<span class="string">&#x27;returned_mail_count_0&#x27;</span>,<span class="string">&#x27;login_recency&#x27;</span>,<span class="string">&#x27;num_accounts_1.0&#x27;</span>,<span class="string">&#x27;promotional_pref_M&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;postcode_change_changed&#x27;</span>,<span class="string">&#x27;has_email_0&#x27;</span>,<span class="string">&#x27;stmt_pref_M&#x27;</span>,<span class="string">&#x27;account_growth_change&#x27;</span>,<span class="string">&#x27;home_tel_change_changed&#x27;</span>,<span class="string">&#x27;email_change_same&#x27;</span>, <span class="string">&#x27;stmt_pref_change_same&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pdpbox <span class="keyword">import</span> pdp, get_dataset, info_plots</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature_name <span class="keyword">in</span> features:</span><br><span class="line">    <span class="comment"># Create the data that we will plot</span></span><br><span class="line">    pdp_goals = pdp.pdp_isolate(model=tree_model, dataset=X_test, model_features=X_train.columns.tolist(), feature=feature_name);</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plot it</span></span><br><span class="line">    pdp.pdp_plot(pdp_goals, feature_name);</span><br><span class="line">    plt.show();</span><br></pre></td></tr></table></figure>
<h3 id="133-shap"><a class="markdownIt-Anchor" href="#133-shap"></a> 13.3 shap</h3>
<p>单个数据的shap图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create object that can calculate shap values</span></span><br><span class="line">explainer = shap.TreeExplainer(tree_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate shap values. This is what we will plot.</span></span><br><span class="line"><span class="comment"># Calculate shap_values for all of val_X rather than a single row, to have more data for plot.</span></span><br><span class="line"><span class="comment"># 计算所有数据而不是单个数据</span></span><br><span class="line">shap_values = explainer.shap_values(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make plot. Index of [1] is explained in text below.</span></span><br><span class="line">shap.summary_plot(shap_values[<span class="number">1</span>],X_test)</span><br></pre></td></tr></table></figure>
<br>
<p>总体数据的shap图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create object that can calculate shap values</span></span><br><span class="line">explainer = shap.TreeExplainer(tree_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate shap values. This is what we will plot.</span></span><br><span class="line"><span class="comment"># Calculate shap_values for all of val_X rather than a single row, to have more data for plot.</span></span><br><span class="line"><span class="comment"># 计算所有数据而不是单个数据</span></span><br><span class="line">shap_values = explainer.shap_values(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make plot. Index of [1] is explained in text below.</span></span><br><span class="line">shap.summary_plot(shap_values[<span class="number">1</span>],X_test)</span><br></pre></td></tr></table></figure>
            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2023/08/21/code-causal-analysis-churn/" data-id="cls1iheat00dv9869dpdnccp0" data-title="code:causal analysis churn"
               class="article-share-link">分享</a>
            
            
            
            
    <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Causal-Analysis-Churn/" rel="tag">Causal Analysis Churn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/coding/" rel="tag">coding</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paper/" rel="tag">paper</a></li></ul>


        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
            <div class="article-nav-link-wrap article-nav-link-left">
                
                    <img data-src="http://www.alleycat.org/wp-content/uploads/2019/03/FELV-cat.jpg" data-sizes="auto" alt="审稿意见"
                         class="lazyload">
                
                <a href="/2023/08/31/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/"></a>
                <div class="article-nav-caption">前一篇</div>
                <h3 class="article-nav-title">
                    
                        审稿意见
                    
                </h3>
            </div>
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://shap.readthedocs.io/en/latest/_images/shap_header.png" data-sizes="auto" alt="shap"
                         class="lazyload">
                
                <a href="/2023/08/13/shap/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        shap
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">304</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">26</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">349</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        <iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/19zq68dbjyd7sBHyeDC1kr?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accumulate/">Accumulate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AimGraduate/">AimGraduate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Future/">Future</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bug/">bug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/internship/SNN/">SNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/spikeBERT/">spikeBERT</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/spikingjelly/">spikingjelly</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/ItWorks-SNN/">ItWorks-SNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/boring-SNN/">boring-SNN</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS231N/">CS231N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/Missing-Semester-of-CS/">Missing Semester of CS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/reading/">reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/Database/">Database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/">ML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/NNDL/">NNDL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/OS/">OS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/SE/">SE</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/d2l/">d2l</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/">智能计算系统</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/0/" style="font-size: 10px;">0</a> <a href="/tags/1/" style="font-size: 11.25px;">1</a> <a href="/tags/11-11/" style="font-size: 10px;">11.11</a> <a href="/tags/17/" style="font-size: 10px;">17</a> <a href="/tags/2/" style="font-size: 11.88px;">2</a> <a href="/tags/2-2/" style="font-size: 10px;">2-2</a> <a href="/tags/3/" style="font-size: 10.63px;">3</a> <a href="/tags/3-1/" style="font-size: 10px;">3-1</a> <a href="/tags/4/" style="font-size: 10.63px;">4</a> <a href="/tags/5/" style="font-size: 10px;">5</a> <a href="/tags/6/" style="font-size: 10px;">6</a> <a href="/tags/7/" style="font-size: 10px;">7</a> <a href="/tags/A4/" style="font-size: 10px;">A4</a> <a href="/tags/A6/" style="font-size: 10px;">A6</a> <a href="/tags/A9/" style="font-size: 11.25px;">A9</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/AI-Ethics/" style="font-size: 10px;">AI Ethics</a> <a href="/tags/Accumulate/" style="font-size: 17.5px;">Accumulate</a> <a href="/tags/Advanced-SQL/" style="font-size: 10px;">Advanced SQL</a> <a href="/tags/Advancing-Spiking-Neural-Networks-towards-Deep-Residual-Learning/" style="font-size: 11.25px;">Advancing Spiking Neural Networks towards Deep Residual Learning</a> <a href="/tags/Ai-Ethics/" style="font-size: 10px;">Ai Ethics</a> <a href="/tags/AimGraduate/" style="font-size: 13.13px;">AimGraduate</a> <a href="/tags/An-Overview-of-the-BLITZ-Computer-Hardware/" style="font-size: 10px;">An Overview of the BLITZ Computer Hardware</a> <a href="/tags/An-Overview-of-the-BLITZ-System/" style="font-size: 10px;">An Overview of the BLITZ System</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/Artificial-neural-networks/" style="font-size: 10px;">Artificial neural networks</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/BLIP/" style="font-size: 10px;">BLIP</a> <a href="/tags/BLIP-2/" style="font-size: 10px;">BLIP-2</a> <a href="/tags/BasciConception/" style="font-size: 10px;">BasciConception</a> <a href="/tags/BatchNorm/" style="font-size: 10px;">BatchNorm</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/Blitz/" style="font-size: 11.88px;">Blitz</a> <a href="/tags/CAS/" style="font-size: 10.63px;">CAS</a> <a href="/tags/CMU15-445/" style="font-size: 10px;">CMU15-445</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CS231N/" style="font-size: 10px;">CS231N</a> <a href="/tags/CV/" style="font-size: 10.63px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 13.13px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/Chapter01/" style="font-size: 10px;">Chapter01</a> <a href="/tags/Container/" style="font-size: 10px;">Container</a> <a href="/tags/Convolutional-SNN-to-Classify-FMNIST/" style="font-size: 10px;">Convolutional SNN to Classify FMNIST</a> <a href="/tags/Cover-Letter/" style="font-size: 10px;">Cover Letter</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Database/" style="font-size: 16.25px;">Database</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 10.63px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Fine-Tuning/" style="font-size: 10px;">Fine-Tuning</a> <a href="/tags/Future/" style="font-size: 12.5px;">Future</a> <a href="/tags/GB/" style="font-size: 10px;">GB</a> <a href="/tags/GNN/" style="font-size: 10px;">GNN</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GiB/" style="font-size: 10px;">GiB</a> <a href="/tags/Git/" style="font-size: 10.63px;">Git</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoAbroad/" style="font-size: 16.88px;">GoAbroad</a> <a href="/tags/Graduate/" style="font-size: 10px;">Graduate</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/IC/" style="font-size: 10px;">IC</a> <a href="/tags/IELTS/" style="font-size: 10.63px;">IELTS</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 10px;">IntelliJ IDEA</a> <a href="/tags/Intermediate-SQL/" style="font-size: 10px;">Intermediate SQL</a> <a href="/tags/Introduction/" style="font-size: 10px;">Introduction</a> <a href="/tags/Introduction-to-SQL/" style="font-size: 10px;">Introduction to SQL</a> <a href="/tags/Introduction-to-the-Relational-Model/" style="font-size: 10px;">Introduction to the Relational Model</a> <a href="/tags/ItWorks/" style="font-size: 10px;">ItWorks</a> <a href="/tags/Jianfei-Chen/" style="font-size: 10px;">Jianfei Chen</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/LMUFORMER/" style="font-size: 10px;">LMUFORMER</a> <a href="/tags/Lab1/" style="font-size: 10px;">Lab1</a> <a href="/tags/Lab3/" style="font-size: 10px;">Lab3</a> <a href="/tags/Lab4/" style="font-size: 10px;">Lab4</a> <a href="/tags/LayerNorm/" style="font-size: 10px;">LayerNorm</a> <a href="/tags/Lec01/" style="font-size: 11.25px;">Lec01</a> <a href="/tags/Lec01s/" style="font-size: 10.63px;">Lec01s</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/Linux/" style="font-size: 11.25px;">Linux</a> <a href="/tags/M2/" style="font-size: 10.63px;">M2</a> <a href="/tags/MIT6-S081/" style="font-size: 12.5px;">MIT6.S081</a> <a href="/tags/ML/" style="font-size: 13.75px;">ML</a> <a href="/tags/MS-ResNet/" style="font-size: 10px;">MS-ResNet</a> <a href="/tags/Mac/" style="font-size: 10.63px;">Mac</a> <a href="/tags/Missing-Semester/" style="font-size: 10px;">Missing Semester</a> <a href="/tags/Monitor/" style="font-size: 10px;">Monitor</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/NNDL/" style="font-size: 17.5px;">NNDL</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Neural-Network-from-Shallow-to-Deep/" style="font-size: 10px;">Neural Network from Shallow to Deep</a> <a href="/tags/Neuromorphic-computing/" style="font-size: 10px;">Neuromorphic computing</a> <a href="/tags/Neuron/" style="font-size: 10px;">Neuron</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/OS/" style="font-size: 12.5px;">OS</a> <a href="/tags/PSN/" style="font-size: 10px;">PSN</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Qingyao-Ai/" style="font-size: 10.63px;">Qingyao Ai</a> <a href="/tags/RISC-V/" style="font-size: 10px;">RISC-V</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/Readme/" style="font-size: 10px;">Readme</a> <a href="/tags/ResNet/" style="font-size: 10.63px;">ResNet</a> <a href="/tags/Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" style="font-size: 10px;">Rethinking the performance comparison between SNNS and ANNS</a> <a href="/tags/SE/" style="font-size: 11.25px;">SE</a> <a href="/tags/SE-3-0/" style="font-size: 10px;">SE-3.0</a> <a href="/tags/SNN/" style="font-size: 12.5px;">SNN</a> <a href="/tags/SNN-vs-RNN/" style="font-size: 10px;">SNN vs RNN</a> <a href="/tags/SNNNLP/" style="font-size: 10px;">SNNNLP</a> <a href="/tags/SPIKEBERT/" style="font-size: 10px;">SPIKEBERT</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/Shell/" style="font-size: 10px;">Shell</a> <a href="/tags/Single-Fully-Connected-Layer-SNN-to-Classify-MNIST/" style="font-size: 10px;">Single Fully Connected Layer SNN to Classify MNIST</a> <a href="/tags/Spiking-Neural-Network-for-Ultra-low-latency-and-High-accurate-Object-Detection/" style="font-size: 10px;">Spiking Neural Network for Ultra-low-latency and High-accurate Object Detection</a> <a href="/tags/Spiking-neural-network/" style="font-size: 10.63px;">Spiking neural network</a> <a href="/tags/Spiking-neural-networks/" style="font-size: 10px;">Spiking neural networks</a> <a href="/tags/SpikingBERT/" style="font-size: 10px;">SpikingBERT</a> <a href="/tags/Surrogate-Gradient-Method/" style="font-size: 10px;">Surrogate Gradient Method</a> <a href="/tags/T1-fighting/" style="font-size: 10.63px;">T1 fighting</a> <a href="/tags/THU/" style="font-size: 10px;">THU</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/Terminal/" style="font-size: 10px;">Terminal</a> <a href="/tags/The-Thread-Scheduler-and-Concurrency-Control-Primitives/" style="font-size: 10px;">The Thread Scheduler and Concurrency Control Primitives</a> <a href="/tags/Undergraduate/" style="font-size: 10px;">Undergraduate</a> <a href="/tags/University/" style="font-size: 13.13px;">University</a> <a href="/tags/VSCode/" style="font-size: 10px;">VSCode</a> <a href="/tags/ViT/" style="font-size: 11.25px;">ViT</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 10.63px;">Yuxiao Dong</a> <a href="/tags/Zero/" style="font-size: 10px;">Zero</a> <a href="/tags/ai-ethics/" style="font-size: 10px;">ai ethics</a> <a href="/tags/alexnet/" style="font-size: 10px;">alexnet</a> <a href="/tags/arxiv/" style="font-size: 10px;">arxiv</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/bert/" style="font-size: 11.88px;">bert</a> <a href="/tags/blitz/" style="font-size: 10px;">blitz</a> <a href="/tags/boring/" style="font-size: 11.25px;">boring</a> <a href="/tags/bug/" style="font-size: 16.88px;">bug</a> <a href="/tags/cat/" style="font-size: 10px;">cat</a> <a href="/tags/chapter00/" style="font-size: 10px;">chapter00</a> <a href="/tags/chapter01/" style="font-size: 11.25px;">chapter01</a> <a href="/tags/chapter02/" style="font-size: 10px;">chapter02</a> <a href="/tags/chapter03/" style="font-size: 10px;">chapter03</a> <a href="/tags/chapter04/" style="font-size: 10.63px;">chapter04</a> <a href="/tags/chapter05/" style="font-size: 10.63px;">chapter05</a> <a href="/tags/chatgpt/" style="font-size: 10px;">chatgpt</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/chmod/" style="font-size: 10px;">chmod</a> <a href="/tags/chrome/" style="font-size: 10px;">chrome</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/code/" style="font-size: 11.25px;">code</a> <a href="/tags/coding/" style="font-size: 10px;">coding</a> <a href="/tags/commit/" style="font-size: 10px;">commit</a> <a href="/tags/conv2d/" style="font-size: 10px;">conv2d</a> <a href="/tags/copilot/" style="font-size: 10.63px;">copilot</a> <a href="/tags/courseinfo/" style="font-size: 10px;">courseinfo</a> <a href="/tags/cpu/" style="font-size: 10px;">cpu</a> <a href="/tags/cuda/" style="font-size: 10px;">cuda</a> <a href="/tags/d2l/" style="font-size: 13.75px;">d2l</a> <a href="/tags/database/" style="font-size: 14.38px;">database</a> <a href="/tags/dataloader/" style="font-size: 10px;">dataloader</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/deep-neural-network/" style="font-size: 10.63px;">deep neural network</a> <a href="/tags/delete/" style="font-size: 10px;">delete</a> <a href="/tags/discussion/" style="font-size: 10px;">discussion</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/dowhy/" style="font-size: 10.63px;">dowhy</a> <a href="/tags/dp/" style="font-size: 10.63px;">dp</a> <a href="/tags/echo/" style="font-size: 10px;">echo</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/embedding/" style="font-size: 10px;">embedding</a> <a href="/tags/explainer/" style="font-size: 10.63px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/file/" style="font-size: 10px;">file</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 12.5px;">github</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gpu/" style="font-size: 10.63px;">gpu</a> <a href="/tags/hacker/" style="font-size: 10px;">hacker</a> <a href="/tags/handout/" style="font-size: 10px;">handout</a> <a href="/tags/hexo/" style="font-size: 10.63px;">hexo</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/import/" style="font-size: 10px;">import</a> <a href="/tags/instructor/" style="font-size: 11.88px;">instructor</a> <a href="/tags/intern-00/" style="font-size: 10px;">intern-00</a> <a href="/tags/intern00/" style="font-size: 11.88px;">intern00</a> <a href="/tags/internship/" style="font-size: 18.75px;">internship</a> <a href="/tags/introduction/" style="font-size: 11.25px;">introduction</a> <a href="/tags/iterm2/" style="font-size: 10px;">iterm2</a> <a href="/tags/knowledge-distillaion/" style="font-size: 10px;">knowledge distillaion</a> <a href="/tags/l1/" style="font-size: 10px;">l1</a> <a href="/tags/l2/" style="font-size: 10px;">l2</a> <a href="/tags/l3/" style="font-size: 10px;">l3</a> <a href="/tags/lab1/" style="font-size: 10px;">lab1</a> <a href="/tags/lab2/" style="font-size: 10.63px;">lab2</a> <a href="/tags/lec01/" style="font-size: 10px;">lec01</a> <a href="/tags/linux/" style="font-size: 11.25px;">linux</a> <a href="/tags/llava/" style="font-size: 10px;">llava</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/loss/" style="font-size: 10px;">loss</a> <a href="/tags/lstm/" style="font-size: 10px;">lstm</a> <a href="/tags/mac/" style="font-size: 12.5px;">mac</a> <a href="/tags/memory/" style="font-size: 11.25px;">memory</a> <a href="/tags/mentor/" style="font-size: 10.63px;">mentor</a> <a href="/tags/mid/" style="font-size: 10.63px;">mid</a> <a href="/tags/ml/" style="font-size: 10px;">ml</a> <a href="/tags/mlp/" style="font-size: 10px;">mlp</a> <a href="/tags/mnist/" style="font-size: 10px;">mnist</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/mysqlclient/" style="font-size: 10px;">mysqlclient</a> <a href="/tags/neuromorphic-computing/" style="font-size: 10.63px;">neuromorphic computing</a> <a href="/tags/nndl/" style="font-size: 10.63px;">nndl</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/nvidia/" style="font-size: 10px;">nvidia</a> <a href="/tags/ohmyzsh/" style="font-size: 10px;">ohmyzsh</a> <a href="/tags/os/" style="font-size: 15px;">os</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/overview/" style="font-size: 10px;">overview</a> <a href="/tags/p1/" style="font-size: 10px;">p1</a> <a href="/tags/p2/" style="font-size: 11.25px;">p2</a> <a href="/tags/p3/" style="font-size: 10px;">p3</a> <a href="/tags/paper/" style="font-size: 19.38px;">paper</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/pku/" style="font-size: 10px;">pku</a> <a href="/tags/player/" style="font-size: 10px;">player</a> <a href="/tags/preparation/" style="font-size: 10px;">preparation</a> <a href="/tags/prml/" style="font-size: 11.88px;">prml</a> <a href="/tags/profile/" style="font-size: 10px;">profile</a> <a href="/tags/project/" style="font-size: 10.63px;">project</a> <a href="/tags/pycharm/" style="font-size: 10px;">pycharm</a> <a href="/tags/pytorch/" style="font-size: 14.38px;">pytorch</a> <a href="/tags/qemu/" style="font-size: 10px;">qemu</a> <a href="/tags/question/" style="font-size: 10px;">question</a> <a href="/tags/reading/" style="font-size: 10.63px;">reading</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/review/" style="font-size: 15px;">review</a> <a href="/tags/rf/" style="font-size: 10px;">rf</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/rsa/" style="font-size: 10px;">rsa</a> <a href="/tags/se/" style="font-size: 15.63px;">se</a> <a href="/tags/self-attention/" style="font-size: 10px;">self-attention</a> <a href="/tags/server/" style="font-size: 10px;">server</a> <a href="/tags/shap/" style="font-size: 10px;">shap</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/shell-vs-terminal/" style="font-size: 10px;">shell vs terminal</a> <a href="/tags/simple/" style="font-size: 10px;">simple</a> <a href="/tags/snn/" style="font-size: 11.25px;">snn</a> <a href="/tags/solution/" style="font-size: 10px;">solution</a> <a href="/tags/sora/" style="font-size: 10px;">sora</a> <a href="/tags/spike/" style="font-size: 10.63px;">spike</a> <a href="/tags/spikeBERT/" style="font-size: 10.63px;">spikeBERT</a> <a href="/tags/spikeBert/" style="font-size: 10px;">spikeBert</a> <a href="/tags/spikebert/" style="font-size: 10px;">spikebert</a> <a href="/tags/spikingjelly/" style="font-size: 12.5px;">spikingjelly</a> <a href="/tags/spikngjelly/" style="font-size: 10.63px;">spikngjelly</a> <a href="/tags/ssh/" style="font-size: 10.63px;">ssh</a> <a href="/tags/terminal/" style="font-size: 10px;">terminal</a> <a href="/tags/test/" style="font-size: 10px;">test</a> <a href="/tags/thu/" style="font-size: 10px;">thu</a> <a href="/tags/tips/" style="font-size: 10.63px;">tips</a> <a href="/tags/tool/" style="font-size: 18.13px;">tool</a> <a href="/tags/transformer/" style="font-size: 13.13px;">transformer</a> <a href="/tags/transformers/" style="font-size: 10px;">transformers</a> <a href="/tags/uml/" style="font-size: 10px;">uml</a> <a href="/tags/vit/" style="font-size: 10px;">vit</a> <a href="/tags/vscode/" style="font-size: 10.63px;">vscode</a> <a href="/tags/wakatime/" style="font-size: 10px;">wakatime</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/xv6/" style="font-size: 10px;">xv6</a> <a href="/tags/zero/" style="font-size: 10px;">zero</a> <a href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" style="font-size: 20px;">专业知识</a> <a href="/tags/%E4%B8%93%E7%A1%95/" style="font-size: 10px;">专硕</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E4%B8%AD%E7%A7%91%E9%99%A2/" style="font-size: 10px;">中科院</a> <a href="/tags/%E5%85%AC%E9%80%89%E8%AF%BE/" style="font-size: 10px;">公选课</a> <a href="/tags/%E5%86%85%E5%AD%98/" style="font-size: 10.63px;">内存</a> <a href="/tags/%E5%86%99%E4%BD%9C%E5%BF%83%E5%BE%97/" style="font-size: 10px;">写作心得</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" style="font-size: 10px;">分布式训练</a> <a href="/tags/%E5%8A%A0%E5%88%86/" style="font-size: 10px;">加分</a> <a href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">动手学深度学习</a> <a href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/" style="font-size: 10px;">博弈论</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0%E7%94%9F%E6%88%90/" style="font-size: 10px;">图像描述生成</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" style="font-size: 10px;">基础优化方法</a> <a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">复习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 10px;">多模态</a> <a href="/tags/%E5%A4%A7%E4%B8%89%E4%B8%8A/" style="font-size: 10px;">大三上</a> <a href="/tags/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" style="font-size: 10px;">大作业</a> <a href="/tags/%E5%A4%A7%E5%88%9B/" style="font-size: 10px;">大创</a> <a href="/tags/%E5%AD%A6%E7%A1%95/" style="font-size: 10px;">学硕</a> <a href="/tags/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/" style="font-size: 10.63px;">审稿意见</a> <a href="/tags/%E5%BC%BA%E5%BC%B1com/" style="font-size: 10px;">强弱com</a> <a href="/tags/%E5%BD%A2%E5%8A%BF%E4%B8%8E%E6%94%BF%E7%AD%96/" style="font-size: 10px;">形势与政策</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%80%80%E6%8F%A3%E7%9D%80%E4%B8%80%E5%AE%9A%E5%8F%AF%E4%BB%A5%E5%81%9A%E5%A5%BD%E7%9A%84%E7%A1%AE%E4%BF%A1/" style="font-size: 10px;">怀揣着一定可以做好的确信</a> <a href="/tags/%E6%83%85%E7%BB%AA%E7%9A%84%E7%A7%98%E5%AF%86/" style="font-size: 10px;">情绪的秘密</a> <a href="/tags/%E6%8F%90%E9%97%AE/" style="font-size: 10px;">提问</a> <a href="/tags/%E6%94%B9%E7%BB%B4%E5%BA%A6/" style="font-size: 10px;">改维度</a> <a href="/tags/%E6%95%99%E8%82%B2%E8%AE%B8%E5%8F%AF/" style="font-size: 10px;">教育许可</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 10px;">数据操作+预处理</a> <a href="/tags/%E6%98%BE%E5%8D%A1/" style="font-size: 10px;">显卡</a> <a href="/tags/%E6%98%BE%E5%AD%98/" style="font-size: 10.63px;">显存</a> <a href="/tags/%E6%99%BA%E6%85%A7%E6%A0%91/" style="font-size: 10px;">智慧树</a> <a href="/tags/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" style="font-size: 14.38px;">智能计算系统</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 10.63px;">服务器</a> <a href="/tags/%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">期中复习</a> <a href="/tags/%E6%9C%9F%E6%9C%AB/" style="font-size: 10px;">期末</a> <a href="/tags/%E6%9C%B1%E8%80%81%E5%B8%88/" style="font-size: 10px;">朱老师</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9D%82%E9%A1%B9/" style="font-size: 11.25px;">杂项</a> <a href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" style="font-size: 10.63px;">李宏毅</a> <a href="/tags/%E6%9D%8E%E6%B2%90/" style="font-size: 10px;">李沐</a> <a href="/tags/%E6%A6%82%E8%AE%BA/" style="font-size: 10px;">概论</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/" style="font-size: 10px;">模型训练流程</a> <a href="/tags/%E6%AF%9B%E6%A6%82/" style="font-size: 13.13px;">毛概</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0/" style="font-size: 10.63px;">特征学习</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">环境搭建</a> <a href="/tags/%E7%94%A8%E4%BE%8B%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">用例模型</a> <a href="/tags/%E7%9F%A5%E8%A1%8C%E5%90%88%E4%B8%80/" style="font-size: 10px;">知行合一</a> <a href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">矩阵计算</a> <a href="/tags/%E7%AC%AC%E4%B8%89%E7%AB%A0/" style="font-size: 10px;">第三章</a> <a href="/tags/%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%BB%BA%E8%AE%AE%E4%B9%A6/" style="font-size: 10px;">系统开发建议书</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 10px;">线性代数</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3/" style="font-size: 10px;">脑机接口</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 10px;">脑机接口信号处理</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">自动求导</a> <a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" style="font-size: 10px;">虚拟机</a> <a href="/tags/%E8%A7%84%E5%88%99/" style="font-size: 10px;">规则</a> <a href="/tags/%E8%A7%A3%E5%8E%8B%E7%BC%A9/" style="font-size: 10px;">解压缩</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87/" style="font-size: 10px;">评测指标</a> <a href="/tags/%E8%AF%BE%E5%A0%82%E8%AE%A8%E8%AE%BA/" style="font-size: 10px;">课堂讨论</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E6%A6%82%E8%A7%88/" style="font-size: 10px;">课程概览</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E8%A1%A8/" style="font-size: 10px;">课程表</a> <a href="/tags/%E8%AF%BE%E8%AE%BE/" style="font-size: 10px;">课设</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 11.25px;">调研</a> <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 10px;">贝叶斯</a> <a href="/tags/%E8%B4%A1%E7%8C%AE%E8%80%85/" style="font-size: 10px;">贡献者</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%A6%82%E8%A6%81%E8%AE%BE%E8%AE%A1/" style="font-size: 10px;">软件概要设计</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">软件生命周期模型</a> <a href="/tags/%E8%BE%93%E5%85%A5%E6%B3%95/" style="font-size: 10px;">输入法</a> <a href="/tags/%E9%87%8F%E5%8C%96/" style="font-size: 10px;">量化</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a> <a href="/tags/%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/" style="font-size: 10px;">需求分析</a> <a href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">面向对象的需求分析建模</a> <a href="/tags/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">领域模型</a>
        </div>
    </div>


    
        

    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">一月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">十一月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    

    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2024
                <span class="footer-info-sep"></span>
                ab
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    611.6k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    39:01
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">304</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">26</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">349</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

