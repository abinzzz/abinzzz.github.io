<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>[转载]2019 Spring:微软实习面试经验</title>
    <url>/2024/03/24/2019-Spring-%E5%BE%AE%E8%BD%AF%E5%AE%9E%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h2>
<p>本篇文章转载自<a href="https://ddadaal.me/articles/2019-spring-ms-intern-interview-experiences">这里</a>。</p>
<p>经过几个月的准备、投递简历、面试以及（最令人苦恼的）等待之后，我终于在4月16日拿到了微软苏州STCA SE的实习Offer。因此，在这里我想记录下这几个月来经历过的与实习相关的事情，并分享一些关于实习和未来规划的思考。</p>
<h2 id="面试前"><a class="markdownIt-Anchor" href="#面试前"></a> 面试前</h2>
<p>面试前最重要的当然是刷题和选择职位投递简历。在这次夏季实习之前的2018年底和2019年初，我还经历了一些与微软相关的面试。此外，这次夏季实习的简历投递过程也颇为曲折，在上海和苏州的职位中犹豫不决，最终选择了苏州。以下是我投递过但最后撤回的职位的图片。</p>
<p><img src="https://pbs.twimg.com/media/GJbzAAGXMAErPqu?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="2018年底微软冬季实习"><a class="markdownIt-Anchor" href="#2018年底微软冬季实习"></a> 2018年底：微软冬季实习</h2>
<p>2018年10月，当我看到冬季实习的消息时（通过<a href="https://mp.weixin.qq.com/s?__biz=MzU1MTU2NjcxMQ==&amp;mid=2247483972&amp;idx=1&amp;sn=f145e95fa8e239730026f76241833071&amp;chksm=fb8e2e5cccf9a74aae92957bc4abd01dec2da4b2868604eaf1d59b5112bf58390776a68d4fd2&amp;mpshare=1&amp;scene=23&amp;srcid=#rd">当时的微信推送</a>），我感到非常兴奋，并迅速投递了简历，选择的职位是微软苏州STCA的SE Intern。</p>
<p>等了一个月，终于在刚下课时接到了来自苏州的电话，一听到是HR非常激动，原以为会像SAP一样进行电话面试，没想到只是询问了我可以上班的时间。我报告了1个月后（寒假期间），HR随意提了如果有进一步消息会再通知，之后就挂断了电话。后来得知这种实习通常需要3个月的时间，因此我选择放弃，最终也没收到后续通知。</p>
<h2 id="2019年1月msra和上海blockchain"><a class="markdownIt-Anchor" href="#2019年1月msra和上海blockchain"></a> 2019年1月：MSRA和上海Blockchain</h2>
<p>在俱乐部邀请了两位去过MSRA的学长学姐来介绍实习经历后（通过<a href="https://mp.weixin.qq.com/s?__biz=MzAxODAzMzczMg==&amp;mid=2659244270&amp;idx=1&amp;sn=84eefec54a126e85853b15714f532000&amp;chksm=80a805c5b7df8cd332704cef69f78060c6f00b787628bebfe2f885569b40f484d75e38787787&amp;mpshare=1&amp;scene=23&amp;srcid=#rd">俱乐部微信推送</a>），受到鼓舞，我请学长帮忙内推MSRA。接下来的面试经历在这篇文章中有详细描述，因此不再赘述。这次面试让我第一次体验了从自信到自我怀疑的全过程，最终还收获了拒绝MSRA的宝贵经历。</p>
<p>实际上，在那段时间里，除了MSRA，我还投递了上海的一个区块链相关职位（如上图所示）。在拒绝MSRA之后，我感到非常沮丧，决定放弃并继续在学院中度过半年的时间。所以，当区块链职位的HR打来电话询问面试时间时，我直接拒绝了面试机会。</p>
<p>随后，我迎来了一个本应用于刷题，但实际上在家中连LeetCode都没有打开的寒假。</p>
<h2 id="2019年2月夏季实习投递简历"><a class="markdownIt-Anchor" href="#2019年2月夏季实习投递简历"></a> 2019年2月：夏季实习投递简历</h2>
<p>寒假结束后的第一个工作日，我看到了夏季实习生开始投递简历的消息。由于刚开学，时间相对充裕，我便花了一段时间更新我的简历，并立即开始投递。简历投递经历了以下几个阶段：</p>
<ul>
<li>苏州STCA、上海C+AI、上海C+AI Open Source</li>
</ul>
<p>最初，我认为可以投递多个职位，因此在浏览实习职位列表时，除了确定要投递的苏州STCA外，我还发现了上海的两个职位。一开始我以为上海微软只有支持岗位，结果发现其实也有开发岗。特别是C+AI Open Source职位吸引了我，这个工作主要是为VSCode编写Java扩展。作为VSCode（当然还有其他微软产品，除了Surface）的忠实用户，我对这个开源项目和开发扩展的工作非常感兴趣，因此也选择了这个职位。</p>
<p>后来听说只能投递一个职位，我经过反复考虑，最终还是选择了苏州的职位，因为觉得在微软写开源代码和在微软写Java听起来非常酷，而且这样也能提高自己参与开源社区的能力，避免自己变成纯粹的螺丝钉，并且还能体验上海的生活。</p>
<p>听说有学长可以帮忙内推后，我再次陷入纠结。内推可以直接免掉笔试，但学长只能内推苏州STCA的职位，而我之前的选择是上海C+AI。最终，追求稳妥的我选择了苏州STCA的职位。</p>
<h2 id="刷题"><a class="markdownIt-Anchor" href="#刷题"></a> 刷题</h2>
<p>面试前最重要的任务就是刷题。对我而言，刷题是一件非常痛苦的事情。每遇到一个题目，我脑中几乎都是一片空白，即便刷过许多题目后也是如此。尽管设定的目标是每天解决5道题目，但大多数时间都是花2小时解决2道中等难度的题目，遇到解决不了的题目时，我就会忍不住去看解答，然后情绪崩溃，寻找3道简单题目来填补，但有时候连简单题目都解不出来。其他同学可能只刷几十道题目甚至更少就能在面试中应对自如，而我即便刷了很多题目，面对新题目时仍然感到茫然和不安。尽管其他人可能觉得刷题是一种放松和乐趣，对我来说却是一种折磨。</p>
<p>总之，这段刷题经历让我终生难忘，也是我最后选择接受内推的主要原因：我实在不想再经历刷题的痛苦了。</p>
<h2 id="面试"><a class="markdownIt-Anchor" href="#面试"></a> 面试</h2>
<p>3月1日结束了投递简历的环节，然后我就开始边刷题边焦虑地等待面试。终于，在3月12日收到了现场面试的邀请。确认了自己有空的时间后，我在3月18日收到了3月20日面试的通知，这种生日面试的体验真的很刺激。第一次面试包括两轮，每轮1小时，基本上都是在白板上做算法题。听说，只要通过一轮就能进入下一轮面试。</p>
<h3 id="第一轮"><a class="markdownIt-Anchor" href="#第一轮"></a> 第一轮</h3>
<p>第一轮面试官在随便寒暄几句后就开始了题目。题目是关于计算一个人被直接和间接关注的总人数，可以通过DFS算法来解决。虽然知道是DFS，但当时我不知怎么地想得太复杂，没能及时想出正确的解法，最后在面试官的提示下才勉强完成。这轮根据面试官的反应和个人感觉，我认为自己表现不佳。</p>
<h3 id="第二轮"><a class="markdownIt-Anchor" href="#第二轮"></a> 第二轮</h3>
<p>第二轮面试官先是询问了我的项目经验，我借机介绍了我的博客。在做题环节，第一题是关于在二叉搜索树中找到一个节点的前驱节点。这个题目相对简单，主要考查对二叉搜索树的理解和中序遍历的应用。面试官要求对解法进行优化，最终我用记录前一项的方法来减少空间复杂度。这轮面试还算顺利，虽然中途遇到了一些小困难，但总体来说完成得还不错。</p>
<h3 id="面试后"><a class="markdownIt-Anchor" href="#面试后"></a> 面试后</h3>
<p>两轮面试结束后，我对自己的表现有些担心，尤其是第一轮。但第二轮的表现还算可以，结合听说通过一轮就能进入下一轮面试的情况，我还是抱有一丝希望。令人高兴的是，3月21日我就收到了三面的安排邮件，最终在4月4日进行了三面。</p>
<h2 id="三面"><a class="markdownIt-Anchor" href="#三面"></a> 三面</h2>
<p>三面的内容较为轻松，<a href="http://xn--ReactASP-5g0my53cphgiq8ky82a.NET">主要围绕React和ASP.NET</a> Core等技术进行了深入的讨论。面试官还出了两道LeetCode原题，幸运的是，我对这两道题都比较熟悉，因此表现不错。面试结束后，我感觉整个过程还是比较顺利的。</p>
<h2 id="结果和感想"><a class="markdownIt-Anchor" href="#结果和感想"></a> 结果和感想</h2>
<p>三面结束后不久，我就收到了微软的Offer，被分配到了Office 365部门。这标志着我的春季招聘过程正式结束。回顾这几个月的经历，我感到非常充实，同时也对未来充满期待。尽管面试过程中遇到了一些挑战，但最终的成功还是让我感到非常欣慰。我期待着在微软的实习经历，希望能够学习到更多的知识，积累宝贵的经验。</p>
<p>此外，我还需要考虑一些未来的规划，比如是否继续在SAP工作，以及如何在繁重的课程和项目中找到平衡。总之，这段时间的经历让我成长了许多，我也更加清楚自己未来想要走的方向。对于未来，尽管我拿到了微软的实习offer，但还有几个重要的决定需要做：</p>
<h3 id="和sap提出离职"><a class="markdownIt-Anchor" href="#和sap提出离职"></a> 和SAP提出离职</h3>
<p>我在SAP的工作经历非常宝贵，SAP是一家非常有人文关怀的公司，不仅工作时间合理（955），而且在各种岗前培训中也能感受到SAP是真心实意地将每位员工当作人才来培养。因此，即使决定离开，我也充满感激。</p>
<h3 id="在第三学期中生存下来"><a class="markdownIt-Anchor" href="#在第三学期中生存下来"></a> 在第三学期中生存下来</h3>
<p>面对czy、zh等四门课程的轰炸，以及三个组队项目和四个大作业，压力山大。尤其是zh的四个pre和五个报告，以及上三节课就开始机考的考试模式，真是让人哭笑不得。</p>
<p>但每个阶段的挑战都是不同的。面试的挑战解决了，以前被搁置的问题又变得突出：</p>
<h3 id="工作还是保研"><a class="markdownIt-Anchor" href="#工作还是保研"></a> 工作还是保研</h3>
<p>这是一个让我纠结很久的问题。是否用两年时间换取一个更高的学历？对我来说，学历并不仅仅是为了得到更好的工作机会或是薪资问题。我更关心的是，学历作为一个硬性指标，在未来职场竞争中可能变得更加重要。但从个人角度，我确实不太想再继续学业，而是更期待能够投入到工作中，做一些真正有意义的事情。</p>
<h3 id="上海还是苏州"><a class="markdownIt-Anchor" href="#上海还是苏州"></a> 上海还是苏州</h3>
<p>这个问题也让我思考良久。尽管之前更倾向于苏州，主要是考虑到生活成本和房价等实际问题。但经过一番考察后发现，苏州的房价并没有想象中那么亲民，而且上海的薪资水平普遍较高，这让我开始重新考虑两者之间的权衡。</p>
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3>
<p>我的微软实习申请过程到此告一段落。现在最重要的是在本学期的课程中存活下来，同时也要找时间重新开始刷算法题，毕竟转正面试也是不可避免的。通过这段时间的经历，我学到了很多，也对自己未来的职业方向有了更清晰的规划。无论如何，我都期待着即将到来的微软实习经历，希望能够在那里继续成长和学习。</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>interns</tag>
      </tags>
  </entry>
  <entry>
    <title>Normalization</title>
    <url>/2024/01/25/BatchNorm-VS-LayerNorm/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/452663865">一文浅析transformer–李沐带你深入浅出transformer</a></li>
<li><a href="https://litianbo243.github.io/2019/09/14/%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82(Normalization-layers)/#%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82-Normalization-layers">归一化层(Normalization layers)</a></li>
<li><a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization</a></li>
<li><a href="https://arxiv.org/pdf/1607.06450v1.pdf">Layer Normalization</a></li>
<li><a href="https://arxiv.org/pdf/1607.08022.pdf">Instance Normalization:The Missing Ingredient for Fast Stylization</a></li>
<li><a href="https://arxiv.org/pdf/1803.08494.pdf">Group Normalization</a></li>
<li><a href="https://arxiv.org/pdf/1806.10779.pdf">DIFFERENTIABLE LEARNING-TO-NORMALIZE VIA SWITCHABLE NORMALIZATION</a></li>
</ul>
<br>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<p>归一化层，目前主要有这几个方法，Batch Normalization（2015年）、Layer Normalization（2016年）、Instance Normalization（2017年）、Group Normalization（2018年）、Switchable Normalization（2018年）；</p>
<p>将输入的图像shape记为[N, C, H, W]，这几个方法主要的区别就是在：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>归一化维度</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>BatchNorm</td>
<td>NHW</td>
<td>在batch上归一化，小batchsize效果不佳</td>
</tr>
<tr>
<td>LayerNorm</td>
<td>CHW</td>
<td>在通道方向上归一化，对RNN作用明显</td>
</tr>
<tr>
<td>InstanceNorm</td>
<td>HW</td>
<td>在图像像素上归一化，适用于风格化迁移</td>
</tr>
<tr>
<td>GroupNorm</td>
<td>分组的CHW</td>
<td>将channel分组后归一化</td>
</tr>
<tr>
<td>SwitchableNorm</td>
<td>BN/LN/IN</td>
<td>结合BN、LN、IN，赋予权重，网络自学习归一化方法选择</td>
</tr>
</tbody>
</table>
<p><img src="https://pbs.twimg.com/media/GEv93DraYAAvXaJ?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="batch-noirmalization"><a class="markdownIt-Anchor" href="#batch-noirmalization"></a> Batch Noirmalization</h2>
<p>首先，在进行训练之前，一般要对数据做归一化，使其分布一致，但是在深度神经网络训练过程中，通常以送入网络的每一个batch训练，这样每个batch具有不同的分布；此外，为了解决internal covarivate shift问题，这个问题定义是随着batch normalizaiton这篇论文提出的，在训练过程中，数据分布会发生变化，对下一层网络的学习带来困难。</p>
<p>所以batch normalization就是强行将数据拉回到均值为0，方差为1的正太分布上，这样不仅数据分布一致，而且避免发生梯度消失。</p>
<p>此外，internal corvariate shift和covariate shift是两回事，前者是网络内部，后者是针对输入数据，比如我们在训练数据前做归一化等预处理操作。</p>
<p><img src="https://pbs.twimg.com/media/GEwE-8KaIAAwkQB?format=png&amp;name=900x900" alt="" /></p>
<p>加入缩放平移变量的原因是：保证每一次数据经过归一化后还保留原有学习来的特征，同时又能完成归一化操作，加速训练。 这两个参数是用来学习的参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注：BatchNorm2d的情况则是在每个通道C上计算H、W和N的均值和方差，即每个通道上的N张图像所有像素计算均值和方差。</span><br></pre></td></tr></table></figure>
<br>
<h2 id="layer-normalization"><a class="markdownIt-Anchor" href="#layer-normalization"></a> Layer Normalization</h2>
<p><strong>batch normalization存在以下缺点</strong>：<strong>对batchsize的大小比较敏感</strong>，由于每次计算均值和方差是在一个batch上，所以如果batchsize太小，则计算的均值、方差不足以代表整个数据分布；</p>
<p>BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。</p>
<p>与BN不同，LN是针对深度网络的某一层的所有神经元的输入按以下公式进行normalize操作。</p>
<p><img src="https://pbs.twimg.com/media/GEwFCi7aMAATSia?format=png&amp;name=small" alt="" /></p>
<p>BN与LN的区别在于：</p>
<ul>
<li>LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；</li>
<li>BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</li>
</ul>
<p>所以，LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。LN用于RNN效果比较明显，但是在CNN上，不如BN</p>
<br>
<hr />
<h2 id="bn-vs-ln"><a class="markdownIt-Anchor" href="#bn-vs-ln"></a> BN VS LN</h2>
<p><strong>Batch Normalization</strong>：在特征d/通道维度做归一化，即归一化不同样本的同一特征。缺点是：</p>
<ul>
<li>计算变长序列时，变长序列后面会pad 0，这些pad部分是没有意义的，这样进行特征维度做归一化缺少实际意义。</li>
<li>序列长度变化大时，计算出来的均值和方差抖动很大。</li>
<li>预测时使用训练时记录下来的全局均值和方差。如果预测时新样本特别长，超过训练时的长度，那么超过部分是没有记录的均值和方差的，预测会出现问题。</li>
</ul>
<p><strong>Layer Normalization</strong>：在样本b维度进行归一化，即归一化一个样本所有特征。</p>
<ul>
<li>NLP任务中一个序列的所有token都是同一语义空间，进行LN归一化有实际意义</li>
<li>因为实是在每个样本内做的，序列变长时相比BN，计算的数值更稳定。</li>
<li>不需要存一个全局的均值和方差，预测样本长度不影响最终结果。</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GEwcpD7bsAAHMdc?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h3 id="二维情况下的对比"><a class="markdownIt-Anchor" href="#二维情况下的对比"></a> 二维情况下的对比</h3>
<p>BatchNorm：</p>
<p>我们模拟简单的二维的情况：每一行是一个样本 X，每一列是一个feature；</p>
<p>每次把一列（1 个 feature）放在一个 mini-batch 里，均值变成 0， 方差变成 1 的标准化</p>
<p>计算方法：（该列向量 - mini-batch 该列向量的均值）/（mini - batch 该列向量的方差）</p>
<p>训练时：mini-batch 计算均值；</p>
<p>测试时：使用 全局 均值、方差。</p>
<p>同样，BatchNorm 还会学 lambda和beta，BatchNorm 可以通过学习将向量 放缩成 任意均值、任意方差 的一个向量。</p>
<p><img src="https://pbs.twimg.com/media/GEwdEw2aoAAELmT?format=png&amp;name=small" alt="" /></p>
<br>
<p>Layernorm：</p>
<p>同样模拟简单的二维输入：LayerNorm：对每个样本做 Normalization（把每一行变成 均值为 0、方差为 1），不是对每个特征做 normalization。</p>
<p>LayerNorm 在操作上 和 BatchNorm (二维输入) 的关系 ：LayerNorm 整个把数据转置一次，放到 BatchNorm 里面出来的结果，再转置回去，基本上可以得到LayerNorm的结果。</p>
<p>上面在二维输入的情况下，简单的介绍了LN和BN之间的区别和联系，现在我们换到三维的输入来看一下。</p>
<p>在transformer和RNN中，输入的维度经常是三维：一个句子有n个词，每个词对应一个向量，再加上batch size就是三维的了。</p>
<p><img src="https://pbs.twimg.com/media/GEwkpXca8AAqt_o?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h3 id="三维情况下的对比"><a class="markdownIt-Anchor" href="#三维情况下的对比"></a> 三维情况下的对比</h3>
<p>列是sequence的输入的长度，为n。第三位是feature，是每个词的向量，在transformer里这个维度d=512。</p>
<p>在三维输入的情况下，BN和LN的计算逻辑：</p>
<p>BN：每次取一个维度的特征，蓝色框表示，拉成一个向量，均值为0，方差为1进行标准化。</p>
<p><img src="https://pbs.twimg.com/media/GEwlMEza4AA3G62?format=jpg&amp;name=medium" alt="" /></p>
<p>LN：从抽取一个特征，变成抽取一个样本，如黄色线表示</p>
<p><img src="https://pbs.twimg.com/media/GEwlVL0aoAAvZFU?format=png&amp;name=small" alt="" /></p>
<br>
<h3 id="举例分析"><a class="markdownIt-Anchor" href="#举例分析"></a> 举例分析</h3>
<p>为什么在时序数据中，LN的使用比BN更多呢？因为在时序样本中，可能很多的样本他们的长度都不一致。</p>
<p><img src="https://pbs.twimg.com/media/GEww9YQaYAAfoTw?format=png&amp;name=small" alt="" /></p>
<p>举例分析：以四个样本为例：</p>
<p>BN切出来的结果：</p>
<p>BatchNorm 计算均值和方差，有效的是阴影部分，其余是 0。</p>
<p>Mini-batch 的均值和方差：如果样本长度变化比较大的时候，每次计算小批量的均值和方差，均值和方差的抖动大。全局的均值和方差：测试时遇到一个特别长的全新样本 （红框），训练时未见过，训练时计算的均值和方差可能不好用。</p>
<p><img src="https://pbs.twimg.com/media/GEwnkDAaIAAxUYL?format=png&amp;name=360x360" alt="" /></p>
<br>
<p>LN切出来的结果如下：LayerNorm 每个样本自己算均值和方差，不需要存全局的均值和方差。LayerNorm 更稳定，不管样本长还是短，均值和方差是在每个样本内计算。</p>
<p><img src="https://pbs.twimg.com/media/GEwnoNPaAAASZr_?format=png&amp;name=360x360" alt="" /></p>
<hr />
<h2 id="instance-normalization"><a class="markdownIt-Anchor" href="#instance-normalization"></a> Instance Normalization</h2>
<p>BN注重对每个batch进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p>
<p>但是图像风格化中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。</p>
<p>和BatchNorm的区别：<br />
<img src="https://pbs.twimg.com/media/GEwHjUXbYAAAoBW?format=jpg&amp;name=large" alt="" /></p>
<br>
<h2 id="group-normalization"><a class="markdownIt-Anchor" href="#group-normalization"></a> Group Normalization</h2>
<p>主要是针对Batch Normalization对小batchsize效果差，GN将channel方向分group，然后每个group内做归一化，算(C//G)HW的均值，这样与batchsize无关，不受其约束。</p>
<br>
<h2 id="normalization-layer的作用"><a class="markdownIt-Anchor" href="#normalization-layer的作用"></a> Normalization layer的作用</h2>
<p>没有它之前，需要小心的调整学习率和权重初始化，但是有了BN可以放心的使用大学习率，但是使用了BN，就不用小心的调参了，较大的学习率极大的提高了学习速度；</p>
<ul>
<li>Batchnorm本身上也是一种正则的方式，可以代替其他正则方式如dropout等；</li>
<li>另外，个人认为，batchnorm降低了数据之间的绝对差异，有一个去相关的性质，更多的考虑相对差异性，因此在分类任务上具有更好的效果。</li>
</ul>
<p>BatchNorm为什么NB呢，关键还是效果好。不仅仅极大提升了训练速度，收敛过程大大加快，还能增加分类效果，一种解释是这是类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果。另外调参过程也简单多了，对于初始化要求没那么高，而且可以使用大的学习率等。总而言之，经过这么简单的变换，带来的好处多得很，这也是为何现在BN这么快流行起来的原因。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>BatchNorm</tag>
        <tag>LayerNorm</tag>
      </tags>
  </entry>
  <entry>
    <title>Canada and Beyond</title>
    <url>/2024/06/29/Canadas/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="加拿大签证"><a class="markdownIt-Anchor" href="#加拿大签证"></a> 加拿大签证</h2>
<ul>
<li>当前政策：收紧低端工签</li>
<li>今年：两个斯滑过签</li>
<li>明年选举，保守党占优</li>
<li>保守党政策：限制移民，减少工签数量</li>
</ul>
<h2 id="run-ca"><a class="markdownIt-Anchor" href="#run-ca"></a> run CA</h2>
<p>相比疫情之前，有点难</p>
<p>但努力还是可以的，来加拿大之前要有几段实习(有含金量，大厂)</p>
<p>什么样的人适合run：</p>
<ul>
<li>资金不要有问题–抗风险能力</li>
<li>孤独(和国内人发消息，可能需要隔天恢复)</li>
<li>加拿大环境：自然，宅，缺少大城市的繁华</li>
</ul>
<h2 id="种族歧视"><a class="markdownIt-Anchor" href="#种族歧视"></a> 种族歧视</h2>
<p>分区：富人区，贫民区，homeless<br />
文化冲突：表面工夫</p>
<h2 id="斯滑下签美国stem签证"><a class="markdownIt-Anchor" href="#斯滑下签美国stem签证"></a> 斯滑下签美国STEM签证</h2>
<p>case：有十年的旅游签 有多次美国往返记录</p>
<h2 id="本科transfer"><a class="markdownIt-Anchor" href="#本科transfer"></a> 本科transfer</h2>
<p>本转美国 签证不会卡<br />
以后就读 不会因为北邮这个被卡(建议phd期间不要回国)<br />
代价：需要钱多</p>
<h2 id="考研vs保研vs出国"><a class="markdownIt-Anchor" href="#考研vs保研vs出国"></a> 考研vs保研vs出国</h2>
<p>first：自己想要什么</p>
<p>好处：国内有3年能刷实习，本科不好，可以在研究生阶段提升自己，拿到好的offer；国外时间短，有更多的时间工作，本科也许要有一到两段的实习经历，不然最后课硕毕业之后可能无法申到大厂。</p>
<p>国内外的坏处：有可能遇到不好的导师，pua，不放实习</p>
<p>国外：花钱多</p>
<p>1.考研VS出国<br />
出国作为考研的plan B ， 找个中介可以把自己完全投入于考研，考研上这笔钱可以理解为打水漂了</p>
<p>2.保研边缘VS出国<br />
就算保研边缘均分比较低，但可以刷智慧树提升</p>
<p>3.能否保到满意的学校VS出国</p>
<h2 id="留学回国的含金量"><a class="markdownIt-Anchor" href="#留学回国的含金量"></a> 留学回国的含金量</h2>
<p>主流的HR还是认得，不用在乎一年硕就被认为水硕</p>
<h2 id="智慧树"><a class="markdownIt-Anchor" href="#智慧树"></a> 智慧树</h2>
<p>主要特别顶级的项目才会看你的成绩单，其他的无所谓。欧陆会查匹配度</p>
<h2 id="中介相关"><a class="markdownIt-Anchor" href="#中介相关"></a> 中介相关</h2>
<p>diy还是中介？</p>
<p>常见话术：我能给你找到xxx的科研，能帮你申xx的学校</p>
<p>中介存在的缘由：</p>
<ul>
<li>省时间</li>
<li>情绪价值</li>
</ul>
<p>diy：</p>
<ul>
<li>语言</li>
<li>选校定位</li>
<li>CV，PS</li>
<li>申请签证</li>
</ul>
<p>中介的鉴定：</p>
<ul>
<li>不要被pua</li>
<li>多问几家</li>
<li>各大平台有避雷贴，一定要当心</li>
<li>别对自己心存幻想和不自信</li>
<li>看买不买付费项目</li>
</ul>
<p>碰到坑中介：</p>
<ul>
<li>帮你做申请，但想要榨更多的油水</li>
<li>真正的坑中介</li>
</ul>
<p>怎么用好中介</p>
<ul>
<li>把中介当成秘书，当成搜索引擎</li>
</ul>
<h2 id="phd申请"><a class="markdownIt-Anchor" href="#phd申请"></a> phd申请</h2>
<p>新二申请全奖PHD：雅思+GRE+一篇A一作 作为门槛</p>
<p>优先级：con&gt;paper&gt;其他</p>
<p>难度：mphil &gt; phd</p>
<h2 id="bupt-vs-hongkong"><a class="markdownIt-Anchor" href="#bupt-vs-hongkong"></a> BUPT VS hongkong</h2>
<ul>
<li>资金是否足够</li>
<li>毕业之后要做什么</li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
  </entry>
  <entry>
    <title>Cuda failure &#39;out of memory&#39;</title>
    <url>/2024/03/14/Cuda-failure-out-of-memory/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="报错详情信息"><a class="markdownIt-Anchor" href="#报错详情信息"></a> 报错详情信息</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Exception has occurred: RuntimeError</span><br><span class="line">NCCL error <span class="keyword">in</span>: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:121, unhandled cuda error, NCCL version 2.14.3</span><br><span class="line">ncclUnhandledCudaError: Call to CUDA <span class="keyword">function</span> failed.</span><br><span class="line">Last error:</span><br><span class="line">Cuda failure <span class="string">&#x27;out of memory&#x27;</span></span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/common/dist_utils.py&quot;</span>, line 114, <span class="keyword">in</span> init_distributed_mode</span><br><span class="line">    torch.distributed.barrier()</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>, line 96, <span class="keyword">in</span> main</span><br><span class="line">    init_distributed_mode(cfg.run_cfg)<span class="comment">#初始化分布式训练模式</span></span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>, line 119, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">RuntimeError: NCCL error <span class="keyword">in</span>: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:121, unhandled cuda error, NCCL version 2.14.3</span><br><span class="line">ncclUnhandledCudaError: Call to CUDA <span class="keyword">function</span> failed.</span><br><span class="line">Last error:</span><br><span class="line">Cuda failure <span class="string">&#x27;out of memory&#x27;</span></span><br></pre></td></tr></table></figure>
<p>这个错误信息表明在执行分布式训练时遇到了CUDA内存不足的问题，因为GPU资源被大量占用，而当前任务又需要更多的内存资源(<strong>感觉默认先用GPU0,但GPU0被占了,所以才无法使用的</strong>)</p>
<br>
<p>这是目前GPU使用情况：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(ab) (base) root@b11a13895df1:/<span class="comment"># nvidia-smi</span></span><br><span class="line">Thu Mar 14 13:07:58 2024       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  NVIDIA GeForce ...  Off  | 00000000:1B:00.0 Off |                  N/A |</span><br><span class="line">| 73%   69C    P2   343W / 350W |  23875MiB / 24576MiB |    100%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   1  NVIDIA GeForce ...  Off  | 00000000:1C:00.0 Off |                  N/A |</span><br><span class="line">| 30%   26C    P8    21W / 350W |      0MiB / 24576MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   2  NVIDIA GeForce ...  Off  | 00000000:1D:00.0 Off |                  N/A |</span><br><span class="line">| 30%   30C    P8    10W / 350W |  20465MiB / 24576MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   3  NVIDIA GeForce ...  Off  | 00000000:1E:00.0 Off |                  N/A |</span><br><span class="line">| 70%   67C    P2   342W / 350W |  23875MiB / 24576MiB |     98%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   4  NVIDIA GeForce ...  Off  | 00000000:3D:00.0 Off |                  N/A |</span><br><span class="line">| 30%   24C    P8    26W / 350W |      2MiB / 24576MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   5  NVIDIA GeForce ...  Off  | 00000000:3F:00.0 Off |                  N/A |</span><br><span class="line">| 30%   26C    P8    26W / 350W |      0MiB / 24576MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   6  NVIDIA GeForce ...  Off  | 00000000:40:00.0 Off |                  N/A |</span><br><span class="line">| 30%   29C    P8    23W / 350W |      0MiB / 24576MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   7  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  N/A |</span><br><span class="line">| 65%   64C    P2   349W / 350W |  20109MiB / 24576MiB |    100%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0   N/A  N/A   1702935      C                                   23857MiB |</span><br><span class="line">|    2   N/A  N/A   2085163      C                                   20461MiB |</span><br><span class="line">|    3   N/A  N/A    877638      C                                   23857MiB |</span><br><span class="line">|    7   N/A  N/A   2094000      C                                   20107MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>有上面我们知道，其中GPU 0、GPU 2、GPU 3和GPU 7的内存几乎已满</p>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>系统中似乎有几个GPU（GPU 1、GPU 4、GPU 5和GPU 6）几乎未被使用，每个GPU的内存使用量仅为2MiB。尝试将训练进程指定到这些GPU上运行，通过设置CUDA_VISIBLE_DEVICES环境变量来做到这一点。</p>
<p>原指令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m torch.distributed.run --nproc_per_node=1 --master_port=2564 train.py --cfg-path lavis/projects/blip2/train/pretrain_stage1.yaml </span><br></pre></td></tr></table></figure>
<p>新指令(指定在GPU1上)：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.run --nproc_per_node=1 --master_port=2564 train.py --cfg-path lavis/projects/blip2/train/pretrain_stage1.yaml </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>cuda</tag>
        <tag>memory</tag>
        <tag>gpu</tag>
      </tags>
  </entry>
  <entry>
    <title>待完成：Chipper开通GPT4只需要40元最低的GPT Plus开通方案</title>
    <url>/2024/04/20/Chipper%E5%BC%80%E9%80%9AGPT4%E5%8F%AA%E9%9C%80%E8%A6%8140%E5%85%83%E6%9C%80%E4%BD%8E%E7%9A%84GPT-Plus%E5%BC%80%E9%80%9A%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Daily Paper | Aug 11, 2025</title>
    <url>/2025/08/11/Daily-Paper-Aug-11-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="on-the-generalization-of-sft-a-reinforcement-learning-perspective-with-reward-rectification"><a class="markdownIt-Anchor" href="#on-the-generalization-of-sft-a-reinforcement-learning-perspective-with-reward-rectification"></a> On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification</h2>
<h2 id="r-zero-self-evolving-reasoning-llm-from-zero-data"><a class="markdownIt-Anchor" href="#r-zero-self-evolving-reasoning-llm-from-zero-data"></a> R-Zero: Self-Evolving Reasoning LLM from Zero Data</h2>
<h2 id="glm-45-agentic-reasoning-and-coding-arc-foundation-models"><a class="markdownIt-Anchor" href="#glm-45-agentic-reasoning-and-coding-arc-foundation-models"></a> GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models</h2>
<h2 id="learning-to-reason-for-factuality"><a class="markdownIt-Anchor" href="#learning-to-reason-for-factuality"></a> Learning to Reason for Factuality</h2>
<h2 id="self-questioning-language-models"><a class="markdownIt-Anchor" href="#self-questioning-language-models"></a> Self-Questioning Language Models</h2>
<h2 id="genie-envisioner-a-unified-world-foundation-platform-for-robotic-manipulation"><a class="markdownIt-Anchor" href="#genie-envisioner-a-unified-world-foundation-platform-for-robotic-manipulation"></a> Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation</h2>
<h2 id="uni-cot-towards-unified-chain-of-thought-reasoning-across-text-and-vision"><a class="markdownIt-Anchor" href="#uni-cot-towards-unified-chain-of-thought-reasoning-across-text-and-vision"></a> Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision</h2>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | Aug 2, 2025</title>
    <url>/2025/08/02/Daily-Paper-Aug-2-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#persona-vectors-monitoring-and-controlling-character-traits-in-language-models">Persona Vectors: Monitoring and Controlling Character Traits in Language Models</a></li>
<li><a href="#gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis">Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</a></li>
<li><a href="#swe-debate-competitive-multi-agent-debate-for-software-issue-resolution">SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution</a></li>
<li><a href="#swe-exp-experience-driven-software-issue-resolution">SWE-Exp: Experience-Driven Software Issue Resolution</a></li>
<li><a href="#falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance">Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance</a></li>
<li><a href="#vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning">VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning</a></li>
<li><a href="#3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding">3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding</a></li>
<li><a href="#viser-imperative-web-based-3d-visualization-in-python">Viser: Imperative, Web-based 3D Visualization in Python</a></li>
<li><a href="#userbench-an-interactive-gym-environment-for-user-centric-agents">UserBench: An Interactive Gym Environment for User-Centric Agents</a></li>
<li><a href="#three-loop-banana-integrals-with-four-unequal-masses">Three-loop banana integrals with four unequal masses</a></li>
<li><a href="#on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective">On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective</a></li>
<li><a href="#unveiling-super-experts-in-mixture-of-experts-large-language-models">Unveiling Super Experts in Mixture-of-Experts Large Language Models</a></li>
<li><a href="#trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling">Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling</a></li>
<li><a href="#compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models">Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models</a></li>
</ul>
<h2 id="persona-vectors-monitoring-and-controlling-character-traits-in-language-models"><a class="markdownIt-Anchor" href="#persona-vectors-monitoring-and-controlling-character-traits-in-language-models"></a> Persona Vectors: Monitoring and Controlling Character Traits in Language Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688dda6258cb8da5c8fd4fc2.png" alt="" /></p>
<p>Github Link:  <a href="https://github.com/safety-research/persona_vectors">https://github.com/safety-research/persona_vectors</a>.<br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21509">https://www.alphaxiv.org/abs/2507.21509</a></p>
<p>The paper introduces <strong>persona vectors</strong>, which are identified as linear directions within a language model’s activation space, representing distinct character traits like “evil,” “sycophancy,” or “propensity to hallucinate.” An <strong>automated pipeline</strong> generates these vectors from natural language descriptions, enabling the <strong>monitoring of personality shifts</strong> during a model’s deployment and <strong>prediction of behavioral changes</strong> during its training. The research demonstrates that these vectors can be used to <strong>mitigate undesirable persona shifts</strong> through “steering” interventions—either by subtracting the persona vector after finetuning or by applying <strong>preventative steering</strong> during the finetuning process itself. Additionally, the study shows that <strong>analyzing training data through the lens of persona vectors</strong> can help <strong>flag problematic datasets or individual samples</strong> that might induce unintended persona shifts, even those that traditional filtering methods miss.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddc3458cb8da5c8fd5457.png" alt="" /></p>
<h2 id="gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis"><a class="markdownIt-Anchor" href="#gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis"></a> Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</h2>
<p><img src="https://pic1.imgdb.cn/item/688ddca358cb8da5c8fd5580.png" alt="" /></p>
<p>Paper Link: <a href="https://arxiv.org/abs/2507.23785">https://arxiv.org/abs/2507.23785</a><br />
Github Link: <a href="https://github.com/ForeverFancy/gvfdiffusion">https://github.com/ForeverFancy/gvfdiffusion</a></p>
<p>The paper from the University of Science and Technology of China and Microsoft Research Asia introduces Gaussian Variation Field Diffusion (GVFDiffusion), a framework that enables high-fidelity 4D content generation from a single video input. This is achieved by creating a canonical 3D Gaussian Splatting representation and generating its temporal variations via a compact latent diffusion model, resulting in significantly faster generation times and improved quality compared to prior methods.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddce658cb8da5c8fd5630.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688ddd5b58cb8da5c8fd5772.png" alt="" /></p>
<h2 id="swe-debate-competitive-multi-agent-debate-for-software-issue-resolution"><a class="markdownIt-Anchor" href="#swe-debate-competitive-multi-agent-debate-for-software-issue-resolution"></a> SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution</h2>
<p><img src="https://pic1.imgdb.cn/item/688ddd9658cb8da5c8fd5823.png" alt="" /></p>
<p>Researchers from Shanghai Jiao Tong University and Huawei developed SWE-Debate, a multi-agent debate framework leveraging graph-guided localization to resolve software issues. The system achieved a 41.4% Pass@1 success rate on the SWE-Bench-Verified dataset and 81.67% file-level localization accuracy on the SWE-Bench-Lite dataset.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddde458cb8da5c8fd5902.png" alt="" /></p>
<h2 id="swe-exp-experience-driven-software-issue-resolution"><a class="markdownIt-Anchor" href="#swe-exp-experience-driven-software-issue-resolution"></a> SWE-Exp: Experience-Driven Software Issue Resolution</h2>
<p><img src="https://pic1.imgdb.cn/item/688dde3d58cb8da5c8fd5a03.png" alt="" /></p>
<p>SWE-Exp introduces an experience-enhanced framework that enables Large Language Model agents to learn from past software issue resolution attempts, achieving a Pass@1 score of 41.6% on the SWE-bench-Verified dataset. It systematically captures and reuses knowledge via a multi-faceted experience bank and a dual-agent architecture, transforming agents from memoryless explorers into strategic, experience-driven problem solvers.</p>
<p><img src="https://pic1.imgdb.cn/item/688dde7b58cb8da5c8fd5aba.png" alt="" /></p>
<h2 id="falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance"><a class="markdownIt-Anchor" href="#falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance"></a> Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance</h2>
<p>Github Link: <a href="https://github.com/tiiuae/falcon-h1">https://github.com/tiiuae/falcon-h1</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22448">https://www.alphaxiv.org/abs/2507.22448</a></p>
<p>The Falcon LLM Team at the Technology Innovation Institute introduces Falcon-H1, a series of hybrid-head language models that integrate Transformer attention with Mamba-2 SSMs, achieving strong performance across various tasks while demonstrating enhanced parameter and training efficiency. The models set new benchmarks for efficiency and capability, particularly in reasoning-intensive domains and long-context processing, often matching or exceeding larger models.</p>
<h2 id="vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning"><a class="markdownIt-Anchor" href="#vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning"></a> VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning</h2>
<p>Github Link: <a href="https://github.com/alibaba-damo-academy/VL-Cogito">https://github.com/alibaba-damo-academy/VL-Cogito</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22607">https://www.alphaxiv.org/abs/2507.22607</a></p>
<p><img src="https://pic1.imgdb.cn/item/688ddfda58cb8da5c8fd6619.png" alt="" /></p>
<p>Researchers from Alibaba’s DAMO Academy and Fudan University developed VL-Cogito, a multimodal large language model, using a Progressive Curriculum Reinforcement Learning framework. This approach systematically enhances the model’s ability to perform complex multimodal reasoning and adaptively adjust its reasoning length, achieving competitive performance across diverse benchmarks in mathematics, science, and general understanding.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddfb058cb8da5c8fd64c2.png" alt="" /></p>
<h2 id="3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding"><a class="markdownIt-Anchor" href="#3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding"></a> 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding</h2>
<p><img src="https://pic1.imgdb.cn/item/688de00c58cb8da5c8fd67ba.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/AIGeeksGroup/3D-R1">https://github.com/AIGeeksGroup/3D-R1</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23478">https://www.alphaxiv.org/abs/2507.23478</a></p>
<p>A generalist 3D Vision-Language Model, 3D-R1, combines cold-start initialization with reinforcement learning and dynamic view selection to enhance reasoning for unified scene understanding. It achieves state-of-the-art performance across seven distinct 3D vision-language tasks, demonstrating an average improvement of 10% over prior methods.</p>
<p><img src="https://pic1.imgdb.cn/item/688de09358cb8da5c8fd6c29.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688de0c158cb8da5c8fd6dcd.png" alt="" /></p>
<h2 id="viser-imperative-web-based-3d-visualization-in-python"><a class="markdownIt-Anchor" href="#viser-imperative-web-based-3d-visualization-in-python"></a> Viser: Imperative, Web-based 3D Visualization in Python</h2>
<p><img src="https://pic1.imgdb.cn/item/688de13058cb8da5c8fd7198.png" alt="" /></p>
<p>Project Link: <a href="https://viser.studio/main/">https://viser.studio/main/</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22885">https://www.alphaxiv.org/abs/2507.22885</a></p>
<p>Viser is a Python library that offers imperative, web-based 3D visualization, addressing the need for a versatile tool that bridges the gap between lightweight and domain-specific visualization solutions. The system provides comprehensive 3D scene and 2D GUI primitives, supports real-time data streaming, and has been adopted across various computer vision and robotics research areas, including as a foundational component for neural rendering frameworks.</p>
<p><img src="https://pic1.imgdb.cn/item/688de17c58cb8da5c8fd743b.png" alt="" /></p>
<h2 id="userbench-an-interactive-gym-environment-for-user-centric-agents"><a class="markdownIt-Anchor" href="#userbench-an-interactive-gym-environment-for-user-centric-agents"></a> UserBench: An Interactive Gym Environment for User-Centric Agents</h2>
<p><img src="https://pic1.imgdb.cn/item/688de1e158cb8da5c8fd77fa.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/SalesforceAIResearch/UserBench">https://github.com/SalesforceAIResearch/UserBench</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22034">https://www.alphaxiv.org/abs/2507.22034</a></p>
<p>UserBench is an interactive Gym environment and benchmark that evaluates LLM-based agents on their ability to understand and align with user needs, particularly when instructions are underspecified, incremental, or indirect, using travel planning scenarios. Evaluations with leading LLMs revealed that models struggle significantly with user preference elicitation and making optimal, user-aligned decisions, even while demonstrating competence in tool use.</p>
<p><img src="https://pic1.imgdb.cn/item/688de25d58cb8da5c8fd7c6e.png" alt="" /></p>
<h2 id="three-loop-banana-integrals-with-four-unequal-masses"><a class="markdownIt-Anchor" href="#three-loop-banana-integrals-with-four-unequal-masses"></a> Three-loop banana integrals with four unequal masses</h2>
<p><img src="https://pic1.imgdb.cn/item/688de28a58cb8da5c8fd7e11.png" alt="" /></p>
<p>Researchers at the Bethe Center, Universität Bonn, constructed the first complete system of canonical differential equations for the master integrals of the three-loop banana diagram with four distinct unequal masses in D=2-2epsilon dimensions. This work identifies that the complex integrals can be expressed using known K3 periods and only two new fundamental iterated integrals, enabling full analytic results for precision calculations.</p>
<h2 id="on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective"><a class="markdownIt-Anchor" href="#on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective"></a> On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective</h2>
<p><strong>The paper is similar to second-order flow matching.</strong></p>
<p>Github Link: <a href="https://github.com/gmongaras/On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective">https://github.com/gmongaras/On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective</a></p>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23632">https://www.alphaxiv.org/abs/2507.23632</a></p>
<p><img src="https://pic1.imgdb.cn/item/688de2f158cb8da5c8fd814e.png" alt="" /></p>
<p>This paper, a preprint by <strong>Gabriel Mongaras</strong> and <strong>Eric C. Larson</strong> from Southern Methodist University, investigates the <strong>expressiveness of softmax attention</strong> within transformer architectures. The authors propose a novel <strong>recurrent neural network (RNN) perspective</strong> on softmax attention, demonstrating that <strong>linear attention</strong> can be understood as a <strong>first-order approximation</strong> of its more complex counterpart. They achieve this by deriving a recurrent form of softmax attention using a <strong>Taylor series expansion</strong> and then empirically evaluating this formulation against traditional softmax and various linear attention methods. The research also <strong>reinterprets the softmax denominator</strong> as either a gate or a norm, with experiments indicating that a <strong>vector norm</strong> most accurately replicates softmax’s behavior, ultimately aiming to explain why softmax attention consistently <strong>outperforms linear attention</strong> in various downstream tasks.</p>
<h2 id="unveiling-super-experts-in-mixture-of-experts-large-language-models"><a class="markdownIt-Anchor" href="#unveiling-super-experts-in-mixture-of-experts-large-language-models"></a> Unveiling Super Experts in Mixture-of-Experts Large Language Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688de50058cb8da5c8fd8f65.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/ZunhaiSu/Super-Experts-Profilling">https://github.com/ZunhaiSu/Super-Experts-Profilling</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23279">https://www.alphaxiv.org/abs/2507.23279</a></p>
<p>Researchers from Tsinghua University and Meituan identified “Super Experts” (SEs) in Mixture-of-Experts Large Language Models, a tiny subset of experts (less than 0.5%) that are mechanistically responsible for inducing massive activations and crucial attention sinks. Removing these SEs leads to a catastrophic collapse in model performance, particularly for reasoning tasks, highlighting their indispensable role in maintaining core LLM capabilities.</p>
<p><img src="https://pic1.imgdb.cn/item/688de56e58cb8da5c8fd9117.png" alt="" /></p>
<h2 id="trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling"><a class="markdownIt-Anchor" href="#trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling"></a> Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling</h2>
<p>Github Link: <a href="https://github.com/bytedance/trae-agent">https://github.com/bytedance/trae-agent</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23370">https://www.alphaxiv.org/abs/2507.23370</a></p>
<p>Software issue resolution is a critical challenge in software engineering and has garnered increasing attention in recent years. With the rapid advancement of large language models (LLMs), substantial progress has been made in addressing real-world software engineering tasks. Recent studies have introduced ensemble reasoning techniques to enhance the performance of LLM-based issue resolution. However, existing prompting-based methods still face limitations in effectively exploring large ensemble spaces and lack the capacity for repository-level understanding, both of which constrain their overall effectiveness. In this paper, we propose Trae Agent, the first agent-based ensemble reasoning approach for repository-level issue resolution. Trae Agent formulates our goal as an optimal solution search problem and addresses two key challenges, i.e., large ensemble spaces and repository-level understanding, through modular agents for generation, pruning, and selection. We conduct extensive experiments using three leading LLMs on the widely-adopted SWE-bench benchmark, comparing Trae Agent against four state-of-the-art ensemble reasoning techniques. Experimental results demonstrate that Trae Agent consistently achieves superior performance, with an average improvement of 10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of 75.20%.</p>
<p><img src="https://pic1.imgdb.cn/item/688de63d58cb8da5c8fd93c6.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688de68458cb8da5c8fd9487.png" alt="" /></p>
<h2 id="compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models"><a class="markdownIt-Anchor" href="#compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models"></a> Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688de6e558cb8da5c8fd9519.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/lavoiems/DiscreteLatentCode">https://github.com/lavoiems/DiscreteLatentCode</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.12318">https://www.alphaxiv.org/abs/2507.12318</a></p>
<p>Researchers at Mila, Université de Montréal, introduce Discrete Latent Codes (DLCs) as a conditioning representation for diffusion models, which enables state-of-the-art unconditional image generation on ImageNet (FID 1.59) and facilitates diverse, compositional image synthesis. The method also enables an efficient text-to-image pipeline that leverages pre-trained language models to generate DLCs, requiring significantly less training data than end-to-end models.</p>
<p><img src="https://pic1.imgdb.cn/item/688de74a58cb8da5c8fd9571.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688de78158cb8da5c8fd9583.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | Aug 1, 2025</title>
    <url>/2025/08/01/Daily-Paper-Aug-1-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#recgpt-technical-report">RecGPT Technical Report</a></li>
<li><a href="#rlvmr-reinforcement-learning-with-verifiable-meta-reasoning-rewards-for-robust-long-horizon-agents">RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents</a></li>
<li><a href="#seed-prover-deep-and-broad-reasoning-for-automated-theorem-proving">Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving</a></li>
<li><a href="#where-to-show-demos-in-your-prompt-a-positional-bias-of-in-context-learning">Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning</a></li>
<li><a href="#cot-self-instruct-building-high-quality-synthetic-prompts-for-reasoning-and-non-reasoning-tasks">CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks</a></li>
<li><a href="#unilip-adapting-clip-for-unified-multimodal-understanding-generation-and-editing">UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing</a></li>
<li><a href="#c3-a-bilingual-benchmark-for-spoken-dialogue-models-exploring-challenges-in-complex-conversations">C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations</a></li>
<li><a href="#screencoder-advancing-visual-to-code-generation-for-front-end-automation-via-modular-multimodal-agents">ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents</a></li>
<li><a href="#i-am-big-you-are-little-i-am-right-you-are-wrong">I Am Big, You Are Little; I Am Right, You Are Wrong</a></li>
<li><a href="#alphaearth-foundations-an-embedding-field-model-for-accurate-and-efficient-global-mapping-from-sparse-label-data">AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data</a></li>
</ul>
<h2 id="recgpt-technical-report"><a class="markdownIt-Anchor" href="#recgpt-technical-report"></a> RecGPT Technical Report</h2>
<p>Author: Alibaba Taobao Team</p>
<p>RecGPT, developed by Taobao, integrates large language models into its recommender system to enable intent-centered personalization. This framework, fully deployed on the Taobao App, increased click-through rate by 6.33%, dwell time by 4.82%, and user-clicked item category diversity by 6.96%, while also mitigating the Matthew effect for merchants.</p>
<p><img src="https://pic1.imgdb.cn/item/688cdf9258cb8da5c8fa8b93.png" alt="" /></p>
<h2 id="rlvmr-reinforcement-learning-with-verifiable-meta-reasoning-rewards-for-robust-long-horizon-agents"><a class="markdownIt-Anchor" href="#rlvmr-reinforcement-learning-with-verifiable-meta-reasoning-rewards-for-robust-long-horizon-agents"></a> RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents</h2>
<p>Github Link: <a href="https://github.com/Tencent/DigitalHuman/tree/main/RLVMR">https://github.com/Tencent/DigitalHuman/tree/main/RLVMR</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22844">https://www.alphaxiv.org/abs/2507.22844</a></p>
<p><img src="https://pic1.imgdb.cn/item/688ce1b158cb8da5c8fa8ccc.png" alt="" /></p>
<p>RLVMR, developed by Tencent, trains Large Language Model agents to perform complex, long-horizon tasks by providing dense, verifiable meta-reasoning rewards during reinforcement learning. This approach leads to enhanced task success and generalization while significantly reducing inefficient exploration, such as repetitive and invalid actions, on benchmarks like ALFWorld and ScienceWorld.</p>
<p><img src="https://pic1.imgdb.cn/item/688ce1f458cb8da5c8fa8e74.png" alt="" /><br />
<img src="https://pic1.imgdb.cn/item/688ce23558cb8da5c8fa9044.png" alt="" /></p>
<h2 id="seed-prover-deep-and-broad-reasoning-for-automated-theorem-proving"><a class="markdownIt-Anchor" href="#seed-prover-deep-and-broad-reasoning-for-automated-theorem-proving"></a> Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving</h2>
<p>Author: ByteDance Seed AI4Math</p>
<p>Github Link: <a href="https://github.com/ByteDance-Seed/Seed-Prover">https://github.com/ByteDance-Seed/Seed-Prover</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23726">https://www.alphaxiv.org/abs/2507.23726</a></p>
<p>ByteDance Seed AI4Math’s Seed-Prover and Seed-Geometry are AI systems that successfully proved 5 out of 6 problems in the IMO 2025 competition, establishing new state-of-the-art results across several formal mathematical benchmarks including MiniF2F and PutnamBench. The systems achieve this through lemma-style proving, multi-tiered inference strategies that integrate iterative refinement and broad conjecture generation, and a fast, specialized geometry engine.</p>
<p><img src="https://pic1.imgdb.cn/item/688ce2dc58cb8da5c8fa9451.png" alt="" /></p>
<h2 id="where-to-show-demos-in-your-prompt-a-positional-bias-of-in-context-learning"><a class="markdownIt-Anchor" href="#where-to-show-demos-in-your-prompt-a-positional-bias-of-in-context-learning"></a> Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning</h2>
<p><img src="https://pic1.imgdb.cn/item/688ce33b58cb8da5c8fa96b0.png" alt="" /></p>
<p>This academic paper explores how the <strong>position of demonstrations</strong> (demos) within a Large Language Model’s (LLM) prompt affects its performance, a phenomenon termed <strong>DPP bias</strong>. Researchers evaluated ten open-source LLMs across various NLP tasks, discovering that <strong>placing demos at the beginning of the prompt</strong> generally leads to <strong>higher accuracy and greater prediction stability</strong>. Conversely, demos positioned at the end of the user message can drastically alter predictions without improving correctness. The study highlights that the <strong>optimal demo placement is not universal</strong>, varying significantly with both the <strong>LLM’s size and the specific task</strong>, emphasizing the critical need for <strong>model-aware and task-sensitive prompt design</strong>.</p>
<p><img src="https://pic1.imgdb.cn/item/688ce38758cb8da5c8fa97b5.png" alt="" /></p>
<h2 id="cot-self-instruct-building-high-quality-synthetic-prompts-for-reasoning-and-non-reasoning-tasks"><a class="markdownIt-Anchor" href="#cot-self-instruct-building-high-quality-synthetic-prompts-for-reasoning-and-non-reasoning-tasks"></a> CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks</h2>
<p><img src="https://pic1.imgdb.cn/item/688ce55c58cb8da5c8fa9834.png" alt="" /></p>
<p>CoT-Self-Instruct, developed by FAIR at Meta, introduces a method for generating high-quality synthetic data for Large Language Models by combining Chain-of-Thought reasoning for instruction creation with robust, automated filtering mechanisms. This approach enables models trained on the synthetic data to achieve superior performance on both reasoning and general instruction-following benchmarks, often surpassing existing synthetic methods and human-annotated datasets.</p>
<p><img src="https://pic1.imgdb.cn/item/688ce61858cb8da5c8fa9874.png" alt="" /></p>
<h2 id="unilip-adapting-clip-for-unified-multimodal-understanding-generation-and-editing"><a class="markdownIt-Anchor" href="#unilip-adapting-clip-for-unified-multimodal-understanding-generation-and-editing"></a> UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing</h2>
<p><img src="https://pic1.imgdb.cn/item/688cfb1258cb8da5c8fa9ba6.png" alt="" /></p>
<p>n this paper, we propose UniLIP, which <strong>extends CLIP to reconstruction, generation and editing</strong>, thereby building a unified tokenizer upon its exceptional comprehension capabilities. Previous CLIP-based unified methods often <strong>require additional diffusion decoders or quantization</strong> to support reconstruction and generation tasks, leading to inconsistent reconstruction or degradation of original comprehension performance. In contrast, we introduce a two-stage training scheme and a self-distillation strategy that progressively integrates reconstruction capabilities into CLIP, allowing it to maintain original comprehension performance while achieving effective image reconstruction. Furthermore, we propose a dualcondition architecture to connect the MLLM and diffusion transformer, using both learnable queries and the last layer multimodal hidden states as joint conditions. This method not only enables the utilization of the MLLM’s strong reasoning capabilities in generation tasks, but also maximizes the exploitation of the rich information in UniLIP features during editing tasks. In text-to-image generation tasks, UniLIP obtains scores of 0.87 and 0.53 on GenEval and WISE benchmark respectively, surpassing all previous unified models of similar scale. In image editing, UniLIP also achieves a score of <strong>3.62</strong> on the ImgEdit Benchmark, surpassing recent state-of-the-art models such as BAGEL and UniWorld-V1. UniLIP effectively expand the application scope of CLIP, enabling continuous CLIP features to not only serve as the optimal choice for understanding tasks but also achieve highly competitive performance in generation and editing tasks.</p>
<p><img src="https://pic1.imgdb.cn/item/688cf98658cb8da5c8fa9b85.png" alt="" /></p>
<h2 id="c3-a-bilingual-benchmark-for-spoken-dialogue-models-exploring-challenges-in-complex-conversations"><a class="markdownIt-Anchor" href="#c3-a-bilingual-benchmark-for-spoken-dialogue-models-exploring-challenges-in-complex-conversations"></a> C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations</h2>
<p>Project Link: <a href="https://step-out.github.io/C3-web/">https://step-out.github.io/C3-web/</a><br />
Github Link: <a href="https://github.com/step-out/C3">https://github.com/step-out/C3</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22968">https://www.alphaxiv.org/abs/2507.22968</a></p>
<p><img src="https://pic1.imgdb.cn/item/688cfb9358cb8da5c8fa9bab.png" alt="" /></p>
<p>This document introduces <strong>C3</strong>, a new <strong>bilingual benchmark</strong> designed to assess <strong>Spoken Dialogue Models (SDMs)</strong> in <strong>complex conversational scenarios</strong>. It highlights <strong>five key challenges</strong> in human speech: <strong>phonological ambiguity</strong>, <strong>semantic ambiguity</strong>, <strong>omission</strong>, <strong>coreference</strong>, and <strong>multi-turn interaction</strong>. The paper presents a <strong>dataset of 1,079 instances</strong> in both English and Chinese, evaluated using an <strong>LLM-based method</strong> that strongly correlates with human judgment. Experimental results reveal that <strong>ambiguity, especially semantic ambiguity in Chinese, poses significant difficulties</strong> for SDMs, and that <strong>omission is the most challenging aspect of context-dependency</strong>.</p>
<p><img src="https://pic1.imgdb.cn/item/688cfbb358cb8da5c8fa9bb1.png" alt="" /></p>
<h2 id="screencoder-advancing-visual-to-code-generation-for-front-end-automation-via-modular-multimodal-agents"><a class="markdownIt-Anchor" href="#screencoder-advancing-visual-to-code-generation-for-front-end-automation-via-modular-multimodal-agents"></a> ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents</h2>
<p><img src="https://pic1.imgdb.cn/item/688cfc8758cb8da5c8fa9bc2.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/leigest519/ScreenCoder">https://github.com/leigest519/ScreenCoder</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22827">https://www.alphaxiv.org/abs/2507.22827</a></p>
<p>The source introduces <strong>ScreenCoder</strong>, a novel framework designed to <strong>automate the conversion of user interface (UI) designs into front-end code</strong>, specifically HTML/CSS. It highlights the limitations of existing methods that primarily rely on text-to-code generation and struggle with visual design nuances. ScreenCoder addresses this by employing a <strong>modular multi-agent system</strong> comprising three stages: <strong>grounding</strong> (detecting and labeling UI components), <strong>planning</strong> (structuring a hierarchical layout), and <strong>generation</strong> (synthesizing code from the structured layout). Furthermore, the paper describes how this framework functions as a <strong>scalable data engine</strong>, generating UI-image/code pairs to <strong>enhance vision-language models (VLMs)</strong> through supervised fine-tuning and reinforcement learning, ultimately achieving state-of-the-art performance in UI-to-code synthesis.</p>
<p><img src="https://pic1.imgdb.cn/item/688cfe5558cb8da5c8fa9be3.png" alt="" /></p>
<h2 id="i-am-big-you-are-little-i-am-right-you-are-wrong"><a class="markdownIt-Anchor" href="#i-am-big-you-are-little-i-am-right-you-are-wrong"></a> I Am Big, You Are Little; I Am Right, You Are Wrong</h2>
<p><img src="https://pic1.imgdb.cn/item/688cff1458cb8da5c8fa9bed.png" alt="" /></p>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23509">https://www.alphaxiv.org/abs/2507.23509</a><br />
Github Link: <a href="https://github.com/ReX-XAI/ReX">https://github.com/ReX-XAI/ReX</a></p>
<p>This paper presents a study on <strong>minimal sufficient pixel sets (MPSs)</strong>, which are the smallest sets of pixels needed for an image classification model to make its original prediction. The authors <strong>investigate various neural network architectures</strong>, including Inception, ResNet, ConvNext, ViT, and EVA, to understand how different models <strong>process visual information</strong>. They specifically examine whether <strong>MPS size and location vary across models and architectures</strong>, and if <strong>misclassifications correlate with larger MPSs</strong>. The research utilizes <strong>ReX, a causal explainable AI (XAI) tool</strong>, to generate these pixel sets, demonstrating that models like ConvNext and EVA often rely on <strong>fewer, more spatially distinct pixels</strong>.</p>
<p><img src="https://pic1.imgdb.cn/item/688cff7258cb8da5c8fa9bf1.png" alt="" /></p>
<h2 id="alphaearth-foundations-an-embedding-field-model-for-accurate-and-efficient-global-mapping-from-sparse-label-data"><a class="markdownIt-Anchor" href="#alphaearth-foundations-an-embedding-field-model-for-accurate-and-efficient-global-mapping-from-sparse-label-data"></a> AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data</h2>
<p><img src="https://pic1.imgdb.cn/item/688cffc058cb8da5c8fa9c02.png" alt="" /></p>
<p>Paper Link: <a href="https://papers-pdfs.assets.alphaxiv.org/2507.22291v1.pdf">https://papers-pdfs.assets.alphaxiv.org/2507.22291v1.pdf</a></p>
<p>The paper introduces <strong>AlphaEarth Foundations (AEF)</strong>, a novel embedding field model developed by Google DeepMind and Google, designed for <strong>accurate and efficient global mapping from sparse Earth observation data</strong>. AEF creates a <strong>highly general, geospatial representation</strong> by integrating spatial, temporal, and measurement contexts from various sources like <strong>Sentinel and Landsat imagery, LiDAR, climate data, and even text</strong>. This innovation addresses the challenge of creating high-quality global maps despite the <strong>scarcity of detailed, labeled data</strong>, consistently outperforming existing <strong>featurization approaches</strong> across diverse mapping tasks such as thematic mapping, biophysical variable estimation, and change detection. The authors plan to release a dataset of global, annual, analysis-ready <strong>embedding field layers</strong> from 2017 to 2024, enabling practitioners to leverage this technology without complex <strong>deep learning workflows</strong>.</p>
<p><img src="https://pic1.imgdb.cn/item/688cfff458cb8da5c8fa9c06.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | Aug 3, 2025</title>
    <url>/2025/08/03/Daily-Paper-Aug-3-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#simura-towards-general-goal-oriented-agent-via-simulative-reasoning-architecture-with-llm-based-world-model">SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model</a></li>
<li><a href="#mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation">Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation</a></li>
<li><a href="#phi-ground-tech-report-advancing-perception-in-gui-grounding">Phi-Ground Tech Report: Advancing Perception in GUI Grounding</a></li>
<li><a href="#fairreason-balancing-reasoning-and-social-bias-in-mllms">FairReason: Balancing Reasoning and Social Bias in MLLMs</a></li>
<li><a href="#dino-vo-a-feature-based-visual-odometry-leveraging-a-visual-foundation-model">DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model</a></li>
<li><a href="#tars--minmax-token-adaptive-preference-strategy-for-hallucination-reduction-in-mllms">TARS : MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs</a></li>
<li><a href="#autotir-autonomous-tools-integrated-reasoning-via-reinforcement-learning">AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning</a></li>
<li><a href="#policy-learning-from-large-vision-language-model-feedback-without-reward-modeling">Policy Learning from Large Vision-Language Model Feedback Without Reward Modeling</a></li>
<li><a href="#first-return-entropy-eliciting-explore">First Return, Entropy-Eliciting Explore</a></li>
</ul>
<h2 id="simura-towards-general-goal-oriented-agent-via-simulative-reasoning-architecture-with-llm-based-world-model"><a class="markdownIt-Anchor" href="#simura-towards-general-goal-oriented-agent-via-simulative-reasoning-architecture-with-llm-based-world-model"></a> SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model</h2>
<p><img src="https://pic1.imgdb.cn/item/688f2f8858cb8da5c8008f65.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/maitrix-org/llm-reasoners/tree/main/examples/ReasonerAgent-Web">https://github.com/maitrix-org/llm-reasoners/tree/main/examples/ReasonerAgent-Web</a><br />
Paper Link: <a href="https://arxiv.org/abs/2507.23773">https://arxiv.org/abs/2507.23773</a></p>
<p>AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SIMURA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, SIMURA overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that SIMURA improves the success of flight search from 0% to 32.2%. World-model-based planning, in particular, shows consistent advantage of up to 124% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make REASONERAGENT-WEB, a web-browsing agent built on SIMURA with pretrained LLMs, available as a research demo for public testing.</p>
<p><img src="https://pic1.imgdb.cn/item/688f304b58cb8da5c80091ac.png" alt="" /></p>
<h2 id="mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation"><a class="markdownIt-Anchor" href="#mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation"></a> Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation</h2>
<p><img src="https://pic1.imgdb.cn/item/688f31b158cb8da5c8009591.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/raymin0223/mixture_of_recursions">https://github.com/raymin0223/mixture_of_recursions</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.10524">https://www.alphaxiv.org/abs/2507.10524</a></p>
<p>The Mixture-of-Recursions (MoR) framework unifies parameter sharing and adaptive computation within Recursive Transformer architectures, allowing models to dynamically apply shared layers to individual tokens. MoR achieves competitive performance with vanilla Transformers while using 50% fewer parameters, 25% fewer training FLOPs, and boosting inference throughput by up to 2.06x.</p>
<h2 id="phi-ground-tech-report-advancing-perception-in-gui-grounding"><a class="markdownIt-Anchor" href="#phi-ground-tech-report-advancing-perception-in-gui-grounding"></a> Phi-Ground Tech Report: Advancing Perception in GUI Grounding</h2>
<p><img src="https://pic1.imgdb.cn/item/688f332058cb8da5c8009944.png" alt="" /></p>
<p>Project Link: <a href="https://zhangmiaosen2000.github.io/Phi-Ground/">https://zhangmiaosen2000.github.io/Phi-Ground/</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23779">https://www.alphaxiv.org/abs/2507.23779</a></p>
<p>The Phi-Ground model family from Microsoft introduces an efficient and high-performing approach to Graphical User Interface (GUI) grounding, achieving state-of-the-art accuracy on five challenging benchmarks for models under 10B parameters by systematically optimizing data, training, and architectural considerations. This work explores practical aspects such as the impact of image tokens and the unexpected effectiveness of Direct Preference Optimization (DPO) for perceptual tasks.</p>
<p><img src="https://pic1.imgdb.cn/item/688f335a58cb8da5c80099de.png" alt="" /></p>
<h2 id="fairreason-balancing-reasoning-and-social-bias-in-mllms"><a class="markdownIt-Anchor" href="#fairreason-balancing-reasoning-and-social-bias-in-mllms"></a> FairReason: Balancing Reasoning and Social Bias in MLLMs</h2>
<p><img src="https://pic1.imgdb.cn/item/688f33d258cb8da5c8009b7d.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/Yutongzhang20080108/FairReason-Balancing-Reasoning-and-Social-Bias-in-MLLMs">https://github.com/Yutongzhang20080108/FairReason-Balancing-Reasoning-and-Social-Bias-in-MLLMs</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.23067">https://www.alphaxiv.org/abs/2507.23067</a></p>
<p>Multimodal Large Language Models (MLLMs) already achieve state-of-the-art results across a wide range of tasks and modalities. To push their reasoning ability further, recent studies explore advanced prompting schemes and post-training fine-tuning. Although these techniques improve logical accuracy, they frequently leave the models’ outputs burdened with pronounced social biases. Clarifying how reasoning gains interact with bias mitigation—and whether the two objectives inherently trade off—therefore remains an open and pressing research problem. Our study begins by benchmarking three bias-mitigation strategies—supervised fine-tuning (SFT), knowledge distillation (KD), and rule-based reinforcement learning (RL)—under identical conditions, establishing their baseline strengths and weaknesses. Building on these results, we vary the proportion of debias-focused and reasoning-centric samples within each paradigm to chart the reasoning-versusbias trade-off. Our sweeps reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement learning cuts stereotype scores by 10% while retaining 88% of the model’s original reasoning accuracy, offering concrete guidance for balancing fairness and capability in MLLMs.</p>
<p><img src="https://pic1.imgdb.cn/item/688f348958cb8da5c8009d72.png" alt="" /></p>
<h2 id="dino-vo-a-feature-based-visual-odometry-leveraging-a-visual-foundation-model"><a class="markdownIt-Anchor" href="#dino-vo-a-feature-based-visual-odometry-leveraging-a-visual-foundation-model"></a> DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model</h2>
<p>affiliation: KAIST</p>
<p>Learning-based monocular visual odometry (VO) poses robustness, generalization, and efficiency challenges in robotics. Recent advances in visual foundation models, such as DINOv2, have improved robustness and generalization in various vision tasks, yet their integration in VO remains limited due to coarse feature granularity. In this paper, we present DINO-VO, a feature-based VO system leveraging DINOv2 visual foundation model for its sparse feature matching. To address the integration challenge, we propose a salient keypoints detector tailored to DINOv2’s coarse features. Furthermore, we complement DINOv2’s robust-semantic features with fine-grained geometric features, resulting in more localizable representations. Finally, a transformer-based matcher and differentiable pose estimation layer enable precise camera motion estimation by learning good matches. Against prior detector-descriptor networks like SuperPoint, DINO-VO demonstrates greater robustness in challenging environments. Furthermore, we show superior accuracy and generalization of the proposed feature descriptors against standalone DINOv2 coarse features. DINO-VO outperforms prior frame-toframe VO methods on the TartanAir and KITTI datasets and is competitive on EuRoC dataset, while running efficiently at 72 FPS with less than 1GB of memory usage on a single GPU. Moreover, it performs competitively against Visual SLAM systems on outdoor driving scenarios, showcasing its generalization capabilities.</p>
<p><img src="https://pic1.imgdb.cn/item/688f365d58cb8da5c800a21c.png" alt="" /></p>
<h2 id="tars-minmax-token-adaptive-preference-strategy-for-hallucination-reduction-in-mllms"><a class="markdownIt-Anchor" href="#tars-minmax-token-adaptive-preference-strategy-for-hallucination-reduction-in-mllms"></a> TARS : MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs</h2>
<p><img src="https://pic1.imgdb.cn/item/688f36c058cb8da5c800a323.png" alt="" /></p>
<p>Github Link: <a href="https://kejiazhang-robust.github.io/tars_web/">https://kejiazhang-robust.github.io/tars_web/</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21584">https://www.alphaxiv.org/abs/2507.21584</a></p>
<p>Multimodal large language models (MLLMs) enable vision-language reasoning, yet often generate plausible outputs that are factually incorrect or visually ungrounded, thereby compromising their reliability. Direct preference optimization (DPO) is a common strategy for correcting hallucinations by aligning model outputs with human preferences. Existing DPO strategies typically treat hallucination-related preferences as fixed targets, relying on static supervision signals during training. This approach tends to overfit to superficial linguistic cues in preference data, leading to distributional rigidity and spurious correlations that impair grounding in causally relevant visual information. To overcome this limitation, we propose TARS, a token-adaptive preference strategy that reformulates DPO as a min-max optimization problem. TARS maximizes token-level distributional shifts under semantic constraints to simulate alignment uncertainty, and simultaneously minimizes the expected preference loss under these controlled perturbations. This joint objective preserves causal grounding while mitigating overfitting to preference patterns, thereby reducing hallucinations in multimodal reasoning. We evaluate TARS on multiple hallucination benchmarks and find consistently strong performance. Using only 4.8k preference samples and no expert feedback, TARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition value from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on several key metrics.</p>
<p><img src="https://pic1.imgdb.cn/item/688f373d58cb8da5c800a456.png" alt="" /></p>
<h2 id="autotir-autonomous-tools-integrated-reasoning-via-reinforcement-learning"><a class="markdownIt-Anchor" href="#autotir-autonomous-tools-integrated-reasoning-via-reinforcement-learning"></a> AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning</h2>
<p><img src="https://pic1.imgdb.cn/item/688f376358cb8da5c800a4b9.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/weiyifan1023/AutoTIR">https://github.com/weiyifan1023/AutoTIR</a>.<br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21836">https://www.alphaxiv.org/abs/2507.21836</a></p>
<p>Large Language Models (LLMs), when enhanced through reasoning-oriented post-training, evolve into powerful Large Reasoning Models (LRMs). Tool-Integrated Reasoning (TIR) further extends their capabilities by incorporating external tools, but existing methods often rely on rigid, predefined tool-use patterns that risk degrading core language competence. Inspired by the human ability to adaptively select tools, we introduce AutoTIR, a reinforcement learning framework that enables LLMs to autonomously decide whether and which tool to invoke during the reasoning process, rather than following static tool-use strategies. AutoTIR leverages a hybrid reward mechanism that jointly optimizes for task-specific answer correctness, structured output adherence, and penalization of incorrect tool usage, thereby encouraging both precise reasoning and efficient tool integration. Extensive evaluations across diverse knowledge-intensive, mathematical, and general language modeling tasks demonstrate that AutoTIR achieves superior overall performance, significantly outperforming baselines and exhibits superior generalization in tool-use behavior. These results highlight the promise of reinforcement learning in building truly generalizable and scalable TIR capabilities in LLMs. The code and data are available at <a href="https://github.com/weiyifan1023/AutoTIR">https://github.com/weiyifan1023/AutoTIR</a>.</p>
<p><img src="https://pic1.imgdb.cn/item/688f37bf58cb8da5c800a59e.png" alt="" /></p>
<h2 id="policy-learning-from-large-vision-language-model-feedback-without-reward-modeling"><a class="markdownIt-Anchor" href="#policy-learning-from-large-vision-language-model-feedback-without-reward-modeling"></a> Policy Learning from Large Vision-Language Model Feedback Without Reward Modeling</h2>
<p>affiliation: KAIST</p>
<p>Offline reinforcement learning (RL) provides a powerful framework for training robotic agents using precollected, suboptimal datasets, eliminating the need for costly, time-consuming, and potentially hazardous online interactions. This is particularly useful in safety-critical real-world applications, where online data collection is expensive and impractical. However, existing offline RL algorithms typically require reward labeled data, which introduces an additional bottleneck: reward function design is itself costly, labor-intensive, and requires significant domain expertise. In this paper, we introduce PLARE, a novel approach that leverages large visionlanguage models (VLMs) to provide guidance signals for agent training. Instead of relying on manually designed reward functions, PLARE queries a VLM for preference labels on pairs of visual trajectory segments based on a language task description. The policy is then trained directly from these preference labels using a supervised contrastive preference learning objective, bypassing the need to learn explicit reward models. Through extensive experiments on robotic manipulation tasks from the MetaWorld, PLARE achieves performance on par with or surpassing existing state-of-the-art VLM-based reward generation methods. Furthermore, we demonstrate the effectiveness of PLARE in real-world manipulation tasks with a physical robot, further validating its practical applicability.</p>
<p><img src="https://pic1.imgdb.cn/item/688f386f58cb8da5c800a74e.png" alt="" /></p>
<h2 id="first-return-entropy-eliciting-explore"><a class="markdownIt-Anchor" href="#first-return-entropy-eliciting-explore"></a> First Return, Entropy-Eliciting Explore</h2>
<p><img src="https://pic1.imgdb.cn/item/688f38a158cb8da5c800a7d6.png" alt="" /></p>
<p>Project Link: <a href="https://huggingface.co/FR3E-Bytedance">https://huggingface.co/FR3E-Bytedance</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.07017">https://www.alphaxiv.org/abs/2507.07017</a></p>
<p>ByteDance researchers developed First Return, Entropy-Eliciting Explore (FR3E), a value-model-free reinforcement learning framework that enhances LLM reasoning by providing semantically grounded intermediate feedback. It identifies high-uncertainty decision points in reasoning paths using token-level entropy and conducts targeted partial rollouts, leading to more stable training and improved performance on mathematical reasoning benchmarks, with an average accuracy increase of over 3% on Qwen2.5 models.</p>
<p><img src="https://pic1.imgdb.cn/item/688f399c58cb8da5c800aa5d.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>ML:Bert</title>
    <url>/2023/10/25/Bert/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接：</h2>
<p>🔗：<a href="https://www.bilibili.com/video/BV17441137fa/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">李宏毅-ELMO, BERT, GPT讲解</a></p>
<br>
<h2 id="一review"><a class="markdownIt-Anchor" href="#一review"></a> 一.Review</h2>
<h2 id="11-1-of-n-encoding"><a class="markdownIt-Anchor" href="#11-1-of-n-encoding"></a> 1.1 <code>1-of-N Encoding</code></h2>
<p>最早采用的方法，显然一个词用一个向量表示不合理<br />
apple=[1 0 0 0 0]</p>
<p>bag=[0 1 0 0 0]</p>
<p>cat=[0 0 1 0 0]</p>
<p>dog=[0 0  0 1 0]</p>
<p>elephant=[0 0 0 0 1]</p>
<br>
<h2 id="12-word-class"><a class="markdownIt-Anchor" href="#12-word-class"></a> 1.2 <code>Word Class</code></h2>
<p>之后才用WOrd CLass，但是这种分类还是太粗糙了</p>
<p><img src="https://pbs.twimg.com/media/F9QBk3BbAAAbtmX?format=png&amp;name=small" alt="" /></p>
<Br>
<h2 id="13-word-embedding"><a class="markdownIt-Anchor" href="#13-word-embedding"></a> 1.3 <code>Word Embedding</code></h2>
<p>每一个词映射到一个连续的向量空间，语义相似的词语在向量空间中距离较近</p>
<p><img src="https://pbs.twimg.com/media/F9QB7xQbAAAizwg?format=png&amp;name=small" alt="" /></p>
<br>
<h2 id="14-contextualized-word-embedding"><a class="markdownIt-Anchor" href="#14-contextualized-word-embedding"></a> 1.4 <code>Contextualized Word Embedding</code></h2>
<p>但是同一个词汇可能有不同的意思，比如：</p>
<ul>
<li>Have you paid that money to the bank yet ?(银行)</li>
<li>It is safest to deposit your money in the bank.(银行)</li>
<li>The victim was found lying dead on the river bank.(河堤)</li>
<li>They stood on the river bank to fish.(河堤)</li>
</ul>
<br>
<p>期待：</p>
<ul>
<li>过去，word type对应一种embedding；现在，word tokens对应一种的embdding</li>
<li>但同时word tokens也取决于其语境</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QX_OoacAA0dP4?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="二elmoembeddings-from-language-model"><a class="markdownIt-Anchor" href="#二elmoembeddings-from-language-model"></a> 二.ELMO=Embeddings from Language Model</h2>
<ul>
<li>RNN-based language models</li>
</ul>
<p>给很多句子去预测下一个句子的token是什么,不仅仅有正向的还有反向的</p>
<p><img src="https://pbs.twimg.com/media/F9QYYFvaYAAoswZ?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>但是深层LSTM的每一层都可以生成一个潜伏的表示，我们该用哪个呢？</p>
<p><img src="https://pbs.twimg.com/media/F9QYaCJbQAACqFg?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>ELMO的思想那个就是我全部都要，不同的Task抽不同层的权重不一样：</p>
<p><img src="https://pbs.twimg.com/media/F9QYcYXagAAKXeD?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="三bertbidirectional-encoder-representations-from-transformers"><a class="markdownIt-Anchor" href="#三bertbidirectional-encoder-representations-from-transformers"></a> 三.BERT=Bidirectional Encoder Representations from Transformers</h2>
<p><img src="https://pbs.twimg.com/media/F9QaYRAacAA5Z6k?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="31-train-approach"><a class="markdownIt-Anchor" href="#31-train-approach"></a> 3.1 train approach</h2>
<p>两种方法要同时使用</p>
<h2 id="311-train-approachmasked-lm"><a class="markdownIt-Anchor" href="#311-train-approachmasked-lm"></a> 3.1.1 train approach：Masked LM</h2>
<p>BERT模型本身就是Transformer的Encoder，输入输出长度一样，BERT会对输入随机mask一些token，然后让机器来填空。Mask有两种处理方法，一是将其标记为一个特殊的符号，二是随机填上一个文字。在下图的例子中，第二个output vector经过Linear transform和softmax之后，得到所有文字在第二个位置出现的概率，选择概率最大的文字为答案。训练目标就是最小化 预测结果与已知的ground truth之间的交叉熵</p>
<p><img src="https://img-blog.csdnimg.cn/2021031611423652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODk3ODAw,size_16,color_FFFFFF,t_70#pic_center" alt="" /></p>
<br>
<h2 id="312-train-approachnext-sentence-prediction"><a class="markdownIt-Anchor" href="#312-train-approachnext-sentence-prediction"></a> 3.1.2 train approach：Next Sentence Prediction</h2>
<p>BERT在做填空的同时，同时也在做NSP任务。对于输入的句子得做两个处理，首先在开始位置加上一个特殊的classification token(CLS)，在两个句子之间加上一个分隔符(SEP)。然后将处理好的向量表示丢给BERT，只取出(CLS)token对应的输出向量，进行线性变换和softmax，来判断Sentence1的下一句是否为Sentence2，但是NSP任务对BERT的下游任务没有什么帮助</p>
<ul>
<li>(CLS):输出分类结果的位置</li>
<li>(SEP):两个句子的边界</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QaciNbQAAbgkM?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="32-pre-train与fine-tune"><a class="markdownIt-Anchor" href="#32-pre-train与fine-tune"></a> 3.2 Pre-Train与fine-tune</h2>
<p>BERT做填空题和NSP对于我们很关心的其他任务来说非常有用，并且这些任务只有少量带标签的数据，我们称训练BERT的过程称为预训练（pre-train），称我们关心的其他任务为下游任务(downstream tasks)。</p>
<p>BERT模型预训练之后，经过微调(fine-tune)之后，可以应用于各式各样的下游任务中。</p>
<Br>
<h2 id="33-how-to-use-bert"><a class="markdownIt-Anchor" href="#33-how-to-use-bert"></a> 3.3 How to use BERT</h2>
<h2 id="331-case-1"><a class="markdownIt-Anchor" href="#331-case-1"></a> 3.3.1 Case 1</h2>
<ul>
<li>输入：stence</li>
<li>输出：class</li>
<li>例如：情感分析，文件分类…</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QammOasAA9R7V?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="332-case-2"><a class="markdownIt-Anchor" href="#332-case-2"></a> 3.3.2 Case 2</h2>
<ul>
<li>输入：sentence</li>
<li>输出：每个词的class</li>
<li>例如：槽位填充</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F9QapUPakAElWOT?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="333-case-3"><a class="markdownIt-Anchor" href="#333-case-3"></a> 3.3.3 Case 3</h2>
<ul>
<li>输入：两个sentence</li>
<li>输出：class</li>
<li>例如：给定一个假设，判断推理是否正确</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20210316115419587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODk3ODAw,size_16,color_FFFFFF,t_70#pic_center" alt="" /></p>
<br>
<h2 id="334-case-4"><a class="markdownIt-Anchor" href="#334-case-4"></a> 3.3.4 Case 4</h2>
<ul>
<li>输入：Document和Query</li>
<li>输出：两个正数s，e(s决定开始，e决定结束)</li>
</ul>
<p>基于抽取的问答的限制是答案必须来自于文章。如下图，输入的document中有N个单词，输入的query或question中有M个单词，最后输出两个整数(s, e)，分别表示答案在document中的起始(start)位置和结束(end)位置。例如第三题&quot;within a cloud&quot;是document的第77到79个单词，所以输出为(77, 79)。</p>
<p><img src="https://pbs.twimg.com/media/F9Qa8g6bQAEVlm5?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>具体如何训练，就是有两组随机初始化的向量，第一组与document对应的输出向量表示(output vector representation)做内积(inner product)，其结果进行线性变换和softmax，选择最大概率0.5所在的位置为起始位置s=2；第二组做同样的操作，选择最大概率0.7所在的位置为结束位置e=3，所以 outpu=(2,3),answer=(d2,d3)</p>
<p><img src="https://pbs.twimg.com/media/F9QbE1DacAA83hV?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="34-ernieenhanced-representation-through-knowledge-integration"><a class="markdownIt-Anchor" href="#34-ernieenhanced-representation-through-knowledge-integration"></a> 3.4 ERNIE=Enhanced Representation through Knowledge Integration</h2>
<p>专门为中文设计的BERT</p>
<p>将Mask LM盖住的character改为盖住word</p>
<p><img src="https://pbs.twimg.com/media/F9QbCZ2akAAr9Q-?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="35-multilingual-bert"><a class="markdownIt-Anchor" href="#35-multilingual-bert"></a> 3.5 Multilingual BERT</h2>
<p>Multi-BERT就是使用多种语言对BERT进行预训练，Multi-BERT使用了104种语言做预训练，实验发现Multi-BERT在一种语言上做微调，在另一种语言上做测试</p>
<p><img src="https://pbs.twimg.com/media/F9QbJk2aIAAflVu?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="4gptgenerative-pre-traininggpt"><a class="markdownIt-Anchor" href="#4gptgenerative-pre-traininggpt"></a> 4.GPT=Generative Pre-Training(GPT)</h2>
<p>GPT是Generative Pre-trained Transformer的缩写。GPT做的事其实是Predict Next Token，顾名思义就是预测下一个token，模型示意如下:</p>
<p><img src="https://pbs.twimg.com/media/F9QbOHcagAAcOuk?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>专业知识</tag>
        <tag>ML</tag>
        <tag>bert</tag>
        <tag>李宏毅</tag>
      </tags>
  </entry>
  <entry>
    <title>Daily Paper | Aug 5, 2025</title>
    <url>/2025/08/05/Daily-Paper-Aug-5-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Our reading list for today includes some ACL Best Papers as listed below:</p>
<ul>
<li><a href="#a-theory-of-response-sampling-in-llms-part-descriptive-and-part-prescriptive">A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive</a></li>
<li><a href="#fairness-through-difference-awareness-measuring-desired-group-discrimination-in-llms">Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs</a></li>
<li><a href="#language-models-resist-alignment">Language Models Resist Alignment</a></li>
<li><a href="#native-sparse-attention-hardware-aligned-and-natively-trainable-sparse-attention">Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</a></li>
</ul>
<h2 id="a-theory-of-response-sampling-in-llms-part-descriptive-and-part-prescriptive"><a class="markdownIt-Anchor" href="#a-theory-of-response-sampling-in-llms-part-descriptive-and-part-prescriptive"></a> A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive</h2>
<p><img src="https://pic1.imgdb.cn/item/6891e20758cb8da5c806b870.png" alt="" /></p>
<p>Paper Link: <a href="https://arxiv.org/abs/2402.11005">https://arxiv.org/abs/2402.11005</a></p>
<p>This paper introduces a theory proposing that Large Language Model response sampling is governed by both a descriptive component reflecting statistical norms and a prescriptive component representing an implicit ideal notion. Empirical studies across various concepts demonstrate LLM outputs consistently deviate towards an internal ideal, a tendency that is robust to debiasing and exacerbated in larger, instruction-tuned models, impacting critical applications such as medical decision-making.</p>
<p><img src="https://pic1.imgdb.cn/item/6891e2d858cb8da5c806bd9d.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6891e40a58cb8da5c806c41e.png" alt="" /></p>
<h2 id="fairness-through-difference-awareness-measuring-desired-group-discrimination-in-llms"><a class="markdownIt-Anchor" href="#fairness-through-difference-awareness-measuring-desired-group-discrimination-in-llms"></a> Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs</h2>
<p><img src="https://pic1.imgdb.cn/item/6891e87158cb8da5c806c964.png" alt="" /></p>
<p>Paper Link: <a href="https://arxiv.org/pdf/2502.01926">https://arxiv.org/pdf/2502.01926</a></p>
<p>This Stanford University-led research proposes and evaluates a new framework, “Fairness through Difference Awareness,” to assess Large Language Models’ ability to appropriately differentiate between demographic groups when contextually relevant. The study empirically demonstrates that leading LLMs often lack this capability and that traditional bias mitigation methods can inadvertently hinder models from recognizing legitimate group differences.</p>
<p><img src="https://pic1.imgdb.cn/item/6891e4ee58cb8da5c806c505.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6891e75858cb8da5c806c921.png" alt="" /></p>
<h2 id="language-models-resist-alignment"><a class="markdownIt-Anchor" href="#language-models-resist-alignment"></a> Language Models Resist Alignment</h2>
<p><img src="https://pic1.imgdb.cn/item/6891e83a58cb8da5c806c961.png" alt="" /></p>
<p>Paper Link: <a href="https://arxiv.org/abs/2406.06144">https://arxiv.org/abs/2406.06144</a></p>
<p>This paper from Peking University and BAAI investigates the fragility of Large Language Model alignment, introducing the concept of ‘elasticity’ where models resist modifications and tend to revert to their pre-trained state. The study provides theoretical evidence from data compression principles and empirical validation demonstrating that this resistance and rebound effect intensifies with increasing model size and pre-training data volume.</p>
<p><img src="https://pic1.imgdb.cn/item/6891ea0258cb8da5c806c9b3.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6891eaf258cb8da5c806c9de.png" alt="" /></p>
<h2 id="native-sparse-attention-hardware-aligned-and-natively-trainable-sparse-attention"><a class="markdownIt-Anchor" href="#native-sparse-attention-hardware-aligned-and-natively-trainable-sparse-attention"></a> Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</h2>
<p><img src="https://pic1.imgdb.cn/item/6891eb3958cb8da5c806caa4.png" alt="" /></p>
<p>Paper Link: <a href="https://arxiv.org/abs/2502.11089">https://arxiv.org/abs/2502.11089</a></p>
<p>DeepSeek-AI researchers developed Native Sparse Attention (NSA), a hardware-aligned and natively trainable sparse attention mechanism that enables efficient and performant long-context modeling for large language models. NSA achieves up to 11.6x decoding speedup and 9.0x training speedup at 64k context length while outperforming full attention on various benchmarks, including long-context reasoning tasks.</p>
<p><img src="https://pic1.imgdb.cn/item/6891ebb558cb8da5c806cd43.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6891ec1458cb8da5c806cf74.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | Attention Sink | Aug 8, 2025</title>
    <url>/2025/08/08/Daily-Paper-Aug-8-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="efficient-streaming-language-models-with-attention-sinks"><a class="markdownIt-Anchor" href="#efficient-streaming-language-models-with-attention-sinks"></a> Efficient Streaming Language Models with Attention Sinks</h2>
<p>Authors: Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, Mike Lewis<br />
Paper Link: <a href="https://arxiv.org/abs/2309.17453">https://arxiv.org/abs/2309.17453</a><br />
Github Link: <a href="https://github.com/mit-han-lab/streaming-llm">https://github.com/mit-han-lab/streaming-llm</a><br />
Blog: <a href="https://hanlab.mit.edu/blog/streamingllm">https://hanlab.mit.edu/blog/streamingllm</a></p>
<p>Researchers from MIT, Meta AI, CMU, and NVIDIA developed StreamingLLM, a framework enabling Large Language Models to efficiently process infinitely long input sequences without fine-tuning. This is achieved by leveraging an “attention sink” phenomenon where LLMs disproportionately attend to initial tokens, allowing the model to maintain stable perplexity and achieve up to a 22.2x speedup in decoding latency.</p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | July 30, 2025</title>
    <url>/2025/07/30/Daily-Paper-July-30-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#agentic-reinforced-policy-optimization">AGENTIC REINFORCED POLICY OPTIMIZATION</a></li>
<li><a href="#kimi-k2">KIMI-K2</a></li>
<li><a href="#flow-matching-policy-gradients">Flow Matching Policy Gradients</a></li>
<li><a href="#geometric-mean-policy-optimization">Geometric-Mean Policy Optimization</a></li>
<li><a href="#arc-hunyuan-video-7b-structured-video-comprehension-of-real-world-shorts">ARC-Hunyuan-Video-7B: Structured Video Comprehension of Real-World Shorts</a></li>
<li><a href="#driveagent-r1-advancing-vlm-based-autonomous-driving-with-hybrid-thinking-and-active-perception">DriveAgent-R1: Advancing VLM-based Autonomous Driving with Hybrid Thinking and Active Perception</a></li>
<li><a href="#security-challenges-in-ai-agent-deployment-insights-from-a-large-scale-public-competition">Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition</a></li>
<li><a href="#rep-mtl-unleashing-the-power-of-representation-level-task-saliency-for-multi-task-learning">Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning</a></li>
<li><a href="#self-guided-masked-autoencoder">Self-Guided Masked Autoencoder</a></li>
<li><a href="#transprune-token-transition-pruning-for-efficient-large-vision-language-model">TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model</a></li>
</ul>
<h2 id="agentic-reinforced-policy-optimization"><a class="markdownIt-Anchor" href="#agentic-reinforced-policy-optimization"></a> AGENTIC REINFORCED POLICY OPTIMIZATION</h2>
<p><img src="https://pic1.imgdb.cn/item/68897a6d58cb8da5c8ee9424.png" alt="" /></p>
<p>The paper “Agentic Reinforced Policy Optimization (ARPO)” introduces a novel reinforcement learning (RL) algorithm designed to enhance the performance and efficiency of Large Language Models (LLMs) in multi-turn, tool-augmented reasoning tasks. Existing RL methods for LLMs often fall short in balancing intrinsic long-horizon reasoning with proficiency in multi-turn tool interactions, primarily due to their trajectory-level sampling approaches.</p>
<p>ARPO addresses this gap by recognizing that LLMs exhibit high token entropy (i.e., uncertainty) immediately after interacting with external tools. Leveraging this insight, ARPO incorporates an entropy-based adaptive rollout mechanism that dynamically balances global trajectory sampling with step-level sampling. This promotes exploration at points of high uncertainty following tool usage. Furthermore, an advantage attribution estimation mechanism is integrated, allowing LLMs to internalize advantage differences in stepwise tool-use interactions.</p>
<p>Experimental results across 13 challenging benchmarks in computational reasoning, knowledge reasoning, and deep search domains demonstrate ARPO’s significant superiority over traditional trajectory-level RL algorithms. Crucially, ARPO achieves improved performance using only half of the tool-use budget required by existing methods, presenting a scalable and efficient solution for aligning LLM-based agents with dynamic real-time environments.</p>
<p><img src="https://pic1.imgdb.cn/item/68897b5a58cb8da5c8ee968f.png" alt="" /></p>
<h2 id="kimi-k2"><a class="markdownIt-Anchor" href="#kimi-k2"></a> KIMI-K2</h2>
<p>The source introduces <strong>Kimi K2</strong>, a large language model designed for <strong>agentic intelligence</strong>, emphasizing its ability to autonomously learn and interact. The paper details the <strong>MuonClip optimizer</strong> which ensures stable pre-training on a massive dataset of 15.5 trillion tokens, highlighting its efficiency and stability. Post-training involves <strong>large-scale agentic data synthesis</strong> for tool use and a <strong>reinforcement learning framework</strong> utilizing both verifiable rewards and self-critique. The document also presents <strong>extensive evaluation results</strong> showcasing Kimi K2’s state-of-the-art performance in areas like coding, mathematics, reasoning, and tool use, often surpassing other open-source and proprietary models. Finally, it outlines the model’s <strong>architecture, training infrastructure, and safety evaluations</strong>, noting its limitations and future research directions.</p>
<p><img src="https://pic1.imgdb.cn/item/68897ce658cb8da5c8ee9a01.png" alt="" /></p>
<h2 id="flow-matching-policy-gradients"><a class="markdownIt-Anchor" href="#flow-matching-policy-gradients"></a> Flow Matching Policy Gradients</h2>
<p><img src="https://pic1.imgdb.cn/item/68897d5758cb8da5c8ee9b96.png" alt="" /></p>
<p>Flow Policy Optimization (FPO) is a novel, on-policy reinforcement learning (RL) algorithm designed to train flow-based generative models, including diffusion models, within the policy gradient framework. FPO addresses key limitations of prior approaches by reformulating policy optimization as maximizing an advantage-weighted ratio derived from the conditional flow matching (CFM) loss. This method sidesteps the need for computationally expensive exact likelihood calculations, a common hurdle for flow-based models in RL. FPO is sampler-agnostic, meaning it is compatible with various diffusion or flow integration methods at both training and inference times, unlike previous diffusion-based RL techniques that bind training to specific sampling procedures. Empirical validation across diverse continuous control tasks, including GridWorld, MuJoCo Playground, and high-dimensional humanoid control, demonstrates that FPO can effectively train diffusion-style policies from scratch. Notably, FPO-trained policies can capture multimodal action distributions and achieve superior performance compared to traditional Gaussian policies, especially in under-conditioned scenarios.</p>
<hr />
<p>On-policy methods learn about the same policy that is used to generate the data. Think of it as learning by doing and only from your own experiences generated by your current way of doing things. Off-policy methods, conversely, learn about a different policy than the one generating the data. This allows them to learn from past experiences (even from an older or different behavior policy) and potentially from observing others.</p>
<h2 id="geometric-mean-policy-optimization"><a class="markdownIt-Anchor" href="#geometric-mean-policy-optimization"></a> Geometric-Mean Policy Optimization</h2>
<p><img src="https://pic1.imgdb.cn/item/68897d5758cb8da5c8ee9b96.png" alt="" /></p>
<p>This document introduces <strong>Geometric-Mean Policy Optimization (GMPO)</strong>, a new approach designed to enhance the <strong>stability and performance of large language models (LLMs)</strong> during reinforcement learning, particularly for reasoning tasks. It addresses issues found in previous methods like <strong>Group Relative Policy Optimization (GRPO)</strong>, which often suffer from <strong>unstable policy updates due to sensitivity to outlier rewards</strong>. GMPO achieves this by <strong>optimizing the geometric mean of token-level rewards</strong>, which inherently handles outliers more effectively, leading to <strong>more stable training and improved exploration capabilities</strong>. The paper provides <strong>theoretical justifications and experimental results</strong>, showcasing GMPO’s <strong>superior performance on various mathematical and multimodal reasoning benchmarks</strong> compared to existing methods.</p>
<p>Geometric-Mean Policy Optimization (GMPO) enhances large language model fine-tuning by replacing the arithmetic mean with a geometric mean in the policy optimization objective, which stabilizes training and improves exploration. GMPO leads to up to 4.1% higher Pass@1 accuracy on mathematical benchmarks and 1.4% on multimodal tasks compared to its predecessor, GRPO.</p>
<p><img src="https://pic1.imgdb.cn/item/6889809558cb8da5c8eeac04.png" alt="" /></p>
<h2 id="arc-hunyuan-video-7b-structured-video-comprehension-of-real-world-shorts"><a class="markdownIt-Anchor" href="#arc-hunyuan-video-7b-structured-video-comprehension-of-real-world-shorts"></a> ARC-Hunyuan-Video-7B: Structured Video Comprehension of Real-World Shorts</h2>
<p><img src="https://pic1.imgdb.cn/item/6889816b58cb8da5c8eeaf05.png" alt="" /></p>
<p>The document introduces <strong>ARC-Hunyuan-Video-7B</strong>, a novel <strong>multimodal model</strong> designed for <strong>structured comprehension of real-world short videos</strong>, particularly those from platforms like WeChat Channel and TikTok. Unlike previous models, it processes <strong>visual, audio, and textual signals</strong> end-to-end to address challenges posed by the fast-paced, information-dense nature of user-generated content. The model excels at <strong>multi-granularity timestamped video captioning, summarization, open-ended question answering, temporal video grounding, and video reasoning</strong>. Its development involved a comprehensive training regimen, including <strong>pre-training, instruction fine-tuning, cold start, and reinforcement learning</strong>, leveraging a high-quality, automatically annotated dataset. The paper presents <strong>qualitative and quantitative evaluations</strong> demonstrating the model’s superior performance in understanding the <strong>chronological flow, thematic nuances, and creative intent</strong> of videos, with <strong>real-world deployment</strong> showing improved user engagement.</p>
<p><img src="https://pic1.imgdb.cn/item/68899e4a58cb8da5c8ef4591.png" alt="" /></p>
<h2 id="driveagent-r1-advancing-vlm-based-autonomous-driving-with-hybrid-thinking-and-active-perception"><a class="markdownIt-Anchor" href="#driveagent-r1-advancing-vlm-based-autonomous-driving-with-hybrid-thinking-and-active-perception"></a> DriveAgent-R1: Advancing VLM-based Autonomous Driving with Hybrid Thinking and Active Perception</h2>
<p><img src="https://pic1.imgdb.cn/item/68899ead58cb8da5c8ef46c8.png" alt="" /></p>
<p>The research introduces <strong>DriveAgent-R1</strong>, an advanced autonomous driving agent designed to address the limitations of current <strong>Vision-Language Models (VLMs)</strong> in complex driving scenarios. It features a <strong>Hybrid-Thinking framework</strong> that adaptively switches between efficient text-based reasoning and in-depth, tool-based reasoning for enhanced decision-making. The agent also incorporates an <strong>Active Perception mechanism</strong> with a <strong>Vision Toolkit</strong> to proactively gather crucial visual information and resolve uncertainties, mirroring human driver behavior. A novel <strong>three-stage progressive reinforcement learning strategy</strong> trains the agent to master these capabilities, enabling it to achieve state-of-the-art performance by grounding its decisions in actively perceived visual evidence. This approach aims to create safer and more intelligent autonomous systems by balancing efficiency with reliability.</p>
<p><img src="https://pic1.imgdb.cn/item/68899f1c58cb8da5c8ef483a.png" alt="" /></p>
<h2 id="security-challenges-in-ai-agent-deployment-insights-from-a-large-scale-public-competition"><a class="markdownIt-Anchor" href="#security-challenges-in-ai-agent-deployment-insights-from-a-large-scale-public-competition"></a> Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition</h2>
<p><img src="https://pic1.imgdb.cn/item/68899fe558cb8da5c8ef4b49.png" alt="" /></p>
<p>This academic paper details a <strong>large-scale public red-teaming competition</strong> designed to evaluate the <strong>security vulnerabilities of AI agents</strong> powered by Large Language Models (LLMs). The study involved 22 frontier AI agents across 44 realistic deployment scenarios, where participants submitted <strong>1.8 million prompt-injection attacks</strong>, with over 60,000 successfully causing policy violations such as unauthorized data access or illicit financial actions. The researchers developed the <strong>Agent Red Teaming (ART) benchmark</strong> from these attacks, demonstrating that nearly all agents exhibit policy violations for most behaviors within 10–100 queries due to <strong>high attack transferability and universality</strong> across models and tasks. A crucial finding is the <strong>lack of correlation between an agent’s robustness and its model size, capability, or inference-time compute</strong>, emphasizing the urgent need for new defense mechanisms. The paper concludes by releasing the ART benchmark to support more rigorous security assessments and drive progress toward safer AI agent deployment.</p>
<p><img src="https://pic1.imgdb.cn/item/6889a03958cb8da5c8ef4c6e.png" alt="" /></p>
<h2 id="rep-mtl-unleashing-the-power-of-representation-level-task-saliency-for-multi-task-learning"><a class="markdownIt-Anchor" href="#rep-mtl-unleashing-the-power-of-representation-level-task-saliency-for-multi-task-learning"></a> Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning</h2>
<p><img src="https://pic1.imgdb.cn/item/6889a18f58cb8da5c8ef5778.png" alt="" /></p>
<p>This paper introduces <strong>Rep-MTL</strong>, a novel approach to multi-task learning (MTL) that aims to enhance performance by <strong>addressing negative transfer and promoting inter-task complementarity</strong> directly within the <strong>shared representation space</strong>. Unlike conventional multi-task optimization (MTO) techniques that primarily focus on optimizer-centric loss scaling and gradient manipulation, Rep-MTL utilizes <strong>representation-level task saliency</strong>. This method, through its <strong>Task-specific Saliency Regulation (TSR)</strong> and <strong>Cross-task Saliency Alignment (CSA)</strong> modules, <strong>preserves individual task learning patterns</strong> and <strong>facilitates beneficial information sharing</strong> without altering optimizers or network architectures. Empirical results across various benchmarks demonstrate Rep-MTL’s <strong>consistent performance gains and efficiency</strong>, even when paired with basic weighting policies.</p>
<p><img src="https://pic1.imgdb.cn/item/6889a1f958cb8da5c8ef5aeb.png" alt="" /></p>
<h2 id="self-guided-masked-autoencoder"><a class="markdownIt-Anchor" href="#self-guided-masked-autoencoder"></a> Self-Guided Masked Autoencoder</h2>
<p><img src="https://pic1.imgdb.cn/item/6889a37e58cb8da5c8ef6ed6.png" alt="" /></p>
<p>This collection of sources centers on an <strong>in-depth analysis and proposed improvement</strong> for <strong>Masked Autoencoders (MAE)</strong>, a self-supervised learning approach used in computer vision. The authors <strong>uncover that MAE inherently learns pattern-based patch clustering</strong> from early stages of pre-training. Building on this understanding, they introduce a <strong>“self-guided masked autoencoder”</strong> that generates <strong>informed masks internally</strong> by leveraging its progress in patch clustering, unlike the original MAE’s random masking. This novel approach <strong>significantly boosts MAE’s learning process</strong> without requiring external models or additional information, a benefit verified through comprehensive experiments on various downstream tasks like image classification, object detection, and semantic segmentation.</p>
<p><img src="https://pic1.imgdb.cn/item/6889a40e58cb8da5c8ef71cb.png" alt="" /></p>
<h2 id="transprune-token-transition-pruning-for-efficient-large-vision-language-model"><a class="markdownIt-Anchor" href="#transprune-token-transition-pruning-for-efficient-large-vision-language-model"></a> TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model</h2>
<p><img src="https://pic1.imgdb.cn/item/6889a63d58cb8da5c8ef8243.png" alt="" /></p>
<p>TransPrune introduces a method for Large Vision-Language Models that prunes less important visual tokens based on their representation transitions within transformer layers. This approach reduces inference TFLOPs of LLaVA-v1.5-7B by nearly 60% without performance degradation, and for LLaVA-Next-7B by 60% with minimal accuracy loss, addressing limitations of prior attention-based pruning.</p>
<p><img src="https://pic1.imgdb.cn/item/6889a71058cb8da5c8ef82cb.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | Aug 7, 2025</title>
    <url>/2025/08/07/Daily-Paper-Aug-7-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="qwen-image-technical-report"><a class="markdownIt-Anchor" href="#qwen-image-technical-report"></a> Qwen-Image Technical Report</h2>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2508.02324">https://www.alphaxiv.org/abs/2508.02324</a><br />
Github Link: <a href="https://github.com/QwenLM/Qwen-Image">https://github.com/QwenLM/Qwen-Image</a></p>
<p>Alibaba Cloud’s Qwen Team developed Qwen-Image, a multimodal foundation model that advances text-to-image generation and image editing. The model delivers state-of-the-art performance in complex text rendering, especially for Chinese, and achieves high precision in various editing tasks by unifying generative and understanding capabilities.</p>
<p><img src="https://pic1.imgdb.cn/item/6895510d58cb8da5c810c4df.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6895515c58cb8da5c810c5eb.png" alt="" /></p>
<h2 id="seed-diffusion-a-large-scale-diffusion-language-model-with-high-speed-inference"><a class="markdownIt-Anchor" href="#seed-diffusion-a-large-scale-diffusion-language-model-with-high-speed-inference"></a> Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference</h2>
<p><img src="https://pic1.imgdb.cn/item/6895520858cb8da5c810c894.png" alt="" /></p>
<p>Project Link: <a href="https://seed.bytedance.com/en/seed_diffusion">https://seed.bytedance.com/en/seed_diffusion</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2508.02193">https://www.alphaxiv.org/abs/2508.02193</a></p>
<p>Developed by ByteDance Seed and Tsinghua University, Seed Diffusion introduces a large-scale discrete-state diffusion model for code generation that achieves an inference speed of 2,146 tokens/second on H20 GPUs. The model maintains competitive performance across various code generation and editing benchmarks, establishing a new efficiency benchmark for code models.</p>
<h2 id="agent-lightning-train-any-ai-agents-with-reinforcement-learning"><a class="markdownIt-Anchor" href="#agent-lightning-train-any-ai-agents-with-reinforcement-learning"></a> Agent Lightning: Train ANY AI Agents with Reinforcement Learning</h2>
<p><img src="https://pic1.imgdb.cn/item/6895524f58cb8da5c810c92b.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/microsoft/agent-lightning">https://github.com/microsoft/agent-lightning</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2508.03680">https://www.alphaxiv.org/abs/2508.03680</a></p>
<p>Agent Lightning, developed by Microsoft Research, introduces a framework that completely decouples reinforcement learning (RL) training from AI agent execution, enabling continuous self-improvement for any LLM-based agent with minimal code modifications. It demonstrates stable and continuous performance improvement across diverse tasks, including Text-to-SQL (LangChain), Retrieval-Augmented Generation (OpenAI Agents SDK), and Math QA (AutoGen).</p>
<p><img src="https://pic1.imgdb.cn/item/689552e358cb8da5c810ca48.png" alt="" /></p>
<h2 id="se-agent-self-evolution-trajectory-optimization-in-multi-step-reasoning-with-llm-based-agents"><a class="markdownIt-Anchor" href="#se-agent-self-evolution-trajectory-optimization-in-multi-step-reasoning-with-llm-based-agents"></a> SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents</h2>
<p><img src="https://pic1.imgdb.cn/item/6895552058cb8da5c810cee2.png" alt="" /></p>
<p>SE-Agent introduces a self-evolution framework for LLM-based agents, optimizing multi-step reasoning through iterative revision, recombination, and refinement of complete interaction trajectories. The framework consistently outperformed strong baselines on the challenging SWE-bench Verified benchmark, achieving up to 112% relative improvement and uniquely solving issues previously unaddressed by other models.</p>
<p><img src="https://pic1.imgdb.cn/item/6895550b58cb8da5c810cece.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6895559258cb8da5c810cfe7.png" alt="" /></p>
<h2 id="beyond-the-trade-off-self-supervised-reinforcement-learning-for-reasoning-models-instruction-following"><a class="markdownIt-Anchor" href="#beyond-the-trade-off-self-supervised-reinforcement-learning-for-reasoning-models-instruction-following"></a> Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models’ Instruction Following</h2>
<p><img src="https://pic1.imgdb.cn/item/6895584558cb8da5c810d9df.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/Rainier-rq/verl-if">https://github.com/Rainier-rq/verl-if</a><br />
Paper link: <a href="https://www.alphaxiv.org/abs/2508.02150">https://www.alphaxiv.org/abs/2508.02150</a></p>
<p>A self-supervised reinforcement learning framework enhances large language models’ instruction-following capabilities by leveraging internal signals, rather than external models, while preserving or improving their core reasoning performance. The approach uses an incremental curriculum and a novel reward model for both hard and soft constraints, achieving higher scores on instruction-following benchmarks and maintaining general reasoning abilities.</p>
<p><img src="https://pic1.imgdb.cn/item/689557eb58cb8da5c810d973.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/6895586558cb8da5c810db1f.png" alt="" /></p>
<h2 id="compassverifier-a-unified-and-robust-verifier-for-llms-evaluation-and-outcome-reward"><a class="markdownIt-Anchor" href="#compassverifier-a-unified-and-robust-verifier-for-llms-evaluation-and-outcome-reward"></a> CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward</h2>
<p><img src="https://pic1.imgdb.cn/item/6896095258cb8da5c812f2b6.png" alt="" /></p>
<p>Paper: <a href="https://www.arxiv.org/pdf/2508.03686">https://www.arxiv.org/pdf/2508.03686</a><br />
Github: <a href="https://github.com/open-compass/CompassVerifier">https://github.com/open-compass/CompassVerifier</a></p>
<p>Researchers from Shanghai AI Laboratory and University of Macau introduce CompassVerifier, a lightweight model for verifying Large Language Model outputs, alongside VerifierBench, a challenging new benchmark. CompassVerifier demonstrates improved accuracy across diverse domains and answer types, and enhances reinforcement learning for LLM optimization by providing precise reward signals.</p>
<p><img src="https://pic1.imgdb.cn/item/68960ae558cb8da5c812f7ba.png" alt="" /><br />
<img src="https://pic1.imgdb.cn/item/68960b1758cb8da5c812f817.png" alt="" /></p>
<h2 id="trainable-dynamic-mask-sparse-attention"><a class="markdownIt-Anchor" href="#trainable-dynamic-mask-sparse-attention"></a> Trainable Dynamic Mask Sparse Attention</h2>
<p><img src="https://pic1.imgdb.cn/item/68960f9858cb8da5c812ff24.png" alt="" /></p>
<p>Paper: <a href="https://www.arxiv.org/pdf/2508.02124">https://www.arxiv.org/pdf/2508.02124</a><br />
Github: <a href="https://github.com/SmallDoges/flash-dmattn">https://github.com/SmallDoges/flash-dmattn</a></p>
<p>Dynamic Mask Attention (DMA) enables Large Language Models to process significantly longer contexts by dynamically selecting relevant tokens for attention computation, achieving up to 15.5x speedup over standard attention while maintaining or improving performance on long-context benchmarks.</p>
<p><img src="https://pic1.imgdb.cn/item/68960fec58cb8da5c813001a.png" alt="" /></p>
<h2 id="tura-tool-augmented-unified-retrieval-agent-for-ai-search"><a class="markdownIt-Anchor" href="#tura-tool-augmented-unified-retrieval-agent-for-ai-search"></a> TURA: Tool-Augmented Unified Retrieval Agent for AI Search</h2>
<p><img src="https://pic1.imgdb.cn/item/6896102958cb8da5c8130063.png" alt="" /></p>
<p><a href="https://www.arxiv.org/pdf/2508.04604">https://www.arxiv.org/pdf/2508.04604</a></p>
<p>TURA introduces a tool-augmented unified retrieval agent to bridge the gap between static content retrieval and dynamic information access in AI search. This framework enables the handling of real-time and transactional queries by integrating RAG with tool-augmented agents, leading to an 8.9% increase in session success rate and a 44.2% reduction in latency for complex queries in a production deployment at Baidu Inc.</p>
<p><img src="https://pic1.imgdb.cn/item/6896104058cb8da5c813008b.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Daily Paper | July 29, 2025</title>
    <url>/2025/07/29/Daily-Paper-July-29-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#alphago-moment-for-model-architecture-discovery">AlphaGo Moment for Model Architecture Discovery</a></li>
<li><a href="#group-sequence-policy-optimization">Group Sequence Policy Optimization</a></li>
<li><a href="#gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning">GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING</a></li>
<li><a href="#step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding">Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</a></li>
<li><a href="#back-to-the-features-dino-as-a-foundation-for-video-world-models">Back to the Features: DINO as a Foundation for Video World Models</a></li>
<li><a href="#gemini-25-pro-capable-of-winning-gold-at-imo-2025">Gemini 2.5 Pro Capable of Winning Gold at IMO 2025</a></li>
<li><a href="#learning-without-training--the-implicit-dynamics-of-in-context-learning">Learning without training : The implicit dynamics of in-context learning</a></li>
<li><a href="#checklists-are-better-than-reward-models-for-aligning-language-models">Checklists Are Better Than Reward Models For Aligning Language Models</a></li>
<li><a href="#gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset">GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</a></li>
</ul>
<h2 id="alphago-moment-for-model-architecture-discovery"><a class="markdownIt-Anchor" href="#alphago-moment-for-model-architecture-discovery"></a> AlphaGo Moment for Model Architecture Discovery</h2>
<p><img src="https://pic1.imgdb.cn/item/68887c2c58cb8da5c8eb80c3.png" alt="" /><br />
The provided text describes ASI-ARCH, an AI system designed to autonomously discover and innovate neural network architectures, moving beyond traditional human-limited search methods. The system operates through three core modules: a Researcher that proposes novel designs, an Engineer that implements and evaluates them, and an Analyst that extracts insights from experiments. ASI-ARCH has successfully identified 106 state-of-the-art linear attention architectures, demonstrating a computational scaling law for scientific discovery in AI research. This breakthrough suggests that AI can significantly accelerate the pace of architectural innovation by continually learning and evolving its own designs, similar to how AlphaGo revealed new strategic principles in games.</p>
<p><img src="https://pic1.imgdb.cn/item/68887baf58cb8da5c8eb7ded.png" alt="" /></p>
<h2 id="group-sequence-policy-optimization"><a class="markdownIt-Anchor" href="#group-sequence-policy-optimization"></a> Group Sequence Policy Optimization</h2>
<p><img src="https://pic1.imgdb.cn/item/68887c4a58cb8da5c8eb8124.png" alt="" /></p>
<p>GSPO addresses critical stability and efficiency issues inherent in previous state-of-the-art RL algorithms like Group Relative Policy Optimization (GRPO), particularly when training gigantic and Mixture-of-Experts (MoE) LLMs.</p>
<p>The core innovation of GSPO lies in its sequence-level approach to importance ratio definition, clipping, rewarding, and optimization, contrasting with GRPO’s token-level methods. This fundamental change is theorized to align more closely with the basic principles of importance sampling, where rewards are granted to entire sequences. GSPO has demonstrated superior training stability, efficiency, and performance, notably resolving the instability challenges in MoE RL training without complex workarounds. These advancements have been instrumental in the “remarkable improvements in the latest Qwen3 models.” GSPO also offers potential for simplifying RL infrastructure by enabling direct use of likelihoods from inference engines.</p>
<h2 id="gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning"><a class="markdownIt-Anchor" href="#gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning"></a> GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING</h2>
<p><img src="https://pic1.imgdb.cn/item/68887ce358cb8da5c8eb84e8.png" alt="" /></p>
<p>This paper introduces GEPA (Genetic-Pareto), a novel prompt optimizer designed for compound AI systems. GEPA distinguishes itself by employing a multi-objective evolutionary search that incorporates natural language feedback from new system rollouts to iteratively refine prompts. Unlike greedy update methods, GEPA maintains a Pareto front of top-performing prompts, fostering diversity and robust generalization to avoid local optima. The authors demonstrate GEPA’s superior sample efficiency and performance against state-of-the-art optimizers like MIPROv2 and GRPO across various tasks, highlighting its ability to generate shorter, more effective prompts and adapt AI systems rapidly even with limited data or budget. The methodology involves reflective prompt mutation and Pareto-based candidate selection, as illustrated by the system’s iterative search process and sample prompt examples for tasks like HotpotQA and PUPA.</p>
<p><img src="https://pic1.imgdb.cn/item/68887d4058cb8da5c8eb886f.png" alt="" /></p>
<h2 id="step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding"><a class="markdownIt-Anchor" href="#step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding"></a> Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</h2>
<p><img src="https://pic1.imgdb.cn/item/68887dcf58cb8da5c8eb8fc2.png" alt="" /></p>
<p>Step-3 is a 321-billion-parameter Vision-Language Model (VLM) developed by StepFun Inc., specifically designed to minimize decoding costs for long-context reasoning tasks. It introduces a novel “model-system co-design” approach that focuses on hardware efficiency. Key innovations include the Multi-Matrix Factorization Attention (MFA) mechanism, which reduces KV cache size and computation while maintaining expressiveness, and Attention-FFN Disaggregation (AFD), a distributed inference system that decouples attention and Feed-Forward Network (FFN) layers.</p>
<p>Step-3 activates 38 billion parameters per token, more than comparable models like DeepSeek-V3 and Qwen3 MoE 235B, yet achieves significantly lower theoretical decoding costs. Its implementation on Hopper GPUs demonstrates a decoding throughput of up to 4,039 tokens per second per GPU, outperforming DeepSeek-V3 and setting a new Pareto frontier for LLM decoding efficiency. The paper argues that total or activated parameter count is a poor indicator of decoding costs, highlighting the critical role of hardware-aligned attention arithmetic intensity, MoE sparsity, and AFD in achieving cost-effectiveness.</p>
<p><img src="https://pic1.imgdb.cn/item/68887e4458cb8da5c8eb9513.png" alt="" /></p>
<h2 id="back-to-the-features-dino-as-a-foundation-for-video-world-models"><a class="markdownIt-Anchor" href="#back-to-the-features-dino-as-a-foundation-for-video-world-models"></a> Back to the Features: DINO as a Foundation for Video World Models</h2>
<p><img src="https://pic1.imgdb.cn/item/68887e9e58cb8da5c8eb984c.png" alt="" /></p>
<p>The paper introduces DINO-world, a novel generalist video world model designed to predict future frames in the latent space of DINOv2. This model addresses key challenges in training effective world models, such as the need for large-scale, annotated video data and the computational cost of pixel-based generative models. By leveraging a pre-trained image encoder (DINOv2) and training a future predictor on a massive, uncurated video dataset, DINO-world achieves superior performance in diverse video prediction benchmarks, including segmentation and depth forecasting, and demonstrates a strong understanding of intuitive physics. A significant advantage is its ability to be fine-tuned on observation-action trajectories for planning, making it suitable for controlling agents in simulated environments. DINO-world offers a more resource-efficient architecture compared to state-of-the-art pixel-based models, making it a promising step towards more generalist and adaptable AI agents.</p>
<p><img src="https://pic1.imgdb.cn/item/68887fa958cb8da5c8eba499.png" alt="" /></p>
<h2 id="gemini-25-pro-capable-of-winning-gold-at-imo-2025"><a class="markdownIt-Anchor" href="#gemini-25-pro-capable-of-winning-gold-at-imo-2025"></a> Gemini 2.5 Pro Capable of Winning Gold at IMO 2025</h2>
<p><img src="https://pic1.imgdb.cn/item/6888803858cb8da5c8ebaad7.png" alt="" /></p>
<p>A recent research paper, “Gemini 2.5 Pro Capable of Winning Gold at IMO 2025,” presents a significant breakthrough in the field of Large Language Models (LLMs) and their ability to solve highly complex mathematical problems, specifically those encountered in the International Mathematical Olympiad (IMO). The authors, Yichen Huang and Lin F. Yang, demonstrate that by employing a sophisticated “self-verification pipeline” with meticulous prompt engineering, Google’s Gemini 2.5 Pro model successfully solved 5 out of 6 problems from the newly released IMO 2025 competition. This performance level is unprecedented for LLMs on Olympiad-level mathematics and suggests a shift from mere pattern recognition or data retrieval to more genuine complex reasoning and proof construction capabilities. The methodology emphasizes rigorous, multi-step logical deduction and an iterative refinement process, indicating that optimal strategies are crucial for harnessing the full potential of powerful LLMs for complex reasoning tasks.</p>
<p><img src="https://pic1.imgdb.cn/item/688880a258cb8da5c8ebb00f.png" alt="" /></p>
<h2 id="learning-without-training-the-implicit-dynamics-of-in-context-learning"><a class="markdownIt-Anchor" href="#learning-without-training-the-implicit-dynamics-of-in-context-learning"></a> Learning without training : The implicit dynamics of in-context learning</h2>
<p><img src="https://pic1.imgdb.cn/item/6888811b58cb8da5c8ebb46a.png" alt="" /></p>
<p>This paper explores In-Context Learning (ICL) in Large Language Models (LLMs), a phenomenon where LLMs acquire new patterns from examples presented in the prompt without explicit weight updates. The authors propose that a transformer block, specifically the stacking of a self-attention layer with an MLP (Multi-Layer Perceptron), implicitly modifies the MLP layer’s weights based on the input context. They introduce the concept of a “contextual block” and demonstrate through theory and experimentation how context translates into a low-rank weight update of the MLP, effectively acting as an implicit fine-tuning mechanism. This implicit update is shown to resemble gradient descent, suggesting a form of implicit learning dynamics at inference time. The research offers a theoretical framework for understanding ICL beyond restrictive assumptions of prior work, although it acknowledges limitations to single transformer blocks and the initial output token.</p>
<h2 id="checklists-are-better-than-reward-models-for-aligning-language-models"><a class="markdownIt-Anchor" href="#checklists-are-better-than-reward-models-for-aligning-language-models"></a> Checklists Are Better Than Reward Models For Aligning Language Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688882e958cb8da5c8ebc2bf.png" alt="" /></p>
<p>The provided text introduces Reinforcement Learning from Checklist Feedback (RLCF), a novel method for aligning large language models (LLMs) to better follow user instructions. Unlike traditional reinforcement learning methods that use fixed criteria, RLCF employs dynamic, instruction-specific checklists to evaluate responses, generating more flexible and precise reward signals. This approach utilizes both AI judges and specialized verifier programs to score how well an LLM’s output satisfies each checklist item. The authors demonstrate that RLCF consistently improves performance across various benchmarks, highlighting its effectiveness in eliciting desirable behaviors in open-ended instruction-following tasks, even for models that haven’t been specifically instruction-tuned. The research also details the creation of “WildChecklists,” a large dataset of instructions and corresponding synthetically generated checklists, and explores the computational efficiency of the method.</p>
<p><img src="https://pic1.imgdb.cn/item/6888832d58cb8da5c8ebc456.png" alt="" /></p>
<h2 id="gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset"><a class="markdownIt-Anchor" href="#gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset"></a> GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</h2>
<p><img src="https://pic1.imgdb.cn/item/6888839258cb8da5c8ebc931.png" alt="" /></p>
<p>The “GPT-IMAGE-EDIT-1.5M” paper introduces a significant new public dataset designed to advance open-source research in instruction-guided image editing. This dataset comprises over 1.5 million high-quality triplets of {instruction, source image, edited image}. It was systematically constructed by leveraging the advanced capabilities of GPT-4o to unify and refine existing popular image-editing datasets (OmniEdit, HQ-Edit, and UltraEdit). The core methodology involves regenerating output images for enhanced visual quality and instruction alignment, and selectively rewriting prompts to improve semantic clarity.</p>
<p>Models fine-tuned on GPT-IMAGE-EDIT-1.5M, specifically FluxKontext, have achieved state-of-the-art performance among open-source methods across various benchmarks (e.g., 7.24@GEdit-EN, 3.80@ImgEdit-Full, 8.78@Complex-Edit). This significantly narrows the performance gap with leading proprietary models like GPT-4o. The release of this dataset aims to “catalyze further open research in instruction-guided image editing.”</p>
<p><img src="https://pic1.imgdb.cn/item/6888843458cb8da5c8ebcdd9.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Failed to connect to github.com port 443 after 75016 ms: Couldn&#39;t connect to server</title>
    <url>/2023/12/10/Failed-to-connect-to-github-com-port-443-after-75016-ms-Couldn-t-connect-to-server/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="number">18</span>:<span class="number">07</span>:<span class="number">19</span>.<span class="number">099</span>: [djangoProject1] git -c credential.helper= -c core.quotepath=false -c log.showSignature=false push --progress --porcelain origin refs/heads/main:refs/heads/main --<span class="built_in">set</span>-upstream</span><br><span class="line"><span class="function">fatal: <span class="title">unable</span> <span class="title">to</span> <span class="title">access</span> &#x27;<span class="title">https</span>://<span class="title">github.com</span>/<span class="title">abinzzz</span>/<span class="title">BUPT_AC_Hotel.git</span>/&#x27;: <span class="title">Failed</span> <span class="title">to</span> <span class="title">connect</span> <span class="title">to</span> <span class="title">github.com</span> <span class="title">port</span> 443 <span class="title">after</span> 75004 <span class="title">ms</span>: <span class="title">Couldn</span>&#x27;<span class="title">t</span> <span class="title">connect</span> <span class="title">to</span> <span class="title">server</span></span></span><br></pre></td></tr></table></figure>
<p>项目已经在 GitHub 上创建成功，但是初始推送（initial push）失败了,在尝试连接到 <a href="http://github.com">github.com</a> 的 443 端口时，经过了 75004 毫秒后仍然无法建立连接，即 “Couldn’t connect to server”.</p>
<p><strong>出错原因</strong>： 网络连接问题</p>
<br>
<p><strong>解决方法</strong>：别用校园网，用流量，我改用流量后的结果如下</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="number">18</span>:<span class="number">16</span>:<span class="number">02</span>.<span class="number">093</span>: [djangoProject1] git -c credential.helper= -c core.quotepath=false -c log.showSignature=false push --progress --porcelain origin refs/heads/main:refs/heads/main --<span class="built_in">set</span>-upstream</span><br><span class="line">Enumerating objects: <span class="number">62</span>, done.</span><br><span class="line">Counting objects:   <span class="number">1</span>% (<span class="number">1</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:   <span class="number">3</span>% (<span class="number">2</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:   <span class="number">4</span>% (<span class="number">3</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:   <span class="number">6</span>% (<span class="number">4</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:   <span class="number">8</span>% (<span class="number">5</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:   <span class="number">9</span>% (<span class="number">6</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">11</span>% (<span class="number">7</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">12</span>% (<span class="number">8</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">14</span>% (<span class="number">9</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">16</span>% (<span class="number">10</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">17</span>% (<span class="number">11</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">19</span>% (<span class="number">12</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">20</span>% (<span class="number">13</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">22</span>% (<span class="number">14</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">24</span>% (<span class="number">15</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">25</span>% (<span class="number">16</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">27</span>% (<span class="number">17</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">29</span>% (<span class="number">18</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">30</span>% (<span class="number">19</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">32</span>% (<span class="number">20</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">33</span>% (<span class="number">21</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">35</span>% (<span class="number">22</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">37</span>% (<span class="number">23</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">38</span>% (<span class="number">24</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">40</span>% (<span class="number">25</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">41</span>% (<span class="number">26</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">43</span>% (<span class="number">27</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">45</span>% (<span class="number">28</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">46</span>% (<span class="number">29</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">48</span>% (<span class="number">30</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">50</span>% (<span class="number">31</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">51</span>% (<span class="number">32</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">53</span>% (<span class="number">33</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">54</span>% (<span class="number">34</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">56</span>% (<span class="number">35</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">58</span>% (<span class="number">36</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">59</span>% (<span class="number">37</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">61</span>% (<span class="number">38</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">62</span>% (<span class="number">39</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">64</span>% (<span class="number">40</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">66</span>% (<span class="number">41</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">67</span>% (<span class="number">42</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">69</span>% (<span class="number">43</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">70</span>% (<span class="number">44</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">72</span>% (<span class="number">45</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">74</span>% (<span class="number">46</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">75</span>% (<span class="number">47</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">77</span>% (<span class="number">48</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">79</span>% (<span class="number">49</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">80</span>% (<span class="number">50</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">82</span>% (<span class="number">51</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">83</span>% (<span class="number">52</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">85</span>% (<span class="number">53</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">87</span>% (<span class="number">54</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">88</span>% (<span class="number">55</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">90</span>% (<span class="number">56</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">91</span>% (<span class="number">57</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">93</span>% (<span class="number">58</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">95</span>% (<span class="number">59</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">96</span>% (<span class="number">60</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects:  <span class="number">98</span>% (<span class="number">61</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects: <span class="number">100</span>% (<span class="number">62</span>/<span class="number">62</span>)</span><br><span class="line">Counting objects: <span class="number">100</span>% (<span class="number">62</span>/<span class="number">62</span>), done.</span><br><span class="line">Delta compression using up to <span class="number">8</span> threads</span><br><span class="line">Compressing objects:   <span class="number">1</span>% (<span class="number">1</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:   <span class="number">3</span>% (<span class="number">2</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:   <span class="number">5</span>% (<span class="number">3</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:   <span class="number">6</span>% (<span class="number">4</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:   <span class="number">8</span>% (<span class="number">5</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">10</span>% (<span class="number">6</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">11</span>% (<span class="number">7</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">13</span>% (<span class="number">8</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">15</span>% (<span class="number">9</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">16</span>% (<span class="number">10</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">18</span>% (<span class="number">11</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">20</span>% (<span class="number">12</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">22</span>% (<span class="number">13</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">23</span>% (<span class="number">14</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">25</span>% (<span class="number">15</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">27</span>% (<span class="number">16</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">28</span>% (<span class="number">17</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">30</span>% (<span class="number">18</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">32</span>% (<span class="number">19</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">33</span>% (<span class="number">20</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">35</span>% (<span class="number">21</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">37</span>% (<span class="number">22</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">38</span>% (<span class="number">23</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">40</span>% (<span class="number">24</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">42</span>% (<span class="number">25</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">44</span>% (<span class="number">26</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">45</span>% (<span class="number">27</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">47</span>% (<span class="number">28</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">49</span>% (<span class="number">29</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">50</span>% (<span class="number">30</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">52</span>% (<span class="number">31</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">54</span>% (<span class="number">32</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">55</span>% (<span class="number">33</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">57</span>% (<span class="number">34</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">59</span>% (<span class="number">35</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">61</span>% (<span class="number">36</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">62</span>% (<span class="number">37</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">64</span>% (<span class="number">38</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">66</span>% (<span class="number">39</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">67</span>% (<span class="number">40</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">69</span>% (<span class="number">41</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">71</span>% (<span class="number">42</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">72</span>% (<span class="number">43</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">74</span>% (<span class="number">44</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">76</span>% (<span class="number">45</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">77</span>% (<span class="number">46</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">79</span>% (<span class="number">47</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">81</span>% (<span class="number">48</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">83</span>% (<span class="number">49</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">84</span>% (<span class="number">50</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">86</span>% (<span class="number">51</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">88</span>% (<span class="number">52</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">89</span>% (<span class="number">53</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">91</span>% (<span class="number">54</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">93</span>% (<span class="number">55</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">94</span>% (<span class="number">56</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">96</span>% (<span class="number">57</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects:  <span class="number">98</span>% (<span class="number">58</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects: <span class="number">100</span>% (<span class="number">59</span>/<span class="number">59</span>)</span><br><span class="line">Compressing objects: <span class="number">100</span>% (<span class="number">59</span>/<span class="number">59</span>), done.</span><br><span class="line">Writing objects:   <span class="number">1</span>% (<span class="number">1</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:   <span class="number">3</span>% (<span class="number">2</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:   <span class="number">4</span>% (<span class="number">3</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:   <span class="number">6</span>% (<span class="number">4</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:   <span class="number">8</span>% (<span class="number">5</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:   <span class="number">9</span>% (<span class="number">6</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">11</span>% (<span class="number">7</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">12</span>% (<span class="number">8</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">14</span>% (<span class="number">9</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">16</span>% (<span class="number">10</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">17</span>% (<span class="number">11</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">19</span>% (<span class="number">12</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">20</span>% (<span class="number">13</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">22</span>% (<span class="number">14</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">24</span>% (<span class="number">15</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">25</span>% (<span class="number">16</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">29</span>% (<span class="number">18</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">30</span>% (<span class="number">19</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">32</span>% (<span class="number">20</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">33</span>% (<span class="number">21</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">35</span>% (<span class="number">22</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">38</span>% (<span class="number">24</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">40</span>% (<span class="number">25</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">41</span>% (<span class="number">26</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">43</span>% (<span class="number">27</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">45</span>% (<span class="number">28</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">46</span>% (<span class="number">29</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">48</span>% (<span class="number">30</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">50</span>% (<span class="number">31</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">51</span>% (<span class="number">32</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">53</span>% (<span class="number">33</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">54</span>% (<span class="number">34</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">56</span>% (<span class="number">35</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">58</span>% (<span class="number">36</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">59</span>% (<span class="number">37</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">61</span>% (<span class="number">38</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">62</span>% (<span class="number">39</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">64</span>% (<span class="number">40</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">66</span>% (<span class="number">41</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">67</span>% (<span class="number">42</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">69</span>% (<span class="number">43</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">70</span>% (<span class="number">44</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">72</span>% (<span class="number">45</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">74</span>% (<span class="number">46</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">75</span>% (<span class="number">47</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">77</span>% (<span class="number">48</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">79</span>% (<span class="number">49</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">80</span>% (<span class="number">50</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">82</span>% (<span class="number">51</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">83</span>% (<span class="number">52</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">85</span>% (<span class="number">53</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">88</span>% (<span class="number">55</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">90</span>% (<span class="number">56</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">91</span>% (<span class="number">57</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">95</span>% (<span class="number">59</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">96</span>% (<span class="number">60</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects:  <span class="number">98</span>% (<span class="number">61</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects: <span class="number">100</span>% (<span class="number">62</span>/<span class="number">62</span>)</span><br><span class="line">Writing objects: <span class="number">100</span>% (<span class="number">62</span>/<span class="number">62</span>), <span class="number">8</span>.<span class="number">47</span> MiB | <span class="number">722</span>.<span class="number">82</span> MiB/s, done.</span><br><span class="line">Total <span class="number">62</span> (delta <span class="number">6</span>), reused <span class="number">0</span> (delta <span class="number">0</span>), pack-reused <span class="number">0</span></span><br><span class="line"><span class="function">remote: <span class="title">Resolving</span> <span class="title">deltas</span>:   0% (0/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>:  16% (1/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>:  33% (2/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>:  50% (3/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>:  66% (4/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>:  83% (5/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>: 100% (6/6)        </span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Resolving</span> <span class="title">deltas</span>: 100% (6/6), <span class="title">done</span>.        </span></span><br><span class="line"><span class="function"><span class="title">To</span> <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">abinzzz</span>/<span class="title">BUPT_AC_Hotel.git</span></span></span><br><span class="line"><span class="function">*	<span class="title">refs</span>/<span class="title">heads</span>/<span class="title">main:refs</span>/<span class="title">heads</span>/<span class="title">main</span>	[<span class="title">new</span> <span class="title">branch</span>]</span></span><br><span class="line"><span class="function"><span class="title">branch</span> &#x27;<span class="title">main</span>&#x27; <span class="title">set</span> <span class="title">up</span> <span class="title">to</span> <span class="title">track</span> &#x27;<span class="title">origin</span>/<span class="title">main</span>&#x27;.</span></span><br><span class="line"><span class="function"><span class="title">Done</span></span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker</title>
    <url>/2024/01/11/Docker/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV14s4y1i7Vf/?p=2&amp;share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">GeekHour】30分钟Docker入门教程</a></li>
</ul>
<h2 id="1docker简介"><a class="markdownIt-Anchor" href="#1docker简介"></a> 1.Docker简介</h2>
<p>目的：解决开发环境问题</p>
<p>docker十一个用于build,run,share应用程序的平台</p>
<p><img src="https://pbs.twimg.com/media/GDqQwdxXoAA3PWM?format=png&amp;name=small" alt="" /></p>
<h3 id="举例说明使用docker的区别"><a class="markdownIt-Anchor" href="#举例说明使用docker的区别"></a> <code>举例说明使用docker的区别</code></h3>
<p>Docker作为一个应用程序平台的作用,可以将应用程序及其依赖项打包在一起,以便在任何环境中正确运行。</p>
<p>通过Docker,可以将网站的各种环境和依赖项打包在一起,而不需要在每个环境中重复安装和配置。这可以大大节省时间和精力,并使应用程序的部署更加容易和可靠</p>
<p>不使用docker：<br />
<img src="https://pbs.twimg.com/media/GDqRXkvWUAA6aaO?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<p>使用docker：<br />
<img src="https://pbs.twimg.com/media/GDqRiZzXwAAGW2z?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="2docker与虚拟机的区别docker-container"><a class="markdownIt-Anchor" href="#2docker与虚拟机的区别docker-container"></a> 2.Docker与虚拟机的区别(docker != container)</h2>
<p>Docker 是属于容器服务的一种，是一个开源的应用容器引擎,不等于容器。</p>
<p>传统虚拟机使用虚拟化技术将物理资源虚拟为多个逻辑资源,需要占用大量资源并且启动速度慢。而容器使用宿主机的操作系统,启动速度快且占用资源少,可以在一台物理服务器上运行更多的容器,更加充分地利用服务器的资源。因此,容器是一种更适合用于提供服务的环境。</p>
<br>
<p>虚拟机：<br />
<img src="https://pbs.twimg.com/media/GDqSymeWAAAczJE?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Docker：<br />
<img src="https://pbs.twimg.com/media/GDqTKoQXIAAl3_Y?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="3基本原理和概念"><a class="markdownIt-Anchor" href="#3基本原理和概念"></a> 3.基本原理和概念</h2>
<p>镜像是只读的模板，用来创建容器;</p>
<p>容器是Docker的运行实例，提供独立的环境;</p>
<p>仓库是存储镜像的地方，最常用的就是Docker Hub。</p>
<p><img src="https://pbs.twimg.com/media/GDqUV2aXcAAICTL?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="4容器化和dokcerfile"><a class="markdownIt-Anchor" href="#4容器化和dokcerfile"></a> 4.容器化和Dokcerfile</h2>
<p>step1: 创建一个dockerfile(类似makefile)</p>
<p>step2: 使用dockerfile构建镜像</p>
<p>step3: 使用镜像创建和运行容器</p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub Copilot申请指北</title>
    <url>/2024/01/10/GitHub-Copilot%E7%94%B3%E8%AF%B7%E6%8C%87%E5%8C%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1-关于github学生包github-student-developer-pack"><a class="markdownIt-Anchor" href="#1-关于github学生包github-student-developer-pack"></a> 1. 关于Github学生包（GitHub Student Developer Pack）</h2>
<p>Github的学生包里包括Github Pro及Github Copilot等Github福利。</p>
<p>您也可以用Github的学生认证直接认证JetBrains的学生认证。</p>
<p>Github学生认证可以享受如：1Password（一年）、termius等的软件订阅权益。</p>
<p>同时也可以借由Github的学生认证申请一系列如Azure等云服务商的有期限免费额度及一些域名商为期一年的免费特定后缀域名。</p>
<br>
<h2 id="2申请条件"><a class="markdownIt-Anchor" href="#2申请条件"></a> 2.申请条件</h2>
<ul>
<li>目前就读于初高中、学院、大学、家庭学校或类似教育机构等可以授予学位或文凭的教育机构</li>
<li>有一个可验证的学校发布的电子邮件地址或上传文件，证明您当前的学生身份</li>
<li>年满13周岁</li>
</ul>
<p>注意事项：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注意：在申请Github学生认证的全程都禁止使用代理（除了Bing地图，下文会提及），并保持给予Github定位权限（必须）</span><br><span class="line"></span><br><span class="line">建议：建议在学校附近进行定位（Windows等可以使用虚拟定位）并使用校园网环境，如果条件允许建议使用手机进行操作。</span><br></pre></td></tr></table></figure>
<br>
<h2 id="3准备材料"><a class="markdownIt-Anchor" href="#3准备材料"></a> 3.准备材料</h2>
<p>教育邮箱（即学校发放的<a href="http://edu.xn--cn-rn6c002kkoffpfir1b">http://edu.cn后缀的邮箱</a>）（bixu）</p>
<p>以下材料四选一</p>
<ul>
<li>带有学校名称，学校公章（如有），个人信息及有效期的学生证</li>
<li>带有学校名称，入学日期和学校公章的录取通知书（推荐）</li>
<li>学信网的个人学籍报告或学校出具的在读证明（最好是学校信纸头的），最好是英文版的（推荐）</li>
<li>学期课表等Github支持的其他认证材料（不推荐）</li>
</ul>
<Br>
<h2 id="4申请过程"><a class="markdownIt-Anchor" href="#4申请过程"></a> 4.申请过程</h2>
<ul>
<li>先申请一个Github账号（这里就不做过多赘述）</li>
<li>打开<a href="https://education.github.com/discount_requests/application">GitHub benefits</a></li>
<li>选择“Student”</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>github</tag>
        <tag>copilot</tag>
      </tags>
  </entry>
  <entry>
    <title>GB与GiB</title>
    <url>/2024/01/10/GB%E4%B8%8EGiB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="gib与gb"><a class="markdownIt-Anchor" href="#gib与gb"></a> GiB与GB</h2>
<p>Gibibyte(giga binary byte的缩写)是信息或计算机硬盘存储的一个单位，简称GiB。由来“GiB”、“KiB”、“MiB”等是于1999年由国际电工协会(IEC)拟定了&quot;KiB&quot;、“MiB”、“GiB&quot;的二进制单位，专用来标示“1024进位”的数据大小。而后，这一标注规范又于2008年并入国际标准化组织(ISO)文件。具体的来说,1GiB=1024MiB，1MiB=1024KiB。他们与GB、MB、KB是不一样的，GB等则是1000进位的数据单位。</p>
<p>根据Wikipedia的注译，GB(gigabyte)是十进制的容量单位，1GB等于1,000,000,000 Bytes。而二进制的容量单位则是用GiB(Gibibyte)就是Giga Binary Byte，相等于1,073,741,824 Bytes。</p>
<p>所以一个160GB的硬盘其实只有149.0116119 GiB，厂商并没有欺骗顾客，更由于无法精确控制盘面的容量，大多数时候都会提供多余的空间以确保品质。</p>
<br>
<h2 id="gb以10为底数的指数10进制"><a class="markdownIt-Anchor" href="#gb以10为底数的指数10进制"></a> GB：以10为底数的指数（10进制）</h2>
<p>例子：</p>
<ul>
<li>1KB=10^3 =1000B,</li>
<li>1MB=10^6=1000000=1000KB，</li>
<li>1GB=10^9=1000000000=1000MB,</li>
</ul>
<br>
<h2 id="gib以2为底数的指数2进制"><a class="markdownIt-Anchor" href="#gib以2为底数的指数2进制"></a> GiB：以2为底数的指数（2进制）</h2>
<p>例子：</p>
<ul>
<li>1KiB=2^10=1024B,</li>
<li>1MiB=2^20=1048576=1024KiB，</li>
<li>1GiB=2^30=1,073,741,824=1024MiB</li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>GB</tag>
        <tag>GiB</tag>
      </tags>
  </entry>
  <entry>
    <title>Github Copilot代理设置</title>
    <url>/2024/01/24/Github-Copilot%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h2>
<p><img src="https://pbs.twimg.com/media/GEnhZBIbQAAKtGR?format=png&amp;name=900x900" alt="" /></p>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<ol>
<li>找到copilot的环境设置</li>
</ol>
<p><img src="https://pbs.twimg.com/media/GEnh6bKa4AAH1Jf?format=jpg&amp;name=medium" alt="" /></p>
<p><img src="https://pbs.twimg.com/media/GEnh6bKa4AAH1Jf?format=jpg&amp;name=medium" alt="" /></p>
<br>
<ol start="2">
<li>将false改为true即可<br />
<img src="https://pbs.twimg.com/media/GEniWGyaMAAadFb?format=jpg&amp;name=medium" alt="" /></li>
</ol>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>github</tag>
        <tag>copilot</tag>
      </tags>
  </entry>
  <entry>
    <title>Daily Paper | July 31, 2025</title>
    <url>/2025/07/31/Daily-Paper-July-31-2025/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#metaclip-2-a-worldwide-scaling-recipe">MetaCLIP 2: A Worldwide Scaling Recipe</a></li>
<li><a href="#x-omni-reinforcement-learning-makes-discrete-autoregressive-image-generative-models-great-again">X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again</a></li>
<li><a href="#hunyuanworld-10-generating-immersive-explorable-and-interactive-3d-worlds-from-words-or-pixels">HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels</a></li>
<li><a href="#graph-r1-towards-agentic-graphrag-framework-via-end-to-end-reinforcement-learning">Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning</a></li>
<li><a href="#learning-only-with-images-visual-reinforcement-learning-with-reasoning-rendering-and-visual-feedback">Learning Only with Images: Visual Reinforcement Learning with Reasoning, Rendering, and Visual Feedback</a></li>
<li><a href="#edge-grpo-entropy-driven-grpo-with-guided-error-correction-for-advantage-diversity">EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity</a></li>
<li><a href="#smallthinker-a-family-of-efficient-large-language-models-natively-trained-for-local-deployment">SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment</a></li>
<li><a href="#mixgrpo-unlocking-flow-based-grpo-efficiency-with-mixed-ode-sde">MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE</a></li>
<li><a href="#towards-a-large-physics-benchmark">Towards a Large Physics Benchmark</a></li>
<li><a href="#stepfun-prover-preview-lets-think-and-verify-step-by-step">StepFun-Prover Preview: Let’s Think and Verify Step by Step</a></li>
</ul>
<h2 id="metaclip-2-a-worldwide-scaling-recipe"><a class="markdownIt-Anchor" href="#metaclip-2-a-worldwide-scaling-recipe"></a> MetaCLIP 2: A Worldwide Scaling Recipe</h2>
<p><img src="https://pic1.imgdb.cn/item/688af73958cb8da5c8f38709.png" alt="" /><br />
Alphaxiv Link: <a href="https://www.alphaxiv.org/abs/2507.22062">https://www.alphaxiv.org/abs/2507.22062</a><br />
Code and Model: <a href="https://github.com/facebookresearch/MetaCLIP">https://github.com/facebookresearch/MetaCLIP</a></p>
<p>Contrastive Language-Image Pretraining (CLIP) is a popular foundation model, supporting from zeroshot classification, retrieval to encoders for multimodal large language models (MLLMs). Although CLIP is successfully trained on billion-scale image-text pairs from the English world, scaling CLIP’s training further to learning from the worldwide web data is still challenging: (1) no curation method is available to handle data points from non-English world; (2) the English performance from existing multilingual CLIP is worse than its English-only counterpart, i.e., “curse of multilinguality” that is common in LLMs. Here, we present MetaCLIP 2, the first recipe training CLIP from scratch on worldwide web-scale image-text pairs. To generalize our findings, we conduct rigorous ablations with minimal changes that are necessary to address the above challenges and present a recipe enabling mutual benefits from English and non-English world data. In zero-shot ImageNet classification, MetaCLIP 2 ViT-H/14 surpasses its English-only counterpart by 0.8% and mSigLIP by 0.7%, and surprisingly sets new state-of-the-art without system-level confounding factors (e.g., translation, bespoke architecture changes) on multilingual benchmarks, such as CVQA with 57.4%, Babel-ImageNet with 50.2% and XM3600 with 64.3% on image-to-text retrieval.</p>
<p><img src="https://pic1.imgdb.cn/item/688af78e58cb8da5c8f388d3.png" alt="" /></p>
<h2 id="x-omni-reinforcement-learning-makes-discrete-autoregressive-image-generative-models-great-again"><a class="markdownIt-Anchor" href="#x-omni-reinforcement-learning-makes-discrete-autoregressive-image-generative-models-great-again"></a> X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again</h2>
<p><img src="https://pic1.imgdb.cn/item/688aff1958cb8da5c8f3bc42.png" alt="" /></p>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2507.22058">https://www.alphaxiv.org/abs/2507.22058</a><br />
Github Link: <a href="https://github.com/X-Omni-Team/X-Omni">https://github.com/X-Omni-Team/X-Omni</a><br />
Project Link: <a href="https://x-omni-team.github.io/">https://x-omni-team.github.io/</a></p>
<p>Numerous efforts have been made to extend the “next token prediction” paradigm to visual contents, aiming to create a unified approach for both image generation and understanding. Nevertheless, attempts to generate images through autoregressive modeling with discrete tokens have been plagued by issues such as low visual fidelity, distorted outputs, and failure to adhere to complex instructions when rendering intricate details. These shortcomings are likely attributed to cumulative errors during autoregressive inference or information loss incurred during the discretization process. Probably due to this challenge, recent research has increasingly shifted toward jointly training image generation with diffusion objectives and language generation with autoregressive objectives, moving away from unified modeling approaches. In this work, we demonstrate that reinforcement learning can effectively mitigate artifacts and largely enhance the generation quality of a discrete autoregressive modeling method, thereby enabling seamless integration of image and language generation. Our framework comprises a semantic image tokenizer, a unified autoregressive model for both language and images, and an offline diffusion decoder for image generation, termed X-Omni. X-Omni achieves state-of-the-art performance in image generation tasks using a 7B language model, producing images with high aesthetic quality while exhibiting strong capabilities in following instructions and rendering long texts.</p>
<p><img src="https://pic1.imgdb.cn/item/688b01f758cb8da5c8f3d841.png" alt="" /></p>
<h2 id="hunyuanworld-10-generating-immersive-explorable-and-interactive-3d-worlds-from-words-or-pixels"><a class="markdownIt-Anchor" href="#hunyuanworld-10-generating-immersive-explorable-and-interactive-3d-worlds-from-words-or-pixels"></a> HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels</h2>
<p><strong>The writing in this aritcle is worth studying.</strong></p>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21809">https://www.alphaxiv.org/abs/2507.21809</a><br />
Project Link: <a href="https://3d.hunyuan.tencent.com/sceneTo3D">https://3d.hunyuan.tencent.com/sceneTo3D</a><br />
Github Link: <a href="https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0">https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0</a></p>
<p>Creating immersive and playable 3D worlds from texts or images remains a fundamental challenge in computer vision and graphics. Existing world generation approaches typically fall into two categories: video-based methods that offer rich diversity but lack 3D consistency and rendering efficiency, and 3D-based methods that provide geometric consistency but struggle with limited training data and memory-inefficient representations. To address these limitations, we present HunyuanWorld 1.0, a novel framework that combines the best of both worlds for generating immersive, explorable, and interactive 3D scenes from text and image conditions. Our approach features three key advantages: 1) 360° immersive experiences via panoramic world proxies; 2) mesh export capabilities for seamless compatibility with existing computer graphics pipelines; 3) disentangled object representations for augmented interactivity. The core of our framework is a semantically layered 3D mesh representation that leverages panoramic images as 360° world proxies for semantic-aware world decomposition and reconstruction, enabling the generation of diverse 3D worlds. Extensive experiments demonstrate that our method achieves state-of-the-art performance in generating coherent, explorable, and interactive 3D worlds while enabling versatile applications in virtual reality, physical simulation, game development, and interactive content creation.</p>
<p><img src="https://pic1.imgdb.cn/item/688b043c58cb8da5c8f3e3c3.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688b037058cb8da5c8f3dffb.png" alt="" /></p>
<h2 id="graph-r1-towards-agentic-graphrag-framework-via-end-to-end-reinforcement-learning"><a class="markdownIt-Anchor" href="#graph-r1-towards-agentic-graphrag-framework-via-end-to-end-reinforcement-learning"></a> Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning</h2>
<p><img src="https://pic1.imgdb.cn/item/688b053a58cb8da5c8f3e8b2.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/LHRLAB/Graph-R1">https://github.com/LHRLAB/Graph-R1</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21892">https://www.alphaxiv.org/abs/2507.21892</a></p>
<p>Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by incorporating external knowledge, but relies on chunk-based retrieval that lacks structural semantics. GraphRAG methods improve RAG by modeling knowledge as entity-relation graphs, but still face challenges in high construction cost, fixed one-time retrieval, and reliance on long-context reasoning and prompt design. To address these challenges, we propose Graph-R1, an agentic GraphRAG framework via end-to-end reinforcement learning (RL). It introduces lightweight knowledge hypergraph construction, models retrieval as a multi-turn agent-environment interaction, and optimizes the agent process via an end-to-end reward mechanism. Experiments on standard RAG datasets show that Graph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in reasoning accuracy, retrieval efficiency, and generation quality. Our code is publicly available.</p>
<p><img src="https://pic1.imgdb.cn/item/688b05a658cb8da5c8f3eafa.png" alt="" /></p>
<h2 id="learning-only-with-images-visual-reinforcement-learning-with-reasoning-rendering-and-visual-feedback"><a class="markdownIt-Anchor" href="#learning-only-with-images-visual-reinforcement-learning-with-reasoning-rendering-and-visual-feedback"></a> Learning Only with Images: Visual Reinforcement Learning with Reasoning, Rendering, and Visual Feedback</h2>
<p><img src="https://pic1.imgdb.cn/item/688b086f58cb8da5c8f3fb61.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/L-OI/RRVF">https://github.com/L-OI/RRVF</a>.<br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.20766">https://www.alphaxiv.org/abs/2507.20766</a></p>
<p>Multimodal Large Language Models (MLLMs) have exhibited impressive performance across various visual tasks. Subsequent investigations into enhancing their visual reasoning abilities have significantly expanded their performance envelope. However, a critical bottleneck in the advancement of MLLMs toward deep visual reasoning is their heavy reliance on curated image-text supervision. To solve this problem, we introduce a novel framework termed “Reasoning-RenderingVisual-Feedback” (RRVF), which enables MLLMs to learn complex visual reasoning from only raw images. This framework builds on the “Asymmetry of Verification” principle to train MLLMs, i.e., verifying the rendered output against a source image is easier than generating it. We demonstrate that this relative ease provides an ideal reward signal for optimization via Reinforcement Learning (RL) training, reducing the reliance on the image-text supervision. Guided by the above principle, RRVF implements a closed-loop iterative process encompassing reasoning, rendering, and visual feedback components, enabling the model to perform selfcorrection through multi-turn interactions and tool invocation, while this pipeline can be optimized by the GRPO algorithm in an end-to-end manner. Extensive experiments on image-to-code generation for data charts and web interfaces show that RRVF substantially outperforms existing opensource MLLMs and surpasses supervised fine-tuning baselines. Our findings demonstrate that systems driven by purely visual feedback present a viable path toward more robust and generalizable reasoning models without requiring explicit supervision. Code will be available at <a href="https://github.com/L-OI/RRVF">https://github.com/L-OI/RRVF</a>.</p>
<p><img src="https://pic1.imgdb.cn/item/688b06ad58cb8da5c8f3f051.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688b084758cb8da5c8f3fa49.png" alt="" /></p>
<h2 id="edge-grpo-entropy-driven-grpo-with-guided-error-correction-for-advantage-diversity"><a class="markdownIt-Anchor" href="#edge-grpo-entropy-driven-grpo-with-guided-error-correction-for-advantage-diversity"></a> EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity</h2>
<p><img src="https://pic1.imgdb.cn/item/688b1eb858cb8da5c8f48499.png" alt="" /></p>
<p>Github Link: <a href="https://github.com/ZhangXJ199/EDGE-GRPO">https://github.com/ZhangXJ199/EDGE-GRPO</a><br />
Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21848">https://www.alphaxiv.org/abs/2507.21848</a></p>
<p>Large Language Models (LLMs) have made remarkable progress in enhancing step-by-step reasoning through reinforcement learning. However, the Group Relative Policy Optimization (GRPO) algorithm, which relies on sparse reward rules, often encounters the issue of identical rewards within groups, leading to the advantage collapse problem. Existing works typically address this challenge from two perspectives: enforcing model reflection to enhance response diversity, and introducing internal feedback to augment the training signal (advantage). In this work, we begin by analyzing the limitations of model reflection and investigating the policy entropy of responses at the fine-grained sample level. Based on our experimental findings, we propose the EDGE-GRPO algorithm, which adopts Entropy-Driven Advantage and Guided Error Correction to effectively mitigate the problem of advantage collapse. Extensive experiments on several main reasoning benchmarks demonstrate the effectiveness and superiority of our approach. It is available at <a href="https://github.com/ZhangXJ199/EDGE-GRPO">https://github.com/ZhangXJ199/EDGE-GRPO</a>.</p>
<p><img src="https://pic1.imgdb.cn/item/688b1f3058cb8da5c8f4887d.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688b1fbd58cb8da5c8f48e48.png" alt="" /></p>
<h2 id="smallthinker-a-family-of-efficient-large-language-models-natively-trained-for-local-deployment"><a class="markdownIt-Anchor" href="#smallthinker-a-family-of-efficient-large-language-models-natively-trained-for-local-deployment"></a> SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment</h2>
<p><img src="https://pic1.imgdb.cn/item/688b204958cb8da5c8f491e8.png" alt="" /></p>
<p>Model Link: <a href="https://huggingface.co/PowerInfer/SmallThinker-4BA0.6B-Instruct">https://huggingface.co/PowerInfer/SmallThinker-4BA0.6B-Instruct</a></p>
<p>Model Link: <a href="https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct">https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct</a></p>
<p>While frontier large language models (LLMs) continue to push capability boundaries, their deployment remains confined to GPU-powered cloud infrastructure. We challenge this paradigm with SmallThinker, a family of LLMs natively designed—not adapted—for the unique constraints of local devices: weak computational power, limited memory, and slow storage. Unlike traditional approaches that mainly compress existing models built for clouds, we architect SmallThinker from the ground up to thrive within these limitations. Our innovation lies in a deployment-aware architecture that transforms constraints into design principles. First, We introduce a two-level sparse structure combining fine-grained Mixture-of-Experts (MoE) with sparse feed-forward networks, drastically reducing computational demands without sacrificing model capacity. Second, to conquer the I/O bottleneck of slow storage, we design a pre-attention router that enables our co-designed inference engine to prefetch expert parameters from storage while computing attention, effectively hiding storage latency that would otherwise cripple on-device inference. Third, for memory efficiency, we utilize NoPE-RoPE hybrid sparse attention mechanism to slash KV cache requirements. We release SmallThinker-4BA0.6B and SmallThinker-21B-A3B, which achieve state-of-the-art performance scores and even outperform larger LLMs. Remarkably, our co-designed system mostly eliminates the need for expensive GPU hardware: with Q4_0 quantization, both models exceed 20 tokens/s on ordinary consumer CPUs, while consuming only 1GB and 8GB of memory respectively.</p>
<p><img src="https://pic1.imgdb.cn/item/688b220858cb8da5c8f4a445.png" alt="" /></p>
<h2 id="mixgrpo-unlocking-flow-based-grpo-efficiency-with-mixed-ode-sde"><a class="markdownIt-Anchor" href="#mixgrpo-unlocking-flow-based-grpo-efficiency-with-mixed-ode-sde"></a> MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE</h2>
<p><strong>The writing for this paper is worth studying.</strong></p>
<p><img src="https://pic1.imgdb.cn/item/688b22c858cb8da5c8f4adde.png" alt="" /></p>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2507.21802">https://www.alphaxiv.org/abs/2507.21802</a><br />
Github Link: <a href="https://github.com/Tencent-Hunyuan/MixGRPO">https://github.com/Tencent-Hunyuan/MixGRPO</a><br />
Project Link: <a href="https://tulvgengenr.github.io/MixGRPO-Project-Page/">https://tulvgengenr.github.io/MixGRPO-Project-Page/</a></p>
<p>Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose MixGRPO, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of stochastic differential equations (SDE) and ordinary differential equations (ODE). This streamlines the optimization process within the MDP to improve efficiency and boost performance. Specifically, MixGRPO introduces a sliding window mechanism, using SDE sampling and GRPOguided optimization only within the window, while applying ODE sampling outside. This design confines sampling randomness to the time-steps within the window, thereby reducing the optimization overhead, and allowing for more focused gradient updates to accelerate convergence. Additionally, as time-steps beyond the sliding window are not involved in optimization, higher-order solvers are supported for sampling. So we present a faster variant, termed MixGRPO-Flash, which further improves training efficiency while achieving comparable performance. MixGRPO exhibits substantial gains across multiple dimensions of human preference alignment, outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50% lower training time. Notably, MixGRPO-Flash further reduces training time by 71%.</p>
<p><img src="https://pic1.imgdb.cn/item/688b258258cb8da5c8f4cbae.png" alt="" /></p>
<h2 id="towards-a-large-physics-benchmark"><a class="markdownIt-Anchor" href="#towards-a-large-physics-benchmark"></a> Towards a Large Physics Benchmark</h2>
<p><img src="https://pic1.imgdb.cn/item/688b279a58cb8da5c8f4d916.png" alt="" /></p>
<p>We introduce a benchmark framework developed by and for the scientific community to evaluate, monitor and steer large language model development in fundamental physics. Building on philosophical concepts of scientific understanding and creativity, we develop a scoring system in which each question is scored by an expert for its correctness, difficulty, and surprise. The questions are of three forms: (i) multiple-choice questions for conceptual understanding, (ii) analytical problems requiring mathematical derivation, and (iii) openended tasks requiring complex problem solving. Our current dataset contains diverse set of examples, including a machine learning challenge to classify high-energy physics events, such as the four top quark signal. To ensure continued relevance, we propose a “living” benchmark, where physicists contribute questions, for instance alongside new publications. We invite contributions via: <a href="http://www.physicsbenchmarks.org/">http://www.physicsbenchmarks.org/</a>. We hope that this benchmark will enable a targeted AI development that can make a meaningful contribution to fundamental physics research.</p>
<h2 id="stepfun-prover-preview-lets-think-and-verify-step-by-step"><a class="markdownIt-Anchor" href="#stepfun-prover-preview-lets-think-and-verify-step-by-step"></a> StepFun-Prover Preview: Let’s Think and Verify Step by Step</h2>
<p><img src="https://pic1.imgdb.cn/item/688b292958cb8da5c8f4e066.png" alt="" /></p>
<p>Paper Link: <a href="https://www.alphaxiv.org/abs/2507.20199">https://www.alphaxiv.org/abs/2507.20199</a></p>
<p>We present StepFun-Prover Preview, a large language model designed for formal theorem proving through tool-integrated reasoning. Using a reinforcement learning pipeline that incorporates tool-based interactions, StepFun-Prover can achieve strong performance in generating Lean 4 proofs with minimal sampling. Our approach enables the model to emulate human-like problem-solving strategies by iteratively refining proofs based on real-time environment feedback. On the miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of 70.0%. Beyond advancing benchmark performance, we introduce an end-to-end training framework for developing tool-integrated reasoning models, offering a promising direction for automated theorem proving and Math AI assistant.</p>
<p><img src="https://pic1.imgdb.cn/item/688b296558cb8da5c8f4e080.png" alt="" /></p>
]]></content>
      <categories>
        <category>Daily Paper</category>
      </categories>
  </entry>
  <entry>
    <title>Github项目添加成员</title>
    <url>/2023/12/10/Github%E9%A1%B9%E7%9B%AE%E6%B7%BB%E5%8A%A0%E6%88%90%E5%91%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1创建自己的github项目"><a class="markdownIt-Anchor" href="#1创建自己的github项目"></a> 1.创建自己的github项目</h2>
<br>
<h2 id="2在setting中找到下面内容"><a class="markdownIt-Anchor" href="#2在setting中找到下面内容"></a> 2.在setting中找到下面内容</h2>
<p><img src="https://pbs.twimg.com/media/GA-s26xb0AAs7oS?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="3输入内容即可"><a class="markdownIt-Anchor" href="#3输入内容即可"></a> 3.输入内容即可</h2>
<p><img src="https://pbs.twimg.com/media/GA-tHzwbYAADMCc?format=jpg&amp;name=medium" alt="" /></p>
<br>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>github</tag>
        <tag>贡献者</tag>
      </tags>
  </entry>
  <entry>
    <title>Git本地delete后commit</title>
    <url>/2024/01/10/Git%E6%9C%AC%E5%9C%B0delete%E5%90%8Ecommit/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="问题描述"><a class="markdownIt-Anchor" href="#问题描述"></a> 问题描述</h2>
<p>假设我们现在已经把所有文件都commit了，但是我在本地删除了一个文件，commit上面目前还是有这个文件。我的想法就是要把commit上也要删除这个文件，避免这个文件提交到远程仓库</p>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>前提：我已经右键点击，并且删除了<code>pytorch_model.bin</code>文件</p>
<p>step1: <code>git rm google/vit-base-patch16-224/pytorch_model.bin</code></p>
<p>step2: <code>git commit -m &quot;delete pytorch_model.bin&quot;</code></p>
<p>step3: <code>git push origin main</code></p>
<h2 id="另外的思考"><a class="markdownIt-Anchor" href="#另外的思考"></a> 另外的思考</h2>
<p>如果我是修改了文件呢？那该怎么办</p>
<p>如果我修改了<code>README.md</code>文件，需要以下指令：</p>
<ul>
<li><code>git add .</code></li>
<li><code>git commit -m &quot; &quot;</code></li>
<li><code>git push -u origin main</code></li>
</ul>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>commit</tag>
        <tag>git</tag>
        <tag>delete</tag>
      </tags>
  </entry>
  <entry>
    <title>GoAbroad</title>
    <url>/2023/07/22/GoAbroad/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1mphilmsc与phd"><a class="markdownIt-Anchor" href="#1mphilmsc与phd"></a> 1.mphil，msc与phd</h2>
<p>MSC=Master of Science,泛指一切的理学硕士<br />
Mphil=Master of Phisolophy,研究型硕士或者博士预科，攻读博士的一部分<br />
Phd=Doctor of Phisolophy,学术性博士<br />
mphil理解成一个规模更小的phd就好<br />
🔗：<a href="https://zhuanlan.zhihu.com/p/343017545">MSc,MPhil和PhD有什么区别</a><br />
🔗：<a href="https://zhuanlan.zhihu.com/p/164506545">MPhil（研究型硕士）详细介绍</a><br />
🔗：<a href="https://zhuanlan.zhihu.com/p/35891317">MPhil是什么学位？和PhD又有什么不可割舍的关系？</a></p>
<h2 id="2学校地址"><a class="markdownIt-Anchor" href="#2学校地址"></a> 2.学校地址</h2>
<p>Room XXX, Student Apartment XXX, /P.O.Box XXX<br />
Beijing University of Posts and Telecommunications,<br />
No. 10 Xi Tu Cheng Road,<br />
Beijing, 100876, China<br />
可以不写学校或者缩写成BUPT，因为邮递员蜀黍是认识路牌的~</p>
<h2 id="3姓名的写法"><a class="markdownIt-Anchor" href="#3姓名的写法"></a> 3.姓名的写法</h2>
<p>family name=last name=surname=姓，first name=名，middle name中国人没有<br />
例：猪八戒  last name=Zhu, first name=Bajie<br />
下面几种写法都是可以的：</p>
<ul>
<li>Bajie Zhu</li>
<li>Zhu, Bajie</li>
<li>ZHU Bajie</li>
</ul>
<p>其中Bajie可以写成 Ba-Jie, 但不要拆开成 Ba Jie<br />
建议：一旦采用了某一种写法，那么在所有的申请材料中都坚持这种写法，不要随意改变。</p>
<h2 id="4电话号码写法"><a class="markdownIt-Anchor" href="#4电话号码写法"></a> 4.电话号码写法</h2>
<p>固定电话：86-10-6277****（北京）<br />
其他地区：如区号是0451，为86-451-2922****<br />
手机：86-13*********</p>
<p>一般来讲，留国际长途号码都是+86-10-66666666，+1-612-456-7890这样的，+是国际长途接入号，这个代表的号码是在不同国家是不同的，在中国是00，也就是说从中国往其他国家播都是00xxxx…，比如001-612-456-7890；而+号在美国是代表011，所以往中国播，就是011-86-10-66666666。</p>
<h2 id="5gpa"><a class="markdownIt-Anchor" href="#5gpa"></a> 5.GPA</h2>
<p>直接填写百分制就可以了，如85/100</p>
<p>一点体会：因为不同的学校有不同的GPA,往往不同的年级整体分数也有一定差异，所<br />
以GPA算起来不必特别较真，对方学校如果询问起来（一般说明对方学校想要你了），可<br />
以解释自己的算法不同。比较高的算法是除以25（合适于低分段），比如平均分75，算成<br />
75/100*4=3.0。当然，GPA也正是由于算法的不同，所以不如Rank更有说服力。</p>
<h2 id="6cv"><a class="markdownIt-Anchor" href="#6cv"></a> <a href="http://6.CV">6.CV</a> 即</h2>
<p>Curriculum Vitae，和Resume略有不同</p>
<h2 id="7学校网址查询"><a class="markdownIt-Anchor" href="#7学校网址查询"></a> 7.学校网址查询</h2>
<p>参见x-5-1-1-1, 或者用www.google.com输入校名进行查询</p>
<h2 id="8时间查询"><a class="markdownIt-Anchor" href="#8时间查询"></a> 8.时间查询</h2>
<p>🔗：<a href="https://www.worldtimeserver.com">WorldTimeServer</a><br />
🔗：<a href="https://www.worldtimezone.com/time-usa24.php">worldtimezone</a></p>
<h2 id="9成绩单问题"><a class="markdownIt-Anchor" href="#9成绩单问题"></a> 9.成绩单问题</h2>
<p>官方成绩单即official transcript<br />
一般到院里开。成绩单有些学校要求2份，所以要比所选的学校多开出一部分。比如申<br />
请10所，最好开出15份左右。具体要求需要看学校网页。</p>
<p>北邮开具成绩单基本指南：</p>
<ul>
<li>到院所在教务科开具中英文简明成绩单</li>
<li>部分院的攻略在精华区</li>
<li>给成绩单盖章：如果你还没有毕业，那么成绩单应该是在院里盖章；如果已经毕业了，<br />
成绩单是在校教务处盖章。</li>
<li>成绩单是两页，但要印在一张纸的反正面。</li>
</ul>
<p>优良中差翻译问题：<br />
参考我校教务处提供的《中英文课程目录》翻译课程名称，按学时、学分、考试课、考<br />
查课对应填入分数，成绩中的&quot;优&quot;、“良”、“中”、“及格&quot;分别翻成&quot;A”、“B”、“C”、“D”；<br />
“合格&quot;翻译成&quot;P”。若成绩中有补考成绩，可按补考成绩计。</p>
<h2 id="10寄材料的时间"><a class="markdownIt-Anchor" href="#10寄材料的时间"></a> 10.寄材料的时间</h2>
<p>如果用平信，最好留出一个月的时间</p>
<p>如果用快递，比如联邦、DHL、UPS等，4天应该差不多了</p>
<p>Deadline在1月左右的学校，最好圣诞节前寄到，以免圣诞节放假，没人处理材料<br />
备注：北京邮电大学UPS业务点已成立，具体事宜请关注飞越重洋版面，或联系斑竹。</p>
<h2 id="11️"><a class="markdownIt-Anchor" href="#11️"></a> 11.✉️</h2>
<p>在学苑超市买信封就行，一共三种信封，大中小，分别对应 装所有材料、装推荐信、<br />
装成绩单，学位证、毕业证 不能与成绩单装在同一信封内，而且也没必要单独装信封<br />
信封所需数量：</p>
<ul>
<li>大信封：申请的学校数量</li>
<li>推荐信信封：3×申请的学校数量（很多学校可以用网推）</li>
<li>成绩单信封：1.5×申请的学校数量（有的学校要2份成绩单）</li>
<li>小信封骑缝盖学院教务处的章</li>
<li>大信封封面写上名字，生日，网申ID，申请program</li>
</ul>
<h2 id="12"><a class="markdownIt-Anchor" href="#12"></a> 12.💳</h2>
<p>比较常用的是VISA卡，可以在各个银行办理，常见中行、工行、招行。中行年费$12，<br />
保证金$500或者￥5000，学生可以办。工行普通卡学生不能办，需要有工作。招行年费￥100，交易6次可免年费，没有保证金，本科生信用额度3000，研究生8000。最好不要办农行。</p>
<h2 id="13"><a class="markdownIt-Anchor" href="#13"></a> 13.📧</h2>
<p>Email：可以使用GMail。需要GMail邀请的朋友，请到Google版发文求助。<br />
另外，Yahoo的邮箱也是一个不错的选择。<br />
如果使用Hotmail，请把过滤级别设置为低，防止发生丢信。</p>
<h2 id="14陶瓷"><a class="markdownIt-Anchor" href="#14陶瓷"></a> 14.陶瓷</h2>
<p>所谓套磁，就是和国外教授主动通过书信往来建立联系和彼此印象，从而加大录取和<br />
拿奖学金的一种行为。简单的说，申请PhD的要比申Master的有用，因为Master是没有导<br />
师带的，申请理工科的比文科的有用。因为对于理工科的同学，你所拿到的奖学金其实就<br />
是教授的研究经费的一部分，因此说是学校给你发奖学金不如说是教授给你发。而对于文<br />
科，情况完全不同，的确是系里在决定经费，教授可以起到的作用很有限。</p>
<p>一些技巧：国外教授时间都很宝贵，不要问一些有没有钱之类的话题（这些问题问小<br />
米助教就行了）。而应该通过网页了解对方的研究内容，和对方探讨问题，有人曾经挑出<br />
对方教授文章中的一些毛病，这很容易引起对方的重视。当然陶瓷时也要适当的表达一下<br />
决心。</p>
<p>总之：如果有精力，不套白不套</p>
<h2 id="15tggpa不够怎么办"><a class="markdownIt-Anchor" href="#15tggpa不够怎么办"></a> 15.T，G&amp;GPA不够怎么办</h2>
<p>申请材料的评审是一个综合的过程，整个申请材料将全面展示申请者的能力、潜力、<br />
兴趣取向以及个性化的东西。T,G,GPA这些远远不是个人展现的全部，在这些方面有缺憾<br />
的网友不要放弃。如果离要求相差不多，而且有其他方面的优势（比如不错的论文、不错<br />
的关系、牛推荐、竞赛、大项目、体育特长等等），一些条条框框可以不理会。当然，这<br />
时可以陶瓷对教授说明情况。</p>
<h2 id="16word转换pdf"><a class="markdownIt-Anchor" href="#16word转换pdf"></a> 16.word转换pdf</h2>
<p>下载Acrobat Professional 7.0版本。<br />
其他有关于PDF的问题请咨询Paper版</p>
<h2 id="17in"><a class="markdownIt-Anchor" href="#17in"></a> <a href="http://17.in">17.in</a> what capacity</h2>
<p>填推荐人和你的关系，比如说as his teacher/adviser</p>
<h2 id="18print"><a class="markdownIt-Anchor" href="#18print"></a> 18.print</h2>
<p>据jj0810前辈说, Print 就是 “打印” 或者 “工整的写”, 并非指&quot;大写&quot;</p>
<h2 id="19是否waive入学后检查推荐信的权力"><a class="markdownIt-Anchor" href="#19是否waive入学后检查推荐信的权力"></a> 19.是否waive入学后检查推荐信的权力</h2>
<p>这是你的权力，自己看着办</p>
<h2 id="20需要推荐人在线提交推荐信怎么办"><a class="markdownIt-Anchor" href="#20需要推荐人在线提交推荐信怎么办"></a> 20.需要推荐人在线提交推荐信怎么办</h2>
<p>如果老师没有时间的话，可以让他把邮件转发给你，让你提交。或者问问小米能不能提交<br />
paper形式的推荐信，一般都可以</p>
<h2 id="21xxx学校的推荐表在哪里可以下载"><a class="markdownIt-Anchor" href="#21xxx学校的推荐表在哪里可以下载"></a> 21.XXX学校的推荐表在哪里可以下载</h2>
<p>如果系主页和网申系统都没找到的话，可以问问小米，确认一下是否有推荐表。</p>
<h2 id="22推荐信有两个封口是否都要签名"><a class="markdownIt-Anchor" href="#22推荐信有两个封口是否都要签名"></a> 22.推荐信有两个封口，是否都要签名</h2>
<p>都要骑缝签名</p>
<h2 id="23title和position有什么区别"><a class="markdownIt-Anchor" href="#23title和position有什么区别"></a> 23.Title和Position有什么区别</h2>
<p>Title是头衔，可以填Dr.，也可以是Prof.。Position是职位，填Prof.之类的。国内的副研究员=副教授</p>
<h2 id="24推荐信基本格式"><a class="markdownIt-Anchor" href="#24推荐信基本格式"></a> 24.推荐信基本格式</h2>
<p>英文信件的基本格式</p>
<h2 id="25are-you-currently-on-academic-suspension-from-a-college"><a class="markdownIt-Anchor" href="#25are-you-currently-on-academic-suspension-from-a-college"></a> 25.Are you currently on academic suspension from a college</h2>
<p>这个东西是一种类似于勒令停学的严厉校纪处分，仅次于开除，你只要google一下<br />
academic suspension就知道他是个什么东西了。</p>
<h2 id="26-date-transcript-requested"><a class="markdownIt-Anchor" href="#26-date-transcript-requested"></a> 26. Date Transcript Requested</h2>
<p>你寄出成绩单的时间，国外学校出具成绩单的过程一般都是学生给自己学校的registrar一份transcript request form，可以邮寄传真或者当面递交，这张表授权registrar把自己的成绩单直接寄到指定的地方，一般是免费的，除非要求特快服务。你们申请材料中收到的这种表格也就是干这个用的。有了这个date transcript requested，你要申请的学校就可以大致知道成绩单应该什么时候寄到。对中国学生来说，基本上没有哪个大学是直接寄出成绩单的，都是开成绩单密封给学生随其他申请材料一块寄出，所以这个要求成绩单的日期无所谓，随便填一个。</p>
<h2 id="27transcript-request-form"><a class="markdownIt-Anchor" href="#27transcript-request-form"></a> 27.transcript request form</h2>
<p>成绩单申请表</p>
<h2 id="28ssn"><a class="markdownIt-Anchor" href="#28ssn"></a> 28.SSN</h2>
<p>美国的Social Security Number，中国人没有，不用填</p>
<h2 id="29网申邮编"><a class="markdownIt-Anchor" href="#29网申邮编"></a> 29.网申邮编</h2>
<p>Zip Code是美国的邮编，我们填International Postal Code</p>
<h2 id="30寄材料快递电话"><a class="markdownIt-Anchor" href="#30寄材料快递电话"></a> 30.寄材料快递电话</h2>
<ul>
<li>Fedex(清华工字厅收发室): 62782436</li>
<li>UPS(清华紫荆6#一层西侧): 51533179</li>
<li>DHL(清华紫荆9#一层东侧): 62797058, <a href="http://www.51heji.com">www.51heji.com</a></li>
</ul>
<p>备注：北邮UPS代理点负责人联系电话：62285750<br />
DHL 北邮书屋旁边打印店<br />
UPS 在国院有代理</p>
<h2 id="31没答应接受offer就寄来了i-20表"><a class="markdownIt-Anchor" href="#31没答应接受offer就寄来了i-20表"></a> 31.没答应接受offer，就寄来了I-20表</h2>
<p>只要没答应接受就没事，至于I-20表是否需要寄回去，一定要向学校问清楚！</p>
<h2 id="32-415协议"><a class="markdownIt-Anchor" href="#32-415协议"></a> 32. “4.15协议”</h2>
<p>加入协议的学校按道理给的deadline应该是4.15，如果早于这个，你可以据理力争</p>
<p>但是协议只是协议，没有法律效用，所以学校从法律上来说没有义务一定等到4.15</p>
<p>根据协议，4.15之前接受的offer，如在4.15之前要反悔，最好征得该学校的同意<br />
4.15之后接受的offer，如果没有学校的正式文书许可，不可以反悔</p>
<p>拒绝offer不用赶4.15时限，因为过了4.15不接受offer就自动视为放弃</p>
<p>Admission不受4.15协议限制</p>
<h2 id="33为什么我的rata是one-half-time-rata"><a class="markdownIt-Anchor" href="#33为什么我的rata是one-half-time-rata"></a> 33.为什么我的RA/TA是one-half time RA/TA</h2>
<p>学生根据规定最多只能做半职，因为你最少要留一半时间来学习，所以one-half time一<br />
般是每周20小时工作量，就是全奖了</p>
<h2 id="34关于offer的答复时间是否需要在限期前寄到"><a class="markdownIt-Anchor" href="#34关于offer的答复时间是否需要在限期前寄到"></a> 34.关于offer的答复时间：是否需要在限期前寄到</h2>
<p>这个限期都是学校说了算，所以是否需要在限期前寄到，还是只要在此之前寄出，最好跟<br />
学校确认一下。</p>
<p>一般来讲，先跟学校email确认接受offer，然后再寄出正式回执，晚一点到达学校没事。</p>
<p>当然，这种情况最好先征得学校的同意。</p>
<h2 id="35最近的公证处"><a class="markdownIt-Anchor" href="#35最近的公证处"></a> 35.最近的公证处</h2>
<p>海淀区公证处：海淀黄庄十字路口向东300米马路南侧  豪景大厦三层</p>
<h2 id="36入党是否对出国有影响"><a class="markdownIt-Anchor" href="#36入党是否对出国有影响"></a> 36.入党是否对出国有影响</h2>
<p>Q：现读大学本科可以有入党的机会，但我以后想去美国深造（或工作），请问如果是共<br />
产党员是不是对申请有影响<br />
A： 国外的公司不会在乎这个的。这都属于个人选择和隐私，申请时不会过问的。我相信<br />
高校也不会在乎的。甚至高校应该没有权力过问。（在美国，为了保证公平，很多个人背<br />
景都不可过问，例如申请学校或工作时你可以选择不回答“种族”这个问题）。<br />
一个例外是如果你想到美国公司工作，而那个公司是和国防有关的,例如需要 security<br />
clearance 的国家实验室,或 Defense Contractor (i.e. Lockeed Martin, Northrup<br />
etc.),或是做很敏感的研究课题的。</p>
<h2 id="37me与ms"><a class="markdownIt-Anchor" href="#37me与ms"></a> 37.ME与MS</h2>
<ul>
<li>MSE（？）工学硕士：Master of Science in Engineering</li>
<li>ME，工程硕士：Master of Engineering</li>
<li>MS，理学硕士：Master of Science</li>
</ul>
<p>具体对于ME的解释各个学校都不一样，所以请仔细察看学校对于ME的定义。如果是一年制绝无奖学金的则为工程硕士，一般不招海外学生。</p>
<h2 id="38户口和档案"><a class="markdownIt-Anchor" href="#38户口和档案"></a> 38.户口和档案</h2>
<p>可以寄放在留服</p>
<p>教育部留学服务中心不在北语办公了，已迁至： 北京市海淀区北四环西路56号辉煌时代大厦 6层</p>
<p>电话：0086-10-62677800（想打进去基本很难，耐心耐心…）</p>
<p>有问题如果打不进电话可以访问：<a href="http://xn--www-u68dy61btngu24cmxq.cscse.edu.cn">中国留学网www.cscse.edu.cn</a></p>
<h2 id="39智慧树刷gpa可行吗"><a class="markdownIt-Anchor" href="#39智慧树刷gpa可行吗"></a> 39.智慧树刷gpa可行吗</h2>
<p>可以，但是有的大学在申请时会重新计算gpa 。</p>
<h2 id="4010043"><a class="markdownIt-Anchor" href="#4010043"></a> 40.“10043”</h2>
<p>目前有北邮title 的学生在申请美国学签（包括硕士、博士等）时会大概率被拒，（人文类专业通过概率稍微大一点但只是稍微）。如果 运气极好 拿到签证后，在入境美国时也有可能被遣返。 但是本科转学美国一般问题不大。</p>
<p>另： 10043目前不卡工签，但是有一些小道的、未被证实或证伪的“歪门邪道”。</p>
<h2 id="41diy-中介"><a class="markdownIt-Anchor" href="#41diy-中介"></a> 41.Diy/ 中介？</h2>
<p>论坛大部分分享贴都说想申请好学校就diy</p>
<h2 id="42如果是以出国为目的需要按卷保研的学习强度卷gpa"><a class="markdownIt-Anchor" href="#42如果是以出国为目的需要按卷保研的学习强度卷gpa"></a> 42.如果是以出国为目的，需要按卷保研的学习强度卷gpa</h2>
<p>需要，但可能要更努力一点。很多学长学姐都是以出国为目的地学习，拥有保研名额都只是顺便。</p>
<h2 id="43发paper有用吗"><a class="markdownIt-Anchor" href="#43发paper有用吗"></a> 43.发paper有用吗</h2>
<p>从对留学申请的帮助来看：一般一作和共一属于一个档次，二作属于一个档次，其他属于另一个档次</p>
<h2 id="44我现在大x-了-但是感觉什么也不会想-去找老师-进实验室打工能找到吗"><a class="markdownIt-Anchor" href="#44我现在大x-了-但是感觉什么也不会想-去找老师-进实验室打工能找到吗"></a> 44.我现在大X 了， 但是感觉什么也不会，想 去找老师 进实验室打工，能找到吗？</h2>
<p>可以，基本上只要你想找就能找到。方法包括但不限于给老师发邮件问缺不缺人、通过认识的学长学姐介绍或通过授课老师的介绍。</p>
<h2 id="45推荐信作用"><a class="markdownIt-Anchor" href="#45推荐信作用"></a> 45.推荐信作用</h2>
<p>私人推荐&gt;强推&gt;一般推荐信（私人推荐指导师 老板通过个人关系帮你推荐）</p>
<h2 id="46实习有没有用"><a class="markdownIt-Anchor" href="#46实习有没有用"></a> 46.实习有没有用</h2>
<p>看具体申请的专业和类型</p>
<h2 id="47本科tranfer去美国要多少钱"><a class="markdownIt-Anchor" href="#47本科tranfer去美国要多少钱"></a> 47.本科tranfer去美国要多少钱</h2>
<p>100w以上</p>
<h2 id="48硕士申请难度"><a class="markdownIt-Anchor" href="#48硕士申请难度"></a> 48.硕士申请难度</h2>
<p>研究硕&gt;授课硕</p>
<h2 id="49体测不及格影响出国吗"><a class="markdownIt-Anchor" href="#49体测不及格影响出国吗"></a> 49.体测不及格影响出国吗</h2>
<p>不影响</p>
<h2 id="50公选课挂科有关系吗"><a class="markdownIt-Anchor" href="#50公选课挂科有关系吗"></a> 50.公选课挂科有关系吗</h2>
<p>没关系，只要下次别选就行</p>
<h2 id="51大创认可度如何"><a class="markdownIt-Anchor" href="#51大创认可度如何"></a> 51.大创认可度如何</h2>
<p>国外一般不知道雏雁、大创是什么，但是可以当成一段正常的项目经历来写。（但是一般水分很高、很虚的项目经历可能会让你文书 简历掉价）</p>
<h2 id="52怎么获取留学相关信息"><a class="markdownIt-Anchor" href="#52怎么获取留学相关信息"></a> 52.怎么获取留学相关信息</h2>
<p>群里、 byrbbs 、一亩三分地 、寄托天下 等等</p>
<h2 id="53csc是什么"><a class="markdownIt-Anchor" href="#53csc是什么"></a> 53.csc是什么</h2>
<p>CSC是国家留学基金管理委员会（China Scholarship Council）英文字母的缩写，通俗点来说就是公派留学，再通俗点来说就是奖学金，国家给你发的奖学金。</p>
<h2 id="54出国开的均分是哪个均分"><a class="markdownIt-Anchor" href="#54出国开的均分是哪个均分"></a> 54.出国开的均分是哪个均分</h2>
<ul>
<li>带公选课</li>
<li>带挂科重修后</li>
<li>不带竞赛</li>
</ul>
<h2 id="55授课硕与研究硕的区别"><a class="markdownIt-Anchor" href="#55授课硕与研究硕的区别"></a> 55.授课硕与研究硕的区别</h2>
<h3 id="1授课硕"><a class="markdownIt-Anchor" href="#1授课硕"></a> 1.授课硕</h3>
<h3 id="11-授课硕分类"><a class="markdownIt-Anchor" href="#11-授课硕分类"></a> 1.1 授课硕分类</h3>
<p>授课型硕士即Taught Postgraduate (PGT) Courses包括：MSc，MA，MBA、MEng，MEd、LLM、MEng、MFA、MMus等。</p>
<ul>
<li>
<p>文学硕士：Master of Arts (MA) degrees<br />
MA泛指艺术，人文等相关学科硕士学位。在学生完成论文前，通常需要完成一系列课程。</p>
</li>
<li>
<p>理学硕士：Master of Science (MSc) degrees<br />
MSc即修读科学、技术等学科的授课型硕士学位，通常需完成一系列教学单元。</p>
</li>
<li>
<p>艺术硕士：Master of Fine Arts (MFA) degrees<br />
MFA是偏向于实践创意类的学位课程。这样的课程更适于初出茅庐的作家、艺术家或设计师。</p>
</li>
<li>
<p>文学硕士Master of Letters (MLitt) degrees<br />
这是一类相对小众的硕士学位，部分英国大学可以授予。在苏格兰地区，有些MLitt可以代替MA授予学生，有些英国大学授予MLitt以代替研究型学位，如MPhil。因此MLitt既可以是授课型，也可以是研究型硕士学位。</p>
</li>
<li>
<p>法学硕士Master of Laws (LLM) degrees<br />
法律专业的授课型硕士学位，它并不是专门的律法培训课程，但可以选择法律的某一分支方向。</p>
</li>
<li>
<p>工商管理硕士Master of Business Administration (MBA) degrees<br />
专为商务人士设计，聚焦于领导力和管理的课程。</p>
</li>
<li>
<p>工程学专业硕士：Master of Engineering (MEng) degrees</p>
</li>
</ul>
<br>
<p>授课型硕士学习方式和现在大学本科上课形式类似，以老师上课为主，修到足够学分就满足毕业条件。课堂注重互动性，有很多案例分析、研讨会、讲座，目的在于增加在某领域的专业知识，培养学生对这个专业技能。最常见的就是小型学术演讲和小论文，理工科还需要实验报告，项目报告、研究报告等。最后以演讲的形式，给这些报告、论文做一个presentation。</p>
<h3 id="12-授课型硕士的学费-申请难度及奖学金获得情况"><a class="markdownIt-Anchor" href="#12-授课型硕士的学费-申请难度及奖学金获得情况"></a> 1.2 授课型硕士的学费、申请难度及奖学金获得情况</h3>
<p>授课型硕士申请难度相对不大，要交学费，几乎没有奖学金。</p>
<h3 id="13-授课方式"><a class="markdownIt-Anchor" href="#13-授课方式"></a> 1.3 授课方式</h3>
<p>授课型硕士，教学方式如其名，也就是以老师讲课为主，课业相对来说会重一些，当时我在港中文的时候，一年到头真的没闲着，全英文授课，预习复习都不能落下，还有各种paper、考试，闲着没事还要操心下你的实习，虽然忙吧但也充实。</p>
<h3 id="14-毕业要求"><a class="markdownIt-Anchor" href="#14-毕业要求"></a> 1.4 毕业要求</h3>
<p>修满学分</p>
<h3 id="15-tips"><a class="markdownIt-Anchor" href="#15-tips"></a> 1.5 tips</h3>
<p>一般来说，授课型对成绩和专业相关度比较看重，有的专业，比如MBA，需要相关工作经验。</p>
<h3 id="2研究硕"><a class="markdownIt-Anchor" href="#2研究硕"></a> 2.研究硕</h3>
<h3 id="21研究硕分类"><a class="markdownIt-Anchor" href="#21研究硕分类"></a> 2.1研究硕分类</h3>
<p>研究型硕士即Postgraduate Research (PGR) Programs，学位包括MPhil、MRes。</p>
<ul>
<li>
<p>MPhil：哲学硕士，相当于学生读博前两年的准备课程，完善专业知识，提升研究技能，可以作为学生以后的博士研究的基础。如果顺利读完MPhil的学生可以直接转读PhD。</p>
</li>
<li>
<p>MRes：研究硕士，学生需要选择一个具体的研究领域进行研究，需要做项目实验，文献探索，发表论文等，最终评估标准是看学术论文的质量。</p>
</li>
</ul>
<h3 id="22研究型硕士的学费-申请难度及奖学金获得情况"><a class="markdownIt-Anchor" href="#22研究型硕士的学费-申请难度及奖学金获得情况"></a> 2.2研究型硕士的学费、申请难度及奖学金获得情况</h3>
<p>研究型硕士一般减免学费、申请难度相对较大，有奖学金。研究型硕士后期转成直博的比例非常高，这与国内的直博学生的前两年相似</p>
<h3 id="23教学方式"><a class="markdownIt-Anchor" href="#23教学方式"></a> 2.3教学方式</h3>
<p>研究硕的话，两年时间只有半年在上课，其他时间你可能都在跟着导师做项目。据我之前一个研究硕的学生说她第一年会跟其他课程的研究生一起上一些比较general的课，第二年开始准备自己的毕业论文，发paper，改稿子，开会…两年的时间也是弹指一挥间。</p>
<h3 id="24毕业方式"><a class="markdownIt-Anchor" href="#24毕业方式"></a> 2.4毕业方式</h3>
<p>对论文要求较高</p>
<h3 id="25-tips"><a class="markdownIt-Anchor" href="#25-tips"></a> 2.5 tips</h3>
<p>一般来说，研究型硕士对本科毕业院校、科研背景、科研潜力比较看重。非常看重RP的写作。</p>
<h3 id="3总结"><a class="markdownIt-Anchor" href="#3总结"></a> 3.总结</h3>
<p>说了一堆，关于MSc和MPhil到底应该怎么选，不知道你们心里的小天平有没有一点倾斜。其实答案很简单，你要看你自己到底想干嘛。如果你们家拿出这20W的学费不是问题，你又想毕业后赶紧工作，没什么犹豫的，肯定选MSc啊，省时省力，申请难度相对而言也没有那么高。你可以在短时间内掌握更多基础知识，认识更多人，提升你的英语能力和学习能力，而且你在早出来的这一年里学习到的工作经验和技能对以后你工作上的重要性我想也不用我多说了。</p>
<p>至于MPhil，如果你很想要读一个香港的硕士但是家里经济又负担不起高额的学费，可以考虑MPhil，就是难度…所以你应该足够优秀，条件不行还是乖乖选其他路子吧。但是，如果你真的很想做research，我强烈建议你直接申PhD，导师也更愿意招，系统性也更强，不读博的MPhil是没有意义且浪费时间的。</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>Anything</tag>
      </tags>
  </entry>
  <entry>
    <title>Guide to Rebuttal</title>
    <url>/2025/07/27/Guide-to-Rebuttal/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="the-power-of-a-good-rebuttal"><a class="markdownIt-Anchor" href="#the-power-of-a-good-rebuttal"></a> The Power of a Good Rebuttal</h2>
<p>Receiving reviewer comments for your paper can bring feelings of excitement and frustation. While it might like a final judement, the rebuttal phase is your crucial opportunity to make the case for you work.</p>
<p>An academic rebuttal is not a simple defense; It is a stragetic and respectful dialogue with reviewers. It is your chance to clarify misunderstanding and thoughtfully address their concerns. A well-crafted response shows your professionlism and can gennuinely change the outcome for your paper, potentially turning a “Weak Reject” into a “Weak Accept”.</p>
<p>This guide will show you how to analyze feedback and write a persuasive rebuttal to give your paper its best chance of acceptance.</p>
<h2 id="rebuttal-examples"><a class="markdownIt-Anchor" href="#rebuttal-examples"></a> Rebuttal Examples</h2>
<p>To give you a more intuitive understanding of how to proceed, we will now break down and analyze a few simulated examples.</p>
<h3 id="lack-of-empirical-verifications"><a class="markdownIt-Anchor" href="#lack-of-empirical-verifications"></a> Lack of empirical verifications</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Overall, this work sims to develop a new approach for the RoPE-based attention, which is used widely nowadays foundation models. As an improved algorithm for it, there are no empirical verifications from efficiency comparison, performance demonstrations and real-world applications. Therefore, the practicability of the proposed algorithm is doubtful, which makes the confidence and reliability of the submission discounted.</span><br></pre></td></tr></table></figure>
<p>The goal of our paper is to continue therecent line of work on determining theretically whether fast algorithm are possible for attention.</p>
]]></content>
  </entry>
  <entry>
    <title>IELTS:Listening</title>
    <url>/2024/03/13/IELTS-Listening/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="雅思听力入门必知考点和填空题方法"><a class="markdownIt-Anchor" href="#雅思听力入门必知考点和填空题方法"></a> 雅思听力入门必知考点和填空题方法</h2>
<h3 id="课堂测试1"><a class="markdownIt-Anchor" href="#课堂测试1"></a> 课堂测试1</h3>
<p>million +s :只有<code>millions of</code>才+s</p>
<p><strong>发音基础</strong>：aisle， salmon ，sword， sea view suite， mistake<br />
<strong>词汇基础</strong>：eclipse,antibiotics，specimen,herbivorous,cottage,velvet,cathedral,vaccination<br />
<strong>语法基础</strong>：长安街18号，三分之二，13.87</p>
<h3 id="基础问题"><a class="markdownIt-Anchor" href="#基础问题"></a> 基础问题</h3>
<ol>
<li>时间的写法：会写月份和星期，会说所有的时间(five to ten)</li>
<li>生活常识： air canda=AC</li>
<li>字母：26字母发音，Z的发音很特别(Zed,Z)</li>
<li>数字：手机里号码，购物的订单号(不管什么数字都要记下来)</li>
<li>银行卡：VISA,master,American Express</li>
</ol>
<br>
<p><img src="https://pic.imgdb.cn/item/66bafbccd9c307b7e989670d.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">6 17 October</span><br><span class="line">7 </span><br><span class="line">8 Thomson</span><br><span class="line">9 </span><br><span class="line">10 （发音 不熟）</span><br></pre></td></tr></table></figure>
<h3 id="课堂测试2-熟词生义"><a class="markdownIt-Anchor" href="#课堂测试2-熟词生义"></a> 课堂测试2 熟词生义</h3>
<p>landing：降落 | 楼梯？<br />
poor：贫穷的 | 糟糕的<br />
address：地址 | 演讲<br />
subject：学科 | 研究对象</p>
<p><img src="https://pbs.twimg.com/media/GIh7oGjXcAAw6gK?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h3 id="雅思听力part1"><a class="markdownIt-Anchor" href="#雅思听力part1"></a> 雅思听力Part1</h3>
<p><img src="https://pbs.twimg.com/media/GIh_f92WYAAlLm5?format=jpg&amp;name=medium" alt="" /></p>
<h3 id="做题步骤"><a class="markdownIt-Anchor" href="#做题步骤"></a> 做题步骤</h3>
<ol>
<li>
<p>看字数限制以及是否可以写数字</p>
</li>
<li>
<p>做标记：空格前2后2,空格前的人名和年代，连词(so next，and，today)</p>
<ul>
<li>较稳定：数字，名词，专有名词(英语中介词需要固定搭配，所以不一定会改)</li>
<li>不稳定：形容词动词</li>
<li>大坑词：形容词最高级，反义词，否定词</li>
</ul>
</li>
<li>
<p>防弹衣原则：听到要害</p>
<ul>
<li>shopping,but…to the</li>
<li>because…</li>
<li>start…at…</li>
<li>So，one thing another thing</li>
</ul>
</li>
<li>
<p>真考点：不是答案词</p>
<ul>
<li>发音</li>
<li>逻辑</li>
<li>改写<br />
<img src="https://pbs.twimg.com/media/GIiCbyKXUAA0cw2?format=jpg&amp;name=medium" alt="" /><br />
<img src="https://pbs.twimg.com/media/GIiE7eMXoAAOVDX?format=jpg&amp;name=medium" alt="" /><br />
<img src="https://pbs.twimg.com/media/GIiFp97WYAAqn5-?format=jpg&amp;name=medium" alt="" /></li>
</ul>
</li>
<li>
<p>练习：能够听懂40个答案句，答案句至少读10遍</p>
</li>
</ol>
<h3 id="原则"><a class="markdownIt-Anchor" href="#原则"></a> 原则</h3>
<ol>
<li>听力问题思考禁止超过五分钟</li>
<li>提问</li>
</ol>
<h3 id="听力基本认识"><a class="markdownIt-Anchor" href="#听力基本认识"></a> 听力基本认识</h3>
<ol>
<li>听力四部分：PART1~4</li>
<li>40题</li>
<li>笔试：40min=30+10</li>
<li>机考：32min=30+2</li>
<li>7:30到考场</li>
</ol>
<p><img src="https://pbs.twimg.com/media/GIiHUeFWUAAC6aX?format=png&amp;name=small" alt="" /></p>
<br>
<h2 id="雅思花样填空的解题秘技"><a class="markdownIt-Anchor" href="#雅思花样填空的解题秘技"></a> 雅思花样填空的解题秘技</h2>
<p>定位答案：</p>
<ul>
<li>原词</li>
<li>逻辑词：but，and</li>
<li>替换词：today=thismorning</li>
</ul>
<p>动物的长牙：tusk<br />
围裙：apron<br />
眼药水：eyedrop</p>
<p>发音热身(英语绕口令)：Betty bought butter but the butter was bitter, so Betty bought better butter to make the bitter butter better.</p>
<p><img src="https://pbs.twimg.com/media/GIyxDDXaoAApZUt?format=png&amp;name=small" alt="" /></p>
<p>同音词：</p>
<ul>
<li>by,buy</li>
<li>break,brake</li>
<li>wait,weight</li>
<li>toot,route</li>
<li>waste,waist</li>
</ul>
<p>同义词：</p>
<ul>
<li>skill，ability</li>
<li>kid，child</li>
<li>brother-in-law</li>
</ul>
<p>多音词：</p>
<ul>
<li>data</li>
<li>Z</li>
<li>adult</li>
<li>garage</li>
<li>adult</li>
<li>record</li>
<li>produce</li>
<li>literature</li>
</ul>
<h3 id="第四部分填空题"><a class="markdownIt-Anchor" href="#第四部分填空题"></a> 第四部分填空题</h3>
<ul>
<li>around=approximately</li>
<li>than…</li>
<li>连读</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GI2mBtOWcAAwSU8?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="地图题精准定位方法"><a class="markdownIt-Anchor" href="#地图题精准定位方法"></a> 地图题精准定位方法</h2>
<ul>
<li>hi ber na tion</li>
<li>pe ri o di cal</li>
<li>psy cho lo gy</li>
<li>pe des tri an</li>
<li>4-liter engine = 4 liters’ engine（连字符代表形容词）</li>
</ul>
<p>地图题要点:</p>
<ul>
<li>
<p>方向</p>
</li>
<li>
<p>已知地点</p>
</li>
<li>
<p>路：path road</p>
</li>
<li>
<p>弯路：corner bend (sharp)</p>
</li>
<li>
<p>箭头arrow</p>
</li>
<li>
<p>入口：door，entrance，gate，front，side，behind<br />
<img src="https://pbs.twimg.com/media/GI7CNegXUAAO_WA?format=jpg&amp;name=medium" alt="" /></p>
</li>
<li>
<p>drive 路</p>
</li>
<li>
<p>practice 诊所</p>
</li>
<li>
<p>film 电影 薄膜 胶卷</p>
</li>
<li>
<p>foil 锡纸</p>
</li>
<li>
<p>plan 地图</p>
</li>
<li>
<p>plant  工厂</p>
</li>
</ul>
<h2 id="听力精听"><a class="markdownIt-Anchor" href="#听力精听"></a> 听力精听</h2>
<p>精听适合的人群：王陆语料库至少认识70%以上</p>
<p>精听需要准备的材料：</p>
<ul>
<li>草稿纸：记录听到的原文</li>
<li>本子：记录这些发音的点</li>
<li>黑笔和红笔</li>
</ul>
<p>精听的具体步骤：</p>
<ul>
<li>播放一句雅思听力，点击暂停：播放一秒钟反映全句内容，养成习惯</li>
<li>把草稿纸上写上完整的话</li>
<li>自己没听出来的部分，反复放(如果不知道是什么单词，可以先把读音写下来)</li>
<li>打开原文，再放这个部分，对比我们脑海中读音和实际读音：根据记录和原声，反复放读，直到和原文一样</li>
<li>发现差异的点，记录在笔记本上，每日反复仿读</li>
</ul>
<p>注意点：</p>
<ul>
<li>光听不写</li>
<li>过早放弃</li>
<li>光做不复盘</li>
</ul>
<p>听力6.5以及以上可以直接听section3，4（前提一定是听过语料库），6.5以下但听过语料库大概60%都会的，可以听section1，2，没听过语料库与5分以下的童鞋，请不要精听，没什么太大意义，事倍功半，去听语料库</p>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1FS421w7FD/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【何琼雅思听力网课全集】2024年最新何琼听力技巧课！做题方法+作业讲解高清视频】 </a></li>
<li><a href="https://www.bilibili.com/video/BV1rt411h75v/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">6周破8分 | 雅思精听10天见效 | 真正对普通人有用的精听步骤 | 打破雅思听力原地踏步</a></li>
<li><a href="https://www.bilibili.com/video/BV1AK4y1W7dh/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">手把手教你做听力Part4 | 雅思听力填空题</a></li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>IELTS</tag>
        <tag>Listening</tag>
      </tags>
  </entry>
  <entry>
    <title>IELTS:Writing Task 1</title>
    <url>/2024/09/18/IELTS-Writing-Task-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-contents"><a class="markdownIt-Anchor" href="#table-of-contents"></a> Table of Contents</h2>
<ul>
<li><a href="#remember">Remember</a></li>
<li><a href="#line-graph">Line Graph</a>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#overview">Overview</a></li>
<li><a href="#details">Details</a></li>
</ul>
</li>
<li><a href="#bar-chart">Bar Chart</a>
<ul>
<li><a href="#introduction-1">Introduction</a></li>
<li><a href="#overview-1">Overview</a></li>
<li><a href="#details-1">Details</a></li>
</ul>
</li>
<li><a href="#pie-charts">Pie charts</a>
<ul>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#overview-2">Overview</a></li>
<li><a href="#details-2">Details</a></li>
</ul>
</li>
<li><a href="#tables">Tables</a>
<ul>
<li><a href="#overview-3">Overview</a></li>
<li><a href="#introducion">Introducion</a></li>
<li><a href="#details-3">Details</a></li>
<li><a href="#volcabulary">Volcabulary</a></li>
</ul>
</li>
<li><a href="#2-different-charts">2 different charts</a>
<ul>
<li><a href="#overview-4">Overview</a></li>
<li><a href="#introduction-3">Introduction</a></li>
<li><a href="#details-4">Details</a></li>
<li><a href="#vocabulary">Vocabulary</a></li>
</ul>
</li>
<li><a href="#process-diagram">Process diagram</a>
<ul>
<li><a href="#overview-5">Overview</a></li>
<li><a href="#introduction-4">Introduction</a></li>
<li><a href="#details-5">Details</a></li>
<li><a href="#vocabulary-1">Vocabulary</a></li>
</ul>
</li>
<li><a href="#comparison-diagram">Comparison diagram</a>
<ul>
<li><a href="#overview-6">Overview</a></li>
<li><a href="#introduction-5">Introduction</a></li>
<li><a href="#details-6">Details</a></li>
<li><a href="#vocabulary-2">Vocabulary</a></li>
</ul>
</li>
<li><a href="#20min%E6%95%99%E4%BC%9A%E4%BD%A0%E5%86%99%E5%A5%BD%E5%B0%8F%E4%BD%9C%E6%96%87">20min教会你写好小作文</a>
<ul>
<li><a href="#%E5%BC%80%E5%A4%B4">开头</a></li>
<li><a href="#%E4%B8%AD%E9%97%B4-%E5%8A%A8%E6%80%81%E5%9B%BE">中间-动态图</a></li>
<li><a href="#%E7%BB%93%E5%B0%BE">结尾</a></li>
</ul>
</li>
<li><a href="#links">Links</a></li>
</ul>
<br>
<h2 id="remember"><a class="markdownIt-Anchor" href="#remember"></a> Remember</h2>
<ul>
<li><strong>describe what you see</strong>,dont give opinions</li>
<li><strong>no conclusion</strong>,instead a summary</li>
</ul>
<p>type:</p>
<ul>
<li>line graph</li>
<li>Bar chart</li>
<li>Pie chart</li>
<li>Pie chart</li>
<li>Table</li>
<li>Diagram - comparing</li>
<li>Diagram - process</li>
</ul>
<p>structure:</p>
<ul>
<li>Introducion:one sentence,<strong>Paraphrase the question</strong></li>
<li>Overview: two sentences,the main and general things</li>
<li>Details:  特点1</li>
<li>Details:  特点2</li>
</ul>
<p>评分标准:<br />
<img src="https://pic.imgdb.cn/item/66ea85bbf21886ccc07fbdea.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/670cf154d29ded1a8c029260.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/670cf0ccd29ded1a8c01f315.png" alt="" /></p>
<br>
<h2 id="line-graph"><a class="markdownIt-Anchor" href="#line-graph"></a> Line Graph</h2>
<ul>
<li>Genral Comparison and Detailed Comparison</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/66ea89bff21886ccc086178d.png" alt="" /></p>
<h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3>
<p>The graph below shows electricity production(in terawatt hours) in France between 1980 and 2012.</p>
<p>The line graph compares the amount of electricity produced in France using four different sources  over a period of 32 years.</p>
<p>pharase：</p>
<ul>
<li>the graph below shows -&gt; the line graph compares</li>
<li>electricity production -&gt; the amount of electricity produced</li>
<li>between 1980 and 2012 -&gt; over  a period of 32 years</li>
<li>add: in France（from tittle）</li>
</ul>
<h3 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h3>
<ul>
<li>highest and lowest</li>
</ul>
<p>It is clear the nuclear power was by far the most important means of electricity generation over the period shown.Renewables provided the lowest amount of electricity in each year.</p>
<h3 id="details"><a class="markdownIt-Anchor" href="#details"></a> Details</h3>
<p><img src="https://pic.imgdb.cn/item/66ea8b9cf21886ccc08c1308.png" alt="" /></p>
<ul>
<li>1980对比</li>
<li>交叉点</li>
</ul>
<p>In <strong>1980</strong>,<strong>thermal</strong> power stations were the main source of electricity in France,generating around 120 terawatt hours of power. <strong>Nuclear</strong> and <strong>hydroelectric</strong> provided a negligible amount. Just one year later,<strong>nuclear</strong> power <code>overlook</code> <strong>thermal</strong> power as the primary source of electricity.</p>
<p><img src="https://pic.imgdb.cn/item/66ea8cb2f21886ccc08d2195.png" alt="" /></p>
<ul>
<li>趋势</li>
<li>峰值</li>
</ul>
<p>Between <strong>1980</strong> and <strong>2005</strong>,electricity production from <strong>nuclear</strong> power <code>rose</code> dramatically to a peak of 430 terawatt hours. By contrast,the figure for <strong>thermal</strong> power fell to only 50 terawatt hour s in 1985, and <code>reamined</code> at this level for the rest of the period. <strong>Hydroelectric</strong> power generation <code>remained</code> relatively stable,at between 50 and 80 terawatt hours,for the whole 32-year period,but <strong>renewable</strong> electricity production saw only a small <code>rise</code> to approximately 25 terawatt hours by <strong>2012</strong>.</p>
<p>Vocabulary：</p>
<ul>
<li>amount of electricity produced</li>
<li>source of provided/generating</li>
<li>means of electricity generation</li>
<li>over a period of/over the period shown</li>
<li>by far the most important</li>
<li>a negligible amount</li>
<li>unclear power overtook thermal power</li>
<li>as the primary source of electricity</li>
<li>rose dramatically to a peak of</li>
<li>by contrast</li>
<li>remained at this level,remianed stable</li>
<li>saw only a small rise</li>
</ul>
<br>
<h2 id="bar-chart"><a class="markdownIt-Anchor" href="#bar-chart"></a> Bar Chart</h2>
<ul>
<li>Compare bars</li>
</ul>
<h3 id="introduction-2"><a class="markdownIt-Anchor" href="#introduction-2"></a> Introduction</h3>
<ul>
<li>paraphrase the question</li>
</ul>
<p>The chart below shows global sales of the top  five moible phone brands between 2009 and 2013</p>
<p>The chart compares the number of mobile phone sold worldwide by the five most popular manufacturers in the year 2009, 2011, and 2013.</p>
<p>paraphrase:</p>
<ul>
<li>the chart below shows -&gt; the bat chart compares</li>
<li>global sales of the top five mobile phone brands -&gt; the number of mobile phone sold wordwide bu the five most popular manufacuturers</li>
<li>between 2009 and 2013 -&gt; in the year 2009 ,2011 and 2013</li>
</ul>
<h3 id="overview-2"><a class="markdownIt-Anchor" href="#overview-2"></a> Overview</h3>
<ul>
<li>most</li>
<li>trend</li>
</ul>
<p>It is clear that Nokia sold the most mobile phones between 2009 and 2011,but Samsung became the best selling brand in 2013.Samsung and Apple saw the biggest rise in sale s over the 5-year period.</p>
<h3 id="details-2"><a class="markdownIt-Anchor" href="#details-2"></a> Details</h3>
<ul>
<li>2</li>
<li>compare Samsung with Nokia</li>
<li>trend</li>
<li>most</li>
<li>2009</li>
<li>over the following four years</li>
</ul>
<p>In 2009,<strong>Nokia</strong> sold close to 450 million mobile phones, which was <code>almost double</code> the number of handsets sold by the <code>second most successful</code> manufacturer,<strong>Samsung</strong>. Over the following four years,however, <strong>Nokia</strong>’s sale fell by approximately 200 milliion units,<code>whereas</code> <strong>Samsung</strong> saw sale rise by a similar amount. By 2013,<strong>Samsung</strong> <code>had become market leader</code> with sales reaching 450 milliion units.</p>
<p>The other three top selling mobile phone brands between <strong>2009</strong> and <strong>2013</strong> were <strong>LG</strong>,<strong>ZTE</strong> and <strong>Apple</strong>. In <strong>200</strong>9,these companies sold around 125 million,50 million and 25 millon mobile phone handsets respectively, but <strong>Apple</strong> <code>overtook the other two vendors</code> in <strong>2011</strong>. In <strong>2013</strong>,<code>purchase of Apple handsets reached 150 million units</code>,while <strong>LG</strong> <code>saw declining sales</code> and the figures for <strong>ZTE</strong> <code>rose only slightly</code>.</p>
<p>Vocabulary: pharaphrasing,comparing and change over time</p>
<ul>
<li>sold worldwide</li>
<li>sales figures,purchases</li>
<li>most popular,best selling brand,top selling</li>
<li>second most successful manufacturer</li>
<li>market leader</li>
<li>mobile phones,handsets,units</li>
<li>brands,manufacturers,companies,vendors</li>
<li>saw the biggest rise, saw declining sales</li>
<li>close to, almost,approximately,around</li>
<li>double the number</li>
<li>rise by a similar amount</li>
<li>respectively</li>
</ul>
<br>
<h2 id="pie-charts"><a class="markdownIt-Anchor" href="#pie-charts"></a> Pie charts</h2>
<ul>
<li>show numbers and percentages</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/66eadc7ff21886ccc0e7b432.png" alt="" /></p>
<h3 id="introduction-3"><a class="markdownIt-Anchor" href="#introduction-3"></a> Introduction</h3>
<p>The charts below show household spending patterns in two countries between 1980 and 2008.</p>
<p>The pie charts compare five categories of household expenditure in the UK and New Zealand in the years 1980 and 2008.</p>
<p>pharaphrase :</p>
<ul>
<li>household spending patterns -&gt; five categories of household expenditure</li>
<li>in two coutries -&gt; in the UK and New Zeland</li>
<li>between 1980 and 2008 -&gt; in the years 1980 and 2008</li>
</ul>
<h3 id="overview-3"><a class="markdownIt-Anchor" href="#overview-3"></a> Overview</h3>
<p><img src="https://pic.imgdb.cn/item/66eadfbff21886ccc0eb6a22.png" alt="" /></p>
<ul>
<li>no number</li>
<li>both trend</li>
<li>相反的 trend</li>
</ul>
<p>It is noticeable that the proportion of spending on food and drink fell in both countries over the 28-year period,while spending on utility bills rose.  Also,UK residents spent a significantly larger percentage of their household budgets on leisure than their New Zeland counterparts.</p>
<h3 id="details-3"><a class="markdownIt-Anchor" href="#details-3"></a> Details</h3>
<ul>
<li>针对Overview中的第一句话进行详细的比较</li>
<li>1980 and 2008</li>
<li>Food &amp; drink</li>
<li>Utility bills</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/66eae23ef21886ccc0ee38a3.png" alt="" /></p>
<p>In <strong>1980</strong>,29% of anverage <strong>New Zealand</strong> household budget went <strong>food and drink</strong>, while the equivalent figure for a <strong>UK</strong> home was 23%. By <strong>2008</strong>,expenditure on <strong>food and drink</strong> had fallen by 4% in <strong>New Zeland</strong> and buy a full 10% in the <strong>UK</strong>. By contrast,both countries saw an increase in expenditure on <strong>utility bills</strong> for the average home,from 27% to 31% in <strong>New Zealand</strong> and from 26% to 28% in the <strong>UK</strong>.</p>
<ul>
<li>针对Overview中的第二句话进行详细的比较</li>
</ul>
<p><strong>Leisure</strong> activities accounted for the highest proportion of UK household spending in both years, but only the third highest proportion in the <strong>New Zealand</strong>. In fact, in 2008, <strong>New Zealand</strong> spent only half as much in relative terms on recreation(17%) as UK residents(24%). In both countries, <strong>transport</strong> costs and <strong>other</strong> costs took roughly 15% and 10% of household budgets respectively.</p>
<p>tips:</p>
<ul>
<li>Compare across countries and years.</li>
<li>Refer to each category.</li>
<li>Separate features in overview and details.</li>
<li>Mention “Other” briefly.</li>
<li>Avoid simplistic statements like “X was Y%”.</li>
</ul>
<p>Vocabulary:</p>
<ul>
<li>spending, expenditure,spent,costs</li>
<li>proportion of spending</li>
<li>percentage of household budget</li>
<li>the equivalent figure for a UK home</li>
<li>fell,rose,saw an increase in</li>
<li>by 2008,expenditure had fallen</li>
<li>spent a significantly larger percentage</li>
<li>than their New Zealadnd counterparts</li>
<li>29% of an average household bydget went to</li>
<li>while ,by contrast</li>
<li>leisure accounted for the highest proportion</li>
<li>spent half as much in relative terms</li>
<li>recreation</li>
</ul>
<br>
<h2 id="tables"><a class="markdownIt-Anchor" href="#tables"></a> Tables</h2>
<p>Tables can show:</p>
<ul>
<li>any kind of number</li>
<li>the smae information as a line graph, bar chart or pie chart</li>
<li>comparisons</li>
<li>changes over time</li>
<li>a lot of information</li>
</ul>
<p>A key skill is ‘selecting’ which information to mention</p>
<p><img src="https://pic.imgdb.cn/item/6715382ed29ded1a8c70fa6b.png" alt="" /></p>
<h3 id="overview-4"><a class="markdownIt-Anchor" href="#overview-4"></a> Overview</h3>
<p><code>The table below shows</code> statistics about <code>the top five countries</code> <code>for</code> <code>international tourism</code> <code>in 2012 and 2013</code>.</p>
<p><code>The table compares</code> <code>the five highest ranking coutries</code> <code>in terms of</code> <code>the numbers of visits and the money spent by tourists</code> <code>over a period of two years</code>.</p>
<h3 id="introducion"><a class="markdownIt-Anchor" href="#introducion"></a> Introducion</h3>
<p>It is clear that France was the world’s most popular tourist destination in the years 2012 and 2013. However, the USA earned by far the most revenue from tourism over the same period.</p>
<h3 id="details-4"><a class="markdownIt-Anchor" href="#details-4"></a> Details</h3>
<p>In <strong>2012</strong>, 83 million <strong>tourists visited</strong> <strong>France</strong>, and the <strong>USA</strong> was the second most visited country, with 66.7 million tourists. Spain and <strong>China</strong> each received just under 58 million visitors, while <strong>Italy</strong> was ranked fifth with 46.4 million tourists. <strong>2013</strong> saw a rise of between 1 and 4 million tourist visits to each country, with the exception of China, which received 2 million fewer visitors than in the previous year.</p>
<p>Spending by tourists visiting the USA increased from $126.2 billion in 2012 to $139.6 billion in 2013, and these figures were well over twice as high as those for any other country. Spain received the second highest amounts of tourist revenue, rising from $56.3 billion to $60.4 billion, followed by France, China and Italy. Interestingly, despite falling numbers of tourists, Chinese revenue from tourism rose by $1.7 billion in 2013.</p>
<p>Key skill: selecting information—You can’t mention every number.</p>
<h3 id="volcabulary"><a class="markdownIt-Anchor" href="#volcabulary"></a> Volcabulary</h3>
<ul>
<li>five highest ranking countries</li>
<li>the world’s most popular tourist destination</li>
<li>earned by far the most</li>
<li>revenue from tourism</li>
<li>the second most visited country</li>
<li>received…visitors</li>
<li>ranked fifith</li>
<li>2013 saw a rise of</li>
<li>fewer visitors than in the previous year</li>
<li>these figures were well over twice as high as</li>
<li>amount of tourist revenue</li>
<li>despite falling numbers</li>
<li>saw a rise, increased, rising form, rose by</li>
</ul>
<br>
<h2 id="2-different-charts"><a class="markdownIt-Anchor" href="#2-different-charts"></a> 2 different charts</h2>
<ul>
<li>First, look for one main feature in each chart</li>
<li>Second, describe specific numbers for each chart separately</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/67153f37d29ded1a8c816675.png" alt="" /></p>
<h3 id="overview-5"><a class="markdownIt-Anchor" href="#overview-5"></a> Overview</h3>
<p><code>The bar chart below shows</code> the numbers of <code>men and woman</code> <code>attending various evening courses at an audlt education centre</code> <code>in the year 2009</code>. <code>The pie chart gives information about</code> <code>the ages of these course participants</code>.</p>
<p><code>The bar chart compares</code> the numbers of <code>males and females</code> <code>who took four different evening classes</code> <code>in 2009</code>, and <code>the pie chart shows</code> <code>the age profile of these attendees</code>.</p>
<h3 id="introduction-4"><a class="markdownIt-Anchor" href="#introduction-4"></a> Introduction</h3>
<p>It is clear that significantly more women than men atteded evening classes at the education centre. We can also see that evening courses were much more popular among older adults.</p>
<h3 id="details-5"><a class="markdownIt-Anchor" href="#details-5"></a> Details</h3>
<p>According to the <strong>bar chart</strong>, <strong>drama</strong>, <strong>painting</strong> and <strong>language courses</strong> all attracted <strong>more woman than men</strong> to the education centre in 2009. Language classes had the highest number of participants overall, <code>with</code> <strong>40 female and 20 male</strong> students, while painting was a popular choice among <strong>both genders</strong>, <code>attracting</code> <strong>30 females and 25 male attendees</strong>. The only course with a higher number of males was <strong>sculpture</strong>, but this course was taken by a mere <strong>15 people in total</strong>.</p>
<p>Looking at the age profile pie chart, we can see that the <strong>majority</strong> of people attending evening lessons were <code>over 40 years of age</code>. To be precise, <strong>42%</strong> of them ere aged <code>50 or more</code>, and <strong>26%</strong> were aged <code>between 40 and 49</code>. Younger adults were in the <strong>minority</strong>, with only <strong>11%</strong> of students <code>aged 20 to 29</code>,and only <strong>5%</strong> <code>aged under 20</code>.</p>
<h3 id="vocabulary"><a class="markdownIt-Anchor" href="#vocabulary"></a> Vocabulary</h3>
<ul>
<li>attending course, who took classes</li>
<li>participants, attendees, students</li>
<li>males and females</li>
<li>course attracted more woman</li>
<li>a popular choice among both genders</li>
<li>significantly more, higher, highest</li>
<li>had the highest number, with(number)</li>
<li>was taken by a mere 15 people</li>
<li>According to the bar chart</li>
<li>Looing at the age profile pie chart</li>
<li>the majority of people</li>
<li>were in the minority</li>
<li>To be precise</li>
</ul>
<br>
<h2 id="process-diagram"><a class="markdownIt-Anchor" href="#process-diagram"></a> Process diagram</h2>
<p><img src="https://pic.imgdb.cn/item/6715eb85d29ded1a8cb1c7db.png" alt="" /></p>
<p>Differences:</p>
<ul>
<li>no numbers</li>
<li>can’t compare anything</li>
<li>can’t describe trends</li>
</ul>
<p>–</p>
<p>So what can we describe?</p>
<ul>
<li>how many steps</li>
<li>where the process begins and ends</li>
<li>each step in the process</li>
</ul>
<p>–</p>
<p>Language for process descriptions:</p>
<ul>
<li>steps language</li>
<li>passive verbs</li>
</ul>
<h3 id="overview-6"><a class="markdownIt-Anchor" href="#overview-6"></a> Overview</h3>
<p><code>The diagrams below show</code> <code>how galss containers</code>, such as bottles, <code>are producted</code> and <code>recycled</code>.</p>
<p><code>The first flow diagram illustrates</code> <code>the process of</code> <code>glass container production</code>, and <code>the second diagram shows</code> <code>steps in the process of</code> <code>recycling used glass</code>.</p>
<h3 id="introduction-5"><a class="markdownIt-Anchor" href="#introduction-5"></a> Introduction</h3>
<p>We can see that glass is made using three main raw materials, and that the manufacturing process consists of four distinct stages. // It requires five steps to turn used glass into new glass products.</p>
<h3 id="details-6"><a class="markdownIt-Anchor" href="#details-6"></a> Details</h3>
<p><strong>At the first stage in</strong> the production of glass, sand, soda ash, limestone and other chemicals <code>are mixed</code> together. <strong>Next</strong>, this mixture <code>is heated</code> in a glass furnace at approximately 1500‘C to produce molten glass. THe molten glass can <strong>then</strong> <code>be shaped</code>, by blowing, to create the <strong>end products</strong>, namely glass containers.</p>
<p>Glass recycling <strong>begins with</strong> the collection of used galss products. The collected glass <code>is sorted</code> according to its colour, <strong>and then</strong> <code>washed</code> in order to remove any impurities. <strong>At the fourth stage of</strong> recycling, the glass <code>is crushed and melted</code>, and the resulting molten glass can <strong>finally</strong> <code>be moulded</code> to create new items.</p>
<h3 id="vocabulary-2"><a class="markdownIt-Anchor" href="#vocabulary-2"></a> Vocabulary</h3>
<ul>
<li>steps/stages in the process of</li>
<li>consists of four distinct stages</li>
<li>it reuqires five steps</li>
<li>raw materials, end products</li>
<li>production, manufacturing</li>
<li>turn used glass into new products</li>
<li>at the first stage, next, then, begins with</li>
<li>ate mixed, is heated, can be shaped</li>
<li>is sorted according to</li>
<li>can be moulded to create</li>
<li>are mixed -&gt; this mixture</li>
<li>collected -&gt; the collected glass</li>
<li>is melted -&gt; the resulting molten glass</li>
</ul>
<br>
<h2 id="comparison-diagram"><a class="markdownIt-Anchor" href="#comparison-diagram"></a> Comparison diagram</h2>
<p>Comparison diagrams show:</p>
<ul>
<li>changes to something</li>
<li>two alternative designs</li>
<li>even two alternative locations on a map</li>
</ul>
<p>–</p>
<p>Your job is to compare the diagrams:</p>
<ul>
<li>Describe the changes</li>
<li>Descirbe things that don’t change</li>
<li>Describe the differences</li>
<li>Describe the similarities</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6715eb64d29ded1a8cb178f5.png" alt="" /></p>
<h3 id="overview-7"><a class="markdownIt-Anchor" href="#overview-7"></a> Overview</h3>
<p><code>The diagrams below show</code> <code>the existing ground floor plan of a house</code> and <code>a proposed plan for some building work</code>.</p>
<p><code>The two prictures compare</code> <code>the current layout of the ground floor of a house</code> <code>with a plan to redesign the same living space</code>.</p>
<h3 id="introduction-6"><a class="markdownIt-Anchor" href="#introduction-6"></a> Introduction</h3>
<p>We can see that the new design proposal involves marking a number of changes to the ground floor of the house, mainly in the central hall area. There are no plans to change external walls or entrances.</p>
<h3 id="details-7"><a class="markdownIt-Anchor" href="#details-7"></a> Details</h3>
<p>The most noticeable change from the existing to the proposed floor plan is that there whill no longer be a separete hall area when the building work has been done. This will be achived by removing the internal wall and foor between the hall and living room, along with the current staircase and understair storage cupboard. With no separate hall area, the proposed living room will also contain the staircase to the first floor.</p>
<p>To replace the current straight staircase, a new set of winding stairs will be installed in the corner of the living room. The internal door between the hall and kitchen will also be replaced with double doors connecting the kitchen with the new living room. Finally, the planned building work will also include the installation of some kitchen furniture.</p>
<h3 id="vocabulary-3"><a class="markdownIt-Anchor" href="#vocabulary-3"></a> Vocabulary</h3>
<ul>
<li>existing plan -&gt; current layout</li>
<li>proposed plan -&gt; plan to redesign</li>
<li>design proposal, planned building work</li>
<li>there will no longer be</li>
<li>this will be achieved by removing</li>
<li>will also contain, will also include</li>
<li>will be installed, will be replaced</li>
<li>the design proposal involves</li>
<li>when the building work has been done</li>
<li>living space, central hall area, staircase</li>
<li>under-stair storage cupboard</li>
<li>a new set of winding stairs</li>
<li>the installation of some kitchen furniture</li>
</ul>
<br>
<h2 id="20min教会你写好小作文"><a class="markdownIt-Anchor" href="#20min教会你写好小作文"></a> 20min教会你写好小作文</h2>
<h3 id="开头"><a class="markdownIt-Anchor" href="#开头"></a> 开头</h3>
<p><strong>结构</strong>：This/These graph/chart/table compare/indicate/show/illustrate/contains/give the information</p>
<p><strong>分类简单</strong>：This chart shows the <code>percentage of British people living a solitary life of 5 age groups</code> in terms of XXX <code>in the four years (of 1850,1900, 1950, and 2000)</code></p>
<p><strong>分类复杂</strong>：</p>
<ul>
<li>The information given by the table is about the <code>proportion of buyer expenditure on eating, dressing and leisure</code> <code>in five different nations</code> <code>in 2002</code></li>
<li>The table indiacates the <code>proportion of buyer expenditure  in five different nations</code> <code>on eating, dressing and leisure</code> <code>in 2002</code></li>
</ul>
<h3 id="中间-动态图"><a class="markdownIt-Anchor" href="#中间-动态图"></a> 中间-动态图</h3>
<p>如果是预测值：be likely to/ be projected to/ be predicted to/ be expected to</p>
<p>Main body:</p>
<ul>
<li>趋势类型分组：上升/下降</li>
<li>变化幅度分组：不变，有变化</li>
<li>按照时间分组</li>
</ul>
<hr />
<p>上升动词：climb &lt; increase rise/grow &lt; jump/surge/soar/escalate/shoot up</p>
<p>上升名词：increase,rise,growth,jump,surge,an upward trend</p>
<p>下降动词：slide &lt; decrease/drop/decline/fall/dip &lt; subside/slump/plunge</p>
<p>下降名词：decrease,drop,decline,fall,reduction,drop a downward trend</p>
<p>波动动词：fluctuate, go up and down, rise and fall</p>
<p>波动名词/形容词：fluctuation, variable=inconsistent</p>
<p>持平动词：remain the same, stabilize, remain stable, remain constant</p>
<p>修饰程度的副词：steadily &lt; slightly/slowly/gradually/moderately &lt; significantly/considerably/sharply/rapidly/dramatically/drastically/steady &lt; slight/slow/gradual/moderate &lt; significant/considerable/sharp/rapid/dramatic/drastic</p>
<p>大约：about/almost/approximately/around</p>
<p>极大值/极小值：peak/top/highest point; bottom/lowest point</p>
<hr />
<p>多：</p>
<ul>
<li>double/triple/quadruple/fourfold</li>
<li>increase to 3 times</li>
<li>increase by 3 times</li>
<li>two times as many as…</li>
</ul>
<p>–</p>
<p>少：</p>
<ul>
<li>half</li>
<li>one third</li>
<li>quarter</li>
</ul>
<p>–</p>
<p>时间描述：throughout/over/during the period, from…to… , at the beginning of, by the middle of, at the end of, in the first/second half of, in the first/following 50 years(decade)</p>
<hr />
<p><img src="https://pic.imgdb.cn/item/67173e51d29ded1a8cea560a.png" alt="" /></p>
<p>趋势变化：</p>
<ul>
<li>The proportion of 26-40 year olds living a solitary life declined slightly to 22% in 1900, <strong>and then</strong> it increase to 45% over the next 100 years.</li>
<li>The percentage of 26-40 year olds living alone in the UK fell from 25% to 22% in 1900, <strong>before rising</strong> to 45% from 1900 to 2000.</li>
<li>The percentage of 26-40 year olds living alone in the UK fell from 25% to 22% in 1900, <strong>after which</strong> the figure rise to 45% from 1900 to 2000.</li>
<li>The proportion of 26-40 year olds living a solitary life significantly increased from 25% in 1850 to 45% in 2000, <strong>although</strong> it had a slight decrease from in the first 50 years.</li>
</ul>
<p>–</p>
<p>趋势相反：</p>
<ul>
<li>There was an opposite trend in the figure for 26-40 years old, falling from 20% in 1850 to only half of the beginning.</li>
<li>In terms of figure for 26-40 years old, the tendency is opposite, which decrease from 20% in 1850 to 10% in 2000.</li>
</ul>
<p>–</p>
<p>虽然生了但仍然最低，虽然讲了但仍然最高：<br />
Although the figure for insurance rose fourfold to 8%, it remained the lowest.</p>
<hr />
<p>对象+趋势动词+副词+数值+时间：The proportion of 55-65 year olds living a solitary life <strong>declined considerably</strong> from 3% in 1850 to 15% in 1900</p>
<p>对象+动词+形容词+趋势名词+数值+时间：The proportion of 55-65 year olds living a solitary life <strong>experienced a significant decrease</strong> from 3% in 1850 to 15% in 1900</p>
<p>There be + 趋势名词 + in + 对象 + 时间：<strong>There was</strong> a 12% drop in the percentage of 55-65 year olds living by their own from 1850 to 2000</p>
<p>趋势名词+be seen+in+对象+时间：<strong>A downward trend was seen</strong> in the proportion of 26-40 year olds living a solitary life from 25% to 20% during the first 50 years.</p>
<p>时间+seewitness+趋势的名词+in+对象+数值：The first 50 years <strong>witnessed a downward trend</strong> in the propotion of 26-40 year olds living a solitary life from 25% to 20%.</p>
<hr />
<p>静态图</p>
<p>分类：</p>
<ul>
<li>按顺序分类</li>
<li>按照类别分类</li>
<li>倍数关系/差值整数的为一组</li>
<li>最大最小值和其他的一组</li>
</ul>
<hr />
<p><img src="https://pic.imgdb.cn/item/6717425ed29ded1a8cefa3d7.png" alt="" /></p>
<p>句型(比较)</p>
<p><strong>while</strong>: For primary school, the average teaching time per year in the USA was the highest(about 900 hours), while the figure for other three countries was almost the same(at 600).</p>
<p><strong>followed by</strong>: For primary school, the average teaching time per year in the USA was the highest(about 900), followed by the figure for the other three countries(600)</p>
<p><strong>compared with</strong>: For primary school, the average teaching time per year in the USA was 900 hours, compared with 600 in the other three countries.</p>
<p><strong>换分类</strong>：<br />
In Spain, the average teaching time per year in the USA was 900 hours, which is 600 in the other three contries.</p>
<p><strong>which</strong>: For primary school, the average teaching time year in the USA was 900 hours, which is 600 in the other three countries.</p>
<p><strong>比较级</strong>: For primary school, the average teaching time per year in the USA was much longer than the gigure for Japan, at 900 and 500 respectively.</p>
<p><strong>整减</strong>：Teachers from upper secondary school in USA topped the list of teaching time per year, with an average number of 1,100 hours, 100 hours higher than the figure for Spain(1000h)</p>
<p><strong>倍数关系</strong>：In Spain, the teaching time in upper secondary was the highest(1000h), nearly twice as long as the figure for primary and lower secondary(about 500)</p>
<hr />
<p>排序：</p>
<ul>
<li>In the consumers’ opinions, the most effective method to alleviate global warming is recycling, which is <strong>at the bottom of</strong> the researchers’ list.</li>
<li>Recycling is regarded as the most effective way to cope with global warming by the consumers, but it only <strong>ranks fifth</strong> in the researchers’ opinions.</li>
<li>The consumers believe that recycling <strong>comes first</strong> in terms of reducing global warming, whereas the researchers rate it the lowest in their effectiveness ratings.</li>
<li>Although both the consumers and the researchers advocate recycling, <strong>its rankings on</strong> their lists are strikingly different, first in comparison with last.</li>
</ul>
<p>–</p>
<p>常用词语：</p>
<ul>
<li>Rank/Rank high/Top/Ahead of/followed by/Maintain Middle posiions/At the top of the table/At the bottom of the list/At the bottom of /rank frist/come first</li>
</ul>
<hr />
<p>句式表达</p>
<p><strong>对象+be+数字</strong>：In the USA, the average teaching time per year in upper decondary was 1100.</p>
<p><strong>对象+take up+数字</strong>：In the USA, the average teaching time in upper decondary toke up 1100 hours per year.</p>
<p><strong>更换对象+spend/work等主动词+数字</strong>：In the USA, each teacher in upper decondary school spent work about 1100 hours per year.</p>
<p><strong>被动语态</strong>：In the USA, 1100 hours were spent on teaching in upper decondary school per year.</p>
<p><strong>where</strong>: In the USA, the average teaching time is the highest in upper decondary, where teacher spend 1100 hours each year.</p>
<p><strong>with</strong>: Teachers from upper secondary school in USA topped the list of teaching time per year, with an average number of 1100 hours.</p>
<h3 id="结尾"><a class="markdownIt-Anchor" href="#结尾"></a> 结尾</h3>
<p>动态图：</p>
<ul>
<li>挑典型</li>
<li>分趋势</li>
<li>分变化</li>
</ul>
<p>静态图：</p>
<ul>
<li>挑典型</li>
<li>换方向对比</li>
</ul>
<h2 id="links"><a class="markdownIt-Anchor" href="#links"></a> Links</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1xM4m1m7GY/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【作文】Simon正版课程合集|中英字幕，对照讲义逐节学习</a></li>
<li><a href="https://www.bilibili.com/video/BV1v4pBeEErd/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【雅思写作】抽奖！！20min教会你写好小作文（含免费资料和福利）</a></li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
  </entry>
  <entry>
    <title>IELTS:Writing Task 2</title>
    <url>/2024/10/21/IELTS-Writing-Task-2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="table-of-contents"><a class="markdownIt-Anchor" href="#table-of-contents"></a> Table of Contents</h2>
<ul>
<li><a href="#remeber">Remeber</a></li>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#discussion">Discussion</a></li>
<li><a href="#opinion">Opinion</a></li>
<li><a href="#problem-and-solution">Problem and solution</a></li>
<li><a href="#two-part-question">Two-part question</a></li>
</ul>
</li>
<li><a href="#main-body-paragraphs">Main body paragraphs</a>
<ul>
<li><a href="#firstly-secondly-finally">Firstly, Secondly, Finally</a></li>
<li><a href="#idea-explain-example">Idea, Explain, Example</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a>
<ul>
<li><a href="#discurssion">Discurssion</a></li>
<li><a href="#opinion-1">Opinion</a></li>
<li><a href="#problem-and-solution-1">Problem and solution</a></li>
<li><a href="#two-part-question-1">two-part question</a></li>
</ul>
</li>
<li><a href="#planning">Planning</a></li>
<li><a href="#opinion-essay">Opinion essay</a>
<ul>
<li><a href="#introduction-1">Introduction</a></li>
<li><a href="#details">Details</a></li>
<li><a href="#conclusion-1">Conclusion</a></li>
<li><a href="#vocabulary">Vocabulary</a></li>
</ul>
</li>
<li><a href="#discussion-essay">Discussion essay</a>
<ul>
<li><a href="#introduction-2">Introduction</a></li>
<li><a href="#main-body">Main body</a></li>
<li><a href="#conclusion-2">Conclusion</a></li>
<li><a href="#vocabulary-1">Vocabulary</a></li>
</ul>
</li>
<li><a href="#problem-and-solution-essay">Problem and solution essay</a>
<ul>
<li><a href="#introduction-3">Introduction</a></li>
<li><a href="#main-body-1">Main body</a></li>
<li><a href="#conclusion-3">Conclusion</a></li>
<li><a href="#vocabulary-2">Vocabulary</a></li>
</ul>
</li>
<li><a href="#2-part-question">2-part question</a>
<ul>
<li><a href="#introduction-4">Introduction</a></li>
<li><a href="#main-body-2">Main body</a></li>
<li><a href="#conclusion-4">Conclusion</a></li>
<li><a href="#vocabulary-3">Vocabulary</a></li>
</ul>
</li>
<li><a href="#extra-help-for-agree-or-disagree-questions">Extra help for “Agree or disagree?” questions</a>
<ul>
<li><a href="#agree">agree</a></li>
<li><a href="#disagree">disagree</a></li>
<li><a href="#partly-agree">partly agree</a></li>
</ul>
</li>
<li><a href="#peeel">PEEEL</a></li>
<li><a href="#link">Link</a></li>
</ul>
<Br>
<h2 id="remeber"><a class="markdownIt-Anchor" href="#remeber"></a> Remeber</h2>
<p>IELTS Training:</p>
<ul>
<li>1.Understand the task</li>
<li>2.Break the task into parts</li>
<li>Methods, techiniques</li>
<li>Lots of practice</li>
<li>Feedback, measure progress</li>
</ul>
<p>–</p>
<p>Write an essay</p>
<ul>
<li>Minimum 250 words</li>
<li>40 minutes</li>
<li>Universal topics</li>
<li>4 question types</li>
</ul>
<p>–</p>
<p>Four scoring criteria</p>
<ul>
<li>Task response</li>
<li>Coherence and cohesion</li>
<li>Vocabulary</li>
</ul>
<p>–</p>
<p>Break the task into parts</p>
<ul>
<li>250 words</li>
<li>4 paragraphs: Introduction+Two main paragraphs + conclusion</li>
<li>about 13 sentences: 2+5+5+1</li>
<li>Timing: 10minutes(plan) + 5 minutes(intro) + 20 minutes + 5 minutes(conclusion)</li>
</ul>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<p>Method(2 sentences):</p>
<ul>
<li>introduce the topic</li>
<li>give a general answer</li>
</ul>
<p>–</p>
<p>Four types of question:;</p>
<ul>
<li>discussion</li>
<li>opinion</li>
<li>problem and solution</li>
<li>two-part question</li>
</ul>
<p>–</p>
<h3 id="discussion"><a class="markdownIt-Anchor" href="#discussion"></a> Discussion</h3>
<p>Some people think that it is more effective for students to study in groups, while others believe that it is better for them to study alone. Disscuss both views and give your own opinion.</p>
<p>Plan:</p>
<ul>
<li>Topic-study in groups or alone</li>
<li>Answer-sometimes better alone, usually better in a group</li>
</ul>
<p>–</p>
<p>People have different views about the effectiveness of group study <code>as opposed to</code> working alone. <code>While</code> there are some benefits to studying independently, I believe that group work is usually more productive.</p>
<h3 id="opinion"><a class="markdownIt-Anchor" href="#opinion"></a> Opinion</h3>
<p>Some people believe that unpaid community service should be a compulsory part of high school programmes. To what extent do you agree or disagree?</p>
<p>Plan:</p>
<ul>
<li>Topic-community service for all teengaers</li>
<li>Answer-3 choices: agree, disagree, or balanced opinion</li>
</ul>
<p>–</p>
<p>It is sometimes argued that high school students should be made to do some work in their local communities. I completely agree that this kind of scheme would be a good idea.</p>
<p>It is sometimes argued that high school students should be made to do some work in their local communities. In my opinion, it would be worng to force teenageers to do any kind of unsalaried work.</p>
<p>It is sometimes argued that high school students should be made to do some work in their local communities. While I disagree with the idea of making such programmes compulsory, I do believe voluntary community service could benefit young people.</p>
<h3 id="problem-and-solution"><a class="markdownIt-Anchor" href="#problem-and-solution"></a> Problem and solution</h3>
<p>Many criminal s reoffend afer they have been punished. Why do some people continue to commit crimes after they have been punished, and what measures can be taken to tackle this problem?</p>
<p>Plan:</p>
<ul>
<li>Topic-criminals reoffend</li>
<li>Answer-several reasons, a variety of measures(governments,communities)</li>
</ul>
<p>–</p>
<p>It is true that punishments do not always deter criminals from committing more cirmes. There are various reasons why offenders repeatedly break the law, but governments could certainly take steps to address this issue.</p>
<h3 id="two-part-question"><a class="markdownIt-Anchor" href="#two-part-question"></a> Two-part question</h3>
<p>As most people spend a major part of their adult life at work, job satisfaction is an important elemnt of individual well-being. What factors contribute to job satisfaction? How realistic is the expection of job satisfaction fro all workers?</p>
<p>Plan:</p>
<ul>
<li><strong>Topic</strong>-job satisfaction</li>
<li><strong>Answer</strong>-serveral factors, usrealistic/impossible</li>
</ul>
<p>–</p>
<p>Work plays a central role in our lives, and we would all like to feel fulfilled professionally. while a variety of factors may lead to job satisfaction, it would be unrealistic to expect everone to be happy at work.</p>
<br>
<h2 id="main-body-paragraphs"><a class="markdownIt-Anchor" href="#main-body-paragraphs"></a> Main body paragraphs</h2>
<p>4 paragraph essay:</p>
<ul>
<li>2 main body paragraphs</li>
<li>5 sentences in each</li>
<li>link words, topic volcabulary</li>
</ul>
<p>–</p>
<p>2 methods:</p>
<ul>
<li>Firstly, Secondly, Finally: advantages, disadvantgages, problems, solutions</li>
<li>Idea, Explain, Example: one idea, a reason, an opinion</li>
</ul>
<h3 id="firstly-secondly-finally"><a class="markdownIt-Anchor" href="#firstly-secondly-finally"></a> Firstly, Secondly, Finally</h3>
<p>Some people believe that unpaid community service should be a compulsory part of high school programmes. To what extent do you agree or disagree?</p>
<p>3-minutes plan:</p>
<ul>
<li><strong>disagree for several reasons</strong></li>
<li>school timetable is full, no time for community service</li>
<li>students’ work in other subjects would be affected</li>
<li>teenagers might not want to do it(reluctant, no motivation)</li>
</ul>
<p>–</p>
<p>There are several reasons why I would argue against having <strong>compulsory community service</strong> for secondary school students. <code>Firstly</code>, the <strong>school curriculum</strong> is already full with important <strong>academic subjects</strong>, <code>such as</code> maths, science and languages. <code>For example</code>, I remember having an <strong>extremely busy timetable</strong> when I was at high school, and it would not have been possible to add to it. <code>Secondly</code>, <strong>studens’ performance</strong> in other subjects would be affected if valuable study time were taken by <strong>charity work or neighbourhood imporovement schemes</strong>. <code>Finally</code>, I believe that teenage students would be <strong>reluctant</strong> to take part in any programme of <strong>obligatory work</strong>, and this could lead to <strong>poor motivation</strong> and even bad behavior.</p>
<h3 id="idea-explain-example"><a class="markdownIt-Anchor" href="#idea-explain-example"></a> Idea, Explain, Example</h3>
<p>3-minutes plan:</p>
<ul>
<li>voluntary(not compulsory) community service is positive</li>
<li>students more motivated if they can choose</li>
<li>gain work experience, self confidence, skills</li>
<li>good for CVs, career, university admissions, employers</li>
</ul>
<p>–</p>
<p><strong>On the other hand</strong>, the <code>oppotunity</code> to do <code>voluntary community service</code> could be extremely positive for high school students. By making <strong>these programmes</strong> optional, schools would <code>ensure that only motivated students took part</code>. <strong>These young people</strong> would <code>gain valuable experience</code> in an <code>adult working enviroment</code>, which could help to build <strong>their</strong> <code>self confidience</code> and <code>enhance their skills</code>. Having <strong>such experience and skills</strong> on their CVs could greatly <code>improve school leavers' career prospects</code>. <strong>For example</strong>, a period of voluntary work experience might <code>impress a university admissions officer or a future employer</code>.</p>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2>
<p>2 easy rules:</p>
<ul>
<li>never write anything new</li>
<li>one sentence:repeat,summarise</li>
</ul>
<p>–</p>
<p>Paraphrase the answer that you gave in your introductoin</p>
<h3 id="discurssion"><a class="markdownIt-Anchor" href="#discurssion"></a> Discurssion</h3>
<p>In many cities the use of video cameras in public places is being increased in order to reduce crime, but some people believe that these measures restrict our individual freedom. Do the benefits of increased security outweigh the drawbacks?</p>
<p>–Introduction–</p>
<p>It is true that video surveillance has become commonplace in many cities in recent years. While I understand that critics may see this as an invasion of privacy, I believe that there are m<strong>ore benefits than drawbacks</strong>.</p>
<p>–Conclusion–</p>
<p>In conclusion, I would argue that the <strong>advantages</strong> of using video security systems in public places do <strong>outweigh the disadvantages</strong>.</p>
<h3 id="opinion-2"><a class="markdownIt-Anchor" href="#opinion-2"></a> Opinion</h3>
<p>Families who send their children to private schools should not be required to pay taxes that support the state education system. To what extent do you agree or disagree with this statement?</p>
<p>–Introduction–</p>
<p>Some people believe that parents of children who attend private schools should not need to contribute to state schools through taxes, Personally, I completely disagree with this view.</p>
<p>–Conclusion–</p>
<p>In conclusion, I do not believe that any financial concessions should be made for people who choose private education.</p>
<h3 id="problem-and-solution-2"><a class="markdownIt-Anchor" href="#problem-and-solution-2"></a> Problem and solution</h3>
<p>In the developed world, average life expectancy is increasing. What problems will this cause for individuals and society? Suggest some measure that could be taken to reduce the impact of ageing populations.</p>
<p>–Introduction–</p>
<p>It is true that <code>people in industrialised nations can expect to live longer</code> than ever before. Although <code>there will undoubtedly be some negative consequences</code> of this trend, societies can <code>take steps to mitigate these potential problems</code>.</p>
<p>–Conclusion–</p>
<p>In conclusion,<code> vairous measures can be taken to tackle</code> <code>the problems that certain to arise</code> as the <code>populations of coutries grow older</code>.</p>
<h3 id="two-part-question-2"><a class="markdownIt-Anchor" href="#two-part-question-2"></a> two-part question</h3>
<p>There are many different types of music in the world today. Why do we need music? Is the traditional music of a country more important than the international music that is heard everywhere nowadays?</p>
<p>–Introdution–</p>
<p>It is true that a rich variey of musical stydles can be found around the world. Music is <code>a vital part of all human cultures</code> for a range of reasons, and <code>I would argue</code> that traditional music <code>is more important</code> than modern, internaltional music.</p>
<p>–Conclusion–</p>
<p>In conclusion, music is <code>a necessary part of human existence</code>, and <code>I believe</code> that traditional music should be <code>given more importance</code> than internaltional music.</p>
<h2 id="planning"><a class="markdownIt-Anchor" href="#planning"></a> Planning</h2>
<p>Spend 10 minutes planning your essay</p>
<p>Some people think that it is more effective for students to study in groups, while others believe that it is better for them to study alone. Discuss both views and give your own opinion.</p>
<p>1.Reading and understand the question</p>
<ul>
<li>highlight/underline key parts</li>
</ul>
<p>–</p>
<p>2.Plan your essay structure(4 paragraphs)</p>
<ul>
<li>Introduction: topic+answer(study in groups or alone, sometimes better alone, usually better in a group)</li>
<li>Benefits of studying alone</li>
<li>Benefits of group study</li>
<li>Conclusion: repeat answer(both have benefits, but I prefer group)</li>
</ul>
<p>–</p>
<p>3.Plan ideas for the two main paragraphs</p>
<ul>
<li>brainstorm, note down any ideas you have</li>
<li>develop ideas in detail</li>
<li>keep asking yourself ‘why’?</li>
<li>think of examples to support your ideas</li>
<li>finally, try to group related ideas(number them)</li>
</ul>
<p><strong>Benefits of studying alone</strong>:<br />
concentrate better, no distractions, focus on the task, read books or articles, study at own pace, e.g. when revising for an exam, memorise information</p>
<p><strong>Benefits of group study</strong>:<br />
<code>more ideas, share knowledge, gather more information</code> <code>e.g. research project, learn from each other</code>, <code>more motivating, responsibility to the group, sense of competition</code></p>
<ul>
<li>viewpoint</li>
<li>example</li>
<li>interpretation</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/67165f90d29ded1a8c897fd4.png" alt="" /></p>
<br>
<h2 id="opinion-essay"><a class="markdownIt-Anchor" href="#opinion-essay"></a> Opinion essay</h2>
<p>Do <strong>YOU</strong> agree or disagree?</p>
<p>–</p>
<p>The money spent by governments on space programmes would be better spent on vital public services such as school and hospitals. To what extent do you agree or disagree?</p>
<p>Plan your essay structure:</p>
<ul>
<li>Introduction: topic(government spending) + answer(public services instead of space projects)</li>
<li>explain why ‘space’ spending should be stopped</li>
<li>explain why public service spending is better</li>
<li>Conclusion: repeat answer(spend on services that benefit us all)</li>
</ul>
<p>–</p>
<p><strong>Why speace spending should be stopped</strong>:<br />
waste of money when projects fail, expensive(scientists, facilities, equipment), no benefit to normal people, politicians showing power, risk of accidents, deaths e.g. Challenger space shuttle</p>
<p><strong>Why public service spending is better</strong>:<br />
cheaper e.g. doctors,teachers police instead of astronauts, public services impact on everyone, reduce poverty, better quality of life, we all use schools, hospitals, police, roads etc.</p>
<p><img src="https://pic.imgdb.cn/item/671666dcd29ded1a8c927689.png" alt="" /></p>
<h3 id="introduction-2"><a class="markdownIt-Anchor" href="#introduction-2"></a> Introduction</h3>
<p>Governments in some countries spend large amounts of money on space exploration programmes. I completely agree with the idea that these are a waste of money, and that the funds should be allocated to public services.</p>
<h3 id="details"><a class="markdownIt-Anchor" href="#details"></a> Details</h3>
<p>There are several reasons why space programmes should be abandoned. Firstly, it is extremely expensive to train scientists and other staff involved with space missions, and facilities and equipment also come at a huge cost to the government. Secondly, these programmes do not benefit normal people in our daily lives; they are simply vanity projects for politicians, Financially, many missions to space fail completely, and the smallest technological error can cost astronauts their lives. The Challenger space shuttle disaster showed us that space travel is extremely dangerous, and in my opinion it is not worth the risk.</p>
<p>I believe that money from space programmes should go to vital public services instead. It is much cheaper to train doctors, teachers, police and other public service workers than it is to train astronauts or the scientists and engineers who work on space exploration projects. Futhermore, public servants do jobs that have a positive impact on every member of society. For example, we all use schools, hospitals and roads, and we all need the security that the police provide. If governments reallocated the money spent on space travel and research, many thousands of people could be lifted out of poverty or given a better quality of life.</p>
<h3 id="conclusion-2"><a class="markdownIt-Anchor" href="#conclusion-2"></a> Conclusion</h3>
<p>In conclusion, my view is that governments should spend money on services that benefits all memebrs of society, and it is wrong to waste rescources on projects that do not improve our everyday lives.</p>
<h3 id="vocabulary"><a class="markdownIt-Anchor" href="#vocabulary"></a> Vocabulary</h3>
<ul>
<li>space programmes, exploration, missions, projects, travel, research</li>
<li>funds should be abandoned</li>
<li>facilities and equipment come at a huge cost</li>
<li>vanity projects for politicians</li>
<li>can cost astronauts their lives</li>
<li>space shuttle disaster</li>
<li>public servants</li>
<li>a positive impact on every member of society</li>
<li>if governments reallocated</li>
<li>could be lifted out of poverty</li>
<li>given a better quality of life</li>
</ul>
<br>
<h2 id="discussion-essay"><a class="markdownIt-Anchor" href="#discussion-essay"></a> Discussion essay</h2>
<p>Some people think that a sense of competitiion in children should be encouraged. Others believe that children who are taught to co-operate rather than compete become more useful adults. Discuss both these views and give your own opinion.</p>
<p>Plan your essay structure:</p>
<ul>
<li>Introduction: topic + answer(benefits of both, co-operation more important)</li>
<li>Why encourage competition</li>
<li>Why teach co-operation(my view)</li>
<li>Conclusion:</li>
</ul>
<p>–</p>
<p><strong>Why encourage competition</strong>:<br />
motivation to work harder, be better than other children, self confidence, independent work, faster progress, competitive situations when leave school<br />
e.g. job interviews,prepared for adult life</p>
<p><strong>Why teach co-operation(my view)</strong>:<br />
co-operation even more important, e.g. at work(teams,follow boss’s instructions, help junior staff), collaboration more useful than winning, better attitude for young people, working together</p>
<p>–</p>
<h3 id="introduction-3"><a class="markdownIt-Anchor" href="#introduction-3"></a> Introduction</h3>
<p>People have different views about whether children should be taught to be competitive or co-operative. While a spirit of competition can sometimes be useful in life, I believe that the ability to co-operate is more important.</p>
<h3 id="main-body"><a class="markdownIt-Anchor" href="#main-body"></a> Main body</h3>
<p>On the one hand, competition can be a great source of motivation for children. When teachers use games or prizes to introduce an element of competitveness into lessons, it can encourage children to work harder to outdo the other pupils in the class. This kind of healthy rivalry may help to build children’s self confidence, while pushing them to work independently and progress more quickly. when these children leave school, their confidence and determination will help them in competitive situations such as job interviews. It can therefore be argued that competition should be encouraged in order to prepare children for adult life.</p>
<p>On the other hand, it is perhaps even more important to prepare children for the many aspects of adult life that require co-operation. In the workplace, adults are expected to work in teams, follow instructions given by their superiors, or supervise and support the more junior members of staff. Team collaboration skills are much more useful than a competitive determination to win. This is the attitude that I believe schools should foster in young people. Insted of promoting the idea that people are either winners or losers, teachers could show children that they gain more from working together.</p>
<h3 id="conclusion-3"><a class="markdownIt-Anchor" href="#conclusion-3"></a> Conclusion</h3>
<p>In conclusion, I can understand why people might want to encourage competitiveness in children, but it seems to me that a co-operativr attitude is much more desiable ion adult life.</p>
<h3 id="vocabulary-2"><a class="markdownIt-Anchor" href="#vocabulary-2"></a> Vocabulary</h3>
<ul>
<li>competition/co-operation, competitve, co-operative, co-operate, competitiveness</li>
<li>a spirit of competition</li>
<li>a source of motivation</li>
<li>introduce an element of competitiveness</li>
<li>outdo other pupils, healthy rivalry</li>
<li>build self confidence, determination</li>
<li>aspects of adult life</li>
<li>superiors, junior members of staff</li>
<li>team collaboration skills</li>
<li>attitude that schools should foster</li>
<li>promoting the idea</li>
<li>a co-operative attitude is more desiable</li>
</ul>
<Br>
<h2 id="problem-and-solution-essay"><a class="markdownIt-Anchor" href="#problem-and-solution-essay"></a> Problem and solution essay</h2>
<p>In many countries schools have severe problems with student behaviour. What do you think are the causes of this? What solutions can you suggest?</p>
<p>Plan your essay structure:</p>
<ul>
<li>Introduction: student behavior in schools variety of reasons, steps can be taken to tackle</li>
<li>Causes of bad student behaviour</li>
<li>My suggested solutions</li>
<li>Conclusion: summarise the problem and steps</li>
</ul>
<p>–</p>
<p><strong>Cause of bad student behaviour</strong>:<br />
parents not strict(too lenient), children don’t accept teachers’ instructions or school rules, teachers’ fault, no control, bad classroom management, influence of celebrities who are a bad example</p>
<p><strong>My suggested solutions</strong>:<br />
parents set rules for children, use punishments, action have consequences, schools train teachers and parents, discipline techniques, better communication, famous people act as role models</p>
<h3 id="introduction-4"><a class="markdownIt-Anchor" href="#introduction-4"></a> Introduction</h3>
<p>It is true that the behaviour of school pupils in some parts of the world has been getting worse in recent years. There are a variety of possible reasons for this, but steps can definitely be taken to tackle the problem.</p>
<h3 id="main-body-2"><a class="markdownIt-Anchor" href="#main-body-2"></a> Main body</h3>
<p>In my opinion, three main factors are to blame for the way young peple behave at school nowdays. Firstly, modern parents tend to be too lenient or permissive. Many children become accustomed to getting whatever they want, and they find it difficult to accept the demands of teachers or the limits imposed on them by school rules. Secondly, if teachers cannot control their students, there must be an issue with the quality of classroom management training or support within schools. Finally, children are influenced by the behaviour of celebrities, many of whom set the example that success can be achieved without finishing school.</p>
<p>Student behaviour can certainly be improved. I believe that the change must start with parents, who need to be persuaded that it is important to set firm rules for their children. When children misbehave or break the rules, parents should use reasonable punishments to demonstrate that actions have consequences. Also, schools could play an important role in training  both teachers and parents to use effective disciplinary techniques, and in improving the communication between both groups. At the same time, famous people, such as musicians and football players, need to understand the responsibility that they have to act as role models to children.</p>
<h3 id="conclusion-4"><a class="markdownIt-Anchor" href="#conclusion-4"></a> Conclusion</h3>
<p>In conclusion, schools will continue to face discipline problems unless parents, teachers and public figures set clear rules and demonstrate the right behaviour themselves.</p>
<h3 id="vocabulary-3"><a class="markdownIt-Anchor" href="#vocabulary-3"></a> Vocabulary</h3>
<ul>
<li>steps can be taken to tackle the problem</li>
<li>three main factors are to blame</li>
<li>parents tend to be too lenient or permissive</li>
<li>children become accustomed to</li>
<li>limits imposed on them</li>
<li>quality of classroom management</li>
<li>celebrities, famous people, public figures</li>
<li>set an example</li>
<li>set firm rules, reasonable punishments</li>
<li>play an important role in</li>
<li>effective disciplinary techniques</li>
<li>responsibility to act as role models</li>
<li>face discipline problems</li>
</ul>
<br>
<h2 id="2-part-question"><a class="markdownIt-Anchor" href="#2-part-question"></a> 2-part question</h2>
<p>News editors decide what to broadcast on television and what to print in newspapers. What factors fo you think influence these decisions? Do we become used to bad news, and would it be better if more good news was reported?</p>
<p>Plan your essay structure:</p>
<ul>
<li>Introduction: decisions about news stories variety of factors, yes too much bad news</li>
<li>Factors that influence new editors</li>
<li>Too much bad news, should report more good</li>
<li>Conclusion: diffcult news choices, more positive</li>
</ul>
<p>–</p>
<p><strong>Factors that influence news editors</strong>:</p>
<ul>
<li>interest or attract viewers/readers</li>
<li>inform the public, important issues and events, in the public interest</li>
<li>pressure from owners, promote political views</li>
</ul>
<p>–</p>
<p>Too much bad news, should report more good:<br />
accustomed to bad news, war, crime, natural disasters, human suffering, desensitises us, cynical about the world, prefer positive news, e.g. medical workers, volunteers, kindness, news to inspire us</p>
<h3 id="introduction-5"><a class="markdownIt-Anchor" href="#introduction-5"></a> Introduction</h3>
<p>It is true that editors have to make diffcult decisions about which news stories they broadcast or publish, and their choices are no doubt influenced by a variety of factors. In my opinion, we are exposed to too much bad news, and I would welcome a greater emphasis on good news.</p>
<h3 id="main-body-3"><a class="markdownIt-Anchor" href="#main-body-3"></a> Main body</h3>
<p>Editors face a range of considerations when decidin what news stories to focus on. Firstly, I imagine that they have to consider whether viewers or readers will be interested enough to choose their television channel or their newspaper over competing providers. Secondly, news editors have a responsibility to inform the public aboutimportant events and issues, and they should therefore prioritise stories that are in the public interest. Finally, editors are probably under some pressure from the owners who employ them. For example, a newspapaer owner might have particular political views that he or she wants to promote.</p>
<p>It seems to me that people do become accustomed to negative news. We are exposed on a daily basis to stories about wars, cirme, natural disasters and tragic human suffering around the world. I believe that such repeated exposure gradually desensitises people, and we become more cynical about the world and more sceptical that we can do anything to change it. I would prefer to see more poisitive news stories, such as reports of the work of medical staff afer a natural disaster, or the kindness of volunteers who help in their communities. This kind of news might inspire us all to lead better lives.</p>
<h3 id="conclusion-5"><a class="markdownIt-Anchor" href="#conclusion-5"></a> Conclusion</h3>
<p>In conclusion, it must be extremely difficlut for editors to chooose which new stories to present, but I would like to see a more positive approach to this vital public service.</p>
<h3 id="vocabulary-4"><a class="markdownIt-Anchor" href="#vocabulary-4"></a> Vocabulary</h3>
<ul>
<li>exposed to bad news</li>
<li>welcome a greater emphasis on good news</li>
<li>Editors face a range of considerations</li>
<li>prioritise stories that are in the public interest</li>
<li>under some pressure form the owners</li>
<li>promote particular political views</li>
<li>become accustomed to negative news</li>
<li>natural disasters and tragic human suffering</li>
<li>exposure gradually desensitises people</li>
<li>cynical and sceptical</li>
<li>inspire us all to lead better lives</li>
<li>a more positive approch</li>
<li>vital public service</li>
</ul>
<br>
<h2 id="extra-help-for-agree-or-disagree-questions"><a class="markdownIt-Anchor" href="#extra-help-for-agree-or-disagree-questions"></a> Extra help for “Agree or disagree?” questions</h2>
<h3 id="agree"><a class="markdownIt-Anchor" href="#agree"></a> agree</h3>
<p>The money spent by governments on space programmes would be better spent on vital public services such as school and hospitals. To what extent do you agree or disagree?</p>
<p>Plan your essay structure:</p>
<ul>
<li>Introduction: topic(government spending) + answer(public services instead of space projects)</li>
<li>explain why ‘space’ spending should be stopped</li>
<li>explain why public service spending is better</li>
<li>Conclusion: repeat answer(spend on services that benefit us all)</li>
</ul>
<h3 id="disagree"><a class="markdownIt-Anchor" href="#disagree"></a> disagree</h3>
<p>Some people believe that hobbies need to be difficult to be enjoyable. To what extent do you agree or disagree?</p>
<p>Plan your essay structure:</p>
<ul>
<li>Some hobbies are relatively easy, while others present more of a challenge. Personally, I believe that both types of hobby can be fun, and I therefore disagree with the statement that hobbies need to be difficult in order to be enjoyable.</li>
<li>explain why easy hobbies can be enjoyable</li>
<li>explain why difficult hobbies can be fun</li>
<li>Conclusion: disagree that difficult hobbies are better</li>
</ul>
<h3 id="partly-agree"><a class="markdownIt-Anchor" href="#partly-agree"></a> partly agree</h3>
<p>Many people say that we now live in ‘consumer societies’ where money and possessions are given too much importance. To what extent do you agree or disagree?</p>
<p>Plan your essay structure:</p>
<ul>
<li>It is true that many people criticise modern society because it seems to be too materialistic. I agree with this to some extent, but  I do not think it is the case that everyone is a victim of consumer culture.</li>
<li>I believe many people do focus too much on money</li>
<li>However, many others are not money oriented</li>
<li>Conclusion: partly agree</li>
</ul>
<p>–</p>
<p>In the last century, the first man to walk on the moon said it was “a giant leap for mankind”. However, some people think it has made little difference to our daily lives. To what extent do yhou agree or disagree?</p>
<p>Plan your essay structure:</p>
<ul>
<li>It is often argued that the act of sending a man to the moon has been of no benefit to normal people. While I agree that this is true in practical terms, I believe that the psychological impact of this great achievement should not be underestimated.</li>
<li>no benefit in practical terms(standard of living,health)</li>
<li>but it was an inspiring achievement</li>
<li>Conclusion: partly agree</li>
</ul>
<h2 id="peeel"><a class="markdownIt-Anchor" href="#peeel"></a> PEEEL</h2>
<ul>
<li>Introduction</li>
<li><strong>Main body</strong></li>
<li>Conclusion</li>
</ul>
<p>–</p>
<p>PEEEL:</p>
<ul>
<li>poiont</li>
<li>Explanation: chains of analysis</li>
<li>Example</li>
<li>Evaluation</li>
<li>Link: back to question</li>
</ul>
<h2 id="link"><a class="markdownIt-Anchor" href="#link"></a> Link</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1xM4m1m7GY/?p=11&amp;share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【作文】Simon正版课程合集|中英字幕，对照讲义逐节学习</a></li>
<li><a href="https://www.bilibili.com/video/BV1Q441177Kq/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【剑桥学霸】教你如何写论文 ｜ 一学就会de绝招 这个方法我从高中一直用到现在 每次都得满分的论文步骤 构造 分析方法</a></li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
  </entry>
  <entry>
    <title>IELTS:Reading</title>
    <url>/2024/03/12/IELTS-Reading/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="备考ielts-7分攻略"><a class="markdownIt-Anchor" href="#备考ielts-7分攻略"></a> 备考IELTS 7分攻略</h2>
<p><img src="https://pbs.twimg.com/media/GJKUzzwXoAAyZBd?format=jpg&amp;name=medium" alt="" /></p>
<p><img src="https://pbs.twimg.com/media/GJKUOCpXgAAFE5A?format=jpg&amp;name=medium" alt="" /></p>
<p><img src="https://pbs.twimg.com/media/GJPalXeWcAADVdj?format=jpg&amp;name=medium" alt="" /></p>
<p><img src="https://pbs.twimg.com/media/GJcA41eXgAAa1aT?format=png&amp;name=small" alt="" /></p>
<p><img src="https://pbs.twimg.com/media/GJcDW6rXcAAb9EM?format=png&amp;name=360x360" alt="" /></p>
<p>标记T1，T2，T3</p>
<p>选择题：<br />
<img src="https://pbs.twimg.com/media/GJcIb4MWsAAfdZa?format=jpg&amp;name=medium" alt="" /></p>
<p><img src="https://pbs.twimg.com/media/GJcJpcGWwAA_Hs0?format=jpg&amp;name=medium" alt="" /></p>
<p>大意：看一下上面做过的题</p>
<p><img src="https://pbs.twimg.com/media/GJcJ7sdWsAAf7Mw?format=png&amp;name=medium" alt="" /></p>
<br>
<p><img src="https://pbs.twimg.com/media/GJcKPWdXYAAa6L6?format=png&amp;name=medium" alt="" /><br />
<img src="https://pbs.twimg.com/media/GJcKzsZWcAAtkqS?format=jpg&amp;name=medium" alt="" /><br />
<img src="https://pbs.twimg.com/media/GJcK4fdXMAAilIQ?format=jpg&amp;name=medium" alt="" /><br />
<img src="https://pbs.twimg.com/media/GJcOqTMWUAASLQs?format=jpg&amp;name=medium" alt="" /><br />
<img src="https://pbs.twimg.com/media/GJcQuZFWEAAvQXb?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="雅思阅读真经"><a class="markdownIt-Anchor" href="#雅思阅读真经"></a> 雅思阅读真经</h2>
<p>需要的东西：剑7 8 9 10+笔记本+真经5</p>
<h3 id="lecture1-总纲-单词题"><a class="markdownIt-Anchor" href="#lecture1-总纲-单词题"></a> Lecture1 总纲、单词题</h3>
<p>文章特点</p>
<ul>
<li>提升速度</li>
<li>文章很长</li>
<li>插图，排版</li>
</ul>
<p>提干中：</p>
<ul>
<li>模板词：account</li>
<li>主题词：可以猜出来,不认识没关系</li>
<li>考点词：445个</li>
</ul>
<p>3类keywords</p>
<ul>
<li>眼球级词汇：数字，大写，连字符</li>
<li>朴素级词汇：dog，man，winter</li>
<li>逻辑关系词：并列，转折，因果</li>
</ul>
<p>3组以上同义词替换就选true</p>
<h2 id="精读"><a class="markdownIt-Anchor" href="#精读"></a> 精读</h2>
<p>英语阅读精读时，到底在读什么？</p>
<p>1、学科核心词+生词</p>
<ul>
<li>同一个类型文章单词重合度很高</li>
<li>学科词、生词、眼熟词</li>
<li>单词一定要复习，复习的方法就是第二天再把阅读文章拿来看，还是不认得的单词，在笔记本上打✳️，后期着重看打✳️的单词。</li>
</ul>
<p>2、同义替换+错题复盘</p>
<ul>
<li>把每道题的同义替换单词都记下；做对的题的同义替换也要记下来</li>
<li>错题复盘，分析怎么错非常重要</li>
</ul>
<p>3、长难句不回读训练</p>
<ul>
<li>三行以上的长难句非常容易出题</li>
<li>新东方 杨鹏《GRE&amp;GMART阅读难句教程》</li>
<li>看到长难句，习惯性地做一个主谓宾的切割；有意识地强制自己<strong>不做回读</strong>；每天连5个长难句，强制自己就读一遍，打死也不要回读。</li>
</ul>
<p>4、段落中心句位置与文章结构积累</p>
<ul>
<li>“首二末”，第一、第二、最后一句。70%都在“首二末”里，相信积累的力量<br />
-试试只看首二末，是否能做出中心题，是否能快速定位细节题。训练只看“首二末”，大概就能知道这段讲什么</li>
</ul>
<h2 id="标题题list-of-headings雅思阅读详细分解"><a class="markdownIt-Anchor" href="#标题题list-of-headings雅思阅读详细分解"></a> 标题题List of Headings雅思阅读详细分解</h2>
<p>正面词还是负面词，好的还是坏的，要写上下箭头</p>
<p>首二末是指首句和末句，如果首句转折就往下看第二句</p>
<ol>
<li>先做细节题，再做LOH</li>
<li>干掉例子</li>
<li>扣题干(突兀词：人地大写，方向词，非高频词),做预测(同义替换)</li>
<li>读段落，首二末70%，转折词</li>
<li>同义替换(方向性，逻辑cause，词汇)</li>
</ol>
<h2 id="true-flase-not-given"><a class="markdownIt-Anchor" href="#true-flase-not-given"></a> True, Flase, Not Given</h2>
<p>Ture:维度一致+方向一致</p>
<p>False:维度一致+方向相反</p>
<p>Not Given：维度没提；维度一致+方向没提</p>
<hr />
<p><strong>Passage</strong>：Plato believed humour to be a sign od above-average <code>intelligence</code>.</p>
<p><strong>Question</strong>：Plato express the idea that humour is simply a delighted <code>feeling</code> of superiority over others.</p>
<p>上面两个题不在同一个维度，也就是说，文章里说的是intelligence，而题目里说的是feeling，所以这题选Not Given</p>
<br>
<p><strong>Passage</strong>: <code>Methods</code> for predicting the Earth’s population have recerntly <code>change</code>.</p>
<p><strong>Question</strong>：Applying the most conservative estimates to current demographic trends,the human <code>population</code> will <code>increase</code> by about three billion people by then.</p>
<p>上面的两个题也是不在同一个维度，也就是说，文章里说的是Methods改变了， 然而问题里说的是population改变了，选Not Given</p>
<hr />
<h2 id="选择题"><a class="markdownIt-Anchor" href="#选择题"></a> 选择题</h2>
<p>错误的选项有哪几种情况：</p>
<ul>
<li>反了</li>
<li>真没有：一点也没提</li>
<li>真没有比较：不相干的东西进行比较</li>
<li>真没有极端： all，never</li>
<li>张冠李戴</li>
<li>擦边球：词和原文中的词有很多重合，但是逻辑是不同的</li>
</ul>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1gy4y1q7LG/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【雅思阅读方法全解|手把手教你做雅思阅读|9分阅读】</a></li>
<li><a href="https://www.bilibili.com/video/BV1Vb411V7Zt/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">真题演示 | 标题题List of Headings雅思阅读详细分解 | 读题时怎么做预测 | 划题干方法精解 | 模仿词汇量较低同学视角做阅读</a></li>
<li><a href="https://www.bilibili.com/video/BV1Ui4y1F73Z/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">雅思阅读判断题｜「难做错」的TFNG满分思路分享，没有技巧，全是真诚</a></li>
<li><a href="https://www.bilibili.com/video/BV1a4411c7Rx/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">识别错误选项，比垃圾分类容易多了 | 雅思阅读 | 选择题 | 剑桥真题 | 真题演示</a></li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>IELTS</tag>
        <tag>Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>IELTS:大作文知识点总结</title>
    <url>/2024/11/04/IELTS-%E5%A4%A7%E4%BD%9C%E6%96%87%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E9%9B%85%E6%80%9D%E5%A4%A7%E4%BD%9C%E6%96%87%E5%86%99%E4%BD%9C%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93">雅思大作文写作技巧总结</a>
<ul>
<li><a href="#1%E5%88%86%E7%B1%BB">1.分类</a></li>
<li><a href="#2-to-what-extent-do-you-agree-or-disagree">2. To what extent do you agree or disagree?</a>
<ul>
<li><a href="#21-travel">2.1 travel</a></li>
<li><a href="#22-art">2.2 art</a></li>
<li><a href="#23-%E8%BA%AB%E4%BD%93%E5%81%A5%E5%BA%B7">2.3 身体健康</a></li>
<li><a href="#24-%E6%96%87%E5%8C%96">2.4 文化</a></li>
<li><a href="#25-c10-t2-p2">2.5 C10-T2-P2</a></li>
</ul>
</li>
<li><a href="#3-do-you-think-the-advantage-of-this-develoment-outweigh-the-disadvantages">3. Do you think the advantage of this develoment outweigh the disadvantages?</a>
<ul>
<li><a href="#31-temporary-jobs">3.1 temporary jobs</a></li>
<li><a href="#32-criminal-trials">3.2 Criminal trials</a></li>
</ul>
</li>
<li><a href="#4discuss-both-views-and-give-your-opinion">4.Discuss both views and give your opinion</a>
<ul>
<li><a href="#41-environmental-protection">4.1 environmental protection</a></li>
</ul>
</li>
<li><a href="#5-do-you-think-this-is-a-positive-or-a-negative-development">5. Do you think this is a positive or a negative development?</a>
<ul>
<li><a href="#51-city-countryside">5.1 city-countryside</a></li>
</ul>
</li>
<li><a href="#6what-problems-does-it-cause-how-can-we-solve-these-problems">6.What problems does it cause? How can we solve these problems?</a>
<ul>
<li><a href="#61-healthy-lifestyle">6.1 healthy lifestyle</a></li>
</ul>
</li>
<li><a href="#volcabulary">Volcabulary</a>
<ul>
<li><a href="#%E5%A5%BD%E5%A4%84">好处</a></li>
<li><a href="#%E5%9D%8F%E5%A4%84%E5%8F%A5%E5%9E%8B">坏处句型</a></li>
<li><a href="#%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB">因果关系</a></li>
<li><a href="#%E8%A7%A3%E9%87%8A%E9%80%BB%E8%BE%91">解释逻辑</a></li>
</ul>
</li>
<li><a href="#%E5%8F%8D%E9%A9%B3%E6%AE%B5">反驳段</a></li>
<li><a href="#%E8%8C%83%E6%96%87%E5%88%86%E6%9E%90">范文分析</a>
<ul>
<li><a href="#%E5%A4%96%E5%9B%BD%E6%B8%B8%E5%AE%A2%E6%98%AF%E5%90%A6%E5%BA%94%E8%AF%A5%E6%AF%94%E6%9C%AC%E5%9C%B0%E6%B8%B8%E5%AE%A2%E8%8A%B1%E6%9B%B4%E5%A4%9A%E9%92%B1">外国游客是否应该比本地游客花更多钱</a></li>
<li><a href="#%E9%80%89%E6%8B%A9%E5%B7%A5%E4%BD%9C%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E8%80%83%E8%99%91%E5%9B%A0%E7%B4%A0%E6%98%AF%E8%96%AA%E6%B0%B4%E4%B9%88">选择工作最重要的考虑因素是薪水么</a></li>
<li><a href="#%E9%9D%92%E5%B0%91%E5%B9%B4%E6%98%AF%E5%90%A6%E5%BA%94%E8%AF%A5%E6%97%A0%E5%81%BF%E4%B8%BA%E7%A4%BE%E5%8C%BA%E5%B7%A5%E4%BD%9C">青少年是否应该无偿为社区工作</a></li>
<li><a href="#%E6%88%91%E4%BB%AC%E5%BA%94%E8%AF%A5%E5%8F%AA%E5%85%B3%E5%BF%83%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9B%BD%E5%AE%B6%E4%B9%88">我们应该只关心自己的国家么</a></li>
<li><a href="#%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD%E5%BA%94%E8%AF%A5%E6%9C%89%E6%8C%91%E6%88%98%E6%80%A7%E6%89%8D%E6%9C%89%E8%B6%A3">兴趣爱好应该有挑战性才有趣</a></li>
<li><a href="#%E5%A4%A7%E5%AD%A6%E6%AF%8F%E4%B8%AA%E7%A7%91%E7%9B%AE%E7%94%B7%E5%A5%B3%E7%94%9F%E6%95%B0%E9%87%8F%E5%BA%94%E8%AF%A5%E7%9B%B8%E7%AD%89">大学每个科目男女生数量应该相等</a></li>
<li><a href="#%E4%BF%9D%E6%8A%A4%E9%87%8E%E7%94%9F%E5%8A%A8%E7%89%A9%E6%98%AF%E5%90%A6%E6%B5%AA%E8%B4%B9%E8%B5%84%E6%BA%90">保护野生动物是否浪费资源</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<br>
<h2 id="雅思大作文写作技巧总结"><a class="markdownIt-Anchor" href="#雅思大作文写作技巧总结"></a> 雅思大作文写作技巧总结</h2>
<h3 id="1分类"><a class="markdownIt-Anchor" href="#1分类"></a> 1.分类</h3>
<p>议论文：</p>
<ul>
<li>To what extent do you agree or disagree?</li>
<li>Discuss both views and give your opinion.</li>
<li>Do you think the advantage of this develoment outweigh the disadvantages?</li>
<li>Do you think this is a positive or a negative development?</li>
</ul>
<p>–</p>
<p>报告文：</p>
<ul>
<li>What is the <strong>reason</strong>, and what can be done to <strong>encourage</strong> a positive attitude to learning?</li>
<li>What are the <strong>reasons</strong>? What are the <strong>effects</strong> on society and the family?</li>
<li>What problems does it <strong>cause</strong>? How can we <strong>solve</strong> these problems?</li>
</ul>
<h3 id="2-to-what-extent-do-you-agree-or-disagree"><a class="markdownIt-Anchor" href="#2-to-what-extent-do-you-agree-or-disagree"></a> 2. To what extent do you agree or disagree?</h3>
<p>结构：</p>
<ul>
<li>Some suggest that…</li>
<li>To begin with, …65-85-100(如果不写反驳段，需要扩充到100字)</li>
<li>In addition, …65-85-100</li>
<li>*反驳段…65-85</li>
<li>In conclusion, I firmly believe that …This not only 复述分论点1 but also复述分论点2</li>
</ul>
<p>–</p>
<p>中间段：</p>
<ul>
<li>分论点</li>
<li>前提背景</li>
<li>解释</li>
<li>小推导</li>
</ul>
<h4 id="21-travel"><a class="markdownIt-Anchor" href="#21-travel"></a> 2.1 travel</h4>
<p>Parents should encourage their children to spend less time on studying and more time on physical activities. To what extent do you agree or disagree?</p>
<p><img src="https://pic.imgdb.cn/item/672f0fb3d29ded1a8c3d330a.png" alt="" /></p>
<p>开始段：Some suggest that mothers and fathers ought to motivate motive their offspring to allocate more time to physical pursuits instead of academic learning. <s>spend less time on studying than on physical activities.</s> However, I strongly disagree with this perspective for several reasons.</p>
<p>To begin with, traveling can offer young people beneficial chances to relax and unwind <code>A-B 好处</code>.// In today’s competitive academic landscape, many children experience overwhelming pressure from studies, potentially contributing to mental health problems such as anxiety and depression <code>背景</code>.// Through travel, young generations have the opportunity to engage in a wide range of activities such as exploring prominent landmarks, sampling local culinary delights, and capturing photographs of memorable moments <code>A1-A2-A3 例子</code>.// These activities can allow them to enjoy the thrill of exploration and temporarily detach from their academic burdens, which can facilitate relaxation <code>A3-B</code>.// This stress relief not only enables them to re-engage with their subsequent studies with renewed motivation but also enhances their psychological well-being <code>B-小推导</code>.</p>
<p>分段：</p>
<ul>
<li><strong>A-B 好处</strong>：旅行让年轻人放松和舒缓压力。</li>
<li><strong>背景</strong>：当前激烈的学术环境可能导致孩子们承受巨大学业压力，甚至影响心理健康。</li>
<li><strong>A1-A2-A3 例子</strong>：旅行活动（探访地标、品尝美食、拍照）有助于探索、暂时远离学业压力。</li>
<li><strong>A3-B</strong>：探索的活动有助于放松。</li>
<li><strong>B-小推导</strong>：这种压力缓解带来动力和心理健康的提升。</li>
</ul>
<p>–</p>
<p>旅游的好处：</p>
<ul>
<li>旅游能拓展孩子们的视野</li>
<li>旅游能使孩子们交到更多的朋友</li>
<li>旅游能提升孩子们解决问题的能力</li>
<li>旅游能使人们放松</li>
</ul>
<p>–</p>
<p>例子：</p>
<ul>
<li>分论点1：旅游A能使人们放松B</li>
<li>前提背景：In today’s competitive academic landscape, 很多孩子面临着巨大的压力，导致一些心理健康问题比如说焦虑。</li>
<li>解释：当人们旅游的时候，他们有机会尝试各种各样的娱乐活动，比如看风景，享受美食，参与当地节日，拍美照等等，这能让他们享受活动带来的快乐以及从学习压力中解脱出来，这能他们放松。</li>
<li>小推导：这种放松不仅能让他们以更积极的心态对待接下来的学习还能提高他们的心理健康。</li>
</ul>
<p>When/By/Through A-A1-A2-A3-A4-A5-B-B1</p>
<p>–</p>
<p>Topic volcabulary：</p>
<ol>
<li><strong>放松</strong>: relax, unwind</li>
<li><strong>减少压力</strong>: reduce stress, alleviate stress, relieve stress</li>
<li><strong>缓解心理压力</strong>: alleviate mental strain</li>
<li><strong>压力缓解</strong>: stress alleviation, stress relief</li>
<li><strong>作为一个缓解压力的宝贵途径</strong>: serve as a valuable outlet for stress alleviation</li>
<li><strong>充当一种缓解压力的方法</strong>: act as a means of stress relief</li>
<li><strong>学术压力</strong>: academic stress</li>
<li><strong>学业负担</strong>: academic burdens</li>
<li><strong>在当今竞争激烈的学术环境中</strong>: in today’s competitive academic landscape</li>
<li><strong>在当今高度竞争的环境中</strong>: in today’s highly competitive environment</li>
<li><strong>面临重大/强烈/巨大的压力</strong>: face significant/intense/enormous stress</li>
<li><strong>经历巨大的学习压力</strong>: experience overwhelming pressure from studies</li>
<li><strong>为年轻人提供有益的放松机会</strong>: offer young people beneficial chances to relax and unwind</li>
<li><strong>因学业压力而感到巨大压力</strong>: experience overwhelming pressure from studies</li>
<li><strong>可能导致焦虑和抑郁等心理健康问题</strong>: potentially contributing to mental health problems such as anxiety and depression</li>
<li><strong>参与广泛的活动</strong>: engage in a wide range of activities</li>
</ol>
<ul>
<li>16.1 <strong>探索著名地标</strong>: exploring prominent landmarks</li>
<li>16.2 <strong>品尝当地美食</strong>: sampling local culinary delights</li>
<li>16.3 <strong>拍摄难忘时刻的照片</strong>: capturing photographs of memorable moments</li>
<li>16.4 <strong>享受探索的刺激</strong>: enjoy the thrill of exploration</li>
</ul>
<ol start="17">
<li><strong>暂时摆脱学业负担</strong>: temporarily detach from their academic burdens</li>
<li><strong>促进放松</strong>: facilitate relaxation</li>
<li><strong>使他们能够以新的动力投入后续的学习</strong>: enables them to re-engage with their subsequent studies with renewed motivation</li>
<li><strong>提升他们的心理健康</strong>: enhances their psychological well-being</li>
<li><strong>身体健康</strong>: physical well-being</li>
<li><strong>激励/启发</strong>: encourage, inspire, motivate, stimulate</li>
<li><strong>花费/分配/投入时间和精力</strong>: spend…doing, allocate…to do, dedicate…to doing, devote…to sth/doing sth</li>
<li><strong>身体活动</strong>: physical activities, physical pursuits</li>
<li><strong>户外活动</strong>: outdoor pursuits</li>
<li><strong>学术学习</strong>: studying, academic learning</li>
<li><strong>养育</strong>: bring up, raise</li>
<li><strong>孩子/后代</strong>: children, offspring</li>
</ol>
<h4 id="22-art"><a class="markdownIt-Anchor" href="#22-art"></a> 2.2 art</h4>
<p>Some people think that art should be a compulsory subject at high school. To what extent do you agree or disagree?</p>
<p>–</p>
<p>Some suggest that students ought to learn art as a compulsory subject at high school. I strongly agree with this perspective for several reasons.</p>
<p>To begin with, art courses can offer young people beneficial chances to relax and unwind. In today’s competitive academic landscape, many children experience overwhelming pressure from studies, potentially contributing to mental health problems such as anxiety and depression. Through attending art classes, young generations have the opportunity to engage in a wide range of activities such as  painting, sketching, and drama. These activities can allow them to enjoy the thrill of creation and temporarily detach from their academic burdens, which can facilitate relaxation. This stress relief not only enables them to re-engage with their subsequent studies with renewed motivation but also enhances their psychological well-being.</p>
<p>In addition, artistic education plays a pivotal role in broadening students’ horizons. Traditional education prioritizes examinations and academic performance, often sidelining creative subjects, ultimately limiting students’ opportunities to explore diverse cultural perspectives. Learning art provides young individuals with valuable opportunities to appreciate various forms of art, such as sculptures infused with traditional culture, video works with historical themes, and oil paintings rich in religious significance, which can expand their artistic perspectives. This not merely helps them become well-rounded individuals but also enables them to think from different angles.</p>
<p>In conclusion, I firmly believe that art should be made mandatory in high schools. This not only empowers students to alleviate mental strain but also increases their knowledge and offers a deeper understanding of various art forms.</p>
<p>–</p>
<p>Topic Volcabulary:</p>
<ol>
<li><strong>强制性</strong>: compulsory, mandatory, obligatory</li>
<li><strong>科目</strong>: subject, discipline, domain</li>
<li><strong>将艺术设为必修课</strong>: make art compulsory</li>
<li><strong>将艺术纳入课程</strong>: incorporate art into the curriculum</li>
<li><strong>被纳入学校课程</strong>: be incorporated into the school curriculum</li>
<li><strong>优先考虑考试和学业成绩</strong>: prioritizes examinations and academic performance</li>
<li><strong>经常忽视创造性学科</strong>: often sidelining creative subjects</li>
<li><strong>最终限制学生的机会去</strong>: ultimately limiting students’ opportunities to</li>
<li><strong>探索多元文化视角</strong>: explore diverse cultural perspectives</li>
<li><strong>融合传统文化的雕塑</strong>: sculptures infused with traditional culture</li>
<li><strong>具有历史主题的视频作品</strong>: video works with historical themes</li>
<li><strong>富有宗教意义的油画</strong>: oil paintings rich in religious significance</li>
<li><strong>拓展他们的艺术视野</strong>: expand their artistic perspectives</li>
<li><strong>帮助他们成为全面发展的个体</strong>: helps them become well-rounded individuals</li>
<li><strong>使他们能够从不同角度思考</strong>: enables them to think from different angles</li>
</ol>
<h4 id="23-身体健康"><a class="markdownIt-Anchor" href="#23-身体健康"></a> 2.3 身体健康</h4>
<p>Parents should encourage their children to spend less time on studying and more time on physical activities. To what extent do you agree or disagree? 1 放松 2身体健康</p>
<p>–</p>
<p>Some suggest that parents ought to motivate their offspring to devote more time to physical activities instead of academic learning. I strongly agree with this perspective for several reasons.</p>
<p>To begin with, physical pursuits can offer a beneficial chance to relax and unwind. In today’s competitive academic landscape, many children experience overwhelming pressure from studies, potentially contributing to mental health problems such as anxiety and depression. Through participating in physical activities, young generations have the opportunity to engage in a wide range of outdoor pursuits such as playing table tennis, practicing yoga, and going to the gym. These activities allow them to enjoy the thrill of physical exertion and temporarily detach from their academic burdens, which can facilitate relaxation. This stress relief not only enables them to re-engage with their subsequent studies with renewed motivation but also enhances their psychological well-being.</p>
<p>In addition, taking part in physical pursuits plays a crucial role in maintaining overall health. Traditional education prioritizes academic performance, often sidelining physical education, ultimately limiting adolescents’ physical fitness. Attending physical activities provides young individuals with valuable opportunities to improve physical fitness, such as scaling scenic mountains, trekking with friends, and cycling across diverse cities, which can boost their physical well-being.</p>
<p>This not only helps them strengthen their immunity but also equips them with greater energy to deal with academic and life challenges.</p>
<p>In conclusion, I firmly believe that parents should inspire their children to allocate more time to physical activities. This not only empowers young people to alleviate mental strain but also sustains overall health.</p>
<p>–<br />
Teacher’s version:</p>
<p>In addition, taking part in physical pursuits plays a crucial role in maintaining overall health. In contemporary society, with heavy workloads, most children dedicate considerable time and effort to their studies, leading to sedentary lifestyles, which increases the risk of health issues, such as obesity. Participating in physical activities like running, swimming, and cycling can not only strengthen cardiovascular health and build muscle strength but also keep children active, reducing the risk associated with a stationary lifestyle and contributing to effective weight management. This active engagement promotes overall physical well-being, enhancing focus and learning productivity.</p>
<p>–</p>
<p>Topic Vocabulary：</p>
<ol>
<li><strong>参与其中</strong>: get involved in, take part in</li>
<li><strong>享受体力消耗的刺激</strong>: enjoy the thrill of physical exertion</li>
<li><strong>保持健康</strong>: maintaining health</li>
<li><strong>维持整体健康</strong>: sustaining overall health</li>
<li><strong>身体健康/身体素质</strong>: physical fitness</li>
<li><strong>提供某人某物</strong>: provide sb with sth, provide sth for sb</li>
<li><strong>提供某人某物/赋予</strong>: offer sb sth, afford sb sth</li>
<li><strong>装备某人以便做某事</strong>: equip sb with sth to do sth
<ul>
<li>8.1 <strong>旅行赋予个人更广阔的视角，以欣赏不同文化</strong>: traveling equips individuals with a broader perspective to appreciate different cultures</li>
</ul>
</li>
<li><strong>增强免疫力</strong>: strengthen their immunity</li>
<li><strong>提升身体健康</strong>: boost their physical well-being</li>
<li><strong>赋予他们更大的能量去应对学术和生活挑战</strong>: equips them with greater energy to deal with academic and life challenges</li>
<li><strong>攀登风景优美的山峰</strong>: scaling scenic mountains</li>
<li><strong>与朋友一起徒步旅行</strong>: trekking with friends</li>
<li><strong>骑行穿越多样化的城市</strong>: cycling across diverse cities</li>
<li><strong>保持健康体重并增加肌肉</strong>: maintaining a healthy weight and build muscle</li>
<li><strong>过着主要久坐的生活方式</strong>: lead predominantly sedentary lifestyles</li>
<li><strong>繁重的工作负担</strong>: heavy workloads</li>
<li><strong>投入大量时间和精力于学习</strong>: dedicate considerable time and effort to their studies</li>
<li><strong>导致久坐生活方式</strong>: leading to sedentary lifestyles</li>
<li><strong>增加患健康问题的风险，如肥胖和糖尿病</strong>: increases the risk of health issues, such as obesity and diabetes</li>
<li><strong>增强心血管健康</strong>: strengthen cardiovascular health</li>
<li><strong>增强肌肉力量</strong>: build muscle strength</li>
<li><strong>保持儿童活力</strong>: keep children active</li>
<li><strong>减少与久坐生活方式相关的风险</strong>: reducing the risk associated with a stationary lifestyle</li>
<li><strong>有助于有效的体重管理</strong>: contributing to effective weight management</li>
<li><strong>这种积极参与</strong>: this active engagement</li>
<li><strong>增强专注力和学习效率</strong>: enhancing focus and learning productivity</li>
</ol>
<h4 id="24-文化"><a class="markdownIt-Anchor" href="#24-文化"></a> 2.4 文化</h4>
<p>It is not necessary to travel to other places to learn about the culture, since one can learn as much as from books, films, and the Internet. To what extent do you agree or disagree?</p>
<p>–</p>
<p>Some suggest that embarking on a journey to other locations for cultural learning is superfluous/is no longer needed, as individuals can acquire a wealth of cultural knowledge from secondary sources, such as books, films, and the Internet. However, I strongly disagree with this perspective for several reasons.</p>
<p>改写：</p>
<ul>
<li>travel to -&gt; embarking on a journey to</li>
<li>places -&gt; locations</li>
<li>learn about the culture -&gt; for cultural learning</li>
<li>it is no necessary to … -&gt; … is superfluous/no longer needed</li>
<li>book, films, and the Internet -&gt; secondary sourses</li>
<li>learn about -&gt; acquire a wealth of cultural knowledge from</li>
</ul>
<p>–</p>
<p>To begin with, visiting famous places allows people to gain a comprehensive understanding of culture. In contemporary society, many writers, directors, and reporters tend to display attractive content instead of comprehensive cultural descriptions, providing only a superficial understanding. Through travel, people have the oppotunity to immerse themselves in prominent architecture, artworks with historical themes, and sculptures infused with traditional culture. These immersive experience enable visitiors to delve deeper into diverse cultural perspectives, which not only enriches/broadens their understanding but also strengthens their critical thinking skills when evaluating others’ depictions of culture.</p>
<p>–</p>
<p>In addition, travel<s>l</s>ing plays a crucial role in inspiring people to explore culture. Nowadays, many people, especially adolescent, spend considerable time on recreative book and online recourses, leading to little interest in culture. Visiting <s>to</s> culturally rich places <s>rich in culture</s>, <s>such as celebrating</s> participating in local festival and appreciating traditional arts, not only <s>provides people with</s> offer immersive opportunities to <s>feel</s> experience culture but also cultivate a <strong>genuine</strong> interest in it <s>culture</s>.</p>
<p>Admittedly, some may argue that books and online recourses are <s>greater</s> a better way to learn about culture. They hold the belief that <s>it is convenient to understand culture by</s> books, films, and the Internet offer a convenient way to understand culture, <s>suggesting that prioritizing these methods can</s> saving time and money. However, this argument is flawed as it fails to recognize the crucial role of <s>full</s>  a comprehensive understanding of culture and a deep <s>enthusiasm to</s> appreciate for it, <strong>both of</strong> which are cultivated through traveling <s>to places and are incredibly important in learning about culture</s>. Numerous studies have shown that those who visit culturally rich places <s>rich in culture</s> tend to <s>be more</s> develop a stronger interest<s>ed</s> in culture and <s>display</s> a broader cultural perspective<s>s</s> than those without such exposure.</p>
<p>In conclusion, I firmly believe that people should visit <s>to</s> other places to <strong>truly</strong> understand culture. This not only <s>equips</s> broadens individuals’ <s>with wide horizons</s> perspectives but also cultivates their interest in c<strong>ultural diversity</strong>.</p>
<p>–<br />
旅游学习文化：</p>
<ol>
<li>必要的: necessary-essential</li>
<li>不必要的: not necessary-not essential-unnecessary-obsolete-superfluous</li>
<li>不需要做某事: it is not necessary to-…is no longer needed-there is no need to</li>
<li>旅行到: travel to-visit-pay a visit to-embark on a journey to</li>
<li>其他地方: other places-locations-destinations-areas-regions</li>
<li>了解文化: to learn about the culture-understand-comprehend-grasp-explore-delve deeper into-experience</li>
<li>为了文化学习/理解/掌握/探索/信息/知识/沉浸: for cultural learning/understanding/comprehension/grasp/exploration/information/knowledge/immersion</li>
<li>因为: since-as-because</li>
<li>某人/人们: one-individuals</li>
<li>书籍、电影和互联网: books, films, and the internet-secondary sources</li>
<li>获得: acquire-gain-attain</li>
<li>丰富的知识/信息/经验: a wealth of knowledge/information/experience</li>
<li>丰富的选择/机会: a wealth of options/opportunities</li>
<li>第一手经验: firsthand experience</li>
<li>第二手经验: secondhand experience</li>
<li>第一手旅行: firsthand travel</li>
<li>直接旅行: direct travel</li>
<li>亲身体验: experience sth firsthand/in person</li>
</ol>
<p>–<br />
旅游的好处：</p>
<ol>
<li>提供沉浸式体验: provide an immersive experience</li>
<li>间接的（背景）: indirect (background)</li>
<li>仅提供浅显的理解: provide only a superficial understanding</li>
<li>往往缺乏真实互动和感官参与: often lack authentic interaction and sensory engagement</li>
<li>使深入理解文化精髓变得困难: make it difficult to gain a more thorough understanding of a culture’s essence</li>
<li>直接与……互动: interact directly with-communicate directly with-engage directly with (local residents/local customs/ways of life)</li>
<li>观察他们的日常生活: observe their daily lives</li>
<li>亲身体验各种文化面貌，例如传统、美食、语言、建筑和节日: experience various cultural facets firsthand, such as traditions, cuisine, language, architecture, and festivals</li>
<li>增强对当地文化的理解: enhance/improve their understanding of local culture</li>
<li>提供/获得/促进更深入/完整/全面/真实/准确/细致/深刻的当地文化理解: offer/gain/foster a more thorough/complete/comprehensive/authentic/accurate/nuanced/in-depth/profound understanding of local culture</li>
<li>帮助打破刻板印象: help break stereotypes</li>
<li>培养对不同文化的同理心: foster empathy towards diverse cultures</li>
<li>使旅行者具备以更包容和尊重的方式与不同背景的人互动的能力: equip travelers with the ability to interact with people from various backgrounds in a more inclusive and respectful manner</li>
</ol>
<p>–<br />
书本的坏处</p>
<ol>
<li>具有误导性: misleading</li>
<li>往往具有固有的偏见和局限: often carry inherent biases and limitations</li>
<li>经常受到编辑、制作人或创作者的主观观点影响: are frequently shaped by the subjective perspectives of editors, producers, or creators</li>
<li>导致读者或观众形成片面/不准确的文化理解: lead readers or viewers to form a one-sided/inaccurate understanding of a culture</li>
<li>甚至可能加深误解: may even deepen misunderstandings</li>
<li>阻碍对文化的深入理解: hinder a thorough understanding of a culture</li>
<li>沉浸在文化环境中: immerse themselves in the cultural environment</li>
<li>使旅行者认识到许多先前的假设是毫无根据/错误的: enable travelers to recognize that many of their prior assumptions are unfounded/erroneous</li>
<li>只有通过直接旅行，人们才能摆脱这些误解，并获得对当地文化的更全面理解: only through direct travel can people escape these misconceptions and gain a more comprehensive understanding of local culture</li>
<li>文化的描绘: portrayals of culture</li>
<li>文化的描述: depictions of culture</li>
<li>留下深刻印象: leave a lasting impression</li>
<li>对文化形成持久记忆: develop a lasting memory of the culture</li>
<li>使体验更加生动难忘: make the experience more engaging and memorable</li>
</ol>
<p>–</p>
<ol>
<li>文化丰富的地方: culturally rich places</li>
<li>参与当地节庆: participating in local festivals</li>
<li>欣赏传统艺术: appreciating traditional arts</li>
<li>提供沉浸式的文化体验机会: offer immersive opportunities to experience culture</li>
<li>培养对文化的真正兴趣: cultivate a genuine interest in it</li>
<li>提供理解文化的便捷途径: offer a convenient way to understand culture</li>
<li>对文化的全面理解与深刻欣赏: a comprehensive understanding of culture and a deep appreciation for it</li>
<li>发展对文化的更强兴趣和更广的文化视角: develop a stronger interest in culture and a broader cultural perspective</li>
<li>培养对文化多样性的兴趣: cultivates their interest in cultural diversity</li>
</ol>
<h4 id="25-c10-t2-p2"><a class="markdownIt-Anchor" href="#25-c10-t2-p2"></a> 2.5 C10-T2-P2</h4>
<ol>
<li>一般智力测试: a general intelligence test</li>
<li>他们的家庭教育资源: their home educational provision</li>
<li>他们的教育支持质量: the quality of their educational backup</li>
<li>与父母的语言交流: verbal interactions with parents</li>
<li>基于年龄标准的当前成就: current achievement based on age-norms</li>
<li>运用他们的知识和技能: manipulate their knowledge and know-how</li>
<li>在测试范围内: within the terms of the test</li>
<li>在任何领域达到极高水平: reach an exceptionally high standard in any area</li>
<li>有能力的孩子: able children</li>
<li>可以利用的材料: material to work with</li>
<li>专注且具有挑战性的教学: focused challenging tuition</li>
<li>鼓励追随梦想: the encouragement to follow their dream</li>
<li>在方式上的质的不同: qualitative difference in the way</li>
<li>外部调节: external regulation</li>
<li>补偿缺乏内部调节(自律): compensates for lack of internal regulation</li>
<li>好奇心: feelings of curiosity</li>
<li>自我调节(自律): self-regulatory</li>
<li>将这些策略应用于应对陌生任务: transfer these strategies to deal with unfamiliar tasks</li>
<li>在特定领域展示才能: demonstrating talent in particular areas</li>
<li>情况并非完全如此: this is not entirely the case</li>
<li>考虑到个体思维的多种方式: take account of the many ways individuals think</li>
<li>减少天才学生的学习自主性: diminish their gifted pupils’ learning autonomy</li>
<li>产生极高的考试成绩: produce extremely high examination results</li>
<li>高能力的: highly competent</li>
<li>来自贫困地区的聪明孩子: bright children from deprived areas</li>
<li>出色的表现: outstanding performance</li>
<li>对特定领域了解甚多: know a great deal about a specific domain</li>
<li>达到更高水平: achieve at a higher level</li>
<li>在科学进步中的强大力量: a strong force in scientific advance</li>
<li>受控制/驾驭之中: in harness</li>
<li>强烈的环境控制欲望: a strong desire to control their environment</li>
<li>天才儿童的家庭背景: domestic background on the gifted child</li>
<li>社会地位低下儿童: socially-disadvantaged children</li>
<li>实现他们的目标: reach their goals</li>
<li>将他们的情感引导至学习中: channel their feelings to assist their learning</li>
<li>来自亲密亲属的适当支持: appropriate support from close relatives</li>
<li>在他们的学科上学到了大量知识: learnt a considerable amount about their subject</li>
<li>取得一系列令人印象深刻的成绩: produce sets of impressive grades</li>
</ol>
<h3 id="3-do-you-think-the-advantage-of-this-develoment-outweigh-the-disadvantages"><a class="markdownIt-Anchor" href="#3-do-you-think-the-advantage-of-this-develoment-outweigh-the-disadvantages"></a> 3. Do you think the advantage of this develoment outweigh the disadvantages?</h3>
<h4 id="31-temporary-jobs"><a class="markdownIt-Anchor" href="#31-temporary-jobs"></a> 3.1 temporary jobs</h4>
<p>Some people prefer to have temporary jobs, which means they only work a few months in a year and use the rest of the time to do what they want.  Do the advantages outweigh the disadvantages?</p>
<p>–<br />
outline:</p>
<p>假设优点大于缺点：你也可以缺点大于优点</p>
<ol>
<li>改写题目 However, I believe that positive effects of 话题 outbalance the negative ones.</li>
<li>On the one hand, there are indeed some drawbacks to话题. Firstly, … Secondly, …  ( 110字)</li>
<li>On the other hand, I believe that the merits of话题outweigh the demerits. First of all, … Additionally, …( 110字)</li>
<li>In conclusion, even though 缺点是什么, the potential benefits, such as总结成名词and总结成名词,are more significant than the possible dangers.  // 或者In conclusion, even though …has its drawbacks , the potential benefits are more significant than the possible dangers. 总结优点1+优点2</li>
</ol>
<p>–</p>
<ol>
<li>优点：benefits - positive effects - advantages - merits - potential benefits</li>
<li>缺点：drawbacks - negative effects - disadvantages - demerits - possible dangers</li>
<li>超过：outbalance - outweigh - be more significant than</li>
</ol>
<p>–</p>
<p>Some opt to engage in seasonal work, meaning that they /allowing them to only work several months in a year and devote the remainder of their time to pursuing their personal interests. However, I believe that the negative effects of working temporarily outbalance the positive ones.</p>
<p>On the one hand, there are indeed some advantages to temporary jobs. Firstly, seasonal employment enhances one’s mental well-being. This work pattern provides individuals with valuable opportunities to do the things that they are enthusiastic about, such as exploring prominent landmarks, sampling local culinary delights, and capturing photographs of memorable moments. These pursuits can distract their attention and allow them to temporarily detach from their work-related stress, which facilitates relaxation, ultimately promoting their psychological health. Secondly, short-term work contributes significantly to one’s physical health. In today’s competitive environment, many office workers lead predominantly sedentary lifestyles, increasing the risk of health problems, such as obesity. Working temporarily offers flexibility, enabling them to have more time to participate in physical activities, such as scaling scenic mountains, cycling, and trekking with close friends. This not only strengthens their cardiovascular health but also keeps them active, reducing the risk of overweight and contributing to effective weight management, eventually improving their overall well-being.</p>
<p>On the other hand, I believe that the demerits of temporary jobs outweigh the merits. To begin with, temporary positions can impede career development. Temporary employees often dedicate limited time to specific tasks, making it challenging for them to become experts in a specialized field. Besides, employers are often unwilling to invest significant resources in short-term employees, so they typically Lack access to systematic training and skill development opportunities, leading to limited skill accumulation, ultimately hindering them from climbing the corporate ladder. In addition, working temporarily impedes future employment opportunities. Employers tend to favor candidates with long-term employment experience, as these candidates are perceived as reliable and self-disciplined. This preference discourages short-term workers from securing high-paying jobs./This preference deprives short-term workers of the chance to secure high-paying jobs.</p>
<p>In conclusion, even though temporary jobs are flexible, the possible dangers, such as limiting their career development and impairing future employment opportunities, are more significant than the potential benefit.</p>
<p>–</p>
<p>Topic volcabulary:</p>
<ol>
<li>更喜欢：prefer to / choose to / opt to / select to</li>
<li>做临时工作：have temporary jobs</li>
<li>从事临时工作：engage in temporary work</li>
<li>暂时工作：work temporarily</li>
<li>工作：jobs / work / employment / positions / careers / occupations</li>
<li>临时的/短期的/季节性的：temporary / short-term / seasonal</li>
<li>长期的/永久的工作：long-term / permanent work</li>
<li>这种方法/做法/这么做：this approach / this practice / doing so</li>
<li>这种工作模式：this work pattern</li>
<li>在就业市场：in the job market / in the employment market</li>
<li>工作机会/就业机会：job opportunities / employment opportunities</li>
<li>工作经验：employment experience</li>
<li>这意味着：which means / meaning that</li>
<li>表示/意味着：mean / indicate / signify</li>
<li>几个月：a few months</li>
<li>剩余的时间：the rest of the time / the remainder of their time</li>
<li>做他们想做的事：do what they want / do what they like</li>
<li>做他们感兴趣的事：do what they are interested in</li>
<li>做他们热衷的事：do what they are enthusiastic about</li>
<li>做他们喜欢的事：do the things they like</li>
<li>做他们热衷的事：do the things they are enthusiastic about</li>
<li>追求个人兴趣：pursue their personal interests</li>
<li>相对应的人/事：counterparts</li>
<li>职业发展：career development / career progression / career growth</li>
<li>收入不稳定：income instability</li>
<li>高薪工作：well-paid jobs / high-paying jobs</li>
<li>专业知识：expertise</li>
<li>获得专业知识：the acquisition of expertise</li>
</ol>
<p>–</p>
<ol>
<li>找到工作：find jobs / secure jobs / secure employment</li>
<li>晋升：climb the corporate ladder</li>
<li>工作满意度：job satisfaction</li>
<li>保持良好的工作与生活平衡：maintain a good work-life balance</li>
<li>没有前途的工作：dead-end jobs</li>
<li>跳槽：jump ships / job hopping</li>
<li>加班：work overtime</li>
<li>加班时间长：put in long hours</li>
<li>加班疲劳：the overtime grind</li>
<li>感到筋疲力尽：feel drained</li>
<li>面临职业倦怠：face burnout</li>
</ol>
<p>–</p>
<ol>
<li>对短期雇员投入大量资源：invest significant resources in short-term employees</li>
<li>通常缺乏系统的培训和技能发展机会：typically lack access to systematic training and skill development opportunities</li>
<li>导致技能积累有限：lead to limited skill accumulation</li>
<li>导致晋升机会少：lead to few chances of promotion</li>
<li>最终阻碍他们晋升：ultimately hindering them from climbing the corporate ladder</li>
<li>阻碍未来的就业机会：impedes future employment opportunities</li>
<li>雇主倾向于青睐具有长期工作经验的候选人：employers tend to favor candidates with long-term employment experience</li>
<li>被认为是可靠且自律的：are perceived as reliable and self-disciplined</li>
<li>阻止短期工人获得高薪工作：discourages short-term workers from securing high-paying jobs</li>
<li>剥夺短期工人获得高薪工作的机会：deprives short-term workers of the chance to secure high-paying jobs</li>
</ol>
<h4 id="32-criminal-trials"><a class="markdownIt-Anchor" href="#32-criminal-trials"></a> 3.2 Criminal trials</h4>
<p>In some countries, criminal trials are shown on TV and the general public can watch them. Do the advantages outweigh the disadvantages?</p>
<p>–</p>
<p>In some countries, criminal trials are shown on TV and the general public can watch them. Do the advantages outweigh the disadvantages?</p>
<p>In some parts of the world, criminal trials are broadcast on TV, allowing the general popular to observe them. However, I believe that the positive effects of showing criminal trials outbalance the negative ones.</p>
<p>On the one hand, there are indeed some drawbacks to reporting criminal trails publicly. Firstly, making trials public may negatively impact viewers’ psychological well-being. Such trails typically involve disturbing details, such as graphic and unsettling images, especially in the case of violent crimes, causing anxiety and fear, which can have a detrimental effect on the audience. This is particularly true for impressionable and vulnerable viewers, such as adolescents or those with emotional sensitivities. Secondly, TV exposure infringes on the privacy of both victims and defendants. During the trial, their personal information, such as family background or aspects of the crime, will be disclosed. Such excessive exposure could not only affect their social reputation and future life but also exacerbate the psychological burden on both victims and defendants.</p>
<p>On the other hand, I believe that the merits of airing criminal trials on TV outweigh the demerits. First of all, public trials serve as a deterrent. By watching public trials, individuals become aware that criminal behavior will be met with strict legal punishments and realize the serous repercussions of illegal behavior, deterring prospective criminals from committing offenses. This deterrent effect helps reduce crime rates and promotes societal safety and stability. Second of all, televising criminal trails holds significant educational value. When observing these trials, the public gains direct exposure to the mechanisms of legal procedures and judicial decision-making and help them gain a deeper understanding of how the judicial system ensures fairness and how evidence is evaluated. This educational source is particularly valuable for students and those who aspire to pursue a career in law. This educational value can enhance the public’s legal awareness, while also cultivating more law-abiding citizens.</p>
<p>In conclusion, even though showing criminal trials has its disadvantages, the potential benefits, such as acting as a powerful deterrent and holding educational value, are more significant than the possible dangers</p>
<p>–<br />
Topic Volcabulary</p>
<p>犯罪动词：</p>
<ol>
<li>犯罪 commit a crime(crimes) / an offense/offenses</li>
<li>参与犯罪活动 engage in criminal activities</li>
<li>违法 break the law/violate the law/offend against the law</li>
</ol>
<p>–</p>
<p>人：</p>
<ol>
<li>罪犯 criminals/offenders/convicts</li>
<li>年轻罪犯 young criminals/offenders = juvenile criminals/offenders/delinquents</li>
<li>青少年犯罪 juvenile delinquency</li>
<li>受害者 victims</li>
<li>原告 accusers</li>
<li>被告 defendants</li>
<li>法官 judges</li>
<li>陪审团 jurors</li>
<li>潜在罪犯 potential/prospective criminals</li>
</ol>
<p>–</p>
<p>犯罪行为：</p>
<ol>
<li>犯罪行为/违法行为 criminal behavior/acts/activities/wrong4doing=illegal behavior/acts/activities/actions</li>
<li>反社会行为 antisocial behavior</li>
<li>有害行为 harmful behavior</li>
</ol>
<p>–</p>
<p>法律意识：</p>
<ol>
<li>法律意识：legal awareness/consciousness</li>
<li>提升法律意识：raise legal awareness</li>
<li>加强市民的法律意识：enhance public understanding of the law=enhance the public’s legal awareness=enhance society’s legal awareness=strengthen public understanding of the law/legal knowledge</li>
</ol>
<p>–</p>
<p>后果：</p>
<ol>
<li>违法行为的后果 the consequences/repercussions/ramifications of illegal behavior</li>
</ol>
<p>–</p>
<p>形容青少年：</p>
<ol>
<li>敏感的，易受影响的：impressionable</li>
<li>脆弱的：vulnerable</li>
<li>不成熟的：immature</li>
</ol>
<p>–</p>
<p>威慑作用：</p>
<ol>
<li>作为一个威慑：serve as a deterrent</li>
<li>通过看公开审判：By watching public trials</li>
<li>要意识到犯罪行为将会受到严厉的法律惩罚：become aware that criminal behavior will be met with strict legal punishment</li>
<li>意识到违法行为的严重后果：realize the serous repercussions of illegal behavior</li>
<li>阻止潜在的罪犯犯罪：deterring prospective criminals from committing offenses</li>
<li>帮助减少犯罪率：helps reduce crime rates</li>
<li>促进社会安全与稳定：promotes societal safety and stability</li>
</ol>
<p>–</p>
<p>教育意义：</p>
<ol>
<li>具有重要的教育价值：holds significant educational value</li>
<li>能够直接接触：gains direct exposure to</li>
<li>法律程序和司法决策机制：the mechanisms of legal procedures and judicial decision-making</li>
<li>司法制度如何确保公平：how the judicial system ensure fairness</li>
<li>如何评估证据：how evidence is evaluated</li>
<li>学生以及有志从事法律工作的人士：students and those who aspire to pursue a career in law</li>
<li>提升公众的法律意识：enhance the public’s legal awareness</li>
<li>遵守法律：obey the law</li>
<li>遵守法律：abide by the law</li>
<li>守法公民：law-abiding citizens</li>
</ol>
<h3 id="4discuss-both-views-and-give-your-opinion"><a class="markdownIt-Anchor" href="#4discuss-both-views-and-give-your-opinion"></a> 4.Discuss both views and give your opinion</h3>
<p>discuss结构：5段式<br />
1 改写题目. This essay will discuss both views and present my own opinion.<br />
2 On the one hand, some argue that…Firstly, …,Secondly,…<br />
3 On the other hand, it is also suggested that …First of all, … Moreover, …<br />
4 In my opinion, freestyle 可以有倾向性、可以反驳、可以两个都要、可以提供解决方案<br />
5 In conclusion, even though…, I believe that…</p>
<p>–</p>
<h4 id="41-environmental-protection"><a class="markdownIt-Anchor" href="#41-environmental-protection"></a> 4.1 environmental protection</h4>
<p>Some people believe that environmental protection is the responsibility of individuals, while others think it is the responsibility of governments. Discuss both views and give your opinion<br />
<code>分析理由，不是利弊</code></p>
<p>–</p>
<p>环保是个人的责任：已知B 直接回答为什么</p>
<p>个人行为影响环境:</p>
<ul>
<li>举例：正面思考</li>
<li>if怎么做，影响</li>
<li>if 反着说，每个人都忽视</li>
</ul>
<p>个人行为可以产生累积效应</p>
<p>–</p>
<p>Developments in science and technology have caused environmental problems. Some people think a simpler way of life will solve the problems, while others believe science and technology have the answers. Discuss both views and give your own opinion.</p>
<p>In my opinion, while adopting a simple way of life can help alleviate some environmental challenges by reducing resource waste and carbon emissions, it is not a complete solution. Science and technology are essential for addressing large-scale environmental issues, such as climate change, global warming, and resource deletion. By combining a simple way of life with science and technology, we can create a more sustainable future. 个人观点：俩个都同意的观点</p>
<p>简单生活方式能解决环境问题：已知B，拆解已知B</p>
<ul>
<li>1.简单生活方式能减少<strong>资源浪费</strong> (生活方式：节约用水用电、理性消费、循环利用)<br />
By 拆解简单生活</li>
<li>2.简单生活方式能减少<strong>污染</strong> （生活方式：不开车、公共交通、低碳饮食、使用可再生能源）<br />
选择…,</li>
</ul>
<p>科学技术能解决环境问题：</p>
<ul>
<li>1.提供高效的解决方案</li>
<li>2.促进资源替代</li>
</ul>
<p>–</p>
<p>个人责任：为什么</p>
<ol>
<li>个人的生活方式和消费习惯对环境产生了直接影响</li>
<li>个人的环保行为可以产生显著的累积效应 cumulative effective</li>
</ol>
<p>政府责任：为什么</p>
<ol>
<li>政府拥有制定环保政策和法规的权利</li>
<li>政府能够为环境保护提供财政支持</li>
</ol>
<hr />
<p>Some suggest that individuals bear the responsibility for environmental conservation, while others contend that it is the duty of governments. This essay will discuss both views and present my own opinion.</p>
<p>On the one hand, some argue that protecting the environment is an individual responsibility. Firstly, an individual’s daily lifestyle and consumption habits directly determine their impact on the environment. Choosing to use public transportation instead of driving can effectively reduce carbon emissions and mitigate air pollution. Besides, purchasing products with eco-friendly packaging or supporting brands that focus on sustainable production can help reduce resource waste and lessen the burden on the natural environment. Secondly, the environmental actions of individuals can have a significant cumulative effect. Everyday environmentally-friendly practices such as reducing plastic bag usage, conserving water, and sorting waste, when adopted by everyone, can significantly reduce resource waste and environmental pollution. Although individual environmental actions may seem insignificant in the short term, their cumulative effect can be highly substantial if everyone actively participates and remains consistent.</p>
<p>On the other hand, it is also suggested that the responsibility lies with governments. To begin with, the government has the authority to formulate environmental policies and regulations. As the governing body of the nation, the government holds the power to formulate and enforce environmental protection policies and regulations. These policies and regulations can effectively regulate and guide environmentally responsible behaviors. For example, the government can set pollution emission standards to limit the harmful actions of businesses, imposing penalties on violators in order to reduce the environmental damage caused by industrial activities. In addition, the government is able to provide financial support for environmental protection. The government can establish dedicated environmental protection funds to finance projects related to pollution control, ecological restoration, and sustainable development. For example, the government can support the research, development, and application of clean energy technologies, encourage businesses to invest in environmental protection facilities, and reduce carbon emissions.</p>
<p>In my opinion, while individual environmental actions play an important role in daily life, the primary responsibility for environmental protection should lie with the government. The government can not only promote environmental protection through legislation and policies but also mobilize resources, develop long-term strategies, and lead collective efforts across all sectors of society to address global environmental challenges.</p>
<p>In conclusion, even though individual actions can have a positive impact, relying solely on changes at the individual level is insufficient to solve global and systemic problems.</p>
<hr />
<p>Topic Volcabulary</p>
<p>环保：</p>
<ul>
<li>Protect the environment</li>
<li>onserve the environment</li>
<li>Preserve the environment</li>
<li>Care for the environment</li>
<li>Safeguard the environment</li>
<li>Environmental protection</li>
<li>Environmental conservation</li>
<li>Environmental preservation</li>
</ul>
<p>–</p>
<p>问题：</p>
<ul>
<li>Environmental issues/problems/concerns/challenges</li>
<li>Ecological challenges</li>
</ul>
<p>–</p>
<p>环境污染：</p>
<ul>
<li>Pollute the environment</li>
<li>Contaminate the environment</li>
<li>Environmental pollution</li>
<li>Environmental contamination</li>
</ul>
<p>–</p>
<p>环保行为、政策、意识:</p>
<ul>
<li>Environmentally-friendly practices</li>
<li>Environmental awareness/consciousness</li>
<li>Environmental policies</li>
<li>environmental protection policies and regulations</li>
</ul>
<p>–</p>
<p>有权利有能力:</p>
<ul>
<li>holds the power to</li>
<li>Has the authority to</li>
<li>Possesses the ability to</li>
<li>Is capable of</li>
</ul>
<p>–</p>
<p>对环境负责任行为:</p>
<ul>
<li>environmentally responsible behaviors</li>
<li>Sustainable behaviors</li>
<li>Eco-friendly practices</li>
<li>Green behaviors</li>
</ul>
<p>–</p>
<p>责任:</p>
<ul>
<li>人bear the responsibility for sth</li>
<li>responsibility-duty</li>
<li>the responsibility lies with sb</li>
<li>Sth is an individual responsibility</li>
<li>人be held accountable for</li>
<li>Sth falls under the responsibility of sb</li>
</ul>
<p>–</p>
<p>个人责任:</p>
<ul>
<li>Individual environmental efforts</li>
<li>environmental efforts of individuals</li>
<li>the environmental actions of individuals</li>
<li>individual environmental actions</li>
<li>seem insignificant</li>
</ul>
<p>–</p>
<p>个人怎么做：<br />
<code>(1)选择公共交通</code> Choosing to use public transportation instead of driving</p>
<p>好处: reduce carbon emissions<br />
好处: mitigate air pollution</p>
<p><code>(2)改变消费习惯</code></p>
<ul>
<li>purchasing products with eco-friendly packaging</li>
<li>supporting brands that focus on sustainable production</li>
</ul>
<p>好处: reduce resource waste<br />
好处: lessen the burden on the natural environment</p>
<p><code>(3)累积效应</code> Everyone adopts everyday environmentally-friendly practices</p>
<p>日常环保行为:</p>
<ul>
<li>reducing plastic bag usage</li>
<li>conserving water</li>
<li>sorting waste</li>
</ul>
<p>好处: ignificantly reduce resource waste<br />
好处: reduce environmental pollution</p>
<p>–</p>
<p>政府怎么做：<br />
<code>(1)制定环保政策和法规</code></p>
<ul>
<li>formulate environmental policies and regulations</li>
<li>formulate and enforce environmental protection policies and regulations</li>
<li>regulate and guide environmentally responsible behaviors</li>
</ul>
<p>具体例子:</p>
<ul>
<li>set pollution emission standards to limit the harmful actions of businesses</li>
<li>imposing penalties on violators in order to reduce the environmental damage caused by industrial activities</li>
</ul>
<p><code>(2)提供财政支持</code></p>
<ul>
<li>provide financial support for environmental protection</li>
</ul>
<p>具体例子:</p>
<ul>
<li>establish dedicated environmental protection funds</li>
<li>finance projects related to pollution control, ecological restoration, and sustainable development</li>
</ul>
<p>更具体的例子:</p>
<ul>
<li>support the research, development, and application of clean energy technologies</li>
<li>encourage businesses to invest in environmental protection facilities</li>
<li>reduce carbon emissions</li>
</ul>
<p>自己的观点：支持是政府的责任</p>
<ul>
<li>promote environmental protection through legislation and policies</li>
<li>mobilize resources</li>
<li>develop long-term strategies</li>
<li>lead collective efforts across all sectors of society to address global environmental challenges</li>
</ul>
<p>–</p>
<p>政府怎么做：<br />
<code>(1)制定环境政策和法规 </code></p>
<ol>
<li>制定并执行环境保护政策和法规 - Formulate and enforce environmental protection policies and regulations</li>
<li>规范和引导环境负责行为 - Regulate and guide environmentally responsible behaviors</li>
</ol>
<p>具体例子:</p>
<ol>
<li>制定污染排放标准以限制企业的有害行为 - Set pollution emission standards to limit the harmful actions of businesses</li>
<li>对违规者施加处罚以减少工业活动对环境的破坏 - Imposing penalties on violators in order to reduce the environmental damage caused by industrial activities</li>
</ol>
<p><code>(2)提供财政支持</code> Provide financial support for environmental protection</p>
<p>具体例子:</p>
<ol>
<li>建立专门的环境保护基金 - Establish dedicated environmental protection funds</li>
<li>为与污染控制、生态修复和可持续发展相关的项目提供资金 - Finance projects related to pollution control, ecological restoration, and sustainable development</li>
</ol>
<p>更具体的例子:</p>
<ol>
<li>支持清洁能源技术的研究、开发和应用 - Support the research, development, and application of clean energy technologies</li>
<li>鼓励企业投资环境保护设施 - Encourage businesses to invest in environmental protection facilities</li>
<li>减少碳排放 - Reduce carbon emissions</li>
</ol>
<p>自己的观点：支持是政府的责任:</p>
<ol>
<li>通过立法和政策促进环境保护 - Promote environmental protection through legislation and policies</li>
<li>动员资源 - Mobilize resources</li>
<li>制定长期战略 - Develop long-term strategies</li>
<li>引领全社会各领域的共同努力以应对全球环境挑战 - Lead collective efforts across all sectors of society to address global environmental challenges</li>
</ol>
<h3 id="5-do-you-think-this-is-a-positive-or-a-negative-development"><a class="markdownIt-Anchor" href="#5-do-you-think-this-is-a-positive-or-a-negative-development"></a> 5. Do you think this is a positive or a negative development?</h3>
<p>带有倾向：</p>
<ul>
<li>直接改写题目. From my perspective, while there are challenges associated with…, the overall impact is largely positive.</li>
<li>On the one hand, … can be seen as a negative development. Firstly, …Secondly, …</li>
<li>However, it is important to acknowledge the benefits associated with…To begin with, … Moreover, …</li>
<li>In conclusion, while … 确实有消极影响, the overall impact is positive. 总结好处1+总结好处</li>
<li>写主语A至少3个 Some people believe that young people who commit serious crimes should be punished in the same way as adults. To what extent do you agree or disagree?</li>
</ul>
<h4 id="51-city-countryside"><a class="markdownIt-Anchor" href="#51-city-countryside"></a> 5.1 city-countryside</h4>
<p>In many countries around the world, rural people are moving to cities, so the population in the countryside is decreasing. Do you think this is a positive or a negative development?</p>
<p>–</p>
<p>In many parts of the world, individuals from rural regions are migrating to metropolitan areas, leading to a reduction in the rural population. From my perspective, while there are challenges associated with rural-urban migration, the overall impact is largely positive.</p>
<p>On the one hand, the migration of rural individuals to urban centers. A growing number of villagers moving to cities can significantly increase the urban population, which signifies the<br />
distribution of social resources reduce, rendering it challenging for both rural individuals and existing city residents to secure employment. Besides, the population growth places enormous pressure on urban infrastructure, including housing, transportation, and public services, making it difficult to meet the rising demand. Secondly, rural migration negatively affects the development of the countryside. A significant overflow of rural residents weaken rural regions, hindering rural construction. Most of people left in the countryside are the elderly and children, reducing the vitality of rural communities and leading to population aging.</p>
<p>However, it it important to acknowledge the benefits associated with rural-urban migration. To begin with, this migration increass urban diversity. As rural people with different cultural backgrounds move to cities, this can provide urban dwellers with valuable opportunities to experience various cultural facets firsthand, such as traditions and cuisine. These experiences not only enrich citizen’s lives but also enable them to gain a comprehensive understanding of diverse customs in rural areas, which can help foster empathy among city resident and break stereotype. Moreover, this movement promotes urban development. An influx of people from impoverished regions to cities can contribute to a rise in the urban labor force, which can be conducive to the development of industries such as services, manufacturing, and construction. The increase in the labor force enhances work productivity, facilitating urban economic growth. Also, this migration can result in a rise in consumer demand, which simulates sectors such as catering, futhering improving the city’s economy.</p>
<p>In conclusion, while rural migration has detrimental effects, the overall impact is positive. This practice not only fosters urban diversity but also contributes to the economic development of urban areas.</p>
<hr />
<p>农村迁移城市：</p>
<ul>
<li>农村人：rural people=rural individuals=rural residents=people living in rural areas=people living in the countryside=individuals from rural regions</li>
<li>乡村：countryside=rural areas=rural regions</li>
<li>迁移到城市：are moving to cities=are migrating to=are relocating to=are shifting to</li>
<li>城市：cities=urban areas=urban regions=urban centers=urban zones=metropolitan areas</li>
<li>乡村人口：the population in the countryside=the rural population=the number of rural individuals</li>
</ul>
<p>–<br />
迁移者、城市居民：</p>
<ul>
<li>migrants</li>
<li>city residents=city dwellers=citizens=existing city residens</li>
</ul>
<p>–</p>
<p>贫困：</p>
<ul>
<li>贫困人：deprived people=impoverished people=socially-disadvantaged children</li>
<li>贫困地区：deprived=poverty-stricken areas=impoverished areas</li>
<li>poverty issues</li>
</ul>
<p>–</p>
<p>话题： rual-urban migration = rural migration = the migration of rural residents to urban centers = an flux of rural residents to urban = a significant overflow of rural residents = rural people moving to cities</p>
<p>越来越多的农村人迁到城市：a growing number of villagers moving to cities</p>
<h3 id="6what-problems-does-it-cause-how-can-we-solve-these-problems"><a class="markdownIt-Anchor" href="#6what-problems-does-it-cause-how-can-we-solve-these-problems"></a> 6.What problems does it cause? How can we solve these problems?</h3>
<ul>
<li>改写题目: The reasons for 话题名词 are varied, but there are several potential solutions that can be implemented to address the problem effectively.</li>
<li>原因段: There are multiple reasons why…A significant reason for话题 is…<br />
… is another reason for 话题        110个字</li>
<li>解决方案段(一般从政府、公司、学校、个人这几个角度): However, some measures can be implemented to … One of the most effective solutions is to … … is another vital approach… 110字</li>
<li>In conclusion, 这个话题(名词/动名词)can be caused by名词/动名词.  Addressing the issue of 话题 requires a multifaceted approach involving …and… By addressing the root causes and providing practical solutions, （governments） and （communities ）can help individuals make healthier choices.</li>
</ul>
<h4 id="61-healthy-lifestyle"><a class="markdownIt-Anchor" href="#61-healthy-lifestyle"></a> 6.1 healthy lifestyle</h4>
<p>Scientists advise people to lead a healthy lifestyle, but most people continue with unhealthy activities. Why do you think it is, and what can be done about it?</p>
<hr />
<p>Simple Version:</p>
<ul>
<li>改写题目The reasons for 话题名词 are varied, but there are several potential solutions that can be implemented to address the problem effectively.</li>
<li>原因段 There are multiple reasons why…One significant reason is…<br />
Another contributing factor is…  110个字</li>
<li>解决方案段To tackle these issues, several measures can be implemented. One of the most effective solutions is to … … is another vital approach… 110字</li>
<li>In conclusion, 这个话题(名词/动名词)can be caused by名词/动名词.  Addressing the issue requires a multifaceted approach involving …and… By addressing the root causes and providing practical solutions, （governments） and （communities ）can help individuals make healthier choices.</li>
</ul>
<p>一般解决方案从政府、公司、学校、个人这几个角度</p>
<hr />
<p>健康的生活方式：</p>
<ul>
<li>lead/adopt/follow/maintain/embrace a healthy lifestyle</li>
<li>lifestyle = a way of life</li>
<li>continue = persist in = refuse to change…。</li>
<li>be unwilling to do = be reluctant to do sth</li>
<li>unhealthy activities/habits/behavior</li>
<li>harmful activities/habits/behavior</li>
<li>detrimental</li>
<li>healthy=wholesome 有益身心健康的</li>
<li>unhealthy=unwholesome 不益身心健康的</li>
<li>healthy/nutritious diets</li>
<li>essential nutrients</li>
</ul>
<hr />
<p>报告文原因类分论点3种写法：</p>
<ul>
<li>heavy workloads <strong>lead to</strong> harmful behavior</li>
<li>harmful behavior <strong>stems from/arises from</strong> heavy workloads</li>
<li>one significant reason(for harmful lifestyles) is heavy workloads</li>
<li>xxx is another reason</li>
<li>another contributing factor is xxx</li>
</ul>
<hr />
<p>参考理由：<strong>缺乏意识</strong><br />
One significant reason is a lack of health awareness. Many individuals are unware of the long-term repercussions of unhealthy habits, making them reluctant to change their unhealthy lifestyles. Moreover, many do not understand what constitutes a healthy lifestyle, hindering them from making informed decisions about their well-being.</p>
<p>Reference Solutions:</p>
<ul>
<li>One of the most effective solutions is promoting work-like balance. Employers can implement policies that promote work-life balance, such as flexible working hours, and provide fitness and rest facilities for employees, encouraging healthy living.</li>
<li>Implementing stricter food safety policies is another vital approach. Governments can regulate the advertising of unhealthy products, especially those targeting childern, and impose higher taxs on junk food and sugary drinks. These measures can hinder unhealthy behavior and inspire healthier lifestyles.</li>
<li>Additionally, government can hold public information campaigns in schools and workplaces, which can educate individuals about the benefits of healthy living and the risks of unhealthy habits. This can effectively enhance the health consciousness of the public.</li>
</ul>
<hr />
<p>Scientists suggest that individuals ought to adopt a healthy way of life, yet a large number of people persist in engaging in harmful activities. The reasons for this phenomenon are varied, but there are several potential solutions that could be implemented to address this <strong>problem</strong> effectively.</p>
<p>There are multiple reasons why individuals prefer unwholesome lifestyles. One significant reason is heavy workloads. In today’s competitive work environment, people dedicate considerable time and effort to their work, leading to sedentary lifestyle, which may increase the <strong>risk</strong> of health problems such as obesity and diabetes. Another contributing factor is the pursuit of temporary happiness. Fast food ,serve as a popular option in contemporary society because of its convenience and taste, provides momentary satisfaction. However, it is often high in fat and lacks essential nurtrients, like vitamin, having a determental impact on health.</p>
<p>To tackle these issues, several measures can be implemented. One of the most effective solutions is establishing gyms within <strong>workplaces</strong>. This practice provides more employees with opportunities to engage in physical exercise, [, keeping them active. This active engagement reduce the risk of overwight, contributing to effective weight management and promoting overall health]help them build muscle and strengthen cardiovascular health, enhancing their physical health. Implementing stricter food safety policies is another vital approach. Governments can provide financial support for healthy catering service, promoting the development of healthy food. Besides, governments can publicize the significance of healthy eating, enhancing individuals’ awareness of nutritious diets.</p>
<ul>
<li>方案一问题：具体方案少，优点多</li>
<li>方案二问题：policy没有细化；宣传健康饮食的重要性，怎么宣传？？？？</li>
</ul>
<p>–</p>
<p>In conclusion, unhealthy lifestyles can be caused by hectic schedules and the pursuit of momentary happiness. Addressing the issue requires a multifaceted approach, involving setting up gyms in workplaces, enforcing food safety policies, and publizing the significane of healthy diets. By addressing the root causes and providing practical solutions, companies and governments can help individuals make healthier choices.</p>
<h3 id="volcabulary"><a class="markdownIt-Anchor" href="#volcabulary"></a> Volcabulary</h3>
<h4 id="好处"><a class="markdownIt-Anchor" href="#好处"></a> 好处</h4>
<ol>
<li>使某人做某事: make sb do sth</li>
<li>让某人做某事: let sb do sth</li>
<li>帮助某人做某事: help sb do sth</li>
<li>允许某人做某事: allow sb to do sth</li>
<li>使某人能够做某事: enable sb to do sth</li>
<li>授权某人做某事: empower sb to do sth</li>
<li>增强/改善某事物: enhance/improve sth</li>
<li>促进/有助于某事: facilitate sth/contribute to sth/promote/foster</li>
<li>在做某事方面发挥关键作用: play a crucial/pivotal role in doing sth A-B</li>
<li>为某人提供有利的机会做某事: offer sb beneficial chances to do sth</li>
<li>为某人提供宝贵的机会做某事: provide sb with valuable opportunities to do sth A1</li>
<li>有机会做某事: have the opportunity to do sth A1</li>
<li>装备某人某物以做某事: equip sb with sth to do sth</li>
<li>培养/培育/促进: cultivate/nurture/foster</li>
<li>有助于: be conducive to sth</li>
</ol>
<p>–</p>
<h4 id="坏处句型"><a class="markdownIt-Anchor" href="#坏处句型"></a> 坏处句型</h4>
<ol>
<li>有助于/导致/引起：contribute to / lead to / result in / cause</li>
<li>使某人难以做某事：make it difficult for someone to do something</li>
<li>阻碍某事：hinder / impede / impair something</li>
<li>阻止某人做某事：hinder someone from doing something</li>
<li>阻止某人做某事：prevent / discourage someone from doing something</li>
<li>限制某事的机会：limit opportunities for something</li>
<li>剥夺某人做某事的机会：deprive someone of the chance to do something</li>
<li>负面影响…: Negatively affect/impact/influence</li>
<li>对sth有不好的影响：Have a detrimental/negative effect on sth</li>
<li>对…不利：is detrimental to</li>
<li>加剧：exacerbate</li>
</ol>
<p>–</p>
<h4 id="因果关系"><a class="markdownIt-Anchor" href="#因果关系"></a> 因果关系</h4>
<p>「这」因果关系：</p>
<ul>
<li>1.This library offers a quiet environment. This makes it easier for me to focus</li>
<li>2.This library offers a quiet environment, which makes it easier for me to focus</li>
<li>3.This library offers a quiet environment, potentially making it easier for me to focus</li>
</ul>
<p>–</p>
<h4 id="解释逻辑"><a class="markdownIt-Anchor" href="#解释逻辑"></a> 解释逻辑</h4>
<p>解释逻辑：</p>
<ul>
<li>
<ol>
<li>When doing, 人</li>
</ol>
</li>
<li>
<ol start="2">
<li>By doing, people</li>
</ol>
</li>
<li>
<ol start="3">
<li>Through doing, people</li>
</ol>
</li>
</ul>
<h3 id="反驳段"><a class="markdownIt-Anchor" href="#反驳段"></a> 反驳段</h3>
<p>反驳段：6个步骤</p>
<ol>
<li>Admittedly, some may argue that 跟你相反的观点</li>
<li>They hold the belief that 理由</li>
<li>However, this argument is flawed as it fails to recognize the crucial role of 自己的论点, which are nurtured through 自己的观点</li>
<li>Numerous studies have shown that …</li>
<li>Moreover, 新的论点</li>
<li>Therefore, it is essential for sb to do sth</li>
</ol>
<p>–</p>
<p>范例：<br />
<img src="https://pic.imgdb.cn/item/672f12e5d29ded1a8c3fb283.png" alt="" /><br />
Admittedly, some may argue that art should not be made compulsory in high schools.// They hold the belief that academic subjects like mathematics and science are more directly associated with future careers, suggest that prioritizing these domains can better prepare students for the employment market.// However, this argument is flawed as it fails to recognize the crucial role of mental health and a broad perspective, which are nurtured through art education and are incredibly important in today’s professional environment.// Numerous studies have shown that those who regularly receive art education tend to be mentally healthier and display broader perspectives than those without such exposure.// Moreover, art courses can equip students with a variety of skills, such as critical thinking, creativity, and aesthetic appreciation.// Therefore, it is essential for high schools to incorporate art into the curriculum.</p>
<p>–</p>
<ul>
<li>反对观点：有人认为不应强制学习艺术，认为学术课程更重要。</li>
<li>反驳观点：但这种观点忽略了艺术对心理健康和多元视角的作用。</li>
<li>研究支持：研究表明，接受艺术教育的人心理更健康、视角更广。</li>
<li>艺术的作用：艺术课程培养批判性思维、创造力和审美。</li>
<li>结论：艺术应纳入高中课程。</li>
</ul>
<h3 id="范文分析"><a class="markdownIt-Anchor" href="#范文分析"></a> 范文分析</h3>
<h4 id="外国游客是否应该比本地游客花更多钱"><a class="markdownIt-Anchor" href="#外国游客是否应该比本地游客花更多钱"></a> 外国游客是否应该比本地游客花更多钱</h4>
<p>Foreign visitors should pay more than local visitors for cultural and historical attractions.<br />
To what extent do you agree or disagree with this opinion?</p>
<p>–</p>
<p>反方观点：景点需要通过国家补贴来维持运行-补贴来源于当地人交的税-当地人已经交过了税，而外国人没有交税-外国人需要收更多的钱</p>
<p>正方观点：如果提高价格会抑制外国游客来本地-经济的贡献下降-景点维护费用不足-外国人不需要交更多的钱</p>
<p>外国游客消费 -&gt; 增加经济收入 -&gt; 支持旅游业发展 -&gt; 促进文化遗产维护 -&gt; 吸引更多游客</p>
<h4 id="选择工作最重要的考虑因素是薪水么"><a class="markdownIt-Anchor" href="#选择工作最重要的考虑因素是薪水么"></a> 选择工作最重要的考虑因素是薪水么</h4>
<p>When choosing a job, the salary is the most important consideration. To what extent do you agree or disagree? 部分同意:同意salary重要，其他也一样重要</p>
<p>人们会追求收入高的工作-》钱能满足各种需求-》提升生活质量</p>
<p>其他因素同样重要：</p>
<ul>
<li>办公室的氛围</li>
<li>社会贡献感</li>
</ul>
<h4 id="青少年是否应该无偿为社区工作"><a class="markdownIt-Anchor" href="#青少年是否应该无偿为社区工作"></a> 青少年是否应该无偿为社区工作</h4>
<p>Some people think that all teenagers should be required to do unpaid work in their free time to help the local community. They believe this would benefit both the individual teenager and society as a whole.</p>
<p>Do you agree or disagree?</p>
<p>学生需要每天上课-》学习的压力已经很大-》不应该去社区工作，而是说更多的时间和朋友享受时光，体育活动</p>
<p>强迫工作-》不满情绪-》不会有积极的结果</p>
<h4 id="我们应该只关心自己的国家么"><a class="markdownIt-Anchor" href="#我们应该只关心自己的国家么"></a> 我们应该只关心自己的国家么</h4>
<p>We cannot help everyone in the world that needs help, so we should only be concerned with our own communities and countries.</p>
<p>To what extent do you agree or disagree with this statement?</p>
<p>优先考虑自己国家，然后在国际化</p>
<h4 id="兴趣爱好应该有挑战性才有趣"><a class="markdownIt-Anchor" href="#兴趣爱好应该有挑战性才有趣"></a> 兴趣爱好应该有挑战性才有趣</h4>
<p>Some people believe that hobbies need to be difficult to be enjoyable.</p>
<p>To what extent do you agree or disagree? 部分同意:一些兴趣简单就有趣，一些兴趣难才有趣</p>
<p>简单有趣：比如游泳-》需要很少的装备，容易学，不昂贵，满足感</p>
<p>苦难有趣：有挑战性-》克服挑战会有成就感</p>
<h4 id="大学每个科目男女生数量应该相等"><a class="markdownIt-Anchor" href="#大学每个科目男女生数量应该相等"></a> 大学每个科目男女生数量应该相等</h4>
<p>Universities should accept equal numbers of male and female students in every subject.<br />
To what extent do you agree or disagree? 一边倒完全不同意</p>
<p>上课的学生取决于学校接受的学生<br />
不同课程对与不同性别的吸引力是不同的，</p>
<p>性别来决定录取资格是不公平的，要更加看重申请人的能力-》同样的能力情况下，男女都有同等的机会-》反例，录弱女，不录强男，那么这是不公平的。</p>
<h4 id="保护野生动物是否浪费资源"><a class="markdownIt-Anchor" href="#保护野生动物是否浪费资源"></a> 保护野生动物是否浪费资源</h4>
<p>Wild animals have no place in the 21st century, so protecting them is a waste of resources. To what extent do you agree or disagree?</p>
<p>人类不应该以自己的利益而存在；没有必要毁灭每一寸土地我们才能生存</p>
<p>保护野生动物也是保护我们自己</p>
<p>保护野生动物的栖息地-》栖息地能够产生氧气-》稳定气候-》影响人类</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
  </entry>
  <entry>
    <title>Git</title>
    <url>/2023/09/22/Git/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="category"><a class="markdownIt-Anchor" href="#category"></a> Category</h2>
<ul>
<li>本地篇</li>
<li>1.<code>git commit</code>:本地提交</li>
<li>2.1 <code>git branch xxx</code>:本地创建新的分支</li>
<li>2.2 <code>git checkout xxx</code>:切换分支</li>
<li>3.1 分支合并方法一 <code>git merge xxx</code>:xxx合并到*下</li>
<li>3.2 分支合并方法二 <code>git rebase xxx</code>:*合并到main下</li>
<li>4.HEAD:可以粗略地理解为指向带星号的东西？</li>
<li>5.1 相对引用操作符一 <code>^</code> 操作符:<code>main^ </code>相当于main的父节点</li>
<li>5.2 相对引用操作符二 <code>～</code> 操作符:<code>HEAD~&lt;num&gt;</code>表示向上退num步</li>
<li>5.3 强制修改分支位置 <code>git branch -f main HEAD~3</code>:main指向HEAD~3</li>
<li>6.1 撤销变更方法一 <code>git reset xxx</code>:回退到xxx位置</li>
<li>6.2 撤销变更方法二 <code>git revert xxx</code>:撤销xxx，生成一个xxx上级的提交记录</li>
<li>7.1 整理提交记录方法一 <code>git cherry-pick &lt;提交号&gt;...</code>:将&lt;提交号&gt;放到*下</li>
<li>7.2 整理提交记录方法二 <code>git rebase -i &lt;提交号&gt;</code>:将&lt;提交号&gt;下面的提交记录重新排序</li>
<li>8.本地栈式提交</li>
<li>9.1 提交技巧1</li>
<li>9.2 提交技巧2</li>
<li>10.<code>git tag v1 C1</code>:将标签v1打在C1上</li>
<li>11.<code>git describe xxx</code>:描述离xxx最近的标签，输出<code>&lt;tag&gt;_&lt;numCommits&gt;_g&lt;hash&gt;</code></li>
<li>12.多分支rebase</li>
<li>13.选择parent提交记录 <code>git checkout main^2</code>:切换分支指向main父节点的兄弟节点</li>
<li>14.纠缠不清的分支～纠缠不清的关系</li>
</ul>
<br>
<ul>
<li>远程仓库篇</li>
<li>15.创建远程参股的命令：<code>git clone xxx</code></li>
<li>16.远程分支：本地仓库一个名为 o/main 的分支</li>
<li>17.<code>git fetch</code>:从远程仓库下载本地仓库中缺失的提交记录,并更新远程分支指针(如 o/main)</li>
<li>18.<code>git pull</code>=<code>git fetch;git merge o/main</code> (<code>git pull --rebase</code>=<code>git fetch;git rebase o/main</code>):从远程仓库下载本地仓库中缺失的提交记录,更新远程分支指针(如 o/main)，再将下载的内容合并到*下。</li>
<li>19.模拟团队合作(自造命令) <code>git fakeTeamwork foo &lt;num&gt;</code>:模拟队友推送了<num>个提交记录到远程仓库的foo分支。</li>
<li>20.<code>git push</code>:将你的变更上传到指定的远程仓库</li>
<li>21.偏离的工作(本地与远程不同步) <code>git fetch; git rebase o/main; git push</code>:先合并远程最新的代码，然后才能分享工作</li>
<li>22.远程服务器拒绝：新建一个分支feature, 推送到远程服务器. 然后reset你的main分支和远程服务器保持一致, 否则下次你pull并且他人的提交和你冲突的时候就会有问题.</li>
<li>23.合并特性分支</li>
<li>24.为什么不用merge呢？取决于个人爱好，merge和rebase是等效的。</li>
<li>25.1 远程跟踪分支方法一 <code>git checkout -b totallyNotMain o/main</code>:创建一个名为 <strong>totallyNotMain</strong> 的分支，它跟踪远程分支 <strong>o/main</strong>。</li>
<li>25.2 远程跟踪分支方法二 <code>git branch -u o/main foo</code>：让foo跟踪o/main</li>
<li>26.<code>Git Push</code> 的参数 <code>git push &lt;remote&gt; &lt;place&gt;</code>:切到本地仓库中的<code>&lt;place&gt;</code>分支，获取所有的提交，再到远程仓库中找到<code>&lt;place&gt;</code>分支，将远程仓库中没有的提交记录都添加上去</li>
<li>27.<code>&lt;place&gt;</code>参数详解<code>git push origin &lt;source&gt;:&lt;destination&gt;</code>: 要同时为源和目的地指定 <code>&lt;place&gt;</code></li>
<li>28.<code>Git fetch</code> 的参数<code>git fetch origin for~1:bar</code>:将远程仓库foo~1分支上的提交记录下载到本地的bar分支，并更新</li>
<li>29.1 古怪的1<code>git push origin :side</code>:通过给 <code>push</code> 传空值 <strong>source</strong>，成功删除了远程仓库中的 side 分支</li>
<li>29.2 古怪的2<code>git fetch origin :bugFix</code>:<code>fetch</code> 空 到本地，会在本地创建一个新分支</li>
<li>30.<code>Git pull</code> 参数<code>git pull origin bar~1:bugFix</code>=<code>git fetch origin bar~1:bugFix; git merge bugFix</code></li>
</ul>
<Br>
<h2 id="1git-commit"><a class="markdownIt-Anchor" href="#1git-commit"></a> 1.Git Commit</h2>
<p>Git 仓库中的提交记录保存的是你的目录下所有文件的快照，就像是把整个目录复制，然后再粘贴一样，但比复制粘贴优雅许多！</p>
<p>Git 希望提交记录尽可能地轻量，因此在你每次进行提交时，它并不会盲目地复制整个目录。条件允许的情况下，它会将当前版本与仓库中的上一个版本进行对比，并把所有的差异打包到一起作为一个提交记录。</p>
<p>Git 还保存了提交的历史记录。这也是为什么大多数提交记录的上面都有 parent 节点的原因 —— 我们会在图示中用箭头来表示这种关系。对于项目组的成员来说，维护提交历史对大家都有好处。</p>
<hr />
<p>实际操作一下，看看提交记录是怎样的。右边展示了一个（小型）Git 代码库。当前有两个提交记录 —— 初始提交 <strong>C0</strong> 和其后可能包含某些有用修改的提交 <strong>C1</strong></p>
<p><img src="https://pbs.twimg.com/media/F6oE_4BbwAA18iQ?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>Git Commit</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oFXl8aAAASoHO?format=webp&amp;name=900x900" alt="" /></p>
<p>修改了代码库，并把这些修改保存成了一个提交记录 <strong>C2</strong>。<strong>C2</strong> 的 parent 节点是 <strong>C1</strong>， parent 节点是当前提交中变更的基础。</p>
<br>
<h2 id="2git-branch"><a class="markdownIt-Anchor" href="#2git-branch"></a> 2.Git Branch</h2>
<p>这是因为即使创建再多的分支也不会造成储存或内存上的开销，并且按逻辑分解工作到不同的分支要比维护那些特别臃肿的分支简单多了。</p>
<p>在将分支和提交记录结合起来后，我们会看到两者如何协作。现在只要记住使用分支其实就相当于在说：“我想基于这个提交以及它所有的 parent 提交进行新的工作。</p>
<hr />
<p>我们将要创建一个到名为 <strong>newImage</strong> 的分支。</p>
<p><img src="https://pbs.twimg.com/media/F6oE_4BbwAA18iQ?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git branch newimage</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6oIMSQacAAGNrj?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>创建分支就是这么容易！新创建的分支 <strong>newImage</strong> 指向的是提交记录 <strong>C1</strong>。</p>
<p>现在咱们试着往新分支里提交一些东西。点击下面的按钮</p>
<p>执行：<code>Git Commit</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oJJntaIAAPlVf?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>为什么 <strong>main</strong> 分支前进了，但 <strong>newImage</strong> 分支还待在原地呢？！这是因为我们没有“在”这个新分支上，看到 <strong>main</strong> 分支上的那个星号（*）了吗？这表示当前所在的分支是 <strong>main</strong>。</p>
<p>现在咱们告诉 Git 我们想要切换到新的分支上</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oIMSQacAAGNrj?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout newimage;git commit</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oKYkgacAEVU9g?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>我们的修改已经保存到新的分支里了。</p>
<p>🌟创建分支并切换到新分支：<code>git checkout -b &lt;your branch name&gt;</code></p>
<br>
<h2 id="3分支与合并"><a class="markdownIt-Anchor" href="#3分支与合并"></a> 3.分支与合并</h2>
<p>如何将两个分支合并到一起。就是说我们新建一个分支，在其上开发某个新功能，开发完成后再合并回主线。</p>
<Br>
<h2 id="31-第一种方法-git-merge"><a class="markdownIt-Anchor" href="#31-第一种方法-git-merge"></a> 3.1 第一种方法: <code>git merge</code></h2>
<p>在 Git 中合并两个分支时会产生一个特殊的提交记录，它有两个 parent 节点。翻译成自然语言相当于：“我要把这两个 parent 节点本身及它们所有的祖先都包含进来。”</p>
<hr />
<p>我们准备了两个分支，每个分支上各有一个独有的提交。这意味着没有一个分支包含了我们修改的所有内容。咱们通过合并这两个分支来解决这个问题。</p>
<p>我们要把 <strong>bugFix</strong> 合并到 <strong>main</strong> 里</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oNJozawAAQIgd?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git merge bugFix</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oNgQJbcAA7Vcz?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>首先，<strong>main</strong> 现在指向了一个拥有两个 parent 节点的提交记录。假如从 <strong>main</strong> 开始沿着箭头向上看，在到达起点的路上会经过所有的提交记录。这意味着 <strong>main</strong> 包含了对代码库的所有修改。</p>
<p>咱们再把 <strong>main</strong> 分支合并到 <strong>bugFix</strong>：</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oT2PDa0AAFK_J?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git checkout bugFix; git merge main</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6oU8Rma0AAgc8Z?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>因为 <strong>main</strong> 继承自 <strong>bugFix</strong>，Git 什么都不用做，只是简单地把 <strong>bugFix</strong> 移动到 <strong>main</strong> 所指向的那个提交记录。</p>
<p>现在所有提交记录的颜色都一样了，这表明每一个分支都包含了代码库的所有修改！大功告成！</p>
<Br>
<h2 id="32-第二种合并分支的方法是-git-rebase"><a class="markdownIt-Anchor" href="#32-第二种合并分支的方法是-git-rebase"></a> 3.2 第二种合并分支的方法是: <code>git rebase</code></h2>
<p><strong>Rebase</strong> 实际上就是取出一系列的提交记录，“复制”它们，然后在另外一个地方逐个的放下去。</p>
<p><strong>Rebase</strong> 的优势就是可以创造更线性的提交历史，这听上去有些难以理解。如果只允许使用 <strong>Rebase</strong> 的话，代码库的提交历史将会变得异常清晰。</p>
<hr />
<p>还是准备了两个分支；注意当前所在的分支是 <strong>bugFix</strong>（星号标识的是当前分支）</p>
<p>我们想要把 <strong>bugFix</strong> 分支里的工作直接移到 <strong>main</strong> 分支上。移动以后会使得两个分支的功能看起来像是按顺序开发，但实际上它们是并行开发的。</p>
<p>咱们这次用 <code>git rebase</code> 实现此目标</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oaglTakAA6vKF?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git rebase main</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oazDEbEAA5rIB?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>现在 <strong>bugFix</strong> 分支上的工作在 <strong>main</strong> 的最顶端，同时我们也得到了一个更线性的提交序列。</p>
<p>注意，提交记录 <strong>C3</strong> 依然存在（树上那个半透明的节点），而 <strong>C3’</strong> 是我们 <code>Rebase</code> 到 <strong>main</strong> 分支上的 <strong>C3</strong> 的副本。</p>
<p>现在唯一的问题就是 <strong>main</strong> 还没有更新，下面咱们就来更新它吧……</p>
<p>执行：<code>git checkout main</code></p>
<p>现在我们切换到了 <strong>main</strong> 上。把它 <code>rebase</code> 到 <strong>bugFix</strong> 分支上……</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6objMnbIAAkbCr?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git rebase bugFix</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ocY7aagAAn7zW?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>由于 <strong>bugFix</strong> 继承自 <strong>main</strong>，所以 Git 只是简单的把 <strong>main</strong> 分支的引用向前移动了一下而已。</p>
<br>
<h2 id="在提交树上移动"><a class="markdownIt-Anchor" href="#在提交树上移动"></a> 在提交树上移动</h2>
<p>在接触 Git 更高级功能之前，我们有必要先学习在你项目的提交树上前后移动的几种方法。</p>
<p>一旦熟悉了如何在 Git 提交树上移动，你驾驭其它命令的能力也将水涨船高！</p>
<br>
<h2 id="4head可以粗略地理解为指向带星号的东西"><a class="markdownIt-Anchor" href="#4head可以粗略地理解为指向带星号的东西"></a> 4.HEAD:可以粗略地理解为指向带星号的东西？</h2>
<p>我们首先看一下 “<strong>HEAD</strong>”。 <strong>HEAD</strong> 是一个对当前所在分支的符号引用 —— 也就是指向你正在其基础上进行工作的提交记录。</p>
<p><strong>HEAD</strong> 总是指向当前分支上最近一次提交记录。大多数修改提交树的 Git 命令都是从改变 <strong>HEAD</strong> 的指向开始的。</p>
<p><strong>HEAD</strong> 通常情况下是指向分支名的（如 <strong>bugFix</strong>）。在你提交时，改变了 <strong>bugFix</strong> 的状态，这一变化通过 HEAD 变得可见。</p>
<hr />
<p>下面咱们通过实际操作看一下。我们将会观察提交前后 HEAD 的位置。</p>
<p>分离的 HEAD 就是让其指向了某个具体的提交记录而不是分支名。在命令执行之前的状态如下所示：</p>
<p><code>HEAD -&gt; main -&gt; C1</code></p>
<p>HEAD 指向 main， main 指向 C1</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ofL2qa8AAFgvJ?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout C1</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oiu5ebcAAxqfD?format=webp&amp;name=900x900" alt="" /></p>
<p>现在变成了</p>
<p><code>HEAD -&gt; C1</code></p>
<Br>
<h2 id="5相对引用"><a class="markdownIt-Anchor" href="#5相对引用"></a> 5.相对引用</h2>
<p>通过指定提交记录哈希值的方式在 Git 中移动不太方便。在实际应用时，并没有像本程序中这么漂亮的可视化提交树供你参考，所以你就不得不用 <code>git log</code> 来查查看提交记录的哈希值。</p>
<p>并且哈希值在真实的 Git 世界中也会更长（译者注：基于 SHA-1，共 40 位）。例如前一关的介绍中的提交记录的哈希值可能是 <strong>fed2da64c0efc5293610bdd892f82a58e8cbc5d8</strong>。舌头都快打结了吧…</p>
<p>比较令人欣慰的是，Git 对哈希的处理很智能。你只需要提供能够唯一标识提交记录的前几个字符即可。因此我可以仅输入<strong>fed2</strong> 而不是上面的一长串字符。</p>
<p>正如我前面所说，通过哈希值指定提交记录很不方便，所以 Git 引入了相对引用。这个就很厉害了!</p>
<p>使用相对引用的话，你就可以从一个易于记忆的地方（比如 <strong>bugFix</strong> 分支或 <strong>HEAD</strong>）开始计算。</p>
<p>相对引用非常给力，这里我介绍两个简单的用法：</p>
<ul>
<li>使用 <code>^</code> 向上移动 1 个提交记录</li>
<li>使用 <code>~&lt;num&gt;</code> 向上移动多个提交记录，如 <code>~3</code></li>
</ul>
<br>
<h2 id="51-操作符"><a class="markdownIt-Anchor" href="#51-操作符"></a> 5.1 “^” 操作符</h2>
<hr />
<p>首先看看操作符 <code>^</code>。把这个符号加在引用名称的后面，表示让 Git 寻找指定提交记录的 parent 提交。</p>
<p>所以 <strong>main^</strong> 相当于“<strong>main</strong> 的 parent 节点”。</p>
<p><strong>main^^</strong> 是 <strong>main</strong> 的第二个 parent 节点</p>
<p>现在咱们切换到 <strong>main</strong> 的 parent 节点</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6okYC-aMAAuzVf?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout main^</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6oksW9bwAAb_b5?format=webp&amp;name=900x900" alt="" /></p>
<br>
<h2 id="52-~-操作符"><a class="markdownIt-Anchor" href="#52-~-操作符"></a> 5.2 “~” 操作符</h2>
<p>如果你想在提交树中向上移动很多步的话，敲那么多 <code>^</code> 貌似也挺烦人的，Git 当然也考虑到了这一点，于是又引入了操作符 <code>~</code>。</p>
<p>该操作符后面可以跟一个数字（可选，不跟数字时与 <code>^</code> 相同，向上移动一次），指定向上移动多少次。咱们还是通过实际操作看一下吧</p>
<hr />
<p>咱们用 <code>~&lt;num&gt;</code> 一次后退四步。</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6onAbraYAApVXx?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout HEAD~4</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6onl4rakAALfzT?format=webp&amp;name=900x900" alt="" /></p>
<br>
<h2 id="53-强制修改分支位置"><a class="markdownIt-Anchor" href="#53-强制修改分支位置"></a> 5.3 强制修改分支位置</h2>
<p>你现在是相对引用的专家了，现在用它来做点实际事情。</p>
<p>我使用相对引用最多的就是移动分支。可以直接使用 <code>-f</code> 选项让分支指向另一个提交。例如:</p>
<p><code>git branch -f main HEAD~3</code></p>
<p>上面的命令会将 <strong>main</strong> 分支强制指向 <strong>HEAD</strong> 的第 3 级 parent 提交。</p>
<hr />
<br>
<p><img src="https://pbs.twimg.com/media/F6ooe23bsAAnOIn?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git branch -f main HEAD~3</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ooyYta8AAgLcg?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>这就对了! 相对引用为我们提供了一种简洁的引用提交记录 <strong>C1</strong> 的方式， 而 <code>-f</code> 则容许我们将分支强制移动到那个位置。</p>
<Br>
<h2 id="6撤销变更"><a class="markdownIt-Anchor" href="#6撤销变更"></a> 6.撤销变更</h2>
<p>在 Git 里撤销变更的方法很多。和提交一样，撤销变更由底层部分（暂存区的独立文件或者片段）和上层部分（变更到底是通过哪种方式被撤销的）组成。我们这个应用主要关注的是后者。</p>
<p>主要有两种方法用来撤销变更</p>
<ul>
<li><code>git reset</code></li>
<li><code>git revert</code></li>
</ul>
<Br>
<h2 id="61-本地git-reset撤销的时候接的是上一个提交记录"><a class="markdownIt-Anchor" href="#61-本地git-reset撤销的时候接的是上一个提交记录"></a> 6.1 (本地)Git Reset:撤销的时候接的是上一个提交记录</h2>
<p><code>git reset</code> 通过把分支记录回退几个提交记录来实现撤销改动。你可以将这想象成“改写历史”。<code>git reset</code> 向上移动分支，原来指向的提交记录就跟从来没有提交过一样。</p>
<hr />
<p><img src="https://pbs.twimg.com/media/F6orJhObgAADZtk?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行:<code>git reset HEAD~1</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6orn1dbkAAh3Ec?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>漂亮! Git 把 <strong>main</strong> 分支移回到 <strong>C1</strong>；现在我们的本地代码库根本就不知道有 <strong>C2</strong> 这个提交了(译者注：在reset后， C2 所做的变更还在，但是处于未加入暂存区状态。)</p>
<br>
<h2 id="62-远程git-revert撤销的时候接的是当前提交记录"><a class="markdownIt-Anchor" href="#62-远程git-revert撤销的时候接的是当前提交记录"></a> 6.2 (远程)Git Revert：撤销的时候接的是当前提交记录</h2>
<p>虽然在你的本地分支中使用 <code>git reset</code> 很方便，但是这种“改写历史”的方法对大家一起使用的远程分支是无效的哦！</p>
<hr />
<p>为了撤销更改并分享给别人，我们需要使用 <code>git revert</code>。来看演示:</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6orJhObgAADZtk?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git revert HEAD</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6os1Cob0AAF0SI?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>奇怪！在我们要撤销的提交记录后面居然多了一个新提交！这是因为新提交记录 <strong>C2’</strong> 引入了更改 —— 这些更改刚好是用来撤销 <strong>C2</strong> 这个提交的。也就是说 <strong>C2’</strong> 的状态与 <strong>C1</strong> 是相同的。</p>
<p><code>revert</code> 之后就可以把你的更改推送到远程仓库与别人分享啦。</p>
<br>
<h2 id="7整理提交记录"><a class="markdownIt-Anchor" href="#7整理提交记录"></a> 7.整理提交记录</h2>
<p>到现在我们已经学习了 Git 的基础知识 —— 提交、分支以及在提交树上移动。 这些概念涵盖了 Git 90% 的功能，同样也足够满足开发者的日常需求</p>
<p>然而, 剩余的 10% 在处理复杂的工作流时(或者当你陷入困惑时）可能就显得尤为重要了。接下来要讨论的这个话题是“整理提交记录” —— 开发人员有时会说“我想要把这个提交放到这里, 那个提交放到刚才那个提交的后面”, 而接下来就讲的就是它的实现方式，非常清晰、灵活，还很生动。</p>
<p>看起来挺复杂, 其实是个很简单的概念。</p>
<br>
<h2 id="71-git-cherry-pick"><a class="markdownIt-Anchor" href="#71-git-cherry-pick"></a> 7.1 Git Cherry-pick</h2>
<p>本系列的第一个命令是 <code>git cherry-pick</code>, 命令形式为:</p>
<ul>
<li><code>git cherry-pick &lt;提交号&gt;...</code></li>
</ul>
<p>如果你想将一些提交复制到当前所在的位置 <strong>（HEAD）</strong> 下面的话， <code>Cherry-pick</code> 是最直接的方式了。我个人非常喜欢 <code>cherry-pick</code>，因为它特别简单。</p>
<p>咱们还是通过例子来看一下！</p>
<hr />
<p>这里有一个仓库, 我们想将 <strong>side</strong> 分支上的工作复制到 <strong>main</strong> 分支，你立刻想到了之前学过的 <code>rebase</code> 了吧？但是咱们还是看看 <code>cherry-pick</code> 有什么本领吧。</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ovwDjaEAADvaP?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git cherry-pick C2 C4</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ozXmZbIAAhT6T?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>这就是了！我们只需要提交记录 C2 和 C4，所以 Git 就将被它们抓过来放到当前分支下了。 就是这么简单!</p>
<br>
<h2 id="72-交互式rebase"><a class="markdownIt-Anchor" href="#72-交互式rebase"></a> 7.2 交互式rebase</h2>
<p>当你知道你所需要的提交记录（并且还知道这些提交记录的哈希值）时, 用 <code>cherry-pick</code> 再好不过了 —— 没有比这更简单的方式了。</p>
<p>但是如果你不清楚你想要的提交记录的哈希值呢? 幸好 Git 帮你想到了这一点, 我们可以利用交互式的 <code>rebase</code> —— 如果你想从一系列的提交记录中找到想要的记录, 这就是最好的方法了</p>
<p>咱们具体来看一下……</p>
<p>交互式 <code>rebase</code> 指的是使用带参数 <code>--interactive</code> 的 <code>rebase</code> 命令, 简写为 <code>-i</code></p>
<p>如果你在命令后增加了这个选项, Git 会打开一个 UI 界面并列出将要被复制到目标分支的备选提交记录，它还会显示每个提交记录的哈希值和提交说明，提交说明有助于你理解这个提交进行了哪些更改。</p>
<p>在实际使用时，所谓的 UI 窗口一般会在文本编辑器 —— 如 Vim —— 中打开一个文件。 考虑到课程的初衷，我弄了一个对话框来模拟这些操作。</p>
<p>当 rebase UI界面打开时, 你能做3件事:</p>
<ul>
<li>调整提交记录的顺序（通过鼠标拖放来完成）</li>
<li>删除你不想要的提交（通过切换 pick 的状态来完成，关闭就意味着你不想要这个提交记录）</li>
<li>合并提交。 遗憾的是由于某种逻辑的原因，我们的课程不支持此功能，因此我不会详细介绍这个操作。简而言之，它允许你把多个提交记录合并成一个。</li>
</ul>
<hr />
<p>当你点击下面的按钮时，会出现一个交互对话框。对提交记录做个排序（当然你也可以删除某些提交），点击确定看结果</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pT7rbaAAQ_6qu?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git rebase -i HEAD~4</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pUUxYaAAQ-EU5?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>Git 严格按照你在对话框中指定的方式进行了复制。</p>
<br>
<h2 id="8本地栈式提交"><a class="markdownIt-Anchor" href="#8本地栈式提交"></a> 8.本地栈式提交</h2>
<p>来看一个在开发中经常会遇到的情况：我正在解决某个特别棘手的 Bug，为了便于调试而在代码中添加了一些调试命令并向控制台打印了一些信息。</p>
<p>这些调试和打印语句都在它们各自的提交记录里。最后我终于找到了造成这个 Bug 的根本原因，解决掉以后觉得沾沾自喜！</p>
<p>最后就差把 bugFix 分支里的工作合并回 main 分支了。你可以选择通过 fast-forward 快速合并到 main 分支上，但这样的话 main 分支就会包含我这些调试语句了。你肯定不想这样，应该还有更好的方式……</p>
<p>实际我们只要让 Git 复制解决问题的那一个提交记录就可以了。跟之前我们在“整理提交记录”中学到的一样，我们可以使用</p>
<ul>
<li><code>git rebase -i</code></li>
<li><code>git cherry-pick</code></li>
</ul>
<p>来达到目的。</p>
<br>
<h2 id="9提交的技巧"><a class="markdownIt-Anchor" href="#9提交的技巧"></a> 9.提交的技巧</h2>
<h2 id="91-提交技巧1"><a class="markdownIt-Anchor" href="#91-提交技巧1"></a> 9.1 提交技巧1</h2>
<p>接下来这种情况也是很常见的：你之前在 newImage 分支上进行了一次提交，然后又基于它创建了 <strong>caption</strong> 分支，然后又提交了一次。</p>
<p>此时你想对某个以前的提交记录进行一些小小的调整。比如设计师想修改一下 newImage 中图片的分辨率，尽管那个提交记录并不是最新的了。</p>
<p>我们可以通过下面的方法来克服困难：</p>
<ul>
<li>先用 <code>git rebase -i</code> 将提交重新排序，然后把我们想要修改的提交记录挪到最前</li>
<li>然后用 <code>git commit --amend</code> 来进行一些小修改</li>
<li>接着再用 <code>git rebase -i</code> 来将他们调回原来的顺序</li>
<li>最后我们把 <strong>main</strong> 移到修改的最前端（用你自己喜欢的方法），就大功告成啦！</li>
</ul>
<p>当然完成这个任务的方法不止上面提到的一种（我知道你在看 cherry-pick 啦），之后我们会多点关注这些技巧啦，但现在暂时只专注上面这种方法。 最后有必要说明一下目标状态中的那几个<code>'</code> —— 我们把这个提交移动了两次，每移动一次会产生一个 <code>'</code>；而 C2 上多出来的那个是我们在使用了 amend 参数提交时产生的，所以最终结果就是这样了。</p>
<p>也就是说，我在对比结果的时候只会对比提交树的结构，对于 <code>'</code> 的数量上的不同，并不纳入对比范围内。只要你的 <strong>main</strong> 分支结构与目标结构相同，我就算你通过。</p>
<br>
<h2 id="92-提交技巧2"><a class="markdownIt-Anchor" href="#92-提交技巧2"></a> 9.2 提交技巧2</h2>
<p>如果你还没有完成“提交的技巧 #1”（前一关）的话，请先通过以后再来！</p>
<p>正如你在上一关所见到的，我们可以使用 <code>rebase -i</code> 对提交记录进行重新排序。只要把我们想要的提交记录挪到最前端，我们就可以很轻松的用 --amend 修改它，然后把它们重新排成我们想要的顺序。</p>
<p>但这样做就唯一的问题就是要进行两次排序，而这有可能造成由 <code>rebase</code> 而导致的冲突。下面还是看看 <code>git cherry-pick</code> 是怎么做的吧。</p>
<hr />
<p>要在心里牢记 cherry-pick 可以将提交树上任何地方的提交记录取过来追加到 HEAD 上（只要不是 HEAD 上游的提交就没问题）。</p>
<br>
<h2 id="10git-tags"><a class="markdownIt-Anchor" href="#10git-tags"></a> 10.Git Tags</h2>
<p>相信通过前面课程的学习你已经发现了：分支很容易被人为移动，并且当有新的提交时，它也会移动。分支很容易被改变，大部分分支还只是临时的，并且还一直在变。</p>
<p>你可能会问了：有没有什么可以永远指向某个提交记录的标识呢，比如软件发布新的大版本，或者是修正一些重要的 Bug 或是增加了某些新特性，有没有比分支更好的可以永远指向这些提交的方法呢？</p>
<p>当然有了！Git 的 tag 就是干这个用的啊，它们可以（在某种程度上 —— 因为标签可以被删除后重新在另外一个位置创建同名的标签）永久地将某个特定的提交命名为里程碑，然后就可以像分支一样引用了。</p>
<p>更难得的是，它们并不会随着新的提交而移动。你也不能切换到某个标签上面进行修改提交，它就像是提交树上的一个锚点，标识了某个特定的位置。</p>
<p>咱们来看看标签到底是什么样。</p>
<hr />
<p>咱们先建立一个标签，指向提交记录 C1，表示这是我们 1.0 版本。</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pbSwBaEAATkeZ?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git tag v1 C1</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pbhrSaAAErp6V?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>很容易吧！我们将这个标签命名为 v1，并且明确地让它指向提交记录 C1，如果你不指定提交记录，Git 会用 HEAD 所指向的位置。</p>
<br>
<h2 id="11-git-describe"><a class="markdownIt-Anchor" href="#11-git-describe"></a> 11. Git Describe</h2>
<p>由于标签在代码库中起着“锚点”的作用，Git 还为此专门设计了一个命令用来描述离你最近的锚点（也就是标签），它就是 <code>git describe</code>！</p>
<p><code>Git Describe</code> 能帮你在提交历史中移动了多次以后找到方向；当你用 <code>git bisect</code>（一个查找产生 Bug 的提交记录的指令）找到某个提交记录时，或者是当你坐在你那刚刚度假回来的同事的电脑前时， 可能会用到这个命令。</p>
<Br>
<p><code>git describe</code> 的​​语法是：<code>git describe &lt;ref&gt;</code></p>
<p><code>&lt;ref&gt;</code> 可以是任何能被 Git 识别成提交记录的引用，如果你没有指定的话，Git 会使用你目前所在的位置（<strong>HEAD</strong>）。</p>
<br>
<p>它输出的结果是这样的：<br />
<code>&lt;tag&gt;_&lt;numCommits&gt;_g&lt;hash&gt;</code></p>
<p><code>tag</code> 表示的是离 <code>ref</code> 最近的标签， <code>numCommits</code> 是表示这个 <code>ref</code> 与 <code>tag</code> 相差有多少个提交记录， <code>hash</code> 表示的是你所给定的 <code>ref</code> 所表示的提交记录哈希值的前几位。</p>
<p>当 <code>ref</code> 提交记录上有某个标签时，则只输出标签名称</p>
<hr />
<p>让我们来看一个例子，对于下面的提交树：</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pd36waAAEcC4G?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git tag v2 C3</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6peRdjaAAAyJyF?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p><code>git describe main</code> 会输出：<code>v1_2_gC2</code></p>
<p><code>git describe side</code> 会输出：<code>v2_1_gC4</code></p>
<br>
<h2 id="12多分支rebase"><a class="markdownIt-Anchor" href="#12多分支rebase"></a> 12.多分支rebase</h2>
<p>哇，现在我们这里出现了很多分支呢！让我们把所有这些分支上所做的工作都通过<code>rebase</code> 合并到 <strong>main</strong> 分支上吧。</p>
<p>但是你的领导给你提了点要求 —— 他们希望得到有序的提交历史，也就是我们最终的结果应该是 <strong>C6’</strong> 在 <strong>C7’</strong> 上面， <strong>C5’</strong> 在 <strong>C6’</strong> 上面，依此类推。</p>
<p>即使你搞砸了也没关系，用 <code>reset</code> 命令就可以重新开始了。记得看看我们提供的答案，看你能否使用更少的命令来完成任务</p>
<h2 id="13选择-parent-提交记录"><a class="markdownIt-Anchor" href="#13选择-parent-提交记录"></a> 13.选择 parent 提交记录</h2>
<p>操作符 <code>^</code> 与 <code>~</code> 符一样，后面也可以跟一个数字。</p>
<p>但是该操作符后面的数字与 <code>~</code> 后面的不同，并不是用来指定向上返回几代，而是指定合并提交记录的某个 parent 提交。还记得前面提到过的一个合并提交有两个 parent 提交吧，所以遇到这样的节点时该选择哪条路径就不是很清晰了。</p>
<p>Git 默认选择合并提交的“第一个” parent 提交，在操作符 <code>^</code> 后跟一个数字可以改变这一默认行为。</p>
<p>废话不多说，举个例子。</p>
<hr />
<p>现在来试试选择另一个 parent 提交……</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pkO2QaAAItIZ9?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout main^2</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6pkgwAaAAAYsE1?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>看见了吧？我们回到了另外一个 parent 提交上。</p>
<p>更厉害的是，这些操作符还支持链式操作！试一下这个：</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6plN7rbMAAyflQ?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout HEAD~^2~2</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6plo55aIAAWev2?format=webp&amp;name=900x900" alt="" /></p>
<br>
<h2 id="14纠缠不清的分支~纠缠不清的关系"><a class="markdownIt-Anchor" href="#14纠缠不清的分支~纠缠不清的关系"></a> 14.纠缠不清的分支～纠缠不清的关系</h2>
<p>哇塞大神！这关我们要来点不同的！</p>
<p>现在我们的 main 分支是比 one、two 和 three 要多几个提交。出于某种原因，我们需要把 main 分支上最近的几次提交做不同的调整后，分别添加到各个的分支上。</p>
<p>one 需要重新排序并删除 C5，two 仅需要重排排序，而 three 只需要提交一次。</p>
<p>慢慢来，你会找到答案的 —— 记得通关之后用 show solution 看看我们的答案哦。</p>
<br>
<h2 id="远程仓库"><a class="markdownIt-Anchor" href="#远程仓库"></a> 远程仓库</h2>
<p>远程仓库并不复杂, 在如今的云计算盛行的世界很容易把远程仓库想象成一个富有魔力的东西, 但实际上它们只是你的仓库在另个一台计算机上的拷贝。你可以通过因特网与这台计算机通信 —— 也就是增加或是获取提交记录</p>
<p>话虽如此, 远程仓库却有一系列强大的特性</p>
<p>首先也是最重要的的点, 远程仓库是一个强大的备份。本地仓库也有恢复文件到指定版本的能力, 但所有的信息都是保存在本地的。有了远程仓库以后，即使丢失了本地所有数据, 你仍可以通过远程仓库拿回你丢失的数据。</p>
<p>还有就是, 远程让代码社交化了! 既然你的项目被托管到别的地方了, 你的朋友可以更容易地为你的项目做贡献(或者拉取最新的变更)</p>
<p>现在用网站来对远程仓库进行可视化操作变得越发流行了(像 GitHub), 但远程仓库永远是这些工具的顶梁柱, 因此理解其概念非常的重要!</p>
<Br>
<h2 id="15创建远程仓库的命令"><a class="markdownIt-Anchor" href="#15创建远程仓库的命令"></a> 15.创建远程仓库的命令</h2>
<p>直到现在, 教程都聚焦于本地仓库的操作（<code>branch</code>、<code>merge</code>、<code>rebase</code> 等等）。但我们现在需要学习远程仓库的操作 —— 我们需要一个配置这种环境的命令, 它就是 <code>git clone</code>。 从技术上来讲，<code>git clone</code> 命令在真实的环境下的作用是在本地创建一个远程仓库的拷贝（比如从 <a href="http://github.com">github.com</a>）。 但在我们的教程中使用这个命令会有一些不同 —— 它会在远程创建一个你本地仓库的副本。显然这和真实命令的意思刚好相反，但是它帮咱们把本地仓库和远程仓库关联到了一起，在教程中就凑合着用吧</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ppcuQaAAEk4hX?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git clone</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6ppqL1aAAArUQ1?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>就是它了! 现在我们有了一个自己项目的远程仓库。除了远程仓库使用虚线之外, 它们几乎没有什么差别 —— 在后面的关卡中, 你将会学习怎样在本地仓库和远程仓库间分享工作成果。</p>
<h2 id="16远程分支"><a class="markdownIt-Anchor" href="#16远程分支"></a> 16.远程分支</h2>
<p>既然你已经看过 <code>git clone</code> 命令了，咱们深入地看一下发生了什么。</p>
<p>你可能注意到的第一个事就是在我们的本地仓库多了一个名为 <strong>o/main</strong> 的分支, 这种类型的分支就叫远程分支。由于远程分支的特性导致其拥有一些特殊属性。</p>
<p>远程分支反映了远程仓库(在你上次和它通信时)的状态。这会有助于你理解本地的工作与公共工作的差别 —— 这是你与别人分享工作成果前至关重要的一步.</p>
<p>远程分支有一个特别的属性，在你切换到远程分支时，自动进入分离 HEAD 状态。Git 这么做是出于不能直接在这些分支上进行操作的原因, 你必须在别的地方完成你的工作, （更新了远程分支之后）再用远程分享你的工作成果。</p>
<Br>
<p>为什么有 o/？</p>
<p>你可能想问这些远程分支的前面的 o/ 是什么意思呢？好吧, 远程分支有一个命名规范 —— 它们的格式是:<code>&lt;remote name&gt;/&lt;branch name&gt;</code></p>
<p>因此，如果你看到一个名为 o/main 的分支，那么这个分支就叫 main，远程仓库的名称就是 o。</p>
<br>
<p>大多数的开发人员会将它们主要的远程仓库命名为 <strong>origin</strong>，并不是 o。这是因为当你用 <code>git clone</code> 某个仓库时，Git 已经帮你把远程仓库的名称设置为 <strong>origin</strong> 了</p>
<p>不过 <strong>origin</strong> 对于我们的 UI 来说太长了，因此不得不使用简写 o 😃 但是要记住, 当你使用真正的 Git 时, 你的远程仓库默认为 <strong>origin</strong>!</p>
<p>说了这么多，让我们看看实例:</p>
<p>–<br />
如果切换到远程分支会怎么样呢？</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6pq_o_aAAALwi9?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout o/main; git commit</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6prWncaAAQAf89?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>正如你所见，Git 变成了分离 <strong>HEAD</strong> 状态，当添加新的提交时 <strong>o/main</strong> 也不会更新。这是因为 <strong>o/main</strong> 只有在远程仓库中相应的分支更新了以后才会更新。</p>
<Br>
<h2 id="17-git-fetch"><a class="markdownIt-Anchor" href="#17-git-fetch"></a> 17. Git Fetch</h2>
<p>Git 远程仓库相当的操作实际可以归纳为两点：向远程仓库传输数据以及从远程仓库获取数据。既然我们能与远程仓库同步，那么就可以分享任何能被 Git 管理的更新（因此可以分享代码、文件、想法、情书等等）。</p>
<p>本节课我们将学习如何从远程仓库获取数据 —— 命令如其名，它就是 <code>git fetch</code>。</p>
<p>你会看到当我们从远程仓库获取数据时, 远程分支也会更新以反映最新的远程仓库。在上一节课程中我们已经提及过这一点了</p>
<hr />
<p>在解释 <code>git fetch</code> 前，我们先看看实例。这里我们有一个远程仓库, 它有两个我们本地仓库中没有的提交。</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6twRSyagAAliK9?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fetch</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6twpFGbsAAHJPl?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>就是这样了! <strong>C2</strong>,<strong>C3</strong> 被下载到了本地仓库，同时远程分支 <strong>o/main</strong> 也被更新，反映到了这一变化</p>
<p><code>git fetch</code> 做了些什么</p>
<p><code>git fetch</code> 完成了仅有的但是很重要的两步:</p>
<ul>
<li>从远程仓库下载本地仓库中缺失的提交记录</li>
<li>更新远程分支指针(如 o/main)<br />
<code>git fetch</code> 实际上将本地仓库中的远程分支更新成了远程仓库相应分支最新的状态。</li>
</ul>
<p>如果你还记得上一节课程中我们说过的，远程分支反映了远程仓库在你最后一次与它通信时的状态，<code>git fetch</code> 就是你与远程仓库通信的方式了！希望我说的够明白了，你已经了解 <code>git fetch</code>  与远程分支之间的关系了吧。</p>
<p><code>git fetch</code> 通常通过互联网（使用 <strong>http://</strong> 或 <strong>git://</strong> 协议) 与远程仓库通信</p>
<p><code>git fetch</code> 不会做的事</p>
<p><code>git fetch</code> 并不会改变你本地仓库的状态。它不会更新你的 main 分支，也不会修改你磁盘上的文件。</p>
<p>理解这一点很重要，因为许多开发人员误以为执行了 <code>git fetch</code>以后，他们本地仓库就与远程仓库同步了。它可能已经将进行这一操作所需的所有数据都下载了下来，但是并没有修改你本地的文件。我们在后面的课程中将会讲解能完成该操作的命令 😄</p>
<p>所以, 你可以将 <code>git fetch</code> 的理解为单纯的下载操作。</p>
<Br>
<h2 id="18git-pull"><a class="markdownIt-Anchor" href="#18git-pull"></a> 18.Git Pull</h2>
<p>既然我们已经知道了如何用 git fetch 获取远程的数据, 现在我们学习如何将这些变化更新到我们的工作当中。</p>
<p>其实有很多方法的 —— 当远程分支中有新的提交时，你可以像合并本地分支那样来合并远程分支。也就是说就是你可以执行以下命令:</p>
<ul>
<li>git cherry-pick o/main</li>
<li>git rebase o/main</li>
<li>git merge o/main</li>
<li>等等</li>
</ul>
<p>实际上，由于先抓取更新再合并到本地分支这个流程很常用，因此 Git 提供了一个专门的命令来完成这两个操作。它就是我们要讲的 <code>git pull</code>。</p>
<hr />
<p>我们先来看看 <code>fetch、merge</code>依次执行的效果</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6tzS0Wa0AAojKJ?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fetch;git merge o/main</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6tz80SbcAAGl1A?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>我们用 <code>fetch</code> 下载了 <strong>C3</strong>, 然后通过 <code>git merge o/main</code> 合并了这一提交记录。现在我们的 <strong>main</strong> 分支包含了远程仓库中的更新（在本例中远程仓库名为 <strong>origin</strong>）</p>
<p>如果使用<code>git pull</code>呢</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6tzS0Wa0AAojKJ?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>同样的结果！这清楚地说明了 <code>git pull</code> 就是 <code>git fetch</code> 和 <code>git merge</code> 的缩写！</p>
<BR>
<h2 id="19模拟团队合作"><a class="markdownIt-Anchor" href="#19模拟团队合作"></a> 19.模拟团队合作</h2>
<p>这里有一件棘手的事 —— 为了接下来的课程, 我们需要先教你如何制造远程仓库的变更。</p>
<p>这意味着，我们需要“假装”你的同事、朋友、合作伙伴更新了远程仓库，有可能是某个特定的分支，或是几个提交记录。</p>
<p>为了做到这点，我们引入一个自造命令 <code>git fakeTeamwork</code>！它的名称已经说明了一切，先看演示…</p>
<hr />
<p><code>fakeTeamwork</code> 默认操作就是在远程仓库的 <strong>main</strong> 分支上做一次提交</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6t1W2MaEAAK-Kj?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行: <code>git fakeTeamwork</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6t1vVQbsAAD3dc?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>完成了 —— 远程仓库增加了一个新提交，我们还没有下载它，因为我们还没有执行 <code>git fetch</code>。</p>
<p>你还可以指定提交的分支或是数量，只需要在命令后加上它们就可以了。</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6t2KPqa4AAaxqD?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fakeTeamwork  foo 3</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6t2bwybUAA8oZd?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>通过一个命令，我们就模拟队友推送了 3 个提交记录到远程仓库的 foo 分支。</p>
<br>
<h2 id="20git-push"><a class="markdownIt-Anchor" href="#20git-push"></a> 20.Git Push</h2>
<p>OK，我们已经学过了如何从远程仓库获取更新并合并到本地的分支当中。这非常棒……但是我如何与大家分享我的成果呢？</p>
<p>嗯，上传自己分享内容与下载他人的分享刚好相反，那与 <code>git pull</code> 相反的命令是什么呢？<code>git push</code>！</p>
<p><code>git push</code>负责将你的变更上传到指定的远程仓库，并在远程仓库上合并你的新提交记录。一旦 <code>git push</code> 完成, 你的朋友们就可以从这个远程仓库下载你分享的成果了！</p>
<p>你可以将 <code>git push</code> 想象成发布你成果的命令。它有许多应用技巧，稍后我们会了解到，但是咱们还是先从基础的开始吧……</p>
<p>注意 —— <code>git push</code> 不带任何参数时的行为与 Git 的一个名为 <strong>push.default</strong> 的配置有关。它的默认值取决于你正使用的 Git 的版本，但是在教程中我们使用的是 <strong>upstream</strong>。 这没什么太大的影响，但是在你的项目中进行推送之前，最好检查一下这个配置</p>
<hr />
<p>这里我们准备了一些远程仓库中没有的提交记录, 咱们开始先上传吧!</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6yuO5XbcAAqbo-?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git push</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6yuf9EaMAAAlMJ?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>过去了, 远程仓库接收了 <strong>C2</strong>，远程仓库中的 main 分支也被更新到指向 <strong>C2</strong> 了，我们的远程分支 (o/main) 也同样被更新了。所有的分支都同步了！</p>
<br>
<h2 id="21偏离的工作"><a class="markdownIt-Anchor" href="#21偏离的工作"></a> 21.偏离的工作</h2>
<p>现在我们已经知道了如何从其它地方 <code>pull</code> 提交记录，以及如何 <code>push</code> 我们自己的变更。看起来似乎没什么难度，但是为何还会让人们如此困惑呢？</p>
<p>困难来自于远程库提交历史的偏离。在讨论这个问题的细节前，我们先来看一个例子……</p>
<p>假设你周一克隆了一个仓库，然后开始研发某个新功能。到周五时，你新功能开发测试完毕，可以发布了。但是 —— 天啊！你的同事这周写了一堆代码，还改了许多你的功能中使用的 API，这些变动会导致你新开发的功能变得不可用。但是他们已经将那些提交推送到远程仓库了，因此你的工作就变成了基于项目旧版的代码，与远程仓库最新的代码不匹配了。</p>
<p>这种情况下, git push 就不知道该如何操作了。如果你执行 git push，Git 应该让远程仓库回到星期一那天的状态吗？还是直接在新代码的基础上添加你的代码，亦或由于你的提交已经过时而直接忽略你的提交？</p>
<p>因为这情况（历史偏离）有许多的不确定性，Git 是不会允许你 push 变更的。实际上它会强制你先合并远程最新的代码，然后才能分享你的工作。</p>
<hr />
<p>说了这么多，咱们还是看看实际案例吧！</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6yv3p-a0AAKBGp?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fetch; git rebase o/main; git push</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6yw6BkakAAXc66?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>我们用 git fetch 更新了本地仓库中的远程分支，然后用 rebase 将我们的工作移动到最新的提交记录下，最后再用 git push 推送到远程仓库。</p>
<hr />
<p>还有其它的方法可以在远程仓库变更了以后更新我的工作吗? 当然有，我们还可以使用 merge</p>
<p>尽管 git merge 不会移动你的工作（它会创建新的合并提交），但是它会告诉 Git 你已经合并了远程仓库的所有变更。这是因为远程分支现在是你本地分支的祖先，也就是说你的提交已经包含了远程分支的所有变化。</p>
<p>看下演示…</p>
<br>
<p><img src="https://pbs.twimg.com/media/F6yv3p-a0AAKBGp?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fetch;git merge o/main;git push</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6yypLRbMAAHTc1?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>我们用 <code>git fetch</code> 更新了本地仓库中的远程分支，然后合并了新变更到我们的本地分支（为了包含远程仓库的变更），最后我们用 <code>git push</code> 把工作推送到远程仓库</p>
<hr />
<p>很好！但是要敲那么多命令，有没有更简单一点的？</p>
<p>当然 —— 前面已经介绍过 <code>git pull</code> 就是 <code>fetch</code> 和 <code>merge</code> 的简写，类似的 <code>git pull --rebase</code> 就是 <code>fetch</code> 和 <code>rebase</code> 的简写！</p>
<p>让我们看看简写命令是如何工作的。</p>
<p>这次用 <code>--rebase</code>……</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6yv3p-a0AAKBGp?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git pull--rebase;git pull</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6y0IeVbYAADPJ-?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>跟之前结果一样，但是命令更短了。</p>
<hr />
<p>换用常规的 <code>pull</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6yv3p-a0AAKBGp?format=webp&amp;name=900x900" alt="" /></p>
<p>执行：<code>git pull;git push</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F6y01GTaEAACTv0?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>还是跟以前一样!</p>
<Br>
<h2 id="22远程服务器拒绝remote-rejected"><a class="markdownIt-Anchor" href="#22远程服务器拒绝remote-rejected"></a> 22.远程服务器拒绝!(Remote Rejected)</h2>
<p>如果你是在一个大的合作团队中工作, 很可能是main被锁定了, 需要一些Pull Request流程来合并修改。如果你直接提交(commit)到本地main, 然后试图推送(push)修改, 你将会收到这样类似的信息:</p>
<p><code>! [远程服务器拒绝] main -&gt; main (TF402455: 不允许推送(push)这个分支; 你必须使用pull request来更新这个分支.)</code></p>
<h2 id="为什么会被拒绝"><a class="markdownIt-Anchor" href="#为什么会被拒绝"></a> 为什么会被拒绝?</h2>
<p>远程服务器拒绝直接推送(push)提交到<strong>main</strong>, 因为策略配置要求 <code>pull requests</code> 来提交更新.</p>
<p>你应该按照流程,新建一个分支, 推送(push)这个分支并申请<code>pull request</code>,但是你忘记并直接提交给了<strong>main</strong>.现在你卡住并且无法推送你的更新</p>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>新建一个分支<strong>feature</strong>, 推送到远程服务器. 然后<code>reset</code>你的<strong>main</strong>分支和远程服务器保持一致, 否则下次你pull并且他人的提交和你冲突的时候就会有问题.</p>
<Br>
<h2 id="23合并特性分支"><a class="markdownIt-Anchor" href="#23合并特性分支"></a> 23.合并特性分支</h2>
<p>既然你应该很熟悉 <code>fetch、pull、push</code> 了，现在我们要通过一个新的工作流来测试你的这些技能。</p>
<p>在大型项目中开发人员通常会在（从 main 上分出来的）特性分支上工作，工作完成后只做一次集成。这跟前面课程的描述很相像（把 side 分支推送到远程仓库），不过本节我们会深入一些.</p>
<p>但是有些开发人员只在 main 上做 <code>push、pull</code> —— 这样的话 <strong>main</strong> 总是最新的，始终与远程分支 (o/main) 保持一致。</p>
<p>对于接下来这个工作流，我们集成了两个步骤：</p>
<ul>
<li>将特性分支集成到 <strong>main</strong> 上</li>
<li>推送并更新远程分支</li>
</ul>
<hr />
<p>让我们看看如何快速的更新<code>main</code> 分支并推送到远程。</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6y4ySRbYAAokdA?format=webp&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git pull --rebase; git push</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F6y5Q41a8AA8cxj?format=webp&amp;name=900x900" alt="" /></p>
<Br>
<p>我们执行了两个命令:</p>
<ul>
<li>将我们的工作 <code>rebase</code> 到远程分支的最新提交记录</li>
<li>向远程仓库推送我们的工作</li>
</ul>
<h2 id="24为什么不用-merge-呢"><a class="markdownIt-Anchor" href="#24为什么不用-merge-呢"></a> 24.为什么不用 merge 呢?</h2>
<p>为了 <code>push</code> 新变更到远程仓库，你要做的就是包含远程仓库中最新变更。意思就是只要你的本地分支包含了远程分支（如 o/main）中的最新变更就可以了，至于具体是用 <code>rebase</code> 还是 <code>merge</code>，并没有限制。</p>
<p>那么既然没有规定限制，为何前面几节都在着重于 <code>rebase</code> 呢？为什么在操作远程分支时不喜欢用 <code>merge</code> 呢？</p>
<p>在开发社区里，有许多关于 merge 与 rebase 的讨论。以下是关于 rebase 的优缺点：</p>
<ul>
<li>优点:Rebase 使你的提交树变得很干净, 所有的提交都在一条线上</li>
<li>缺点:Rebase 修改了提交树的历史，比如, 提交 C1 可以被 rebase 到 C3 之后。这看起来 C1 中的工作是在 C3 之后进行的，但实际上是在 C3 之前。</li>
</ul>
<p>一些开发人员喜欢保留提交历史，因此更偏爱 merge。而其他人（比如我自己）可能更喜欢干净的提交树，于是偏爱 rebase。仁者见仁，智者见智。 😄</p>
<Br>
<h2 id="25远程追踪分支"><a class="markdownIt-Anchor" href="#25远程追踪分支"></a> 25.远程追踪分支</h2>
<p>在前几节课程中有件事儿挺神奇的，Git 好像知道 <strong>main</strong> 与 <strong>o/main</strong> 是相关的。当然这些分支的名字是相似的，可能会让你觉得是依此将远程分支 <strong>main</strong> 和本地的 <strong>main</strong> 分支进行了关联。这种关联在以下两种情况下可以清楚地得到展示：</p>
<ul>
<li><code>pull</code> 操作时, 提交记录会被先下载到 <strong>o/main</strong> 上，之后再合并到本地的 <strong>main</strong> 分支。隐含的合并目标由这个关联确定的。</li>
<li><code>push</code> 操作时, 我们把工作从 <strong>main</strong> 推到远程仓库中的 <strong>main</strong> 分支(同时会更新远程分支 <strong>o/main</strong>) 。这个推送的目的地也是由这种关联确定的！</li>
</ul>
<p>直接了当地讲，<strong>main</strong> 和 <strong>o/main</strong> 的关联关系就是由分支的 <strong>“remote tracking”</strong> 属性决定的。<strong>main</strong> 被设定为跟踪 <strong>o/main</strong> —— 这意味着为 <strong>main</strong> 分支指定了推送的目的地以及拉取后合并的目标。</p>
<p>你可能想知道 <strong>main</strong> 分支上这个属性是怎么被设定的，你并没有用任何命令指定过这个属性呀！好吧, 当你克隆仓库的时候, Git 就自动帮你把这个属性设置好了。</p>
<p>当你克隆时, Git 会为远程仓库中的每个分支在本地仓库中创建一个远程分支（比如 <strong>o/main</strong>）。然后再创建一个跟踪远程仓库中活动分支的本地分支，默认情况下这个本地分支会被命名为 <strong>main</strong>。</p>
<p>克隆完成后，你会得到一个本地分支（如果没有这个本地分支的话，你的目录就是“空白”的），但是可以查看远程仓库中所有的分支（如果你好奇心很强的话）。这样做对于本地仓库和远程仓库来说，都是最佳选择。</p>
<p>这也解释了为什么会在克隆的时候会看到下面的输出：</p>
<p><code>local branch &quot;main&quot; set to track remote branch &quot;o/main&quot;</code></p>
<br>
<p>我能自己指定这个属性吗？</p>
<p>当然可以啦！你可以让任意分支跟踪 <strong>o/main</strong>, 然后该分支会像 <strong>main</strong> 分支一样得到隐含的 <code>push</code> 目的地以及 <code>merge</code> 的目标。 这意味着你可以在分支 <strong>totallyNotMain</strong> 上执行 <code>git push</code>，将工作推送到远程仓库的 <strong>main</strong> 分支上。</p>
<h2 id="251-第一种方法远程跟踪分支"><a class="markdownIt-Anchor" href="#251-第一种方法远程跟踪分支"></a> 25.1 第一种方法远程跟踪分支</h2>
<p>通过远程分支切换到一个新的分支，执行:<code>git checkout -b totallyNotMain o/main</code>,就可以创建一个名为 <strong>totallyNotMain</strong> 的分支，它跟踪远程分支 <strong>o/main</strong>。</p>
<hr />
<p>闲话少说，咱们先看看演示！我们切换到一个名叫 <strong>foo</strong> 的新分支，让其跟踪远程仓库中的 <strong>main</strong></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7C92iubwAASux4?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout -b foo o/main; git pull</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F7C-V75awAEEKEm?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>正如你所看到的, 我们使用了隐含的目标 <strong>o/main</strong> 来更新 <strong>foo</strong> 分支。需要注意的是 <strong>main</strong> 并未被更新！</p>
<Br>
<h2 id="252-第二种方法远程跟踪分支"><a class="markdownIt-Anchor" href="#252-第二种方法远程跟踪分支"></a> 25.2 第二种方法远程跟踪分支</h2>
<p>设置远程追踪分支的方法就是使用：<code>git branch -u</code>命令</p>
<p>执行：<code>git branch -u o/main foo</code></p>
<p>这样 <strong>foo</strong> 就会跟踪 <strong>o/main</strong> 了。如果当前就在 <strong>foo</strong> 分支上, 还可以省略 foo：<code>git branch -u o/main</code></p>
<hr />
<p>看看这种方法的实际效果</p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DAWNibsAAnCyM?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git branch -u o/main foo; git commit; git push</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DAu34bYAANOJp?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>跟之前一样, 但这个命令更明确！</p>
<Br>
<h2 id="26git-push-的参数"><a class="markdownIt-Anchor" href="#26git-push-的参数"></a> 26.Git Push 的参数</h2>
<p>很好! 既然你知道了远程跟踪分支，我们可以开始揭开 <code>git push、fetch 和 pull</code> 的神秘面纱了。我们会逐个介绍这几个命令，它们在理念上是非常相似的。</p>
<p>首先来看 <code>git push</code>。在远程跟踪课程中，你已经学到了 Git 是通过当前所在分支的属性来确定远程仓库以及要 <code>push</code> 的目的地的。这是未指定参数时的行为，我们可以为 <code>push</code> 指定参数，语法是：<code>git push &lt;remote&gt; &lt;place&gt;</code></p>
<p><code>&lt;place&gt;</code> 参数是什么意思呢？我们稍后会深入其中的细节, 先看看例子, 这个命令是:</p>
<p><code>git push origin main</code></p>
<p>把这个命令翻译过来就是：切到本地仓库中的“<strong>main</strong>”分支，获取所有的提交，再到远程仓库“<strong>origin</strong>”中找到“<strong>main</strong>”分支，将远程仓库中没有的提交记录都添加上去，搞定之后告诉我。</p>
<p>我们通过“<strong>place</strong>”参数来告诉 Git 提交记录来自于 <strong>main</strong>, 要推送到远程仓库中的 <strong>main</strong>。它实际就是要同步的两个仓库的位置。</p>
<p>需要注意的是，因为我们通过指定参数告诉了 Git 所有它需要的信息, 所以它就忽略了我们所切换分支的属性！</p>
<hr />
<p>我们看看指定参数的例子。注意下我们当前分支的位置。</p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DCrfZawAABB9q?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git checkout C0; git push origin main</code></p>
<Br>
<p><img src="https://pbs.twimg.com/media/F7DDgx5awAAEQCv?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>好了! 通过指定参数, 远程仓库中的 <strong>main</strong> 分支得到了更新。</p>
<Br>
<h2 id="27-place参数详解"><a class="markdownIt-Anchor" href="#27-place参数详解"></a> 27. <code>&lt;place&gt;</code>参数详解</h2>
<p>还记得之前课程说的吧，当为 <code>git push</code> 指定 <strong>place</strong> 参数为 <strong>main</strong> 时，我们同时指定了提交记录的来源和去向。</p>
<p>你可能想问 —— 如果来源和去向分支的名称不同呢？比如你想把本地的 <strong>foo</strong> 分支推送到远程仓库中的 <strong>bar</strong> 分支。</p>
<p>哎，很遗憾 Git 做不到…… 开个玩笑，别当真！当然是可以的啦 😃 Git 拥有超强的灵活性（有点过于灵活了）</p>
<p>接下来咱们看看是怎么做的……</p>
<p>要同时为源和目的地指定 <code>&lt;place&gt;</code> 的话，只需要用冒号 : 将二者连起来就可以了：<code>git push origin &lt;source&gt;:&lt;destination&gt;</code></p>
<p>这个参数实际的值是个 refspec，“refspec” 是一个自造的词，意思是 Git 能识别的位置（比如分支 foo 或者 HEAD~1）</p>
<p>一旦你指定了独立的来源和目的地，就可以组织出言简意赅的远程操作命令了，让我们看看演示！</p>
<hr />
<p>记住，<code>source</code> 可以是任何 Git 能识别的位置：</p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DEsW2bcAARMg8?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git push origin foo^:main</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DF9NkbYAAM7ss?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p>这是个令人困惑的命令，但是它确实是可以运行的 —— Git 将 <strong>foo^</strong> 解析为一个位置，上传所有未被包含到远程仓库里 <strong>main</strong> 分支中的提交记录。</p>
<Br>
<h2 id="28git-fetch-的参数"><a class="markdownIt-Anchor" href="#28git-fetch-的参数"></a> 28.Git fetch 的参数</h2>
<p>我们刚学习了 <code>git push</code> 的参数，很酷的 <code>&lt;place&gt;</code> 参数，还有用冒号分隔的 refspecs（<source>:<destination>）。 这些参数可以用于 <code>git fetch</code> 吗？</p>
<p>你猜中了！<code>git fetch</code> 的参数和 <code>git push</code>极其相似。他们的概念是相同的，只是方向相反罢了（因为现在你是下载，而非上传）</p>
<p>让我们逐个讨论下这些概念……</p>
<br>
<p><code>&lt;place&gt;</code> 参数</p>
<p>如果你像如下命令这样为 <code>git fetch</code> 设置 的话：<code>git fetch origin foo</code></p>
<p>Git 会到远程仓库的 <strong>foo</strong> 分支上，然后获取所有本地不存在的提交，放到本地的 <strong>o/foo</strong> 上。</p>
<p>来看个例子（还是前面的例子，只是命令不同了）</p>
<hr />
<p>通过指定 place…</p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DNCLya4AA8d5_?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fetch origin foo</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DNTXQbIAA3mQK?format=png&amp;name=900x900" alt="" /></p>
<p>我们只下载了远程仓库中 <strong>foo</strong> 分支中的最新提交记录，并更新了</p>
<br>
<p>为何 Git 会将新提交放到 o/foo 而不是放到我本地的 foo 分支呢？之前不是说这样的 参数就是同时应用于本地和远程的位置吗？</p>
<p>好吧, 本例中 Git 做了一些特殊处理，因为你可能在 foo 分支上的工作还未完成，你也不想弄乱它。还记得在 git fetch 课程里我们讲到的吗 —— 它不会更新你的本地的非远程分支, 只是下载提交记录（这样, 你就可以对远程分支进行检查或者合并了）。</p>
<hr />
<p>“如果我们指定 <code>&lt;source&gt;:&lt;destination&gt;</code> 会发生什么呢？”</p>
<p>如果你觉得直接更新本地分支很爽，那你就用冒号分隔的 refspec 吧。不过，你不能在当前切换的分支上干这个事，但是其它分支是可以的。</p>
<p>这里有一点是需要注意的 —— source 现在指的是远程仓库中的位置，而 <code>&lt;destination&gt;</code> 才是要放置提交的本地仓库的位置。它与 <code>git push</code> 刚好相反，这是可以讲的通的，因为我们在往相反的方向传送数据。</p>
<p>理论上虽然行的通，但开发人员很少这么做。我在这里介绍它主要是为了从概念上说明 <code>fetch</code> 和 <code>push</code> 的相似性，只是方向相反罢了</p>
<Br>
<p><img src="https://pbs.twimg.com/media/F7DN2ULbMAAcJ1r?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p>执行：<code>git fetch origin foo~1:bar</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DOFzObwAAKhzG?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>哇! 看见了吧, Git 将 <strong>foo~1</strong> 解析成一个 <strong>origin</strong> 仓库的位置，然后将那些提交记录下载到了本地的 <strong>bar</strong> 分支（一个本地分支）上。注意由于我们指定了目标分支，<strong>foo</strong> 和 <strong>o/foo</strong> 都没有被更新</p>
<hr />
<p>没有参数呢?</p>
<p>如果 <code>git fetch</code> 没有参数，它会下载所有的提交记录到各个远程分支……</p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DOnogbMAA3cle?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git fetch</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DPHMobMAApG3A?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>相当简单，但是仅需更新一次，值得你去做！</p>
<br>
<h2 id="29古怪的-source"><a class="markdownIt-Anchor" href="#29古怪的-source"></a> 29.古怪的 <source></h2>
<p>Git 有两种关于 <source> 的用法是比较诡异的，即你可以在 <code>git push</code> 或 <code>git fetch</code> 时不指定任何 <strong>source</strong>，方法就是仅保留冒号和 <strong>destination</strong> 部分，<strong>source</strong> 部分留空。</p>
<ul>
<li><code>git push origin :side</code></li>
<li><code>git fetch origin :bugFix</code></li>
</ul>
<p>我们分别来看一下这两条命令的作用……</p>
<hr />
<p><code>git push origin :foo</code>:就是这样子, 我们通过给 push 传空值 source，成功删除了远程仓库中的 foo 分支, 这真有意思…</p>
<p><code>git fetch origin :bar</code>:如果 fetch 空 到本地，会在本地创建一个新分支</p>
<br>
<h2 id="30git-pull-参数"><a class="markdownIt-Anchor" href="#30git-pull-参数"></a> 30.Git pull 参数</h2>
<p>既然你已经掌握关于 <code>git fetch</code> 和 <code>git push</code> 参数的方方面面了，关于 <code>git pull</code> 几乎没有什么可以讲的了 😃</p>
<p>因为 <code>git pull</code> 到头来就是 <code>fetch</code> 后跟 <code>merge</code> 的缩写。你可以理解为用同样的参数执行 <code>git fetch</code>，然后再 <code>merge</code> 你所抓取到的提交记录。</p>
<p>还可以和其它更复杂的参数一起使用, 来看一些例子:</p>
<p>以下命令在 Git 中是等效的:</p>
<ul>
<li>
<p><code>git pull origin foo</code> 相当于：<code>git fetch origin foo; git merge o/foo</code></p>
</li>
<li>
<p>还有…</p>
</li>
<li>
<p><code>git pull origin bar~1:bugFix</code> 相当于：<code>git fetch origin bar~1:bugFix; git merge bugFix</code></p>
</li>
</ul>
<p>看到了? git pull 实际上就是 fetch + merge 的缩写, git pull 唯一关注的是提交最终合并到哪里（也就是为 git fetch 所提供的 destination 参数）</p>
<p>一起来看个例子吧：</p>
<hr />
<p><code>pull</code> 也可以用 <strong>source:destination</strong> 吗? 当然喽, 看看吧:</p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DVGsHbEAAs-0I?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>执行：<code>git pull origin main:foo</code></p>
<br>
<p><img src="https://pbs.twimg.com/media/F7DWQ-cbMAAGzWM?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>哇, 这个命令做的事情真多。它先在本地创建了一个叫 <strong>foo</strong> 的分支，从远程仓库中的 <strong>main</strong> 分支中下载提交记录，并合并到 <strong>foo</strong>，然后再 <code>merge</code> 到我们的当前所在的分支 <strong>bar</strong> 上。操作够多的吧？！</p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>ImportError: libGL.so.1: cannot open shared object file: No such file or directory</title>
    <url>/2024/02/03/ImportError-libGL-so-1-cannot-open-shared-object-file-No-such-file-or-directory/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="报错内容"><a class="markdownIt-Anchor" href="#报错内容"></a> 报错内容</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(ab) (base) root@b11a13895df1:/cyb/LAVIS<span class="comment"># bash run_scripts/blip2/train/pretrain_stage1.sh</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>, line <span class="number">16</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">import</span> lavis.tasks <span class="keyword">as</span> tasks</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/__init__.py&quot;</span>, line <span class="number">15</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.datasets.builders <span class="keyword">import</span> *</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/datasets/builders/__init__.py&quot;</span>, line <span class="number">8</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.datasets.builders.base_dataset_builder <span class="keyword">import</span> load_dataset_config</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/datasets/builders/base_dataset_builder.py&quot;</span>, line <span class="number">18</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.processors.base_processor <span class="keyword">import</span> BaseProcessor</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/processors/__init__.py&quot;</span>, line <span class="number">10</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.processors.alpro_processors <span class="keyword">import</span> (</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/processors/alpro_processors.py&quot;</span>, line <span class="number">13</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.processors.randaugment <span class="keyword">import</span> VideoRandomAugment</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/processors/randaugment.py&quot;</span>, line <span class="number">8</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">import</span> cv2</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/cv2/__init__.py&quot;</span>, line <span class="number">181</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    bootstrap()</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/cv2/__init__.py&quot;</span>, line <span class="number">153</span>, <span class="keyword">in</span> bootstrap</span><br><span class="line">    native_module = importlib.import_module(<span class="string">&quot;cv2&quot;</span>)</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/importlib/__init__.py&quot;</span>, line <span class="number">127</span>, <span class="keyword">in</span> import_module</span><br><span class="line">    <span class="keyword">return</span> _bootstrap._gcd_import(name[level:], package, level)</span><br><span class="line">ImportError: libGL.so<span class="number">.1</span>: cannot <span class="built_in">open</span> shared <span class="built_in">object</span> file: No such file <span class="keyword">or</span> directory</span><br><span class="line">ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: <span class="number">1</span>) local_rank: <span class="number">0</span> (pid: <span class="number">15594</span>) of binary: /root/anaconda3/envs/ab/<span class="built_in">bin</span>/python</span><br></pre></td></tr></table></figure>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install opencv-python-headless</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>import</tag>
      </tags>
  </entry>
  <entry>
    <title>ImportError: cannot import name &#39;_expand_mask&#39; from &#39;transformers.models.clip.modeling_clip&#39;</title>
    <url>/2024/02/03/ImportError-cannot-import-name-expand-mask-from-transformers-models-clip-modeling-clip/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="报错内容"><a class="markdownIt-Anchor" href="#报错内容"></a> 报错内容</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(ab) (base) root@b11a13895df1:/cyb/LAVIS<span class="comment"># bash run_scripts/blip2/train/pretrain_stage1.sh</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>, line <span class="number">16</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">import</span> lavis.tasks <span class="keyword">as</span> tasks</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/__init__.py&quot;</span>, line <span class="number">16</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.models <span class="keyword">import</span> *</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/models/__init__.py&quot;</span>, line <span class="number">43</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.models.blip_diffusion_models.blip_diffusion <span class="keyword">import</span> BlipDiffusion</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/models/blip_diffusion_models/blip_diffusion.py&quot;</span>, line <span class="number">29</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> lavis.models.blip_diffusion_models.modeling_ctx_clip <span class="keyword">import</span> CtxCLIPTextModel</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/models/blip_diffusion_models/modeling_ctx_clip.py&quot;</span>, line <span class="number">13</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">from</span> transformers.models.clip.modeling_clip <span class="keyword">import</span> (</span><br><span class="line">ImportError: cannot <span class="keyword">import</span> name <span class="string">&#x27;_expand_mask&#x27;</span> <span class="keyword">from</span> <span class="string">&#x27;transformers.models.clip.modeling_clip&#x27;</span> (/root/anaconda3/envs/ab/lib/python3<span class="number">.9</span>/site-packages/transformers/models/clip/modeling_clip.py)</span><br><span class="line">ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: <span class="number">1</span>) local_rank: <span class="number">0</span> (pid: <span class="number">16897</span>) of binary: /root/anaconda3/envs/ab/<span class="built_in">bin</span>/python</span><br></pre></td></tr></table></figure>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>版本问题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install transformers==4.31.0</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>transformers</tag>
      </tags>
  </entry>
  <entry>
    <title>IELTS:小作文知识点总结</title>
    <url>/2024/10/28/IELTS-%E5%B0%8F%E4%BD%9C%E6%96%87%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><!-- omit in toc -->
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E9%9B%85%E6%80%9D%E5%B0%8F%E4%BD%9C%E6%96%87%E5%86%99%E4%BD%9C%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93">雅思小作文写作技巧总结</a>
<ul>
<li><a href="#1%E6%8F%8F%E8%BF%B0%E6%97%B6%E9%97%B4%E6%AE%B5%E7%9A%84%E8%AF%8D%E7%BB%84">1.描述时间段的词组</a></li>
<li><a href="#2%E5%8D%95%E7%BA%BF%E6%8F%8F%E8%BF%B0%E5%8F%A5%E5%9E%8B">2.单线描述句型</a>
<ul>
<li><a href="#21-the-number-of-teachers-declined-from-in-to-in"><strong>2.1 The number of teachers declined from… in… to… in…</strong></a></li>
<li><a href="#22-there-was-an-ascent-in-the-number-of-sth-from-in-to-in"><strong>2.2 there was an ascent in the number of sth from in to in</strong></a></li>
<li><a href="#23-%E7%9B%B4%E6%8E%A5%E5%AF%B9%E8%B1%A1experienced-an-upward-trend-in-%E4%B8%BB%E8%AF%AD-%E5%AF%B9%E8%B1%A1%E6%98%AF%E5%9B%BD%E5%AE%B6%E5%8D%9A%E7%89%A9%E9%A6%86%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5-rising-from-in-to-in"><strong>2.3 直接对象+experienced an upward trend 【in 主语, 对象是国家、博物馆可以省略】, rising from in to in</strong></a></li>
</ul>
</li>
<li><a href="#3%E5%8F%8C%E7%BA%BF%E6%8F%8F%E8%BF%B0%E5%8F%A5%E5%9E%8B">3.双线描述句型</a>
<ul>
<li><a href="#31-12"><strong>3.1 <code>1+2</code></strong></a></li>
<li><a href="#32-11"><strong>3.2 <code>1+1</code></strong></a></li>
<li><a href="#33-1followed-by"><strong>3.3 <code>1+followed by</code></strong></a></li>
<li><a href="#34-1before"><strong>3.4 <code>1+before</code></strong></a></li>
<li><a href="#35-after1"><strong>3.5 <code>After+1</code></strong></a></li>
<li><a href="#36-there-befollowed-by"><strong>3.6 <code>There be+followed by</code></strong></a></li>
</ul>
</li>
<li><a href="#4%E8%B5%B7%E7%82%B9%E5%8F%A5%E5%9E%8B%E9%9D%99%E6%80%81%E6%8F%8F%E8%BF%B0">4.起点句型=静态描述</a>
<ul>
<li><a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><strong>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</strong></a></li>
<li><a href="#42-the-numberpercentagesalesconsumption-of-sth%E4%B8%BB%E8%AF%AD"><strong>4.2 The number/percentage/sales/consumption of sth主语</strong></a></li>
<li><a href="#43-%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%BB%E8%AF%AD"><strong>4.3 数据作主语</strong></a></li>
<li><a href="#44-the-figure-for-%E5%AF%B9%E8%B1%A1"><strong>4.4 the figure for 对象</strong></a></li>
<li><a href="#45-%E5%AF%B9%E8%B1%A1had"><strong>4.5 对象+had</strong></a></li>
<li><a href="#46-%E5%AF%B9%E8%B1%A1attractedappealed-todrew-%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%B1%BB%E6%96%87%E7%AB%A0%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BA%BA"><strong>4.6 对象+attracted/appealed to/drew (受欢迎类文章+数据是人)</strong></a></li>
<li><a href="#47-%E5%AF%B9%E8%B1%A1be-chosenselectedfavoredpreferred-by-%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%B1%BB%E6%96%87%E7%AB%A0%E6%95%B0%E6%8D%AE%E6%8C%87%E4%BA%BA">4.7 对象be chosen/selected/favored/preferred by 「受欢迎类文章+数据指人」</a></li>
<li><a href="#48-double">4.8 double</a></li>
<li><a href="#49-followed-by">4.9 followed by</a></li>
<li><a href="#410-%E6%80%BB%E7%BB%93">4.10 总结</a></li>
<li><a href="#411-%E4%BA%BA%E5%BC%80%E5%A4%B4%E5%86%99%E7%BB%93%E5%B0%BEpopular%E7%B1%BB%E6%96%87%E7%AB%A0">4.11 人开头写结尾：popular类文章</a></li>
<li><a href="#412-%E7%BB%84%E5%90%88%E5%9B%BE">4.12 组合图</a></li>
</ul>
</li>
<li><a href="#5%E5%8A%A0%E5%88%86%E5%8F%A5%E5%9E%8B">5.加分句型</a>
<ul>
<li><a href="#51-%E8%A1%A8%E7%9B%B8%E5%8F%8D"><strong>5.1 表相反</strong></a></li>
<li><a href="#52-%E5%85%A8%E5%B9%B4%E6%9C%80%E9%AB%98%E5%8F%A5%E5%9E%8B"><strong>5.2 全年最高句型</strong></a></li>
<li><a href="#53-%E8%BF%87%E5%8E%BB%E5%AE%8C%E6%88%90%E6%97%B6%E7%94%A8%E5%9C%A8%E7%BB%88%E7%82%B9"><strong>5.3 过去完成时：用在终点</strong></a></li>
<li><a href="#54-%E8%AF%84%E4%BB%B7%E6%95%B0%E6%8D%AE"><strong>5.4 评价数据</strong></a></li>
<li><a href="#55-%E5%B9%85%E5%BA%A6%E6%8B%93%E5%B1%95"><strong>5.5 幅度拓展</strong></a></li>
<li><a href="#56-%E9%80%9A%E7%94%A8"><strong>5.6 通用</strong></a></li>
<li><a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><strong>5.7 双上升/下降</strong></a></li>
<li><a href="#58-%E5%85%A8%E5%B9%B4%E6%9C%80%E4%BD%8E%E5%BF%BD%E7%95%A5%E8%B6%8B%E5%8A%BF%E7%9A%84%E5%86%99%E6%B3%95"><strong>5.8 全年最低：忽略趋势的写法</strong></a></li>
<li><a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><strong>5.9 两个对象并列写法</strong></a></li>
<li><a href="#510-%E5%B9%85%E5%BA%A6%E5%AF%B9%E6%AF%94"><strong>5.10 幅度对比</strong></a></li>
<li><a href="#511-%E8%B6%85%E8%BF%87%E6%AE%B52%E5%8F%A5%E8%AF%9D"><strong>5.11 超过段：2句话</strong></a></li>
<li><a href="#512-%E4%B8%89%E6%9D%A1%E7%BA%BF%E6%95%B4%E4%BD%93%E5%8C%BA%E9%97%B4%E4%B8%8B%E9%99%8D%E5%8F%AA%E6%9C%89%E4%B8%AD%E9%97%B4%E6%9C%89%E4%B8%80%E4%B8%AA%E5%B0%8F%E4%B8%8A%E5%8D%87"><strong>5.12 三条线整体区间下降，只有中间有一个小上升</strong></a></li>
<li><a href="#513-%E7%AE%80%E5%8C%96%E7%89%88%E5%B9%85%E5%BA%A6%E5%AF%B9%E6%AF%94"><strong>5.13 简化版幅度对比</strong></a></li>
</ul>
</li>
<li><a href="#6%E8%AF%8D%E6%B1%87">6.词汇</a>
<ul>
<li><a href="#61-%E7%9B%B8%E5%8F%8D"><strong>6.1 相反</strong></a></li>
<li><a href="#62-%E4%B8%AD%E6%80%A7%E8%AF%8D"><strong>6.2 中性词</strong></a></li>
<li><a href="#63-%E5%BC%BA%E8%B0%83%E5%B0%8F%E5%B9%85%E5%BA%A6"><strong>6.3 强调小幅度</strong></a></li>
<li><a href="#64-%E8%BF%91%E4%BC%BC"><strong>6.4 近似</strong></a></li>
<li><a href="#64-%E8%B6%8B%E5%8A%BF%E8%A1%A8%E8%BE%BE"><strong>6.4 趋势表达</strong></a></li>
</ul>
</li>
<li><a href="#7%E5%B9%85%E5%BA%A6%E8%AF%8D%E6%B1%87">7.幅度词汇</a></li>
<li><a href="#8%E9%A6%96%E6%AE%B5%E6%94%B9%E5%86%99">8.首段改写</a>
<ul>
<li><a href="#81-%E5%AF%B9%E8%B1%A1"><strong>8.1 对象</strong></a></li>
<li><a href="#82-%E6%95%B0%E6%8D%AE%E5%BD%A2%E5%BC%8F"><strong>8.2 数据形式</strong></a></li>
<li><a href="#83-%E6%97%B6%E9%97%B4%E6%94%B9%E5%86%99"><strong>8.3 时间改写</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%BD%BF%E7%94%A8chatgpt%E6%89%B9%E6%94%B9%E9%9B%85%E6%80%9D%E4%BD%9C%E6%96%87">使用ChatGPT批改雅思作文</a>
<ul>
<li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li>
</ul>
</li>
<li><a href="#%E7%BB%8F%E5%85%B8%E6%A1%88%E4%BE%8B">经典案例</a>
<ul>
<li><a href="#1026-transportation--telephone">10.26 transportation + telephone</a>
<ul>
<li><a href="#transportation">transportation</a></li>
<li><a href="#telephone">telephone</a></li>
</ul>
</li>
<li><a href="#1027-book--cd--meat--telephone_v2">10.27 book + CD + meat + telephone_v2</a>
<ul>
<li><a href="#book">book</a></li>
<li><a href="#cd">CD</a></li>
<li><a href="#meat">meat</a></li>
<li><a href="#telephone_v2">telephone_v2</a></li>
</ul>
</li>
<li><a href="#1029-internet--fishchips">10.29 Internet + fish&amp;chips</a>
<ul>
<li><a href="#internet">Internet</a></li>
<li><a href="#fishchips">fish&amp;chips</a></li>
</ul>
</li>
<li><a href="#1031-transportation_v2--film">10.31 transportation_v2 + film</a>
<ul>
<li><a href="#transporation_v2">transporation_v2</a></li>
<li><a href="#film">film</a></li>
</ul>
</li>
<li><a href="#1102-timber">11.02 timber</a></li>
<li><a href="#1107-honeymoon">11.07 honeymoon</a></li>
<li><a href="#1116-sector--schoolmap--coffee%E6%B5%81%E7%A8%8B%E5%9B%BE">11.16 sector + school(map) + coffee(流程图)</a>
<ul>
<li><a href="#sector">sector</a></li>
<li><a href="#schoolmap">school(map)</a></li>
<li><a href="#coffee">coffee</a></li>
</ul>
</li>
<li><a href="#1118">11.18</a></li>
</ul>
</li>
<li><a href="#1124">11.24</a></li>
</ul>
<Br>
<h2 id="雅思小作文写作技巧总结"><a class="markdownIt-Anchor" href="#雅思小作文写作技巧总结"></a> 雅思小作文写作技巧总结</h2>
<p><strong>全动写法</strong>：适用于交通工具、电话、CD、历史书籍等动词主导的主题。</p>
<p><strong>静动结合写法</strong>：适用于简单线图，如牛肉、因特网、炸鱼薯条、Timber等例子。</p>
<p><strong>静动结合写法(交叉写法)</strong>：交通工具2</p>
<h3 id="1描述时间段的词组"><a class="markdownIt-Anchor" href="#1描述时间段的词组"></a> 1.描述时间段的词组</h3>
<ul>
<li>Over a 10-year period</li>
<li>Throughout the period</li>
<li>During this 10-year period</li>
<li>Over the period</li>
</ul>
<h3 id="2单线描述句型"><a class="markdownIt-Anchor" href="#2单线描述句型"></a> 2.单线描述句型</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="21-the-number-of-teachers-declined-from-in-to-in"><a class="markdownIt-Anchor" href="#21-the-number-of-teachers-declined-from-in-to-in"></a> <strong>2.1 The number of teachers declined from… in… to… in…</strong></h4>
<p>eg: The number of teachers declined from approximately 4.5 million in 1960 to nearly 2.5 million in 1962.</p>
<h4 id="22-there-was-an-ascent-in-the-number-of-sth-from-in-to-in"><a class="markdownIt-Anchor" href="#22-there-was-an-ascent-in-the-number-of-sth-from-in-to-in"></a> <strong>2.2 there was an ascent in the number of sth from in to in</strong></h4>
<p>eg: There was an ascent in the number of teachers from nearly 2.5 million in 1962 to 6 million in 1964.</p>
<h4 id="23-直接对象experienced-an-upward-trend-in-主语-对象是国家-博物馆可以省略-rising-from-in-to-in"><a class="markdownIt-Anchor" href="#23-直接对象experienced-an-upward-trend-in-主语-对象是国家-博物馆可以省略-rising-from-in-to-in"></a> <strong>2.3 直接对象+experienced an upward trend 【in 主语, 对象是国家、博物馆可以省略】, rising from in to in</strong></h4>
<p>Local fixed line calls experienced an upward trend <strong>in usage</strong>, rising from …in …in…</p>
<h3 id="3双线描述句型"><a class="markdownIt-Anchor" href="#3双线描述句型"></a> 3.双线描述句型</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="31-12"><a class="markdownIt-Anchor" href="#31-12"></a> <strong>3.1 <code>1+2</code></strong></h4>
<p>The number of teachers declined from in to in, <strong>but/and then</strong> there was an ascent to …in…<br />
The number of teachers declined from approximately 4.5 million in 1960 to nearly 2.5 million in 1962, but there was an ascent to 6 million in 1964.</p>
<h4 id="32-11"><a class="markdownIt-Anchor" href="#32-11"></a> <strong>3.2 <code>1+1</code></strong></h4>
<p>The number of teachers declined from in to in, but/and then it ascended to…in</p>
<h4 id="33-1followed-by"><a class="markdownIt-Anchor" href="#33-1followed-by"></a> <strong>3.3 <code>1+followed by</code></strong></h4>
<p>The number of teachers declined from in to in, followed by an ascent to…in…</p>
<h4 id="34-1before"><a class="markdownIt-Anchor" href="#34-1before"></a> <strong>3.4 <code>1+before</code></strong></h4>
<p>The number of teachers declined from in to in before ascending to…in…</p>
<h4 id="35-after1"><a class="markdownIt-Anchor" href="#35-after1"></a> <strong>3.5 <code>After+1</code></strong></h4>
<p>After declining from in to in, 主语 ascended to…in</p>
<h4 id="36-there-befollowed-by"><a class="markdownIt-Anchor" href="#36-there-befollowed-by"></a> <strong>3.6 <code>There be+followed by</code></strong></h4>
<p>there was an ascent in the number of sth from in to in, followed by a decline to …in…</p>
<h3 id="4起点句型静态描述"><a class="markdownIt-Anchor" href="#4起点句型静态描述"></a> 4.起点句型=静态描述</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="41-对象-waswere-by-far-the-most-popularfavoredpreferred-of-these-复数-with-数据-非谓语"><a class="markdownIt-Anchor" href="#41-对象-waswere-by-far-the-most-popularfavoredpreferred-of-these-复数-with-数据-非谓语"></a> <strong>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</strong></h4>
<p>或：对象 had the highest/lowest popularity, with…</p>
<p><code>最大值(并不是指相对于自身最大, 而是在总体中最大)</code>:</p>
<ul>
<li>Beef was by far the most popular of these foods, with 220 grams consumed per person per week.</li>
<li>Buses were by far the most popular of these modes of transportation, with 38% of individuals using them.</li>
</ul>
<p>–</p>
<p><code>最小值</code>:</p>
<ul>
<li>…was the least popular __ , with only …</li>
<li>The least favored choice/food was…, with only…</li>
</ul>
<p>–</p>
<p><code>比较</code>：</p>
<ul>
<li>…was much less popular, with…</li>
<li>…and…were much less popular, with…</li>
</ul>
<p>–</p>
<p><code>同等</code>:</p>
<ul>
<li>…and…were equally less popular, with…</li>
</ul>
<p>–</p>
<p><code>第二</code>： … was the second most favored choice, …</p>
<p><code>第三</code>： … was the next preferred option,…</p>
<p>popular类文章并且数据指人-引出数据的方式：</p>
<ul>
<li>…, with only 5% of men choosing them</li>
<li>…, attracting/which attracted only 5% of men</li>
<li>, appealing to/drawing/which appealed to/which drew…</li>
<li>, which were chosen/selected by</li>
<li>, chosen/selected by</li>
</ul>
<h4 id="42-the-numberpercentagesalesconsumption-of-sth主语"><a class="markdownIt-Anchor" href="#42-the-numberpercentagesalesconsumption-of-sth主语"></a> <strong>4.2 The number/percentage/sales/consumption of sth主语</strong></h4>
<p><code>最大值</code>: In 1979, the consumption of beef was by far the highest, at 220 grams.<br />
<code>最小值</code>: In 1979, the consumption of fish was the lowest, at just over 50 grams.<br />
<code>普通</code>: In 1979, the consumption of beef was/started at/stood at 220 grams.<br />
<code>AB比较</code>: the number of A, at…, was higher than that of B, at…</p>
<h4 id="43-数据作主语"><a class="markdownIt-Anchor" href="#43-数据作主语"></a> <strong>4.3 数据作主语</strong></h4>
<p>eg1: In 1979, 220 grams of beef were consumed.<br />
eg2: 20% of men favored comedy movies, while the percentage of men preferring thriller movies was slightly lower, at 15%.</p>
<p>20% of men favored comedy movies, while 15% preferred thriller movies.</p>
<h4 id="44-the-figure-for-对象"><a class="markdownIt-Anchor" href="#44-the-figure-for-对象"></a> <strong>4.4 the figure for 对象</strong></h4>
<p><code>普通</code>: the figure for 对象 was/started at/stood at…<br />
<code>比较</code>:</p>
<ul>
<li>the figure for …was significantly/slightlly lower, at …</li>
<li>the figure for …and… were significantly/slightly lower, at…and…, respectively</li>
</ul>
<p>–</p>
<p><code>相似</code>:</p>
<ul>
<li>the figures for …and…were similar, each hovering around…</li>
<li>the figures for…and…were the same, both at…</li>
</ul>
<p>–</p>
<p><code>最小值</code>：the figure for…was the lowest, at…</p>
<p>tips:</p>
<ul>
<li>The figure for 短</li>
<li>The percentage of 全</li>
</ul>
<p>eg: In 1979, the proportion of individuals who commuted by bus was 38%, while the figure for tube was 18%.</p>
<h4 id="45-对象had"><a class="markdownIt-Anchor" href="#45-对象had"></a> <strong>4.5 对象+had</strong></h4>
<p><code>最大值</code>:</p>
<ul>
<li>The USA had the highest proportion of Internet users, at 20%(动态图)</li>
<li>…had the highest figure/percentage, at 数据</li>
</ul>
<p>–</p>
<p><code>最小值</code>: …had the lowest figure/percentage, at数据</p>
<p>–</p>
<p><code>比较</code>：</p>
<ul>
<li>…had a lower figure/percentage, at 数据</li>
<li>…and… had lower figures/percentages, at…and…, respectively</li>
</ul>
<p>–</p>
<p><code>相似</code>: …and…had similar figure, each hovering around…</p>
<p>–</p>
<p><code>相等</code>：…and…had hte same figure, both at…</p>
<h4 id="46-对象attractedappealed-todrew-受欢迎类文章数据是人"><a class="markdownIt-Anchor" href="#46-对象attractedappealed-todrew-受欢迎类文章数据是人"></a> <strong>4.6 对象+attracted/appealed to/drew (受欢迎类文章+数据是人)</strong></h4>
<p><code>普通</code>: Romantic comedies attracted only 5% of male viewers.</p>
<p>The least preferred choice was romantic comedies, 引出数据 which attracted only 5% of men.</p>
<p>区分：</p>
<ul>
<li>the USA had the highest/lowest proportion of Internet users</li>
<li>Canada had the most/least Internet users in 2009</li>
</ul>
<p>–</p>
<p>Popular类文章常用的动词：</p>
<ul>
<li>Choose-select-opt for sth-opt to do sth</li>
<li>favor=prefer</li>
</ul>
<p>–</p>
<p>eg: Action movies were by far the most <strong>favored</strong> of these films genres among men, with 40% of male viewers choosing to watch them. <strong>In comparison</strong>, 20% of men <strong>favored</strong> comedy movies, while the percentage of men preferring thriller movies was slightly lower, at 15%. <strong>In addition</strong>, science fiction and western movies had the same figure, both at 10%. <strong>On the other hand</strong>, the least preferred choice was romantic comedies, <strong>which attracted</strong> only 5% of men.</p>
<p>–</p>
<p>最大值用法(3),最小值：4个:</p>
<ul>
<li>Action moives were by far the most favored of these films genres among men, with 40% of male viewers choosing to watch them</li>
<li>Action movies had the highest percentage, at 40%</li>
<li>The percentage of men choosing to watch action movies was by far the highest, at 40%</li>
<li>这里相对最小值的用法缺少一个 <code>the figure for</code></li>
</ul>
<h4 id="47-对象be-chosenselectedfavoredpreferred-by-受欢迎类文章数据指人"><a class="markdownIt-Anchor" href="#47-对象be-chosenselectedfavoredpreferred-by-受欢迎类文章数据指人"></a> 4.7 对象be chosen/selected/favored/preferred by 「受欢迎类文章+数据指人」</h4>
<p><strong>可以理解为4.6的另一种表达方法</strong></p>
<p>Romantic comedies were chosen by only 5% of male viewers.</p>
<h4 id="48-double"><a class="markdownIt-Anchor" href="#48-double"></a> 4.8 double</h4>
<p><code>引出新对象</code>：…, double the percentage of graduates pursuing careers in the other sectors, at 2.8%</p>
<p><code>写出旧对象</code>：…-a figure half that of service industries.</p>
<p>eg：The manufacturing industry was the second most favored sector, attracting 16.3% of graduates-a figure half that of service industries.</p>
<p>eg：Civil service employed had the 5.6% of graduates, double the percentage of graduates pursuing careers in the other sectors, at 2.8%.</p>
<h4 id="49-followed-by"><a class="markdownIt-Anchor" href="#49-followed-by"></a> 4.9 followed by</h4>
<p>前面最好用对象开头, followed closed by 对象</p>
<p>eg：Education was the next preferred option, which was chosen by 14.7% of graduates, followed closely by politics &amp; government, with 12.1% of graduates securing employment in this field.</p>
<h4 id="410-总结"><a class="markdownIt-Anchor" href="#410-总结"></a> 4.10 总结</h4>
<table>
<thead>
<tr>
<th>句型</th>
<th>引出数据</th>
</tr>
</thead>
<tbody>
<tr>
<td>popular</td>
<td>, with…/accracting… /chosen by…</td>
</tr>
<tr>
<td>The number of</td>
<td>, at</td>
</tr>
<tr>
<td>数据做主语</td>
<td>0</td>
</tr>
<tr>
<td>The figure for</td>
<td>, at</td>
</tr>
<tr>
<td>对象 had</td>
<td>, at</td>
</tr>
<tr>
<td>对象 attracted</td>
<td>0</td>
</tr>
<tr>
<td>对象 be chosen</td>
<td>0</td>
</tr>
<tr>
<td>double</td>
<td>, at</td>
</tr>
<tr>
<td>, followed by</td>
<td>随机</td>
</tr>
</tbody>
</table>
<h4 id="411-人开头写结尾popular类文章"><a class="markdownIt-Anchor" href="#411-人开头写结尾popular类文章"></a> 4.11 人开头写结尾：popular类文章</h4>
<ul>
<li>Over half of all couples chose Thailand and Bali as their preferred honeymoon destinations.</li>
<li>Only a small number of couples opted to visit the Lake District and Spain.</li>
</ul>
<h4 id="412-组合图"><a class="markdownIt-Anchor" href="#412-组合图"></a> 4.12 组合图</h4>
<ol>
<li>The pie chart illustrates…, and the table depicts…</li>
<li>Looking at the pie chart, …</li>
<li>According to the table, …</li>
<li>To sum up, … It is also evident that…</li>
</ol>
<h3 id="5加分句型"><a class="markdownIt-Anchor" href="#5加分句型"></a> 5.加分句型</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="51-表相反"><a class="markdownIt-Anchor" href="#51-表相反"></a> <strong>5.1 表相反</strong></h4>
<p>In contrast, … experienced an inverse trend/trajectory.</p>
<h4 id="52-全年最高句型"><a class="markdownIt-Anchor" href="#52-全年最高句型"></a> <strong>5.2 全年最高句型</strong></h4>
<p>… was/were the highest throughout the period, growing from in to in. However, it had fallen back to…by…</p>
<h4 id="53-过去完成时用在终点"><a class="markdownIt-Anchor" href="#53-过去完成时用在终点"></a> <strong>5.3 过去完成时：用在终点</strong></h4>
<ul>
<li>全年最高句型终点</li>
<li>1+1句型终点</li>
</ul>
<p>–</p>
<h4 id="54-评价数据"><a class="markdownIt-Anchor" href="#54-评价数据"></a> <strong>5.4 评价数据</strong></h4>
<p><code>回到原点</code>：… , returning to its initial level/ending at the same level as it started.</p>
<h4 id="55-幅度拓展"><a class="markdownIt-Anchor" href="#55-幅度拓展"></a> <strong>5.5 幅度拓展</strong></h4>
<p>先写整体区间的趋势，though the rate of growth decelerated over the last two years/albeit with a slower growth rate over the last two years.</p>
<p>先写整体区间的趋势. This rise was particularly noticeable between 1999 and 2002, exemplified by an astounding climb of 30 billion minutes.</p>
<p>先写整体区间的趋势, with this rise being particularly noticeable between 1999 and 2002, exemplified by an astounding climb of 30 billion minutes.</p>
<h4 id="56-通用"><a class="markdownIt-Anchor" href="#56-通用"></a> <strong>5.6 通用</strong></h4>
<p>最后一年 = at the end of the period in question</p>
<h4 id="57-双上升下降"><a class="markdownIt-Anchor" href="#57-双上升下降"></a> <strong>5.7 双上升/下降</strong></h4>
<p>… saw a downward trend, declining from in to in</p>
<p>There was an ascent in the number of sth, rising from in to in</p>
<p>… declined 不加幅度 from in to in, reflecting/indicating a substantial reduction in the X-year interval.</p>
<h4 id="58-全年最低忽略趋势的写法"><a class="markdownIt-Anchor" href="#58-全年最低忽略趋势的写法"></a> <strong>5.8 全年最低：忽略趋势的写法</strong></h4>
<p>… remained constantly low during this 10-year period, fluctuating within the range of … and …copies.</p>
<p>… remained constantly low during this 10-year period, starting at… and ending at… copies.</p>
<h4 id="59-两个对象并列写法"><a class="markdownIt-Anchor" href="#59-两个对象并列写法"></a> <strong>5.9 两个对象并列写法</strong></h4>
<p>…and…fell (from …and…) to …and …, respectively.</p>
<h4 id="510-幅度对比"><a class="markdownIt-Anchor" href="#510-幅度对比"></a> <strong>5.10 幅度对比</strong></h4>
<p>…also declined, although this drop was much less pronounced, dwindling to/ending at …</p>
<p>…also declined, but this drop was much more pronounced, dwindling to/ending at…</p>
<h4 id="511-超过段2句话"><a class="markdownIt-Anchor" href="#511-超过段2句话"></a> <strong>5.11 超过段：2句话</strong></h4>
<p>…showed an upward trend, overtaking/surpassing that of…in…</p>
<p>By …, it had surged, peaking at…</p>
<h4 id="512-三条线整体区间下降只有中间有一个小上升"><a class="markdownIt-Anchor" href="#512-三条线整体区间下降只有中间有一个小上升"></a> <strong>5.12 三条线整体区间下降，只有中间有一个小上升</strong></h4>
<p>…, though there was a slight ascent between 1980 and 1985.</p>
<h4 id="513-简化版幅度对比"><a class="markdownIt-Anchor" href="#513-简化版幅度对比"></a> <strong>5.13 简化版幅度对比</strong></h4>
<p>…saw a much less/more pronounced rise to…</p>
<h3 id="6词汇"><a class="markdownIt-Anchor" href="#6词汇"></a> 6.词汇</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="61-相反"><a class="markdownIt-Anchor" href="#61-相反"></a> <strong>6.1 相反</strong></h4>
<p>In contrast / Conversely / On the contrary</p>
<h4 id="62-中性词"><a class="markdownIt-Anchor" href="#62-中性词"></a> <strong>6.2 中性词</strong></h4>
<p>Meanwhile / Alternatively / Following a different pattern</p>
<h4 id="63-强调小幅度"><a class="markdownIt-Anchor" href="#63-强调小幅度"></a> <strong>6.3 强调小幅度</strong></h4>
<p>Only / merely / a mere / a meager</p>
<h4 id="64-近似"><a class="markdownIt-Anchor" href="#64-近似"></a> <strong>6.4 近似</strong></h4>
<p>approximately / around / almost / about / nearly / roughly<br />
Just over / just below<br />
just shy of</p>
<h4 id="64-趋势表达"><a class="markdownIt-Anchor" href="#64-趋势表达"></a> <strong>6.4 趋势表达</strong></h4>
<p><code>短语表达上升下降</code>：</p>
<ul>
<li>Experienced / saw / underwent +an upward trend</li>
<li>Showed / displayed / demonstrated + a downward trend</li>
</ul>
<p>–</p>
<p><code>上升</code>:</p>
<ul>
<li>V. : Ascended / rose / grew / escalated / climbed / went up / increased / surged</li>
<li>N. : An ascent / a rise / growth / an escalation / a climb / an upward trend / an increase / a surge</li>
<li>N. ：an upswing; an uptick</li>
</ul>
<p>–</p>
<p><code>恢复</code>: Recovered / A recovery</p>
<p><code>下降</code>:</p>
<ul>
<li>V. : Declined / dropped / dipped / descended / dwindled / reduced / fell / went down / decreased / plunged</li>
<li>N. : A decline / a drop / a dip / a descent / a reduction / a fall / a downward trend / a decrease / a plunge</li>
</ul>
<p>–</p>
<p><code>保持不变</code></p>
<ul>
<li>Remained stable / unchanged; leveled off;</li>
<li>Remained relatively stable/unchanged;</li>
<li>a period of leveling off</li>
</ul>
<p>–</p>
<p><code>波动</code>：</p>
<ul>
<li>Fluctuated</li>
<li>Experienced slight/wild fluctuation</li>
</ul>
<p>–</p>
<p><code>极值</code>:</p>
<ul>
<li>peak at 数据</li>
<li>reach a peak of</li>
<li>hit a high of</li>
<li>hit a low of</li>
<li>bottom out at</li>
</ul>
<h3 id="7幅度词汇"><a class="markdownIt-Anchor" href="#7幅度词汇"></a> 7.幅度词汇</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<p><code>大</code>:</p>
<ul>
<li>ADV. : Massively; substantially; considerably; significantly; enormously; drastically</li>
<li>ADJ. : Massive; substantial; considerable; significant; enormous; drastic</li>
</ul>
<p>–</p>
<p><code>中</code>:</p>
<ul>
<li>ADV. : Moderately; steadily; gradually;</li>
<li>ADJ. : Moderate; steady; gradual</li>
</ul>
<p>–</p>
<p><code>小</code>:</p>
<ul>
<li>ADV. : Slightly; marginally; negligibly; minimally</li>
<li>ADJ. : Slight; marginal; negligible; minimal</li>
</ul>
<h3 id="8首段改写"><a class="markdownIt-Anchor" href="#8首段改写"></a> 8.首段改写</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<p><strong>The diagram depicts the variations in the 数据形式of 对象+地点+时间</strong></p>
<p>The diagram depicts the variations in the number of teachers who worked full time in regular schools (in millions) in China over a 30-year period from 1960 to 1990.</p>
<p>The diagram depicts the variations in the proportion of individuals who used the Internet in the USA, Canada, and Mexico over a ten-year period between 1999 and 2009.</p>
<h4 id="81-对象"><a class="markdownIt-Anchor" href="#81-对象"></a> <strong>8.1 对象</strong></h4>
<p>full-time teachers of regular schools</p>
<p>teachers who worked full time in regular schools 定语从句</p>
<p>Teachers working full time in regular schools</p>
<h4 id="82-数据形式"><a class="markdownIt-Anchor" href="#82-数据形式"></a> <strong>8.2 数据形式</strong></h4>
<p><code>数量</code>：The number of - the amount of 不可数名词单数<br />
<code>百分比</code>：The percentage = the proportion of</p>
<h4 id="83-时间改写"><a class="markdownIt-Anchor" href="#83-时间改写"></a> <strong>8.3 时间改写</strong></h4>
<p>1960-1990<br />
Between 1960 and 1990<br />
From 1960 to 1990<br />
Over a 30-year period from 1960 to 1990 <code>only in the first paragraph</code><br />
In 1960, 1980, and 2000<br />
In three separate years: 1960, 1980, and 2000<br />
In 2005: in the year 2005</p>
<h2 id="使用chatgpt批改雅思作文"><a class="markdownIt-Anchor" href="#使用chatgpt批改雅思作文"></a> 使用ChatGPT批改雅思作文</h2>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h3 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h3>
<ul>
<li><a href="https://www.bilibili.com/video/BV1Nw411D7NZ/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">Bilibili：【建议收藏 】手把手教你用GPT4批改雅思写作</a></li>
<li><a href="https://www.bilibili.com/video/BV1UGYgenE8J/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">Bilibili：如何用ChatGPT科学修改雅思作文</a></li>
</ul>
<h2 id="经典案例"><a class="markdownIt-Anchor" href="#经典案例"></a> 经典案例</h2>
<h3 id="1026-transportation-telephone"><a class="markdownIt-Anchor" href="#1026-transportation-telephone"></a> 10.26 transportation + telephone</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="transportation"><a class="markdownIt-Anchor" href="#transportation"></a> transportation</h4>
<p>题目：The bar chart below shows the different modes of transport used to travel to and from work in one European city in 1960, 1980, and 2000.<br />
<img src="https://pic.imgdb.cn/item/671f5359d29ded1a8c0d1bf2.png" alt="" /></p>
<p>–</p>
<p>The diagram illustrates the variations in the proportion of commuters who used various types of transportation in a specific European city in three separate years: 1960, 1980, and 2000.</p>
<p>The proportion of commuters using buses dwindled<code>[\]</code> massively from approximately 38% in 1960 to 15% in 2000. <strong>Conversely</strong>, there was an enormous escalation<code>[/]</code> in the use of cars from a mere 7% in 1960 to around 38% in 2000.</p>
<p>Train use grew<code>[/]</code> moderately from 18% in 1960 to just over 25% in 1980 before dipping<code>[\]</code> marginally to 23% in 2000. <strong>In contrast, tube usage experienced an inverse trajectory.</strong> It declined<code>[\]</code> from roughly 27% in 1960 to 22% in 1980, followed by a negligible uptick<code>[/]</code> to 25% in 2000.</p>
<p>To sum up, the popularity of trains and cars ascended<code>[/]</code> over the period, <strong>while</strong> that of the other two types of transportation dropped<code>[\]</code>. It is also evident that cars became the most popular method of transportation in the year 2000.</p>
<p>–</p>
<p>Subject：</p>
<ul>
<li>1.the proportion of commuters who used buses</li>
<li>2.the proportion of commuters using buses</li>
<li>3.the proportion of individuals who commuted by bus</li>
<li>4.the proportion of individuals commuting by bus</li>
<li>5.the percentage of bus users/commuters</li>
<li>6.The use of buses</li>
<li>7.The usage of buses</li>
<li>8.Bus use</li>
<li>9.Bus usage</li>
<li>10.The popularity of buses 结尾</li>
</ul>
<p>–</p>
<p>highlight：</p>
<ul>
<li><a href="#34-1before">1+before</a></li>
<li><a href="#33-1followed-by">1+followed by</a></li>
<li><a href="#61-%E7%9B%B8%E5%8F%8D">相反</a>：In contrast, tube usage experienced an inverse trajectory.</li>
</ul>
<hr />
<h4 id="telephone"><a class="markdownIt-Anchor" href="#telephone"></a> telephone</h4>
<p>题目：<br />
<img src="https://pic.imgdb.cn/item/6720d81cd29ded1a8c551a93.png" alt="" /></p>
<p>–</p>
<p>The diagram illustrates the variations in the total number of minutes of three types of telephone calls in Britain over an eight-year period between 1995 and 2002.</p>
<p>The usage of local-fixed line calls ascended<code>[/]</code> steadily from just over 70 billion minutes in 1995 to approximately 90 billion minutes in 1999, before dropping<code>[\]</code> moderately to around 70 billion minutes in 2002.</p>
<p>The use of national and international-fixed line calls escalated<code>[/]</code> gradually from around 25 billion minutes in 1995 to almost 60 billion minutes in 2002.</p>
<p>There was an enormous rise<code>[/]</code> in mobile call usage from a mere 2 billion minutes to nearly 40 billion minutes.</p>
<p>To sum up, the popularity of local-fixed line calls remained relatively stable<code>[-]</code> over the period, while that of the other two types of telephone calls climbed<code>[/]</code>. It is also evident that local fixed line calls were still the most<code>[^]</code> popular call type in the year 2002.</p>
<p>–</p>
<p>Subject：</p>
<ul>
<li>1.the total number of minutes of local-fixed line calls</li>
<li>2.the number of minutes spent on local-fixed line calls</li>
<li>3.The amount of time spent on local-fixed line calls</li>
<li>4.The use of local-fixed line calls</li>
<li>5.The usage of local-fixed line calls</li>
<li>6.Local-fixed line call usage</li>
<li>7.The popularity of local-fixed line calls</li>
</ul>
<p>–</p>
<p>highlight:</p>
<ul>
<li><a href="#34-1before">1+before</a></li>
</ul>
<h3 id="1027-book-cd-meat-telephone_v2"><a class="markdownIt-Anchor" href="#1027-book-cd-meat-telephone_v2"></a> 10.27 book + CD + meat + telephone_v2</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="book"><a class="markdownIt-Anchor" href="#book"></a> book</h4>
<p><img src="https://pic.imgdb.cn/item/6720de56d29ded1a8c5a54f2.png" alt="" /></p>
<p>–<br />
初稿</p>
<p>The diagram illustrates the variations in the sales of four types of reading materials in six separate years: 2002, 2004, 2006, 2008, 2010, and 2012.</p>
<p>The numbers of history books sold ascended massively from over 4 thousand copies in 2002 to 10 thousand copies in 2008, followed by a drop to around 9 thousand copies in 2012.</p>
<p>The sales of Art books negligibly climbed from just below 2 thousand copies in 2002 to 4 thousand copies in 2012. In addition, there was a moderate upswing in entertainment book soles from just shy of 2 thousand copies in 2002 to around 3 thousand copies in 2006, and then it remained relatively unchanged between 2006 and 2012.</p>
<p>Hobby books sales experience wild fluctuation over the 10-year period from 2002 to 2012.</p>
<p>To sum up, the popularity of hobby books fluctuated slightly over the period, while that of other three categories of book escalated. It is also evident that history book became the most popular type of reading materials in the year 2012.</p>
<p>–<br />
修改后</p>
<p>The diagram illustrates the variations in the sales of four types of reading materials over a 10-year period between 2002 and 2012.<br />
The number of history book sold was the highest<code>[^]</code> throughout the period, growing<code>[/]</code> massively from over 4,000 copies in 2002 to 10,000 copies in 2008, with this rise<code>[/]</code> being particularly noticeable between 2004 and 2006, exemplified by an astounding climb<code>[/]</code> of 3,500 copies. However, it had fallen<code>[\]</code> back to around 9,000 copies by 2012.</p>
<p>The sales of art books experienced an upward<code>[/]</code> trend, ascending<code>[/]</code> steadily from just below 2,000 copies in 2002 to 4,000 copies in 2012, though the rate of growth<code>[/]</code> decelerated<code>[\]</code> over the last two years. In addition, there was a moderate upswing<code>[/]</code> in entertainment book sales, increasing<code>[/]</code> from just shy of 2,000 copies in 2002 to around 3,000 copies in 2006, followed by a period of leveling off<code>[-]</code> until the end of the period in question.</p>
<p>Following a different pattern, the sales of hobby books remained constantly low during this 10-year period, fluctuating<code>[~]</code> within the range of 200 and 500 copies. 【Following a different pattern, the sales of hobby books remained constantly low during this 10-year period, starting at 500 copies and ending at 200 copies. 】</p>
<p>To sum up, the popularity of hobby books fluctuated<code>[~]</code> slightly over the period, while that of the other three categories of books witnessed growth escalated<code>[/]</code>. It is also evident that history books were the most popular reading materials. 【history book became the most popular type of reading materials in the year 2012.】</p>
<p>–</p>
<p>Subject:</p>
<ul>
<li>The sales of history books</li>
<li>the number of history books sold</li>
<li>History book sales</li>
<li>The popularity of history books</li>
<li>History books直接对象</li>
</ul>
<p>–</p>
<p>highlight:</p>
<ul>
<li><a href="#52-%E5%85%A8%E5%B9%B4%E6%9C%80%E9%AB%98%E5%8F%A5%E5%9E%8B">全年最高句型</a> + <a href="#55-%E5%B9%85%E5%BA%A6%E6%8B%93%E5%B1%95">幅度拓展</a>: The number of history book sold was the highest<code>[^]</code> throughout the period, growing<code>[/]</code> massively from over 4,000 copies in 2002 to 10,000 copies in 2008, with this rise<code>[/]</code> being particularly noticeable between 2004 and 2006, exemplified by an astounding climb<code>[/]</code> of 3,500 copies. However, it had fallen<code>[\]</code> back to around 9,000 copies by 2012.</li>
<li><a href="#55-%E5%B9%85%E5%BA%A6%E6%8B%93%E5%B1%95">幅度拓展</a>: The sales of art books experienced an upward<code>[/]</code> trend, ascending<code>[/]</code> steadily from just below 2,000 copies in 2002 to 4,000 copies in 2012, though the rate of growth<code>[/]</code> decelerated<code>[\]</code> over the last two years.</li>
<li><a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D">双上升/下降</a> + <a href="#36-there-befollowed-by">There be+followed by</a> : In addition, there was a moderate upswing<code>[/]</code> in entertainment book sales, increasing<code>[/]</code> from just shy of 2,000 copies in 2002 to around 3,000 copies in 2006, followed by a period of leveling off<code>[-]</code> until the end of the period in question.</li>
<li><a href="#62-%E4%B8%AD%E6%80%A7%E8%AF%8D">中性词</a>: Following a different pattern</li>
<li><a href="#58-%E5%85%A8%E5%B9%B4%E6%9C%80%E4%BD%8E%E5%BF%BD%E7%95%A5%E8%B6%8B%E5%8A%BF%E7%9A%84%E5%86%99%E6%B3%95">全年最低：忽略趋势的写法</a>: Following a different pattern, the sales of hobby books remained constantly low during this 10-year period, fluctuating<code>[~]</code> within the range of 200 and 500 copies.</li>
</ul>
<hr />
<h4 id="cd"><a class="markdownIt-Anchor" href="#cd"></a> CD</h4>
<p><img src="https://pic.imgdb.cn/item/6720e5c8d29ded1a8c6079be.png" alt="" /></p>
<p>–<br />
初稿</p>
<p>The diagram illustrates the variations in the number of games software, CDs and DVD or video sold worldwide over a 4-year period from 2000 to 2003.</p>
<p>The sales of games softeware ascended marginally from approximately 12 billion dollar in 2000 to around 18 billion dollar in 2003.</p>
<p>There was a moderate escalation in the DVD or video sales from roughly 18 billion dollar in 2000 to just over 30 billion dollar in 2003.</p>
<p>The number of CDs which were sold in the world dwindled slightly from just shy of 35 billion dollar in 2000 to nearly 32 billion dollar in 2002, but it recovered to 33 billion dollar in 2003.</p>
<p>To sum up, the popularity of CDs sales remained relatively stable over the period, while that of the other two types of multimedia entertainment products climbed. It is also evident that CDs were still the most popular digital products in the year 2003.</p>
<p>–<br />
修改后</p>
<p>The diagram illustrates the variations in the sales of game software, CDs, and DVD or video sold worldwide over a 4-year period from 2000 to 2003.</p>
<p>The sales of CDs were the highest<code>[^]</code> throughout the period, dwindling<code>[\]</code> slightly from just shy of 35 billion dollars in 2000 to nearly 32 billion in 2002. However, sales had recovered<code>[/]</code> to 33 billion by 2003.</p>
<p>There was a massive escalation<code>[/]</code> in DVD or video sales, growing<code>[/]</code> from roughly 18 billion in 2000 to just over 30 billion in 2003, with this rise<code>[/]</code> being particularly noticeable between 2001 and 2002, exemplified by as astounding climb<code>[/]</code> of 7 billion.</p>
<p>The sales of game software experienced an upward<code>[/]</code> trend, ascending<code>[/]</code> steadily from approximately 12 billion in 2000 to around 18 billion dollars in 2002, followed by a period of leveling off<code>[-]</code> until the end of the period in question.</p>
<p>To sum up, the popularity of CDs remained relatively stable<code>[-]</code> over the period, while the other two items witnessed growth<code>[/]</code> . It is also evident that CDs were still the most popular item in the year 2003.</p>
<p>–</p>
<p>Subject：</p>
<ul>
<li>The sales of CDs</li>
<li>Sales of CDs</li>
<li>CDs(直接对象)</li>
<li>The popularity of CDs</li>
<li>CD sales</li>
</ul>
<p>–</p>
<p>highlight:</p>
<ul>
<li><a href="#52-%E5%85%A8%E5%B9%B4%E6%9C%80%E9%AB%98%E5%8F%A5%E5%9E%8B">全年最高句型</a>: The sales of CDs were the highest<code>[^]</code> throughout the period, dwindling<code>[\]</code> slightly from just shy of 35 billion dollars in 2000 to nearly 32 billion in 2002. However, sales had recovered<code>[/]</code> to 33 billion by 2003.</li>
<li><a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D">双上升/下降</a> + <a href="#55-%E5%B9%85%E5%BA%A6%E6%8B%93%E5%B1%95">幅度拓展</a>: There was a massive escalation<code>[/]</code> in the DVD or video sales, growing<code>[/]</code> from roughly 18 billion in 2000 to just over 30 billion in 2003, with this rise<code>[/]</code> being particularly noticeable between 2001 and 2002, exemplified by as astounding climb<code>[/]</code> of 7 billion.</li>
<li><a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D">双上升/下降</a> + <a href="#33-1followed-by">1+followed by</a>: The sales of game software experienced an upward<code>[/]</code> trend, ascending<code>[/]</code> steadily from approximately 12 billion in 2000 to around 18 billion dollars in 2002, followed by a period of leveling off<code>[-]</code> until the end of the period in question.</li>
<li>总结段全年最高：It is also evident that CDs were still the most popular item in the year 2003.</li>
</ul>
<h4 id="meat"><a class="markdownIt-Anchor" href="#meat"></a> meat</h4>
<p><img src="https://pic.imgdb.cn/item/6724ede0d29ded1a8ca4a6ba.png" alt="" /></p>
<p>–<br />
初稿</p>
<p>The diagram illustrates the variations in the consumption of four types of food in a specific European country over a 25-year period from 1979 to 2004.</p>
<p>Beef consumption witnessed a downward trend, declining massively from just shy of 220 grams in 1979 to around 100 in 2024, albeit with a marginal growth over the first eight years.</p>
<p>There was a significant ascent in the consumption of chicken, climbing from almost 150 in 1979 to 250 in 2004. In contrast, lamb consumption experienced an inverse trajectory. It dropped substantially from 150 to just over 50 throughout the duration.<br />
Following a different pattern, the consumption of fish remained constantly low during this 25-year period, starting at approximately 60 and ending at almost 40 grams.</p>
<p>To sum up, the popularity of fish fluctuated slightly over the period, while chicken increased, and the other two categories of meat demonstrated a downward trend in the consumption. It is evident that chicken became the most popular choice in the year 2004.</p>
<p>–</p>
<p>The diagram illustrates the variations in the consumption of four types of food <strong>s-chicken, beef, lamb, and fish-</strong> in a specific European country over a 25-year period from 1979 to 2004.</p>
<p>Beef consumption witnessed a downward trend, declining massively from just shy of 220 grams <strong>per person per week</strong> in 1979 to around 100 <strong>grams</strong> in 2024, albeit with a marginal growth over the first eight years.</p>
<p>There was a significant ascent in the consumption of chicken, climbing from almost 150 <strong>grams</strong> in 1979 to 250 <strong>grams</strong> in 2004. In contrast, lamb consumption experienced an inverse trajectory. It dropped substantially from 150 <strong>grams</strong> to just over 50 <strong>grams</strong> throughout the duration.</p>
<p>Following a different pattern, the consumption of fish remained constantly low during this 25-year period, starting at approximately 60 and ending at almost 40 grams.</p>
<p>To sum up, the popularity of chicken increased over the period, while the other three foods showed declines. It is evident that chicken became the most popular choice in the year 2004.</p>
<p>–</p>
<p>The diagram illustrates the variations in the consumption of four types of foods-chicken, beef, lamb, and fish-in a specific European country over a 25-year period from 1979 to 2004.</p>
<p>In 1979, beef was by far the most<code>[^]</code> popular of these foods, with about 225 grams consumed per person per week.<a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a> The figures for lamb and chicken were similar<code>[=]</code>, each hovering around 150 grams, while the consumption of fish was only 60 grams.<a href="#44-the-figure-for-%E5%AF%B9%E8%B1%A1"><code>the figure for 对象</code></a> 起点段</p>
<p>However, during this 25-year period, the consumption of beef and lamb experienced a massive fall<code>[\]</code>, dipping<code>[\]</code> to approximately 100 grams and 55 grams, respectively.<a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>1-双上升/下降</code></a> <a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><code>2-两个对象并列写法</code></a> The consumption of fish also declined<code>[\]</code>, although this drop<code>[\]</code> was much less pronounced, dwindling<code>[\]</code> to/ending at just blow 50 grams. <a href="#510-%E5%B9%85%E5%BA%A6%E7%9A%84%E5%AF%B9%E6%AF%94"><code>幅度的对比</code></a><br />
下降段</p>
<p>In contrast, the consumption of chicken showed an upward<code>[/]</code> trend, overtaking that of lamb in 1980 and that of beef in 1989. By 2004, it had surged<code>[/]</code>, peaking<code>[^]</code> at almost 250 grams per person per week. <a href="#511-%E8%B6%85%E8%BF%87%E6%AE%B52%E5%8F%A5%E8%AF%9D"><code>超过段：2句话</code></a> 上升段</p>
<p>To sum up, the popularity of chicken increased<code>[/]</code> over the period, while the other three foods showed declines<code>[\]</code>. It is evident that chicken became the most<code>[^]</code> popular choice in the year 2004.</p>
<p>–</p>
<p>Subject：</p>
<ul>
<li>the consumption of beef</li>
<li>the amount of consumed</li>
<li>beef consumption</li>
<li>the popularity of beef</li>
<li>beef</li>
</ul>
<h4 id="telephone_v2"><a class="markdownIt-Anchor" href="#telephone_v2"></a> telephone_v2</h4>
<p><img src="https://pic.imgdb.cn/item/6724f659d29ded1a8cb102ed.png" alt="" /></p>
<p>–</p>
<p>The diagram illustrates the variations in the total number of minutes of three types of telephone calls in Britain over an eight-year period between 1995 and 2002.</p>
<p>The use of local fixed line calls was the highest<code>[^]</code> throughout the period, escalating<code>[/]</code> gradually from 72 billion minutes in 1995 to 90 billion in 1999. However, it had fallen<code>[\]</code> back to 72 billion by 2002, returning to its initial level/ending at the same level as it started. <a href="#52-%E5%85%A8%E5%B9%B4%E6%9C%80%E9%AB%98%E5%8F%A5%E5%9E%8B"><code>全年最高句型</code></a></p>
<p>The usage of national and international fixed line calls experienced an upward<code>[/]</code> trend, growing<code>[/]</code> steadily from 38 billion in 1995 to 61 billion at the end of the period in question <a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a>, though the rate of growth<code>[/]</code> decelerated<code>[\]</code> over the last two years/albeit with a slower growth rate over the last two years . <a href="#55-%E5%B9%85%E5%BA%A6%E6%8B%93%E5%B1%95"><code>幅度拓展</code></a></p>
<p>There was an enormous increase<code>[/]</code> in mobile call usage, surging<code>[/]</code> from a mere 2 billion to 46 billion <a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a>, with this rise<code>[/]</code> being particularly noticeable between 1999 and 2002, exemplified by an astounding climb<code>[/]</code> of 30 billion minutes. <a href="#55-%E5%B9%85%E5%BA%A6%E6%8B%93%E5%B1%95"><code>幅度拓展</code></a></p>
<p>To sum up, the popularity of local-fixed line calls remained relatively stable over the period, while the other two types of telephone calls witnessed growth. It is also evident that local fixed line calls were still the most popular call type in the year 2002.</p>
<h3 id="1029-internet-fishchips"><a class="markdownIt-Anchor" href="#1029-internet-fishchips"></a> 10.29 Internet + fish&amp;chips</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="internet"><a class="markdownIt-Anchor" href="#internet"></a> Internet</h4>
<p><img src="https://pic.imgdb.cn/item/6724f932d29ded1a8cb59799.png" alt="" /></p>
<p>–</p>
<p>The diagram depicts the variations in the proportion of people using the Internet in three different nations-the USA, Canada, and Mexico-over a 10-year period from 1999 to 2009.</p>
<p>In 1999, the percentage of individuals who used the Internet in the USA was by far the highest, at approximately 20%.<a href="#42-the-numberpercentagesalesconsumption-of-sth%E4%B8%BB%E8%AF%AD"><code>The number / percentage / sales / consumption of sth主语</code></a> The figure for Canada stood at 10%, while Internet usage in Mexico was only 5%.<a href="#44-the-figure-for-%E5%AF%B9%E8%B1%A1"><code>the figure for 对象</code></a></p>
<p>During this 10-year period, the figures for the USA and Mexico showed steady growth<a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a>, escalating to just over 80% and nearly 40%, respectively<a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><code>两个对象并列写法</code></a>. Meanwhile, the proportion of Internet users in Canada also went up, but this increase was much more pronounced <a href="#510-%E5%B9%85%E5%BA%A6%E7%9A%84%E5%AF%B9%E6%AF%94"><code>幅度的对比</code></a>, surpassing that of the USA in 2002 and peaking at around 95% in 2009.<a href="#511-%E8%B6%85%E8%BF%87%E6%AE%B52%E5%8F%A5%E8%AF%9D"><code>超过段：2句话</code></a></p>
<p>To sum up, the popularity of the Internet in three different countries experienced an upward trend over the period. It is also evident that Canada had the highest proportion of Internet users at the end of period in the question.</p>
<p>–</p>
<p>Subject:</p>
<ul>
<li>the percentage of individuals who used the Internet in the USA</li>
<li>the percentage of individuals using the Internet in the USA</li>
<li>The use of the Internet in the USA</li>
<li>The usage of the Internet in the USA</li>
<li>Internet use in the USA</li>
<li>Internet usage in the USA</li>
</ul>
<p>–</p>
<h4 id="fishchips"><a class="markdownIt-Anchor" href="#fishchips"></a> fish&amp;chips</h4>
<p><img src="https://pic.imgdb.cn/item/6724fe8bd29ded1a8cbdd398.png" alt="" /></p>
<p>–</p>
<p>The diagram illustrates the variations in the amount of three types of fast foods consumed by teenagers in Australia over a 25-year period from 1975 to 2000.</p>
<p>In 1975, fish and chips were by far the most popular of these fast foods, being consumed around 100 times per year. The figures for hamburgers and pizza were similar, each hovering almost 10 times.</p>
<p>However, during the 25-year period, the consumption of pizza experienced a massive ascent, climbing to just over 80 times. Hamburgers also escalated, but this increase was much more pronounced, ending at approximately 100 times.</p>
<p>In contrast, the number of fish and chips which were consumed displayed a downward trend, being overtaken by hamburgers in 1987 and by pizza in 1991.</p>
<p>To sum up, the popularity of hamburgers and pizza demonstrated noticeable growth over the period, while the other one show a decline. It is also evident that hamburgers became the most popular choice at the end of period in the question.</p>
<p>–</p>
<p>The diagram depicts the variations in the consumption of three types of fast foods consumed by adolescents in Australia over a 25-year period between 1975 and 2000.</p>
<p>In 1975, fish and chips was by far the most<code>[^]</code> popular of these fast foods, consumed 100 times  per year <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>. The figures for hamburgers and pizza were significantly lower, at 10 and 5 times, respectively <a href="#44-the-figure-for-%E5%AF%B9%E8%B1%A1"><code>the figure for 对象</code></a> <a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><code>两个对象并列写法</code></a>.</p>
<p>However, during this 25-year period, the consumption of fish and chips dwindled<code>[\]</code> to approximately 40 times, reflecting a substantial reduction<code>[\]</code> <a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a> , though there was a slight ascent<code>[/]</code> between 1980 and 1985 <a href="#512-%E4%B8%89%E6%9D%A1%E7%BA%BF%E6%95%B4%E4%BD%93%E5%8C%BA%E9%97%B4%E4%B8%8B%E9%99%8D%E5%8F%AA%E6%9C%89%E4%B8%AD%E9%97%B4%E6%9C%89%E4%B8%80%E4%B8%AA%E5%B0%8F%E4%B8%8A%E5%8D%87"><code>三条线整体区间下降，只有中间有一个小上升</code></a>.</p>
<p>In contrast, the consumption of hamburgers and pizza both experienced a climb<code>[/]</code>, overtaking that of fish and chips in 1985 and 1988 <a href="#511-%E8%B6%85%E8%BF%87%E6%AE%B52%E5%8F%A5%E8%AF%9D"><code>超过段：2句话</code></a>, respectively <a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><code>两个对象并列写法</code></a>. By 1995, their consumption had surged<code>[/]</code>, rising<code>[/]</code> to 100 times and 85 times<a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a>, respectively<a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><code>两个对象并列写法</code></a> , followed by a period of leveling off<code>[-]</code> until the end of the period <a href="#33-1followed-by"> <code>1+followed by</code></a>. 一起写</p>
<p>//</p>
<p>In contrast, the consumption of hamburgers showed an upward trend<code>[/]</code>, overtaking that of fish and chips in 1988. By 2000, it had surged<code>[/]</code>, peaking<code>[^]</code> at 100 times per year <a href="#511-%E8%B6%85%E8%BF%87%E6%AE%B52%E5%8F%A5%E8%AF%9D"><code>超过段：2句话</code></a>. The consumption of pizza also rose<code>[/]</code>, although this ascent was less pronounced, growing<code>[/]</code> to 82 times in 1995 <a href="#510-%E5%B9%85%E5%BA%A6%E5%AF%B9%E6%AF%94"><code>幅度对比</code></a> before leveling off<code>[-]</code> until the end of the period <a href="#34-1before"><code>1+before</code></a>. 分开描述</p>
<p>To sum up, the popularity of fish and chips dropped over the period, while the consumption of the other two fast foods increased. It is also evident that hamburgers became the most popular fast food in the year 2000.</p>
<p>–</p>
<p>highlight:</p>
<ul>
<li>teenagers=adolescent</li>
<li>the amount of m没有列出来的话，可以加可以不加s</li>
<li>fish and chips在图片是同一类，所以后面用was</li>
<li>要捕捉上升后平，以及下降过程中的凸起部分</li>
</ul>
<h3 id="1031-transportation_v2-film"><a class="markdownIt-Anchor" href="#1031-transportation_v2-film"></a> 10.31 transportation_v2 + film</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="transporation_v2"><a class="markdownIt-Anchor" href="#transporation_v2"></a> transporation_v2</h4>
<p><img src="https://pic.imgdb.cn/item/67250cb9d29ded1a8cd3884a.png" alt="" /></p>
<p>–</p>
<p>The diagram illustrates the variations in the proportion of commuters who used various types of transportation in a specific European city in three separate years: 1960, 1980, and 2000.</p>
<p>起点段In 1960, buses were by far the most<code>[^]</code> popular of these means of transport, with around 38% of commuters using them <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>. The figures for the tube and trains were lower, at 27% and 18%, respectively <a href="#44-the-figure-for-%E5%AF%B9%E8%B1%A1"><code>the figure for 对象</code></a> <a href="#59-%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%B9%B6%E5%88%97%E5%86%99%E6%B3%95"><code>两个对象并列写法</code></a>, while the least favored choice was cars, with only 7% of people driving to work <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>.</p>
<p>The proportion of commuters using buses dwindled<code>[\]</code> massively to 15% in 2000. Conversely <a href="#51-%E8%A1%A8%E7%9B%B8%E5%8F%8D"><code>表相反</code></a>, there was an enormous escalation<code>[/]</code> in the use of cars to around 38% in 2000.</p>
<p>Train use grew<code>[/]</code> moderately to just over 25% in 1980 before dipping<code>[\]</code> marginally to 23% in 2000 <a href="#34-1before"><code>1+before</code></a>. In contrast, tube usage experienced an inverse trajectory <a href="#51-%E8%A1%A8%E7%9B%B8%E5%8F%8D"><code>表相反</code></a>. It declined<code>[\]</code> to 22% in 1980, followed by a negligible uptick<code>[/]</code> to 25% in 2000 <a href="#33-1followed-by"><code>1+followed by</code></a>.</p>
<p>To sum up, the popularity of trains and cars ascended over the period, while the other two types of transportation witnessed drops. It is also evident that cars became the most popular method of transportation in the year 2000.</p>
<p>–<br />
交叉写法</p>
<p>The diagram illustrates the variations in the proportion of commuters who used various types of transportation in a specific European city in three separate years: 1960, 1980, and 2000.</p>
<p>In 1960, <strong>buses</strong> were by far the most<code>[^]</code> popular of these means of transport, with around 38% of commuters using them <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a> , while the least favored choice was <strong>cars</strong>, with only 7% of people driving to work <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a> . However, during this 40-year period, the proportion of commuters using <strong>buses</strong> saw a massive reduction<code>[\]</code>, dwindling<code>[\]</code> to 15% in 2000 <a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a>, whereas there was an enormous escalation<code>[/]</code> in the use of <strong>cars</strong>, surging<code>[/]</code> to around 38% in 2000 <a href="#57-%E5%8F%8C%E4%B8%8A%E5%8D%87%E4%B8%8B%E9%99%8D"><code>双上升/下降</code></a>.</p>
<p>Train use grew<code>[/]</code> moderately from 18% in 1960 to just over 25% in 1980 before dipping<code>[\]</code> marginally to 23% in 2000 <a href="#34-1before"><code>1+before</code></a>. In contrast, tube usage experienced an inverse trajectory <a href="#51-%E8%A1%A8%E7%9B%B8%E5%8F%8D"><code>表相反</code></a>. It declined<code>[\]</code> from roughly 27% in 1960 to 22% in 1980, followed by a negligible uptick<code>[/]</code> to 25% in 2000 <a href="#33-1followed-by"><code>1+followed by</code></a>.</p>
<p>To sum up, the popularity of trains and cars ascended over the period, while the other two types of transportation witnessed drops. It is also evident that cars became the most popular method of transportation in the year 2000.</p>
<h4 id="film"><a class="markdownIt-Anchor" href="#film"></a> film</h4>
<p><img src="https://pic.imgdb.cn/item/6725133cd29ded1a8cde2702.png" alt="" /></p>
<p>–</p>
<p>Popular类文章常用的动词：</p>
<ul>
<li>Choose-select-opt for sth</li>
<li>Choose-select-opt to do sth</li>
<li>Favor=prefer</li>
</ul>
<p>–</p>
<p>Action movies were by far the most <strong>favored</strong> of these films genres among men <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>, with 40% of male viewers choosing to watch them <a href="#43-%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%BB%E8%AF%AD"><code>数据作主语</code></a>. In comparison, 20% of men <strong>favored</strong> comedy movies <a href="#43-%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%BB%E8%AF%AD"><code>数据作主语</code></a>, while the percentage of men <strong>preferring</strong> thriller movies was slightly lower <a href="#42-the-numberpercentagesalesconsumption-of-sth%E4%B8%BB%E8%AF%AD"><code>The number/percentage/sales/consumption of sth主语</code></a>, at 15%. In addition, science fiction and western movies had the same figure <a href="#45-%E5%AF%B9%E8%B1%A1had"><code>对象+had</code></a>, both at 10%. On the other hand, the least preferred choice was romantic comedies, <strong>which attracted</strong> only 5% of men <a href="#46-%E5%AF%B9%E8%B1%A1attracted%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%B1%BB%E6%96%87%E7%AB%A0%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BA%BA"><code>对象+attracted(受欢迎类文章+数据是人)</code></a>.</p>
<h3 id="1102-timber"><a class="markdownIt-Anchor" href="#1102-timber"></a> 11.02 timber</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<p><img src="https://pic.imgdb.cn/item/6728583ed29ded1a8c4e3676.png" alt="" /></p>
<p>–</p>
<p>The diagram depicts the variations in the production of three types of products-timber, pulp, and paper-in a specific European country over a 20-year period from 1980 to 2000.</p>
<p>In 1980, timber had the highest production, at 6 million tonnes <s>of timber were produced</s> 【这里要用<a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>,因为是加分句型】<s>,which had the highest figure in these products</s>. The production of pulp, at approximately 4 million, was slightly higher than that of paper, at roughly 3 million.</p>
<p>During this 20-year period, <s>the figure for</s> timber showed an upward trend in production, rising to just shy of 8 million, though there was a moderate drop between 1989 and 1995. Paper production experienced a massive climb, surpassing that of timber in 1992. By 2000, it had surged, peaking at 10 million, albeit with a slower growth rate over the last five years. Meanwhile, <strong>the production of</strong> pulp also went up【直接主语要用in the xxx，不用直接做主语的话，那么就要加上the production of…】, although this increase was much less pronounced, ending at 6 million tonnes.</p>
<p>To sum up, the production <s>popularity</s> 【这个作文中写的是产量，所以不能用受欢迎程度】 of three products displayed an ascent <strong>over the period</strong>. It is also evident that paper had the largest production【这个地方和上面犯的错误一样，并且largest不一定等于highest，但这里是等价的】 <s>became the most popular product in the forest industry</s> at the end of period in question.</p>
<h3 id="1107-honeymoon"><a class="markdownIt-Anchor" href="#1107-honeymoon"></a> 11.07 honeymoon</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<p><img src="https://pic.imgdb.cn/item/67307f01d29ded1a8c619005.png" alt="" /></p>
<p>–</p>
<p>The diagram illustrates the number of newlywed British couples who chose the top eight honeymoon destinations in the year 2010.</p>
<p>Thailand was by far the most popular of these honeymoon destinations in this year, with 1410 newlywed British couples choosing it <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>, while Bali was the second most preferred choice, appealing to 1335 couples <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>. In comparison, Costa Rica and the Maldives had the similar figures, both at 750 and 600, respectively <a href="#45-%E5%AF%B9%E8%B1%A1had"><code>4.5 对象+had</code></a>. Additionally, 432 couples favored the Greek Islands <a href="#43-%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%BB%E8%AF%AD"><code>4.3 数据作主语</code></a>, whereas 209 selected Paris as their favorite destination <a href="#43-%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%BB%E8%AF%AD"><code>4.3 数据作主语</code></a>. On the other hand, the least favored choices were the Lake District and Spain, which attracted only 124 and 140 newlywed British couples, respectively <a href="#46-%E5%AF%B9%E8%B1%A1attracted%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%B1%BB%E6%96%87%E7%AB%A0%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BA%BA"><code>4.6 对象+attracted(受欢迎类文章+数据是人) | 同时这里把对象放在了系动词后面</code></a>.</p>
<p>To sum up, over half of all couples chose Thailand and Bali as their preferred honeymoon destinations, while only a small number couples opted to visit the Lake District and Spain.</p>
<h3 id="1116-sector-schoolmap-coffee流程图"><a class="markdownIt-Anchor" href="#1116-sector-schoolmap-coffee流程图"></a> 11.16 sector + school(map) + coffee(流程图)</h3>
<p><a href="#%E7%9B%AE%E5%BD%95">点击回到目录</a></p>
<h4 id="sector"><a class="markdownIt-Anchor" href="#sector"></a> sector</h4>
<p><img src="https://pic.imgdb.cn/item/6739c766d29ded1a8c98a40c.png" alt="" /></p>
<p>–</p>
<p>highlight:<br />
(1)对象 employed<br />
(2)数据主语+人:<br />
(2-1)Secured employment in<br />
(2-2)Pursued careers in<br />
(2-3)With  数据主语+人+上面的短语<br />
(3)新讲了followed by+double</p>
<p>–</p>
<p>The diagram depicts the percentage of graduates from Brighton University who entered various employment sectors in the year 2019.</p>
<p>Service industries were by far the most popular of these employment sectors, with 33.0% of graduates choosing to enter this field <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>, while the manufacturing industry was the second most favored sector, attracting 16.3% of graduates-a figure half that of service industries <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a> <a href="#48-double"><code>4.8 double</code></a> . Education was the next preferred option, which was chosen by 14.7% of graduates <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a> , followed closely by politics &amp; government, with 12.1% of graduates securing employment in this field <a href="#49-followed-by"><code>4.9 followed by</code></a> .</p>
<p>However, the remaining 23.9% was allocated to the other sectors. In detail, the percentages of graduates who entered transportation &amp; warehousing  and science &amp; technology were similar, each hovering around 7.5% <a href="#42-the-numberpercentagesalesconsumption-of-sth%E4%B8%BB%E8%AF%AD"><code>4.2 The number/percentage/sales/consumption of sth主语</code></a> . Civil service employed 5.6% of graduates <a href="#46-%E5%AF%B9%E8%B1%A1attractedappealed-todrew-%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%B1%BB%E6%96%87%E7%AB%A0%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BA%BA"><code>4.6 对象+attracted/appealed to/drew (受欢迎类文章+数据是人)</code></a>, double the percentage of graduates pursuing careers in the other sectors, at 2.8% <a href="#48-double"><code>4.8 double</code></a>. The least preferred choices were charity and sports, which attracted only 0.3% and 0.1% of graduates entering these fields, respectively <a href="#41-%E5%AF%B9%E8%B1%A1-waswere-by-far-the-most-popularfavoredpreferred-of-these-%E5%A4%8D%E6%95%B0-with-%E6%95%B0%E6%8D%AE--%E9%9D%9E%E8%B0%93%E8%AF%AD"><code>4.1 对象 was/were by far the most popular(=favored=preferred) of these 复数, with 数据 + 非谓语</code></a>.</p>
<p>To sum up, almost half of all graduates chose service and manufacturing industries, while only a small number 【of graduates 】opted for charity and sports <a href="#411-%E4%BA%BA%E5%BC%80%E5%A4%B4%E5%86%99%E7%BB%93%E5%B0%BEpopular%E7%B1%BB%E6%96%87%E7%AB%A0"><code>4.11 人开头写结尾：popular类文章</code></a>. 人开头</p>
<h4 id="schoolmap"><a class="markdownIt-Anchor" href="#schoolmap"></a> school(map)</h4>
<p><img src="https://pic.imgdb.cn/item/6739cb17d29ded1a8c9b94d6.png" alt="" /></p>
<p>–</p>
<p>这两幅地图显示了一所英国学校从1985年到现在的格局变化。</p>
<p>(全部用过去时)1985年，该校有1500名学生，其唯一的办公楼坐落于西北角处。其东边是一片停车场。图书馆和教学楼中间还有一个停车场，人们也可以停车在那儿。校园的南面几乎被运动场所覆盖。</p>
<p>现在，当学生人数上升到2300名，北面的就停车场就被改造成一个全新的半圆形，图书馆变成了电脑室。原本东面的小型停车场如今种满了树木和草坪。原有的教学楼添加了一个楼层，另新建了两个教学楼在其南面和西南面。原操场的西面地区被用来建造游泳馆和健身中心了，因此操场的面积缩小了很多。</p>
<p>总之，之所学校为了更好地适应学生数量增长的需求，将其内部格局进行了巨大的整改。</p>
<p>–</p>
<p>The two maps demonstrate the various developmental changes in the campus layout of a UK School in 1985 and present day…</p>
<p>In 1985, the school had 1500 students, and its only office building was located in the northwest corner. To its east, there was a car park. People can also stop their cars in another parking lot between the library and the classroom building. The southern area of the campus was nearly fully covered by a playing field. 过去时</p>
<p>At present, the number of students has exhibited an upward trend, rising to 2300. The old car park in the north area has been reconstructed to a new one with semicircle shapes and the library has been changed into a computer room. To its east, where there was a small car park has been replaced by trees. One storey has been added to the original classroom building, and two new classroom blocks have been constructed to its south and southwest direction. The west area of the playing field has been used for building swimming pool and fitness club, so the playground has shrank significantly. 现在完成时</p>
<p>In sum, this school changed its internal layout dramatically to better suit the need of growth in student number.</p>
<p>–</p>
<p>位于：</p>
<ul>
<li>was/were located in</li>
<li>was/were situated in</li>
</ul>
<p>变了：</p>
<ul>
<li>has/have been reconstructed to …</li>
<li>has/have been added to…</li>
<li>has/have been replaced by…</li>
<li>has/have been changed into…</li>
<li>has/have been converted into…</li>
<li>has/have been used for…</li>
<li>has/have been moved toward the…</li>
</ul>
<p>替代：</p>
<ul>
<li>A is placed in what used to be B</li>
<li>A is located in the area of the previous B</li>
<li>A occupies part of B</li>
</ul>
<h4 id="coffee"><a class="markdownIt-Anchor" href="#coffee"></a> coffee</h4>
<p><img src="https://pic.imgdb.cn/item/6739d13ad29ded1a8ca106e0.png" alt="" /></p>
<p>–</p>
<p>Firstly, Coffee beans are picked in the field.<br />
Then, These beans are dried, roasted and cooled.<br />
After that, these beans are put in a machine for grinding.<br />
The coffee is mixed with hot water.<br />
The mixture is strained and frozen.<br />
The frozen liquid is ground again in the machine.<br />
The coffee is dried in a vacuum so that the water evaporates.<br />
Finally, the coffee is packed into jars;</p>
<p>–</p>
<p>The flow chart illustrates the whole process of coffee manufacture and preparation for sale on the market.</p>
<p>It is clear that there are 11 stages in the production of coffee. The process begins with the picking of coffee beans, and ends at the packing stage. 凑字数</p>
<p>Looking at the coffee production process in detail, coffee beans must first be picked in the fields. These beans are then dried, roasted, and cooled before being put in a grinding machine, which turns the beans into coffee granules.</p>
<p>At the sixth stage in the process, the ground coffee is mixed with hot water, and the resulting mixture is strained. Next, the mixture is frozen and then passed once again through the grinder. After that, the ground, frozen liquid is dried in a vacuum so that the water evaporates, leaving the coffee granules. Finally, these granules are packed into coffee jars for delivery to shops.</p>
<h3 id="1118"><a class="markdownIt-Anchor" href="#1118"></a> 11.18</h3>
<p><img src="https://pic.imgdb.cn/item/6739d27dd29ded1a8ca21768.jpg" alt="" /></p>
<h2 id="1124"><a class="markdownIt-Anchor" href="#1124"></a> 11.24</h2>
<p><img src="https://pic.imgdb.cn/item/6744a6da88c538a9b5bbbcc0.png" alt="" /></p>
<p>–<br />
In London, flats were by far the most popular of these housing types, with approximately 58% of people choosing them, while terraced houses and semi-detached houses had the same figure, both at roughly 16%, respectively. The least favored option was detached houses, while attracted just shy of 10% of residents.</p>
<p>In Oxford, flats also had the highest popularity, with around 30% of people selecting this housing type, followed by semi-detached houses and detached houses, which were favored by 28% and 26% of dwellers, respectively. Terraced houses were selected by 18% of residents.</p>
<p>In Cambridge, detached houses were the most favored type, attracting nearly 36% of individuals, double the percentage of residents favoring terraced houses, at 18%. Meanwhile, 28% of people preferred to semi-detached houses, while 20% opted for 20%.</p>
<p>To sum up, residents in London and Oxford showed a preference for flats, while those in Cambridge chose to live in detached houses</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
  </entry>
  <entry>
    <title>IELTS:Speaking</title>
    <url>/2024/09/22/IELTS-Speaking/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="tips"><a class="markdownIt-Anchor" href="#tips"></a> Tips</h2>
<p>逻辑，大概就是总分总结构</p>
<h2 id="overall"><a class="markdownIt-Anchor" href="#overall"></a> Overall</h2>
<ul>
<li>only one students</li>
<li>20 minutes</li>
<li>The examiner you speak to grades you</li>
<li>fast and clear</li>
<li>no right answers</li>
</ul>
<p>The Speaking Exam:<br />
<img src="https://pic.imgdb.cn/item/66efa4c9f21886ccc03759cb.png" alt="" /></p>
<br>
<h3 id="before-part1-begins"><a class="markdownIt-Anchor" href="#before-part1-begins"></a> Before Part1 begins:</h3>
<p>This is the Speaking test for the international English Language Testing System conducted on … at …</p>
<p>The candidate is … , candidate number … , and the examer is …</p>
<br>
<h3 id="introductory-frame"><a class="markdownIt-Anchor" href="#introductory-frame"></a> Introductory Frame:</h3>
<ul>
<li>Can you tell me your full name,please?(中文名)</li>
<li>Thank you. And what shall I call you?(English name)</li>
<li>And can you tell me where are you from?(国家)</li>
<li>Can I see your identification please?(Of Course)</li>
</ul>
<p>Now in this first part,I would like to ask you some question about yourself.</p>
<br>
<h3 id="the-process"><a class="markdownIt-Anchor" href="#the-process"></a> The process</h3>
<p><code>Part 1</code>: 4-5 min | 3 topics | 9 questions</p>
<p>Questions about yourself,such as：</p>
<ul>
<li>Is there anything you dont like about your living area?</li>
<li>What do you study?</li>
<li>Which do you prefer,Saturday or Sunday?</li>
</ul>
<p>Examiner Only:</p>
<ul>
<li>repeat question</li>
<li>aks you to elaborate</li>
</ul>
<p>Examiner Can’t:</p>
<ul>
<li>explain</li>
<li>create own questions</li>
</ul>
<br>
<p><code>Part 2</code>: 3-4min | 1 min for notes | 1-2 min to talk<br />
Can look at topic card and notes while speaking</p>
<p>Describe a person who often help others,you should say:</p>
<ul>
<li>who this person is</li>
<li>what this person does</li>
<li>how this person help others and explain how you feel about this person</li>
</ul>
<p>Only in Part 2 can you:</p>
<ul>
<li>see the questions/notes</li>
<li>prepare</li>
</ul>
<p>You can’t ask for new topic</p>
<br>
<p><code>Part 3</code> 4-5min | room for discussion and debate</p>
<p>Topic is linked to Part 2;your answer need not be</p>
<p>performance in Part 3 is the  deal breaker</p>
<ul>
<li>What  are some reasons why peopele help others?</li>
<li>Is it necessary to help those in need?</li>
<li>Who should teach children to hepl others?</li>
<li>How can the government help people in your country?</li>
<li>What are some NGOs in your country that help peole?</li>
</ul>
<p>You Can：</p>
<ul>
<li>ask for explainations</li>
<li>redirect the question</li>
<li>ask for new question</li>
</ul>
<Br>
<h2 id="grading-criteria-for-speaking"><a class="markdownIt-Anchor" href="#grading-criteria-for-speaking"></a> Grading Criteria for Speaking</h2>
<ul>
<li><strong>Fluence and coherence</strong></li>
<li><strong>Pronunciation</strong></li>
<li>Lexical Resources</li>
<li>Grammatical Range and Accuracy</li>
</ul>
<h3 id="fluence-and-coherence"><a class="markdownIt-Anchor" href="#fluence-and-coherence"></a> Fluence and coherence</h3>
<p>Dos:</p>
<ul>
<li>Speak at length</li>
<li>Use connectives and discourse markers flexibly</li>
<li>Develop topic well</li>
</ul>
<p>Don’ts:</p>
<ul>
<li>Repeat and self-correct frequently</li>
<li>Have a lot of language-related hesitation</li>
<li>Over-Use connectives and discourse markers</li>
<li>Use connectives and discourse markers wrong</li>
</ul>
<hr />
<p>Do you like eating fish?</p>
<p>too short:</p>
<ul>
<li>Yes,of course. I love it.</li>
<li>No,I don’t,cause it smells, and there are way too many bones</li>
</ul>
<p><strong>Acceptable Length</strong>:<br />
No,I dont,cause it smells,and there are way too many bones. Every time I go by the seafood market, the smell of fish just makes me want to throw up, and I really hate the bones, you know when I was a kid, a fish bone got stuck in my throat, and I ended up in the hospital. It was a complete nightmare, and it’s one of the main reasons why I dislike eating fish.</p>
<hr />
<p><strong>432法则</strong>：带着很多错误和卡壳去说4min，纠正自己的错误去说3min,最后一遍复盘让自己卡到2min</p>
<p><img src="https://pic.imgdb.cn/item/66efb896f21886ccc04b1a13.png" alt="" /></p>
<br>
<h3 id="pronunciation"><a class="markdownIt-Anchor" href="#pronunciation"></a> Pronunciation</h3>
<p><img src="https://pic.imgdb.cn/item/66efbe0ff21886ccc050b427.png" alt="" /></p>
<ul>
<li>must pronounce <strong>vowels(元音)</strong> right</li>
<li>can be slow yet alse fluent</li>
<li>itonation matters a lot</li>
<li>practice word stress and sentence strees</li>
<li>pause where needed(clear meaning)</li>
</ul>
<h3 id="lexical-resources词汇量"><a class="markdownIt-Anchor" href="#lexical-resources词汇量"></a> Lexical Resources(词汇量)</h3>
<ul>
<li>less common and idiomatic(地道的) words</li>
<li>effective paraphrase(遇到不会的词，换个说法讲出来)</li>
<li>topic-related vocab(fishing相关的：防晒帽，拉鱼干等)</li>
<li>style and collocation(整体风格要一致，不要忽高忽低)</li>
<li>precise meaning(比较细致，隐隐作痛用什么来描述)</li>
</ul>
<p>不要用：大词，难词，偏词</p>
<p>Less common words:<br />
<img src="https://pic.imgdb.cn/item/6703a356d29ded1a8c46dca6.png" alt="" /></p>
<p>Idiomatic Vocabulary:<br />
<img src="https://pic.imgdb.cn/item/6703a3d3d29ded1a8c4786b2.png" alt="" /></p>
<p>Paraphrase:<br />
<img src="https://pic.imgdb.cn/item/6703a41ed29ded1a8c47fc40.png" alt="" /></p>
<p>Topic-related vocab:<br />
<img src="https://pic.imgdb.cn/item/6703a444d29ded1a8c482f3e.png" alt="" /></p>
<p>Style and Collocation:<br />
<img src="https://pic.imgdb.cn/item/6703a499d29ded1a8c48b724.png" alt="" /></p>
<p>Precisce Meaning:<br />
<img src="https://pic.imgdb.cn/item/6703a4b6d29ded1a8c48ea12.png" alt="" /></p>
<h3 id="grammatical-range-and-accuracy"><a class="markdownIt-Anchor" href="#grammatical-range-and-accuracy"></a> Grammatical Range and Accuracy</h3>
<ul>
<li>一个句子多个信息点</li>
<li>uses a range of complex structure flexibly</li>
<li>frequently produces error-free sentences</li>
<li>some mistakes persist(不影响理解的错误可以存在)</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703a559d29ded1a8c49e743.png" alt="" /></p>
<p>Complex Structure:<br />
<img src="https://pic.imgdb.cn/item/6703a5c5d29ded1a8c4a8f24.png" alt="" /></p>
<h2 id="part-1"><a class="markdownIt-Anchor" href="#part-1"></a> Part 1</h2>
<p>Outline:</p>
<ul>
<li>Part1 Question Stydles</li>
<li>Brainstorming</li>
<li>Reservoir of Ideas</li>
<li>Linking Words</li>
<li>Basic Requirements</li>
</ul>
<h3 id="part1-question-stydles"><a class="markdownIt-Anchor" href="#part1-question-stydles"></a> Part1 Question Stydles</h3>
<p>Question Style:</p>
<ul>
<li>Question Types:
<ul>
<li>Yes/No</li>
<li>Wh-Questions</li>
<li>Choice Questions</li>
<li>Hypothetical Questions</li>
</ul>
</li>
<li>4 Main Topics(Part2依然是)
<ul>
<li>People</li>
<li>Places</li>
<li>Objects</li>
<li>Events</li>
</ul>
</li>
</ul>
<hr />
<p>Question Types:<br />
<img src="https://pic.imgdb.cn/item/6703a79ed29ded1a8c4ce14c.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6703a80ed29ded1a8c4d7178.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6703a85cd29ded1a8c4dd201.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6703a8bbd29ded1a8c4e4cc8.png" alt="" /></p>
<hr />
<p>4 Main Types:<br />
Peoples:<br />
<img src="https://pic.imgdb.cn/item/6703a90cd29ded1a8c4eae7d.png" alt="" /></p>
<p>Places:<br />
<img src="https://pic.imgdb.cn/item/6703a926d29ded1a8c4ecba5.png" alt="" /></p>
<p>Objects:<br />
<img src="https://pic.imgdb.cn/item/6703a989d29ded1a8c4f4fc5.png" alt="" /></p>
<p>Events:<br />
<img src="https://pic.imgdb.cn/item/6703a9a6d29ded1a8c4f7049.png" alt="" /></p>
<hr />
<p>3 Mandatory Frames(必考话题)</p>
<ul>
<li>Where you live now</li>
<li>Hometown</li>
<li>Work/Study</li>
</ul>
<p>Where you live now:<br />
<img src="https://pic.imgdb.cn/item/6703aaa4d29ded1a8c50a7ee.png" alt="" /></p>
<p>Work/Study:<br />
<img src="https://pic.imgdb.cn/item/6703aac3d29ded1a8c50d008.png" alt="" /></p>
<h3 id="basic-answer-structure"><a class="markdownIt-Anchor" href="#basic-answer-structure"></a> Basic Answer Structure</h3>
<p><img src="https://pic.imgdb.cn/item/6703ab06d29ded1a8c512568.png" alt="" /></p>
<p>Topic Sentence:to give a clear,simple,direct answer</p>
<ul>
<li>no need to repeat the question</li>
<li>no need to paraphrase the question</li>
<li>Must answer accordingly</li>
</ul>
<p>Supporting Details:</p>
<ul>
<li>to elaborate and make your meaning clearer</li>
<li>to communicate effectively</li>
<li>to show your linguistic ability</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703acafd29ded1a8c533a0b.png" alt="" /></p>
<h3 id="brainstroming"><a class="markdownIt-Anchor" href="#brainstroming"></a> BrainStroming</h3>
<p>How to add details:</p>
<ul>
<li>Opinion</li>
<li>Description</li>
<li>Comparaison</li>
<li>Prediction</li>
<li>Reason</li>
<li>Example</li>
<li>Result: good or bad</li>
<li>Reference: 借别人的口来说</li>
</ul>
<hr />
<p>Templates for reference:</p>
<ul>
<li>TS + reason + example + another reason + opinton</li>
<li>TS + reason + comparaison + details</li>
<li>TS + opinion + description + prediction</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703adf1d29ded1a8c54ed28.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6703ae85d29ded1a8c559e75.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6703af1dd29ded1a8c563fc8.png" alt="" /></p>
<hr />
<p>Templates for No Answers:</p>
<ul>
<li>No + reason + opinion + prediction + result</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703b00dd29ded1a8c574a70.png" alt="" /></p>
<h3 id="reservoir-of-ideas"><a class="markdownIt-Anchor" href="#reservoir-of-ideas"></a> Reservoir of Ideas</h3>
<p>Reservoir:</p>
<ul>
<li>Time</li>
<li>Money</li>
<li>Health</li>
<li>Relationships(场景里面涉及到多个人)</li>
<li>Emotions</li>
<li>Experience</li>
<li>Environment：自然环境，城市环境，成长环境(孟母三迁)</li>
<li>Culture</li>
<li>Pressure</li>
<li>Convenience</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703d31ad29ded1a8c845be7.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6703d3bad29ded1a8c84fc7c.png" alt="" /></p>
<h3 id="linking-words"><a class="markdownIt-Anchor" href="#linking-words"></a> Linking Words</h3>
<p>给出另一种可能性：</p>
<ul>
<li>or</li>
<li>either…or…</li>
<li>otherwise,…</li>
<li>on the other hand,…</li>
<li>alternatively,…</li>
</ul>
<p>举例：</p>
<ul>
<li>such as</li>
<li>like…</li>
<li>for example</li>
<li>for instance</li>
</ul>
<p>表达观点：</p>
<ul>
<li>I think</li>
<li>I feel</li>
<li>I believe</li>
<li>in my opinion</li>
<li>in my view</li>
</ul>
<p>给出原因：</p>
<ul>
<li>because</li>
<li>as/for</li>
<li>due to</li>
<li>as a result of</li>
<li>for the reason that</li>
</ul>
<p>加相似或等同观点：</p>
<ul>
<li>and/also</li>
<li>besides</li>
<li>as well as</li>
<li>not only…but also…</li>
<li>another</li>
</ul>
<p>加对立观点：</p>
<ul>
<li>but/yet</li>
<li>on the other hand</li>
<li>still,…</li>
<li>although/even though</li>
<li>in spite of…</li>
</ul>
<p>解释或重述重点：</p>
<ul>
<li>in other words,…</li>
<li>in particular,…</li>
<li>to be specific,…</li>
<li>that is…</li>
</ul>
<p>强调观点：</p>
<ul>
<li>indeed</li>
<li>in fact</li>
</ul>
<h3 id="basic-requirement"><a class="markdownIt-Anchor" href="#basic-requirement"></a> Basic Requirement</h3>
<p>You are aminly scored on(短期很难进步，所以会着重听):</p>
<ul>
<li>Fluency</li>
<li>Pronunciation</li>
</ul>
<p>Control length of answer</p>
<ul>
<li>20~30 sec for each question</li>
<li>about 3~5 sentences</li>
<li>some answers should be long(resons,preferences,experiences,descriptions,importance)</li>
<li>other don’t need to be</li>
<li>be natural,don’t talk too much</li>
</ul>
<p>「Basic grammar」 must be correct:</p>
<ul>
<li>三单</li>
<li>一般过去时</li>
<li>完成时</li>
<li>被动语态</li>
<li>虚拟语气</li>
</ul>
<p>Tips:</p>
<ul>
<li>Record yourself</li>
<li>Listen and note your mistakes</li>
<li>Practice the structure 5-10 times with new sentences</li>
</ul>
<h2 id="part-2"><a class="markdownIt-Anchor" href="#part-2"></a> Part 2</h2>
<p>Part 2 Format:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Describe...</span><br><span class="line">  You should say:</span><br><span class="line">   - who...</span><br><span class="line">   - what...</span><br><span class="line">   - where...</span><br><span class="line"></span><br><span class="line">and explain why/how you feel...</span><br></pre></td></tr></table></figure>
<h3 id="intro"><a class="markdownIt-Anchor" href="#intro"></a> Intro</h3>
<p>Example of Topic Card:<br />
<img src="https://pic.imgdb.cn/item/6703e222d29ded1a8c97afc7.png" alt="" /></p>
<p>Topics(same as Part1):</p>
<ul>
<li>people</li>
<li>Place</li>
<li>Objects</li>
<li>Events</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703e29dd29ded1a8c981a29.png" alt="" /></p>
<p>Procedure:</p>
<ul>
<li>Examiner gives you topic card</li>
<li>Examiner gives you 1 min to prepare</li>
<li>Examiner asks you to stop taking notes afer 1 min</li>
<li>Examiner tells you to start speaking about topic</li>
<li>Examiner stops you afer 1-2 min</li>
<li>Examiner asks follow-up question</li>
</ul>
<p>For the follow-up <strong>question</strong>:</p>
<ul>
<li>you do not need give a full answer</li>
<li>you do not need to give details</li>
<li>you do not need to understand the  question</li>
<li>you do not need to say pardon</li>
<li>JUST SAY YES or NO</li>
<li>over</li>
</ul>
<p>Quick Recap:</p>
<ul>
<li><strong>Fluency and Coherence</strong> (repitition and self-correction,self-correction一定要去改)</li>
<li><strong>Pronunciation</strong>(说到中间的时候需要把语调提起来,清晰，升降起伏，单词的重音)</li>
<li>Grammatical Range and Accuracy</li>
<li>Lexical Resources</li>
<li>fast != fluent</li>
</ul>
<p>Basic Requirements:</p>
<ul>
<li>Speak as soon as examiner says so</li>
<li>Keep hte ball rolling</li>
<li>Speak with feeling</li>
<li>Stop when examiner tells you to</li>
<li>Try not to say “that’s all” and end P2 yourself</li>
</ul>
<p>Reminders for Part 2:</p>
<ul>
<li>will have <strong>1 full minute</strong> for notes</li>
<li>don’t write on book,use paper or whiteboard</li>
<li>if card nad notes are taken,<strong>ask for them back</strong></li>
<li>no need to finish in exactly 2 min(1min50sec)</li>
<li>being interrupted is <strong>normal</strong></li>
<li><strong>can’t ask for new topic</strong></li>
<li>examiner is not allowed to explain topic</li>
<li>eye contact is good,but <strong>not absolutely necessary</strong></li>
<li>examiner may seem unengaged</li>
</ul>
<h3 id="topic-card"><a class="markdownIt-Anchor" href="#topic-card"></a> Topic Card</h3>
<p><img src="https://pic.imgdb.cn/item/6703e818d29ded1a8c9d8a7c.png" alt="" /></p>
<ul>
<li>中间的部分可有可没有</li>
<li>前后两部分一定要有</li>
</ul>
<p>Pay attention to:</p>
<ul>
<li>Key words: 看清题目</li>
<li>Modifiers</li>
<li>tense(时态)</li>
<li>Focus of topic(主次分明，不一定要每个部分都平均)</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703e904d29ded1a8c9e8a6f.png" alt="" /></p>
<ul>
<li>题目里的modifiers多出现几次是没事的(exciting)</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6703eb51d29ded1a8ca163e7.png" alt="" /></p>
<h3 id="brainstorming-method-i"><a class="markdownIt-Anchor" href="#brainstorming-method-i"></a> Brainstorming Method I</h3>
<p><img src="https://pic.imgdb.cn/item/670787dfd29ded1a8c91ae1e.png" alt="" /></p>
<hr />
<p>例子：<br />
Describe an exciting trip you once took.</p>
<p>You should say:</p>
<ul>
<li>where you went</li>
<li>how you travelled there</li>
<li>what you did during the trip</li>
</ul>
<p>and explain how you felt about the trip.</p>
<hr />
<p>Ok,so I am gonna talk about an exciting trip that I took.</p>
<p>背景介绍：</p>
<ul>
<li>a few months ago</li>
<li>end of summer classes</li>
<li>needed a break</li>
<li>with my boyfriend</li>
<li>Chongqing</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/670787dfd29ded1a8c91ae1e.png" alt="" /></p>
<p>总结概括：</p>
<ul>
<li>special ,relaxing</li>
<li>tired</li>
<li>not a big deal,worth it(尽管有点累，但不是什么大事，它是值得的)</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/670789aed29ded1a8c942f3a.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/670789ced29ded1a8c945aa3.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/670789fcd29ded1a8c948f27.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/67078a10d29ded1a8c94a662.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/67078a27d29ded1a8c94be21.png" alt="" /></p>
<ul>
<li>语篇标记，粉色部分可以强调一下，增加层次感</li>
<li>背景介绍的最后一句话，利用modifier点一下题</li>
<li>but表示讲到重点上了</li>
<li>anyway用于总结</li>
</ul>
<h3 id="brainstorming-method-ii"><a class="markdownIt-Anchor" href="#brainstorming-method-ii"></a> Brainstorming Method II</h3>
<ul>
<li>5Ws and H: Who,What,Where,When,Why,How</li>
<li>Turn them into your own questionws:每个部分在上面挑选三个，然后问三个问题<br />
<img src="https://pic.imgdb.cn/item/67078c2dd29ded1a8c96b343.png" alt="" /></li>
<li>Answer these questions,about 2 sentences each</li>
</ul>
<h3 id="framework"><a class="markdownIt-Anchor" href="#framework"></a> Framework</h3>
<p>Who this person is:</p>
<ul>
<li>appearance:帅气男孩女孩，老年人</li>
<li>personality：人的性格，害羞，缩到他的壳里去</li>
<li>who they are to you</li>
</ul>
<p>What this object is:</p>
<ul>
<li>apparance: simply,classic,elegant</li>
<li>brand: 公司，历史</li>
<li>function/pupose：可以做什么事情</li>
</ul>
<p>What this event is:</p>
<ul>
<li>purpose: 为什么要举办</li>
<li>venue：地点场地</li>
<li>attendees：person</li>
</ul>
<p>When you do/did sth:</p>
<ul>
<li>period: 模糊的时间线，两年前，两月之前</li>
<li>exact time：暑假结束的时候，某个周末的早晨</li>
<li>occasion: 高考结束之后</li>
</ul>
<p>Where you do/did sth:</p>
<ul>
<li>relative location</li>
<li>exact place</li>
<li>near/far</li>
<li>how you get there</li>
<li>symbol/meaning</li>
</ul>
<p>How you do/did sth:起因结果结果</p>
<ul>
<li>cause</li>
<li>process</li>
<li>result</li>
</ul>
<p>觉得某个人怎么样：<br />
<img src="https://pic.imgdb.cn/item/6707904ad29ded1a8c9b9c18.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6707906ad29ded1a8c9bbc33.png" alt="" /></p>
<p>评价物品或者事件：<br />
<img src="https://pic.imgdb.cn/item/67079081d29ded1a8c9bd6fc.png" alt="" /></p>
<br>
<p>Guidelines for Taking Notes:</p>
<ul>
<li>Write key words(mostly hypernyms): 比较泛的的大方向词，比如水果和草莓</li>
<li>Write good words/phrases you want to use：好词好句</li>
<li>Don’t write full sentences</li>
<li>Don’t worry about spelling</li>
<li>can use Chinese/symbol/abbreviations(缩写)</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/67079223d29ded1a8c9d97d1.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/67079275d29ded1a8c9df3f9.png" alt="" /></p>
<h3 id="introducing-the-topic"><a class="markdownIt-Anchor" href="#introducing-the-topic"></a> Introducing the Topic</h3>
<p>Brainstorming Method I中使用的是<code>Ok,so I am gonna talk about an exciting trip that I took.</code> 下面再将介绍几种引入topic的方法：</p>
<ul>
<li>Ok，so…,well,…</li>
<li>Ok,so I’am gonna talk about…</li>
<li>Alright,so the topic I’m talking about is…</li>
<li>Today I would like to talk about…</li>
<li>I would like to share sth about…</li>
</ul>
<p>Describe a kind of bag I wanna own,well,it’s…</p>
<ul>
<li>Ok,so a kind of bag I wanna own,well,it’s…</li>
<li>Ok,so I’m gonna talk about a kind of bag I wanna own.</li>
<li>Alright,so the topic I’m talking about is a kinda bag I wanna won.</li>
<li>Today I would like to talk about a kind of a bag I want to own.</li>
<li>I would like to share sth about a kind of bag I want to own.</li>
</ul>
<h3 id="introducing-the-points"><a class="markdownIt-Anchor" href="#introducing-the-points"></a> Introducing the Points</h3>
<ul>
<li>讲完每个点可以喘一下气，似的结构分明</li>
</ul>
<p>Introducing Bullet Points:</p>
<ul>
<li>ask and answer:自问自答</li>
<li>as for…</li>
<li>and about…<br />
And explain…:and finaly,…</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/67079a3ed29ded1a8ca635c0.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/67079a75d29ded1a8ca673f9.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/67079a83d29ded1a8ca6851e.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/67079a9ad29ded1a8ca69d4b.png" alt="" /></p>
<h3 id="recycling-material串题"><a class="markdownIt-Anchor" href="#recycling-material串题"></a> Recycling Material:串题</h3>
<p><img src="https://pic.imgdb.cn/item/67079b0ad29ded1a8ca724e4.png" alt="" /></p>
<h3 id="staying-on-topic"><a class="markdownIt-Anchor" href="#staying-on-topic"></a> Staying on Topic</h3>
<p>You can use the same material for many different topics,however the focus of each topic is entirely different.</p>
<ul>
<li>不要全篇照搬，只能利用一部分<br />
<img src="https://pic.imgdb.cn/item/67079fdad29ded1a8caced57.png" alt="" /></li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6707a021d29ded1a8cad3773.png" alt="" /></p>
<p>Guidelines for recycling</p>
<ul>
<li>Summarize the main points fo your material</li>
<li>Keep the good words and phrases</li>
<li>Avoid obvious operative words from other prompts(不要让其他题目中的关键词明显的重复)</li>
<li>BEST start talking about focus 40-50sec in(早点进入正题)</li>
<li>Talk naturally,don’t recite</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6707a2ccd29ded1a8cafdd4e.png" alt="" /></p>
<h3 id="filling-up-time"><a class="markdownIt-Anchor" href="#filling-up-time"></a> Filling Up Time</h3>
<p>How to fill up time:</p>
<ul>
<li>Oh,I forget to mention…</li>
<li>Something I’d like to add is…</li>
<li>Another point I want to make is…</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6707a55ed29ded1a8cb1beb2.png" alt="" /></p>
<h2 id="part-3"><a class="markdownIt-Anchor" href="#part-3"></a> Part 3</h2>
<h3 id="question-types"><a class="markdownIt-Anchor" href="#question-types"></a> Question Types</h3>
<p>Level 1 Questions(Ban 5/0.5 over or under):</p>
<ul>
<li>relatively <strong>easy</strong>,<strong>basic</strong> vocabulary</li>
<li>function of task is relatively <strong>simple</strong></li>
<li>ask about observations of objective reality</li>
<li>only needs to call on knowledge,no deep thinking</li>
</ul>
<p>Level 2 Questions(Ban 6/0.5 over or under):</p>
<ul>
<li>questions are a bit more complex,bigger vocabulary</li>
<li>function of task requires <strong>arguement</strong> and support</li>
<li>concept behind question is a bit <strong>adstract</strong></li>
<li>requires examinee to have thoughts on the matter</li>
</ul>
<p>Level 3 Questions(Ban 7/0.5 over or under):</p>
<ul>
<li>questions include <strong>unfamiliar</strong> vocabulary and concepts</li>
<li>require argument ,support,and <strong>objectiveness</strong></li>
<li>concept behhind question is very <strong>abstract</strong></li>
<li>requires some exposure to <strong>western culture</strong>/valures(讲全世界通用的东西)</li>
</ul>
<p>Question Types:</p>
<ul>
<li>list</li>
<li>explain or give reasons</li>
<li>compare and constrast</li>
<li>suggest</li>
<li>agree/disagree</li>
<li>predict</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6708bc60d29ded1a8c7b5047.png" alt="" /></p>
<h3 id="discourse-reminders"><a class="markdownIt-Anchor" href="#discourse-reminders"></a> Discourse &amp; Reminders</h3>
<p>Watch your discourse:</p>
<ul>
<li>use the third person(bar giving opinions):个人看法除外</li>
<li>don’t give examples of yourself(没有代表性)：me -&gt; a group of people</li>
<li>talk about groups</li>
<li>phrase your examples to seem typical: 例子更加典型</li>
<li>use plenty of discourse markers</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6708bfcbd29ded1a8c7e4d92.png" alt="" /></p>
<p>Reminders:</p>
<ul>
<li>Part 3 is what decides your <strong>final</strong> score</li>
<li>Don’t recite answers</li>
<li>Make sure you understand before you answer: 可以让考官解释一下</li>
<li>If interrupted after first 1-2 sentences, <strong>wrong answer</strong></li>
<li>Answer can be simple,but meaning needs to be clear</li>
<li>Examiner can make up questions</li>
<li>You need to justify your answer</li>
<li>You can truthfully say “I don’t know”</li>
</ul>
<h3 id="reservoir-of-ideas-2"><a class="markdownIt-Anchor" href="#reservoir-of-ideas-2"></a> Reservoir of ideas</h3>
<p>Tips to crack IELTS Speaking Part3:</p>
<ul>
<li>Specific knowledge about any topic <strong>doesn’t matter</strong></li>
<li>Your opinion matters on IELTS Speaking Part3</li>
<li>You may <strong>contradict the tone of question</strong> in your answers as long as you <strong>justify your opinion</strong></li>
<li>Compare the options if offered in a question and give respective explainations</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6708c57ed29ded1a8c829167.png" alt="" /></p>
<ul>
<li>time</li>
<li>money</li>
<li>energy</li>
<li>feelings</li>
<li>personality</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6708c6cbd29ded1a8c8387c7.png" alt="" /></p>
<h3 id="important-tools"><a class="markdownIt-Anchor" href="#important-tools"></a> Important Tools</h3>
<p>keep asking yourself:一直问自己为什么？<br />
<img src="https://pic.imgdb.cn/item/6709f035d29ded1a8c62c325.png" alt="" /></p>
<ul>
<li>warm and comfortable</li>
<li>dont’t care about style</li>
<li>might look a bit outdated<br />
<img src="https://pic.imgdb.cn/item/6709f11cd29ded1a8c637184.png" alt="" /></li>
</ul>
<hr />
<p>Never Assume Explain exerything(except universally acknowledged facts):<br />
<img src="https://pic.imgdb.cn/item/6709f169d29ded1a8c63a9fd.png" alt="" /></p>
<ul>
<li>在大城市不等于能赚到很多钱</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6709f1c0d29ded1a8c63f067.png" alt="" /></p>
<hr />
<p><img src="https://pic.imgdb.cn/item/6709f25ed29ded1a8c646659.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f275d29ded1a8c6478bc.png" alt="" /></p>
<hr />
<p>Use high-level words:</p>
<ul>
<li>mid-level -&gt; detailed -&gt; high-level<br />
<img src="https://pic.imgdb.cn/item/6709f3a6d29ded1a8c655cda.png" alt="" /></li>
</ul>
<p>如果你提前准备了，可以这样说：<br />
<img src="https://pic.imgdb.cn/item/6709f3d2d29ded1a8c657c4f.png" alt="" /></p>
<h3 id="templatess"><a class="markdownIt-Anchor" href="#templatess"></a> Templatess</h3>
<p>讲正确的废话：<br />
<img src="https://pic.imgdb.cn/item/6709f5bad29ded1a8c674519.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f5d6d29ded1a8c676032.png" alt="" /></p>
<hr />
<p>this template is mainly for listing questions:</p>
<ul>
<li>Step1: Well,I think there are a lot of…(正经的废话)</li>
<li>Step2: but I guess the most… + point 1</li>
<li>Step3: Reason(Example is optional)</li>
<li>Step4: And also,Point 2</li>
<li>Step5: Evidence</li>
<li>Step6: So yeah,those are …(paraphrase prompt)</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6709f6e5d29ded1a8c687622.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f718d29ded1a8c68b1c8.png" alt="" /></p>
<hr />
<p>this template is mainly for Explaining,Comparing,Suggesting,Agree/DIsagreeing,Predicting Questions:</p>
<ul>
<li>Step1:Claim 摆观点和立场</li>
<li>Step2:Evidence/Example</li>
<li>Step3:Reasoning</li>
<li>Step4:Counter Argument 让步</li>
<li>Step5:Reclaim</li>
</ul>
<p><img src="https://pic.imgdb.cn/item/6709f7e1d29ded1a8c6966cd.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f834d29ded1a8c69af08.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f867d29ded1a8c69dbf7.png" alt="" /></p>
<hr />
<p><img src="https://pic.imgdb.cn/item/6709f8bbd29ded1a8c6a1dbb.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f8f6d29ded1a8c6a4ee9.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f912d29ded1a8c6a6759.png" alt="" /></p>
<hr />
<p><img src="https://pic.imgdb.cn/item/6709f92ed29ded1a8c6a7ed2.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f965d29ded1a8c6aac83.png" alt="" /><br />
<img src="https://pic.imgdb.cn/item/6709f9a9d29ded1a8c6ae198.png" alt="" /></p>
<h3 id="discourse"><a class="markdownIt-Anchor" href="#discourse"></a> Discourse</h3>
<p>Try to be more objective:</p>
<ul>
<li>from my experience,…</li>
<li>based on what I know,…</li>
<li>as far as I am concerned,…</li>
<li>I can’t say much about other…</li>
<li>usually,…</li>
<li>most of the time…</li>
<li>some people…</li>
<li>a lot of people …</li>
</ul>
<h2 id="tips-2"><a class="markdownIt-Anchor" href="#tips-2"></a> Tips</h2>
<ul>
<li>如何去表达一个完整的观点：简单想法，给出例子，解释想法</li>
<li>雅思口语要说人话，不要为了装逼而说话</li>
<li>听外国人表达观点的视频：不是看ted演讲，而是人与人之间的交流视频</li>
<li>张嘴去说，想办法用英语去解释周围的一切</li>
<li>要有自信</li>
<li>想赢VS怕输：想赢不会犹豫直接回报名，无论考的多差都会继续行动下去；怕输是无限的备考</li>
</ul>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1Zb411B7tV/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">雅思口语万年5.5分，试试这种方法光速破6 | 说的很流利为何上不了6分 | 雅思外挂告诉我的事儿 | Bellona</a></li>
<li><a href="https://www.bilibili.com/video/BV1wF411a76V/?p=3&amp;share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">【Lina-雅思总分9口语9】七节课教你突破高分雅思口语 - IELTS Speaking】 </a></li>
<li><a href="https://www.bilibili.com/video/BV1L44y197J2/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">2024年雅思口语人人都能口语7分！认清问题，解决根本！不要无效焦虑！</a></li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
        <category>IELTS</category>
      </categories>
  </entry>
  <entry>
    <title>Kernel VS Filter</title>
    <url>/2024/02/28/Kernel-VS-Filter/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考材料"><a class="markdownIt-Anchor" href="#参考材料"></a> 参考材料</h2>
<ul>
<li><a href="https://www.cnblogs.com/yibeimingyue/p/11964515.html">卷积核filter和kernal的区别 </a></li>
<li><a href="https://blog.csdn.net/weixin_38481963/article/details/109906338">卷积核（kernel）和过滤器（filter）的区别</a></li>
</ul>
<br>
<h2 id="说在前面"><a class="markdownIt-Anchor" href="#说在前面"></a> 说在前面</h2>
<p>在深入探讨之前，我想先明确区分“kernel”和“filter”这两个术语，因为我已经看到很多人把它们混为一谈。如前所述，kernel是权重矩阵，将权重矩阵与输入相乘以提取相关特征。卷积名称就是kernel矩阵的维数。例如，<strong>2D卷积的kernel矩阵就是2D矩阵</strong>。</p>
<p>关于卷积核和过滤器的定义，事实上在使用时没有多在意，毕竟能理解作者意思即可。但是看到类似于“该层的输出通道=卷积核的个数？”这种信息时我总是有些疑惑.</p>
<p>对于具体的例子，如果输入数据有3个通道（比如一个RGB格式的图片），并且使用了1个滤波器，可能会有一个误解认为输出也应该有3个通道，因为卷积操作会对每个输入通道进行处理。然而，这个理解是不准确的。在深度学习框架中，一个滤波器会对所有输入通道进行操作，并生成一个单独的输出通道。因此，如果你定义了N个滤波器，无论输入通道的数量是多少，你将得到N个输出通道。每个滤波器跨所有输入通道运算，产生一个输出通道，因此输出通道的数量直接等于滤波器的数量。</p>
<p>那么卷积核=滤波器吗？</p>
<br>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<p>卷积核就是由长和宽来指定的，是一个二维的概念。</p>
<p>过滤器是是由长、宽和深度指定的，是一个三维的概念；过滤器可以看做是卷积核的集合，过滤器比卷积核高一个维度——深度。</p>
<br>
<p><strong>具体示例(多通道)：</strong><br />
<img src="https://pbs.twimg.com/media/GHZnwrhWwAA6qMV?format=png&amp;name=medium" alt="" /></p>
<p>卷积核大小：3x3<br />
卷积核数目 <strong>(和输入通道数相同)</strong> ：3<br />
滤波器 <strong>(3x3x3,前面两个3指的是高度和宽度，后面是卷积核数目)</strong> 数目：1</p>
<p>上面的操作是对三个通道分别做卷积操作，然后将卷积的结果相加，最后输出一个特征图。</p>
<p>由上面可以得知，<strong>输出通道数=卷积核个数不成立</strong></p>
<br>
<p><strong>具体示例(单通道)：</strong><br />
<img src="https://pbs.twimg.com/media/GHZoef5WAAArwUe?format=png&amp;name=small" alt="" /></p>
<p>卷积核大小：3x3<br />
卷积核数目 <strong>(和输入通道数相同)</strong> ：1</p>
<p>在单通道情况下，其实过滤器和卷积核可以看做一个东西，即filter=kernel</p>
<p>由上面可以得知，，<strong>输出通道数=卷积核个数成立</strong></p>
<br>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>对于多通道来说，输出通道数=卷积核个数不成立，而对于单通道来说是成立的。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>CNN</tag>
        <tag>Kernel</tag>
        <tag>Filter</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux终端命令大全</title>
    <url>/2024/01/29/Linux%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="一-文件目录类"><a class="markdownIt-Anchor" href="#一-文件目录类"></a> 一. 文件目录类</h2>
<ol>
<li><strong>建立目录</strong>：<code>mkdir 目录名</code></li>
<li><strong>删除空目录</strong>：<code>rmdir 目录名</code></li>
<li><strong>无条件删除子目录</strong>：<code>rm -rf 目录名</code></li>
<li><strong>改变当前目录</strong>：<code>cd 目录名</code>
<ul>
<li>进入当前用户主目录：<code>cd ~</code> 或 <code>cd</code></li>
<li>进入上一级目录：<code>cd ..</code></li>
</ul>
</li>
<li><strong>查看当前所在目录</strong>：<code>pwd</code></li>
<li><strong>查看当前目录大小</strong>：<code>du</code></li>
<li><strong>显示目录文件列表</strong>：
<ul>
<li>列表显示当前目录下文件：<code>ls –l</code></li>
<li>显示隐含目录：<code>ls -a</code></li>
</ul>
</li>
<li><strong>浏览文件</strong>：
<ul>
<li>显示内容超过一屏的文件（只能向后翻阅）：<code>more filename</code></li>
<li>按页显示文件（可以向前和向后翻阅）：<code>less filename</code></li>
<li>实时显示指定文件的后n行：<code>tail –n –f filename</code></li>
</ul>
</li>
<li><strong>复制文件</strong>：<code>cp 源文件 目标文件</code>（参数-r：包含目录）</li>
<li><strong>查找文件</strong>：<code>find 目录 –name filename</code></li>
<li><strong>建立符号链接</strong>：<code>ln -s 源文件 链接文件</code></li>
</ol>
<h2 id="二-驱动挂载类"><a class="markdownIt-Anchor" href="#二-驱动挂载类"></a> 二. 驱动挂载类</h2>
<ol>
<li><strong>检查硬盘使用情况</strong>：<code>df -T -h</code></li>
<li><strong>检查磁盘分区</strong>：<code>fdisk -l</code></li>
<li><strong>挂载软硬光区</strong>：<code>mount -t 类型 /dev/挂载设备 挂载目录</code>
<ul>
<li>常用类型：<code>vfat--FAT32; ntfs--NTFS; 光驱--iso9660</code></li>
<li>挂载ISO文件：<code>mount -t iso9660 -o loop xxx.iso 挂载目录</code></li>
</ul>
</li>
<li><strong>解除挂载</strong>：<code>umount 挂载目录</code>
<ul>
<li>解除所有挂载：<code>umount -a</code></li>
</ul>
</li>
</ol>
<h2 id="三-程序安装类"><a class="markdownIt-Anchor" href="#三-程序安装类"></a> 三. 程序安装类</h2>
<p><strong>RPM包安装</strong>：</p>
<ol>
<li>安装：<code>rpm -ivh somesoft.rpm</code></li>
<li>反安装：<code>rpm -e somefost.rpm</code></li>
<li>查询安装后位置：<code>rpm -ql somefost.rpm</code></li>
<li>强制安装：<code>rpm -ivh --nodeps --force somesoft.rpm</code></li>
</ol>
<p><strong>源代码包安装</strong>：</p>
<ul>
<li>查阅README文件</li>
<li>基本用法：
<ol>
<li>配置：<code>./configure</code></li>
<li>编译：<code>make</code></li>
<li>安装：<code>make install</code></li>
</ol>
</li>
</ul>
<h2 id="四-压缩解压类"><a class="markdownIt-Anchor" href="#四-压缩解压类"></a> 四. 压缩解压类</h2>
<ol>
<li><strong>解压tar.gz类</strong>：<code>tar -xvzf filename.tar.gz</code></li>
<li><strong>tar类</strong>：
<ul>
<li>解包：<code>tar -xvf filename.tar</code></li>
<li>打包：<code>tar -cvf filename.tar filename1 filename2 …</code></li>
</ul>
</li>
<li><strong>解压zip类</strong>：<code>unzip filename.zip -d dir</code></li>
<li><strong>解压bz2类</strong>：<code>bunzip2 filename.bz2</code></li>
<li><strong>解压z类</strong>：<code>uncompress filename.z</code></li>
</ol>
<h2 id="五-进程控制类"><a class="markdownIt-Anchor" href="#五-进程控制类"></a> 五. 进程控制类</h2>
<ol>
<li><strong>列出当前进程ID</strong>：<code>ps -auxw</code></li>
<li><strong>终止单一进程</strong>：<code>kill 进程ID号</code></li>
<li><strong>查看资源占用情况</strong>：
<ul>
<li>CPU：<code>top</code></li>
<li>内存：<code>free</code></li>
</ul>
</li>
<li><strong>重启</strong>：<code>reboot</code></li>
<li><strong>关机</strong>：<code>shutdown -h now</code></li>
</ol>
<h2 id="六-程序运行类"><a class="markdownIt-Anchor" href="#六-程序运行类"></a> 六. 程序运行类</h2>
<ol>
<li><strong>查询命令</strong>：<code>whereis 命令名</code></li>
<li>**</li>
</ol>
<p>后台运行X-Window程序**：<code>程序名&amp;</code><br />
3. <strong>强行退出X-Window程序</strong>：<code>Ctrl Alt Backspace</code><br />
4. <strong>查看帮助</strong>：</p>
<ul>
<li><code>man 命令名</code></li>
<li><code>help 命令名</code></li>
</ul>
<ol start="5">
<li><strong>查看系统路径</strong>：<code>echo $PATH</code></li>
</ol>
<h2 id="七-权限设定"><a class="markdownIt-Anchor" href="#七-权限设定"></a> 七. 权限设定</h2>
<ul>
<li><strong>文字方法</strong>：<code>chmod -a|u|g|o (+|-|=)(r|w|x) 文件或目录</code>
<ul>
<li>a-所有用户(all), u-本用户(user), g-用户组(group), o-其他用户(others)</li>
<li>+增加权限; -删除权限; =设置权限</li>
<li>文件：r-只读(read); w-写(write); x-执行(execute)</li>
<li>目录：r-列目录文件; w-生成/删除目录文件; x-访问目录</li>
</ul>
</li>
<li><strong>数字方法</strong>：<code>chmod xxx 文件或目录</code>
<ul>
<li>execute=1; write=2; read=4</li>
</ul>
</li>
</ul>
<h2 id="八-vi编辑类"><a class="markdownIt-Anchor" href="#八-vi编辑类"></a> 八. vi编辑类</h2>
<ol>
<li><strong>进入后为命令模式</strong>：
<ul>
<li>插入i；打开0；修改c；取代r；替换s</li>
</ul>
</li>
<li><strong>命令行模式至文本模式</strong>：<code>a/i</code>
<ul>
<li>文本模式至命令行模式：<code>Esc</code></li>
<li>命令模式至末行模式：<code>:</code></li>
</ul>
</li>
<li><strong>退出</strong>：
<ul>
<li>退出：<code>:q</code></li>
<li>强制退出：<code>:q!</code></li>
<li>保存并退出：<code>:wq</code></li>
</ul>
</li>
</ol>
<h2 id="九-网络服务"><a class="markdownIt-Anchor" href="#九-网络服务"></a> 九. 网络服务</h2>
<ol>
<li><strong>显示网络接口参数</strong>：<code>ifconfig</code></li>
<li><strong>联机状况</strong>：<code>ping xxx.xxx.xxx.xxx</code></li>
<li><strong>显示网络状况</strong>：<code>netstat –[options]</code>
<ul>
<li>options：-a:所有sockets; -l:网络设备; -n:数字IP; -o:其他信息; -r:路由表; -t:只列TCP sockets; -u:只列UDP sockets; -w:只列raw sockets; -x:只列Unix Domain sockets</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux服务器配置PyTorch环境</title>
    <url>/2023/12/05/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEPyTorch%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="说在前面"><a class="markdownIt-Anchor" href="#说在前面"></a> 说在前面</h2>
<p>前提是Anaconda安装包已经下载好</p>
<br>
<h2 id="1查看cuda驱动版本"><a class="markdownIt-Anchor" href="#1查看cuda驱动版本"></a> 1.查看cuda驱动版本</h2>
<p>从下图可以看出是11.4版本：<br />
<img src="https://pbs.twimg.com/media/GAlGge8WEAAQlZB?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="2创建屋子"><a class="markdownIt-Anchor" href="#2创建屋子"></a> 2.创建“屋子”</h2>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda create -n ab python=<span class="number">3</span>.<span class="number">9</span></span><br></pre></td></tr></table></figure>
<br>
<p>输出结果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">Collecting package metadata (current_repodata.json): done</span><br><span class="line">Solving environment: done</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">==&gt; WARNING: A newer version of conda exists. &lt;==</span><br><span class="line">  current version: <span class="number">22</span>.<span class="number">9</span>.<span class="number">0</span></span><br><span class="line">  latest version: <span class="number">23</span>.<span class="number">11</span>.<span class="number">0</span></span><br><span class="line"></span><br><span class="line">Please update conda by running</span><br><span class="line"></span><br><span class="line">    $ conda update -n base -c defaults conda</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Package Plan ##</span><br><span class="line"></span><br><span class="line">  environment location: /data5/shitao/anaconda/envs/ab</span><br><span class="line"></span><br><span class="line">  added / updated specs:</span><br><span class="line">    - python=<span class="number">3</span>.<span class="number">9</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The following packages will be downloaded:</span><br><span class="line"></span><br><span class="line">    package                    |            build</span><br><span class="line">    ---------------------------|-----------------</span><br><span class="line">    ca-certificates-<span class="number">2023</span>.<span class="number">08</span>.<span class="number">22</span> |       h06a4308_0         <span class="number">123</span> KB</span><br><span class="line">    openssl-<span class="number">3</span>.<span class="number">0</span>.<span class="number">12</span>             |       h7f8727e_0         <span class="number">5</span>.<span class="number">2</span> MB</span><br><span class="line">    pip-<span class="number">23</span>.<span class="number">3</span>.<span class="number">1</span>                 |   py39h06a4308_0         <span class="number">2</span>.<span class="number">6</span> MB</span><br><span class="line">    python-<span class="number">3</span>.<span class="number">9</span>.<span class="number">18</span>              |       h955ad1f_0        <span class="number">25</span>.<span class="number">1</span> MB</span><br><span class="line">    setuptools-<span class="number">68</span>.<span class="number">0</span>.<span class="number">0</span>          |   py39h06a4308_0         <span class="number">928</span> KB</span><br><span class="line">    tzdata-<span class="number">2023</span>c               |       h04d1e81_0         <span class="number">116</span> KB</span><br><span class="line">    wheel-<span class="number">0</span>.<span class="number">41</span>.<span class="number">2</span>               |   py39h06a4308_0         <span class="number">108</span> KB</span><br><span class="line">    xz-<span class="number">5</span>.<span class="number">4</span>.<span class="number">5</span>                   |       h5eee18b_0         <span class="number">646</span> KB</span><br><span class="line">    ------------------------------------------------------------</span><br><span class="line"><span class="function">                                           Total:        34.7 <span class="title">MB</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">The</span> <span class="title">following</span> <span class="title">NEW</span> <span class="title">packages</span> <span class="title">will</span> <span class="title">be</span> <span class="title">INSTALLED</span>:</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  <span class="title">_libgcc_mutex</span>      <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">_libgcc_mutex</span>-0.1-<span class="title">main</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">_openmp_mutex</span>      <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">_openmp_mutex</span>-5.1-1<span class="title">_gnu</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">ca</span>-<span class="title">certificates</span>    <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">ca</span>-<span class="title">certificates</span>-2023.08.22-<span class="title">h06a4308_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">ld_impl_linux</span>-64   <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">ld_impl_linux</span>-64-2.38-<span class="title">h1181459_1</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">libffi</span>             <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">libffi</span>-3.4.4-<span class="title">h6a678d5_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">libgcc</span>-<span class="title">ng</span>          <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">libgcc</span>-<span class="title">ng</span>-11.2.0-<span class="title">h1234567_1</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">libgomp</span>            <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">libgomp</span>-11.2.0-<span class="title">h1234567_1</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">libstdcxx</span>-<span class="title">ng</span>       <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">libstdcxx</span>-<span class="title">ng</span>-11.2.0-<span class="title">h1234567_1</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">ncurses</span>            <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">ncurses</span>-6.4-<span class="title">h6a678d5_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">openssl</span>            <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">openssl</span>-3.0.12-<span class="title">h7f8727e_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">pip</span>                <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">pip</span>-23.3.1-<span class="title">py39h06a4308_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">python</span>             <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">python</span>-3.9.18-<span class="title">h955ad1f_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">readline</span>           <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">readline</span>-8.2-<span class="title">h5eee18b_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">setuptools</span>         <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">setuptools</span>-68.0.0-<span class="title">py39h06a4308_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">sqlite</span>             <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">sqlite</span>-3.41.2-<span class="title">h5eee18b_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">tk</span>                 <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">tk</span>-8.6.12-<span class="title">h1ccaba5_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">tzdata</span>             <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">noarch</span>::<span class="title">tzdata</span>-2023<span class="title">c</span>-<span class="title">h04d1e81_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">wheel</span>              <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">wheel</span>-0.41.2-<span class="title">py39h06a4308_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">xz</span>                 <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">xz</span>-5.4.5-<span class="title">h5eee18b_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function">  <span class="title">zlib</span>               <span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64::<span class="title">zlib</span>-1.2.13-<span class="title">h5eee18b_0</span> <span class="title">None</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">Proceed</span> ([<span class="title">y</span>]/<span class="title">n</span>)? <span class="title">y</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">Downloading</span> <span class="title">and</span> <span class="title">Extracting</span> <span class="title">Packages</span></span></span><br><span class="line"><span class="function"><span class="title">wheel</span>-0.41.2         | 108 <span class="title">KB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">openssl</span>-3.0.12       | 5.2 <span class="title">MB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">setuptools</span>-68.0.0    | 928 <span class="title">KB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">tzdata</span>-2023<span class="title">c</span>         | 116 <span class="title">KB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">pip</span>-23.3.1           | 2.6 <span class="title">MB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">xz</span>-5.4.5             | 646 <span class="title">KB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">ca</span>-<span class="title">certificates</span>-2023 | 123 <span class="title">KB</span>    | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">python</span>-3.9.18        | 25.1 <span class="title">MB</span>   | ########################################################################################## | 100% </span></span><br><span class="line"><span class="function"><span class="title">Preparing</span> <span class="title">transaction</span>: <span class="title">done</span></span></span><br><span class="line"><span class="function"><span class="title">Verifying</span> <span class="title">transaction</span>: <span class="title">done</span></span></span><br><span class="line"><span class="function"><span class="title">Executing</span> <span class="title">transaction</span>: <span class="title">done</span></span></span><br><span class="line"><span class="function">#</span></span><br><span class="line"><span class="function"># <span class="title">To</span> <span class="title">activate</span> <span class="title">this</span> <span class="title">environment</span>, <span class="title">use</span></span></span><br><span class="line"><span class="function">#</span></span><br><span class="line"><span class="function">#     $ <span class="title">conda</span> <span class="title">activate</span> <span class="title">ab</span></span></span><br><span class="line"><span class="function">#</span></span><br><span class="line"><span class="function"># <span class="title">To</span> <span class="title">deactivate</span> <span class="title">an</span> <span class="title">active</span> <span class="title">environment</span>, <span class="title">use</span></span></span><br><span class="line"><span class="function">#</span></span><br><span class="line"><span class="function">#     $ <span class="title">conda</span> <span class="title">deactivate</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">Retrieving</span> <span class="title">notices</span>: ...<span class="title">working</span>... <span class="title">done</span></span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="3安装pytorch"><a class="markdownIt-Anchor" href="#3安装pytorch"></a> 3.安装pytorch</h2>
<p>进入环境：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(base) root@<span class="number">3090</span>_0002:/data10/cyb/Vision-Transformer# conda activate ab</span><br><span class="line">(ab) root@<span class="number">3090</span>_0002:/data10/cyb/Vision-Transformer# </span><br></pre></td></tr></table></figure>
<br>
<p>根据cuda版本安装pytorch,这里应该为11.4：<br />
<img src="https://pbs.twimg.com/media/GAlLGe9WYAAxgXI?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>安装命令：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=<span class="number">11</span>.<span class="number">4</span> -c pytorch -c nvidia</span><br></pre></td></tr></table></figure>
<br>
<hr />
<p>出现了报错：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(ab) root@<span class="number">3090</span>_0002:/data10/cyb/Vision-Transformer# conda install pytorch torchvision torchaudio pytorch-cuda=<span class="number">11</span>.<span class="number">4</span> -c pytorch -c nvidia</span><br><span class="line">Collecting package metadata (current_repodata.json): done</span><br><span class="line">Solving environment: failed with initial frozen solve. Retrying with flexible solve.</span><br><span class="line">Collecting package metadata (repodata.json): done</span><br><span class="line">Solving environment: failed with initial frozen solve. Retrying with flexible solve.</span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">PackagesNotFoundError: <span class="title">The</span> <span class="title">following</span> <span class="title">packages</span> <span class="title">are</span> <span class="title">not</span> <span class="title">available</span> <span class="title">from</span> <span class="title">current</span> <span class="title">channels</span>:</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  - <span class="title">pytorch</span>-<span class="title">cuda</span>=11.4</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">Current</span> <span class="title">channels</span>:</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">conda.anaconda.org</span>/<span class="title">pytorch</span>/<span class="title">linux</span>-64</span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">conda.anaconda.org</span>/<span class="title">pytorch</span>/<span class="title">noarch</span></span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">conda.anaconda.org</span>/<span class="title">nvidia</span>/<span class="title">linux</span>-64</span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">conda.anaconda.org</span>/<span class="title">nvidia</span>/<span class="title">noarch</span></span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">linux</span>-64</span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">noarch</span></span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">r</span>/<span class="title">linux</span>-64</span></span><br><span class="line"><span class="function">  - <span class="title">https</span>://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">r</span>/<span class="title">noarch</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">To</span> <span class="title">search</span> <span class="title">for</span> <span class="title">alternate</span> <span class="title">channels</span> <span class="title">that</span> <span class="title">may</span> <span class="title">provide</span> <span class="title">the</span> <span class="title">conda</span> <span class="title">package</span> <span class="title">you</span>&#x27;<span class="title">re</span></span></span><br><span class="line"><span class="function"><span class="title">looking</span> <span class="title">for</span>, <span class="title">navigate</span> <span class="title">to</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">https</span>://<span class="title">anaconda.org</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">and</span> <span class="title">use</span> <span class="title">the</span> <span class="title">search</span> <span class="title">bar</span> <span class="title">at</span> <span class="title">the</span> <span class="title">top</span> <span class="title">of</span> <span class="title">the</span> <span class="title">page</span>.</span></span><br></pre></td></tr></table></figure>
<p>这个报错信息表明你尝试在Conda环境中安装PyTorch、TorchVision、TorchAudio以及特定版本的PyTorch CUDA（11.4），但是在当前设置的渠道（channels）中未能找到名为pytorch-cuda=11.4的包。</p>
<br>
<p>所以还是安装和我的版本最接近的指令吧T.T：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio pytorch-cuda=<span class="number">11</span>.<span class="number">8</span> -c pytorch -c nvidia</span><br></pre></td></tr></table></figure>
<hr />
<br>
<h2 id="4验证是否安装成功"><a class="markdownIt-Anchor" href="#4验证是否安装成功"></a> 4.验证是否安装成功</h2>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(ab) root@<span class="number">3090</span>_0002:/data10/cyb/Vision-Transformer# python</span><br><span class="line">Python <span class="number">3</span>.<span class="number">9</span>.<span class="number">18</span> (main, Sep <span class="number">11</span> <span class="number">2023</span>, <span class="number">13</span>:<span class="number">41</span>:<span class="number">44</span>) </span><br><span class="line">[GCC <span class="number">11</span>.<span class="number">2</span>.<span class="number">0</span>] :: Anaconda, Inc. on linux</span><br><span class="line"><span class="built_in">Type</span> &quot;<span class="built_in">help</span>&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; <span class="keyword">for</span> <span class="built_in">more</span> information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; import torchvision</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="number">2</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">&gt;&gt;&gt; <span class="keyword">exit</span>()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>linux</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac M2使用GPU进行训练</title>
    <url>/2023/12/23/Mac-M2%E4%BD%BF%E7%94%A8GPU%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/notes/mps.html">pytorch官方</a></li>
</ul>
<br>
<h2 id="mps介绍"><a class="markdownIt-Anchor" href="#mps介绍"></a> MPS介绍</h2>
<p>Mac M2芯片为了追求高性能和节能，在底层设计上使用的是一种叫做arm架构的精简指令集，不同于Intel等常用CPU芯片采用的x86架构完整指令集。所以有些基于x86指令集开发的软件不能直接在Mac M2芯片电脑上使用。）</p>
<p>需要注意的是，使用Mac M2芯片加速 pytorch 不需要安装 cuda后端，因为cuda是适配nvidia的GPU的，Mac M2芯片中的GPU适配的加速后端是mps，在Mac对应操作系统中已经具备，无需单独安装。只需要安装适配的pytorch即可。</p>
<br>
<p>其实从这里可以看到，俺们mac用户是用不了cuda的T.T:<br />
<img src="https://pbs.twimg.com/media/GCAKYdsXAAA-Se0?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="mps使用"><a class="markdownIt-Anchor" href="#mps使用"></a> MPS使用</h2>
<p>首先要具备arm64的Python，以及1.12版本以上的pytorch<br />
mps用法和cuda很像，只是将“cuda”改为“mps”</p>
<br>
<p>测试mps使用可用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.backends.mps.is_available())</span><br><span class="line"><span class="built_in">print</span>(torch.backends.mps.is_built())</span><br></pre></td></tr></table></figure>
<p>如果输入以下结果，则证明可用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="literal">True</span><span class="comment">#表示macOS版本支持</span></span><br><span class="line"><span class="literal">True</span><span class="comment">#表示mps可用</span></span><br></pre></td></tr></table></figure>
<br>
<p>改动区别：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;mps&#x27;</span> <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>gpu</tag>
        <tag>tool</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac下的Terminal不正常显示机器的名字</title>
    <url>/2024/01/24/Mac%E4%B8%8B%E7%9A%84Terminal%E4%B8%8D%E6%AD%A3%E5%B8%B8%E6%98%BE%E7%A4%BA%E6%9C%BA%E5%99%A8%E7%9A%84%E5%90%8D%E5%AD%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h2>
<p>最近，发现个问题，每次回到家里我的mac的终端里面就不正常显示电脑命的名字，变成了192。这样导致我的blog完全上传不上去。</p>
<br>
<h2 id="原因"><a class="markdownIt-Anchor" href="#原因"></a> 原因</h2>
<p>当路由器的DNS使用默认的 192.168.1.1 或 192.168.0.1 的时候 Terminal 里的计算机名 会变成 localhost</p>
<p>当路由器的DNS使用自定义的 例如 运营商的DNS 或者 公共DNS的时候 Terminal 里的计算机名 会变成 你设置的名字。</p>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>改掉当前wifi的dns即可：</p>
<p>可改选项：</p>
<ul>
<li>8.8.8.8</li>
<li>114.114.114.144</li>
</ul>
<br>
<p>8.8.8.8是谷歌的dns解析地址，这样不会被国内isp劫持。但是缺点就是现在基本上各大网站都做了cdn，所以呢，会根据你的动态dns就近选择最佳的线路，比如说，你是北京的dns就会引导你通过北京的cdn服务器入口访问网站，但是如果你是北京的用户却填写了深圳的dns地址，那么就会让你通过深圳的cdn服务器入口访问网站，自然就慢了。而8.8.8.8是谷歌，是国外的dns，所以访问的时候，cdn认为你是国外的dns，会随意给个cdn入口，这就导致会很慢。</p>
<p><img src="https://pbs.twimg.com/media/GEncTg0WQAABu-K?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>mac</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac使用Chrome浏览器经常卡死</title>
    <url>/2024/01/25/Mac%E4%BD%BF%E7%94%A8Chrome%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BB%8F%E5%B8%B8%E5%8D%A1%E6%AD%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h2>
<p>使用chrome浏览器经常卡死</p>
<p><img src="https://pbs.twimg.com/media/GEv_tIjaAAASx14?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>将下面这个关闭即可：</p>
<p><img src="https://pbs.twimg.com/media/GEsYXM9asAAft92?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>mac</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac上使用Linux虚拟机(M2芯片)</title>
    <url>/2023/10/13/Mac%E4%B8%8A%E4%BD%BF%E7%94%A8Linux%E8%99%9A%E6%8B%9F%E6%9C%BAM2%E8%8A%AF%E7%89%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<p>🔗：<a href="https://www.jianshu.com/p/489ea047caa8">https://www.jianshu.com/p/489ea047caa8</a></p>
<br>
<h2 id="1申请vmware-fusion个人免费试用资格"><a class="markdownIt-Anchor" href="#1申请vmware-fusion个人免费试用资格"></a> 1.申请VMware Fusion个人免费试用资格</h2>
<p>先申请个人免费使用资格：<a href="https://customerconnect.vmware.com/evalcenter?p=fusion-player-personal">https://customerconnect.vmware.com/evalcenter?p=fusion-player-personal</a></p>
<br>
<p>要点：不要切换中文语言，且填写可以参照这里填写：</p>
<ul>
<li>Email address： 填写正确的邮箱，需要用邮箱验证</li>
<li>City： Sacramento</li>
<li>Zip or postal code： 94203</li>
<li>Country/Territory： United States</li>
<li>State or province： California</li>
<li>Business phone： 0013602923672</li>
</ul>
<br>
<p>等待邮箱验证：</p>
<p><img src="https://pbs.twimg.com/media/F8j72-KacAAic2t?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>验证完成！</p>
<p><img src="https://pbs.twimg.com/media/F8j75IgaMAA3S65?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="2下载vmware-fusion"><a class="markdownIt-Anchor" href="#2下载vmware-fusion"></a> 2.下载VMware Fusion</h2>
<p>🔗：<a href="https://link.zhihu.com/?target=https%3A//download3.vmware.com/software/FUS-1302/VMware-Fusion-13.0.2-21581413_universal.dmg">https://link.zhihu.com/?target=https%3A//download3.vmware.com/software/FUS-1302/VMware-Fusion-13.0.2-21581413_universal.dmg</a></p>
<br>
<h2 id="3下载ubuntu"><a class="markdownIt-Anchor" href="#3下载ubuntu"></a> 3.下载Ubuntu</h2>
<p>🔗：<a href="https://ubuntu.com/download/server/arm">Ubuntu Server for ARM</a></p>
<br>
<h2 id="4创建虚拟机"><a class="markdownIt-Anchor" href="#4创建虚拟机"></a> 4.创建虚拟机</h2>
<p>运行VMware Fusion，出现以下画面，点击创建自定虚拟机：</p>
<p><img src="https://pbs.twimg.com/media/F8kJ3T2bYAAS0eS?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>选择Linux：</p>
<p><img src="https://pbs.twimg.com/media/F8kKNG8asAA8dgc?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>选择新建虚拟磁盘：</p>
<p><img src="https://pbs.twimg.com/media/F8kKgjLbUAAWfk1?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>设置CD/VCD，然后重新启动：</p>
<p><img src="https://pbs.twimg.com/media/F8kLM6EboAE2IRk?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>安装Ubuntu：</p>
<p>🔗：<a href="https://www.bilibili.com/video/BV1sW4y1f7YU/?spm_id_from=333.337.search-card.all.click&amp;vd_source=818709367b66eca23fb19fc37329dccb">macOS 使用 VMware Fusion 安装 Ubuntu 桌面版</a></p>
<p><img src="https://pbs.twimg.com/media/F8kMKILakAAP5qF?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>选择语言：</p>
<p><img src="https://pbs.twimg.com/media/F8kML-cakAAPT31?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>按回车：</p>
<p><img src="https://pbs.twimg.com/media/F8kPocbbAAAaTpg?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>回车：</p>
<p><img src="https://pbs.twimg.com/media/F8kRWNrbsAAPqkR?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Done:</p>
<p><img src="https://pbs.twimg.com/media/F8kRYgcbgAAkmYs?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Done:</p>
<p><img src="https://pbs.twimg.com/media/F8kRarra4AAQhM5?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Done:</p>
<p><img src="https://pbs.twimg.com/media/F8kRcwuagAAgfTr?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>设置好自己的用户名以及密码：</p>
<p><img src="https://pbs.twimg.com/media/F8kSozXbwAAwV2_?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Continue(不安装Ubuntu pro)：</p>
<p><img src="https://pbs.twimg.com/media/F8kSrvRbYAAHKFT?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p><strong>Install OpenSSH server打[X]</strong>,然后Done：</p>
<p><img src="https://pbs.twimg.com/media/F8kSuUJacAAEBc8?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Done:</p>
<p><img src="https://pbs.twimg.com/media/F8kbZ9qaUAA0_kw?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>Reboot Now然后再回车:</p>
<p><img src="https://pbs.twimg.com/media/F8kbcTbbsAAtA8l?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="5-登陆和检查"><a class="markdownIt-Anchor" href="#5-登陆和检查"></a> 5. 登陆和检查</h2>
<p>进入登陆界面 输入用户名和密码</p>
<p>可以输入<code>uname</code>和<code>-name-a</code>进行检查是否安装成功</p>
<p>输入：<code>sudo apt install ubuntu-desktop</code>,下载桌面版ubuntu</p>
<br>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>Linux</tag>
        <tag>Mac</tag>
        <tag>M2</tag>
      </tags>
  </entry>
  <entry>
    <title>Missing Semester of CS:Lecture03-Vim</title>
    <url>/2024/03/05/Missing-Semester-of-CS-Lecture03-Vim/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1CV4y167RA/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">[自制双语字幕] 计算机教育缺失的一课(2020) - 第3讲 - 编辑器 (Vim)</a></li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>project</category>
        <category>Missing Semester of CS</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>Missing Semester</tag>
        <tag>Vim</tag>
        <tag>3</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac使用ssh远程连接服务器</title>
    <url>/2023/11/14/Mac%E4%BD%BF%E7%94%A8ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="连接远程服务器命令"><a class="markdownIt-Anchor" href="#连接远程服务器命令"></a> 连接远程服务器命令</h2>
<p>命令：<code>ssh -p &lt;port&gt; root@&lt;hostname&gt;</code></p>
<br>
<h2 id="mac终端指令"><a class="markdownIt-Anchor" href="#mac终端指令"></a> Mac终端指令</h2>
<h3 id="1-目录操作"><a class="markdownIt-Anchor" href="#1-目录操作"></a> 1.  目录操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>mkdir</td>
<td>创建一个目录</td>
<td>mkdir dirnamer</td>
</tr>
<tr>
<td>rmdir</td>
<td>删除一个目录</td>
<td>rmdir dirname</td>
</tr>
<tr>
<td>mvdir</td>
<td>移动或重命名一个目录</td>
<td>mvdir dir1 dir2</td>
</tr>
<tr>
<td>cd</td>
<td>改变当前目录</td>
<td>cd dirname</td>
</tr>
<tr>
<td>pwd</td>
<td>显示当前目录的路径名</td>
<td>pwd</td>
</tr>
<tr>
<td>ls</td>
<td>显示当前目录的内容</td>
<td>ls -ladir</td>
</tr>
<tr>
<td>cmp</td>
<td>比较两个目录的内容</td>
<td>dircmp dir1 dir2</td>
</tr>
</tbody>
</table>
<h3 id="2-文件操作"><a class="markdownIt-Anchor" href="#2-文件操作"></a> 2. 文件操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>cat</td>
<td>显示或连接文件</td>
<td>cat filename</td>
</tr>
<tr>
<td>pg</td>
<td>分页格式化显示文件内容</td>
<td>pg filename</td>
</tr>
<tr>
<td>more</td>
<td>分屏显示文件内容</td>
<td>more filename</td>
</tr>
<tr>
<td>od</td>
<td>显示非文本文件的内容</td>
<td>od -c filename</td>
</tr>
<tr>
<td>cp</td>
<td>复制文件或目录</td>
<td>cp file1 file2</td>
</tr>
<tr>
<td>rm</td>
<td>删除文件或目录</td>
<td>rm filename</td>
</tr>
<tr>
<td>mv</td>
<td>改变文件名或所在目录</td>
<td>mv file1 file2</td>
</tr>
<tr>
<td>ln</td>
<td>联接文件</td>
<td>ln -s file1 file2</td>
</tr>
<tr>
<td>find</td>
<td>使用匹配表达式查找文件</td>
<td>find . -name “*.c” -print</td>
</tr>
<tr>
<td>file</td>
<td>显示文件类型</td>
<td>file filename</td>
</tr>
<tr>
<td>open</td>
<td>使用默认的程序打开文件</td>
<td>open filename</td>
</tr>
</tbody>
</table>
<h3 id="3-选择操作"><a class="markdownIt-Anchor" href="#3-选择操作"></a> 3. 选择操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>head</td>
<td>显示文件的最初几行</td>
<td>head -20 filename</td>
</tr>
<tr>
<td>tail</td>
<td>显示文件的最后几行</td>
<td>tail -15 filename</td>
</tr>
<tr>
<td>cut</td>
<td>显示文件每行中的某些域</td>
<td>cut -f1,7 -d: /etc/passwd</td>
</tr>
<tr>
<td>colrm</td>
<td>从标准输入中删除若干列</td>
<td>colrm 8 20 file2</td>
</tr>
<tr>
<td>paste</td>
<td>横向连接文件</td>
<td>paste file1 file2</td>
</tr>
<tr>
<td>diff</td>
<td>比较并显示两个文件的差异</td>
<td>diff file1 file2</td>
</tr>
<tr>
<td>sed</td>
<td>非交互方式流编辑器</td>
<td>sed “s/red/green/g” filename</td>
</tr>
<tr>
<td>grep</td>
<td>在文件中按模式查找</td>
<td>grep “a” filename</td>
</tr>
<tr>
<td>awk</td>
<td>在文件中查找并处理模式</td>
<td>awk ‘{print $1 $1}’ filename</td>
</tr>
<tr>
<td>sort</td>
<td>排序或归并文件</td>
<td>sort -d -f -u file1</td>
</tr>
<tr>
<td>uniq</td>
<td>去掉文件中的重复行</td>
<td>uniq file1 file2</td>
</tr>
<tr>
<td>comm</td>
<td>comm file1 file2</td>
<td></td>
</tr>
<tr>
<td>wc</td>
<td>统计文件的字符数、词数和行数</td>
<td>wc filename</td>
</tr>
<tr>
<td>nl</td>
<td>给文件加上行号</td>
<td>nl file1 &gt;file2</td>
</tr>
</tbody>
</table>
<h3 id="4-安全操作"><a class="markdownIt-Anchor" href="#4-安全操作"></a> 4. 安全操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>passwd</td>
<td>修改用户密码</td>
<td>passwd</td>
</tr>
<tr>
<td>chmod</td>
<td>改变文件或目录的权限</td>
<td>chmod ug+x filename</td>
</tr>
<tr>
<td>umask</td>
<td>定义创建文件的权限掩码</td>
<td>umask 027</td>
</tr>
<tr>
<td>chown</td>
<td>改变文件或目录的属主</td>
<td>chown newowner filename</td>
</tr>
<tr>
<td>chgrp</td>
<td>改变文件或目录的所属组</td>
<td>chgrp staff filename</td>
</tr>
<tr>
<td>xlock</td>
<td>给终端上锁</td>
<td>xlock -remote</td>
</tr>
</tbody>
</table>
<h3 id="5-编程操作"><a class="markdownIt-Anchor" href="#5-编程操作"></a> 5. 编程操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>make</td>
<td>维护可执行程序的最新版本</td>
<td>make</td>
</tr>
<tr>
<td>touch</td>
<td>更新文件的访问和修改时间</td>
<td>touch -m 05202400 filename</td>
</tr>
<tr>
<td>dbx</td>
<td>命令行界面调试工具</td>
<td>dbx a.out</td>
</tr>
<tr>
<td>xde</td>
<td>图形用户界面调试工具</td>
<td>xde a.out</td>
</tr>
</tbody>
</table>
<h3 id="6-进程操作"><a class="markdownIt-Anchor" href="#6-进程操作"></a> 6. 进程操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>ps</td>
<td>显示进程当前状态</td>
<td>ps u</td>
</tr>
<tr>
<td>kill</td>
<td>终止进程</td>
<td>kill -9 30142</td>
</tr>
<tr>
<td>nice</td>
<td>改变待执行命令的优先级</td>
<td>nice cc -c *.c</td>
</tr>
<tr>
<td>renice</td>
<td>改变已运行进程的优先级</td>
<td>renice +20 32768</td>
</tr>
</tbody>
</table>
<h3 id="7-时间操作"><a class="markdownIt-Anchor" href="#7-时间操作"></a> 7. 时间操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>date</td>
<td>显示系统的当前日期和时间</td>
<td>date</td>
</tr>
<tr>
<td>cal</td>
<td>显示日历</td>
<td>cal 8 1996</td>
</tr>
<tr>
<td>time</td>
<td>统计程序的执行时间</td>
<td>time a.out</td>
</tr>
</tbody>
</table>
<h3 id="8-网络与通信操作"><a class="markdownIt-Anchor" href="#8-网络与通信操作"></a> 8. 网络与通信操作</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>telnet</td>
<td>远程登录</td>
<td>telnet <a href="http://hpc.sp.net.edu.cn">hpc.sp.net.edu.cn</a></td>
</tr>
<tr>
<td>rlogin</td>
<td>远程登录</td>
<td>rlogin hostname -l username</td>
</tr>
<tr>
<td>rsh</td>
<td>在远程主机执行指定命令</td>
<td>rsh f01n03 date</td>
</tr>
<tr>
<td>ftp</td>
<td>在本地主机与远程主机之间传输文件</td>
<td>ftp <a href="http://ftp.sp.net.edu.cn">ftp.sp.net.edu.cn</a></td>
</tr>
<tr>
<td>rcp</td>
<td>在本地主机与远程主机之间复制文件</td>
<td>rcp file1 host1:file2</td>
</tr>
<tr>
<td>ping</td>
<td>给一个网络主机发送回应请求</td>
<td>ping <a href="http://hpc.sp.net.edu.cn">hpc.sp.net.edu.cn</a></td>
</tr>
<tr>
<td>mail</td>
<td>阅读和发送电子邮件</td>
<td>mail</td>
</tr>
<tr>
<td>write</td>
<td>给另一用户发送报文</td>
<td>write username pts/1</td>
</tr>
<tr>
<td>mesg</td>
<td>允许或拒绝接收报文</td>
<td>mesg n</td>
</tr>
</tbody>
</table>
<h3 id="9-korn-shell命令"><a class="markdownIt-Anchor" href="#9-korn-shell命令"></a> 9. Korn Shell命令</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>history</td>
<td>列出最近执行过的几条命令及编号</td>
<td>history</td>
</tr>
<tr>
<td>r</td>
<td>重复执行最近执行过的某条命令</td>
<td>r -2</td>
</tr>
<tr>
<td>alias</td>
<td>给某个命令定义别名</td>
<td>alias del=rm -i</td>
</tr>
<tr>
<td>unalias</td>
<td>取消对某个别名的定义</td>
<td>unalias del</td>
</tr>
</tbody>
</table>
<h3 id="10-其他命令"><a class="markdownIt-Anchor" href="#10-其他命令"></a> 10. 其他命令</h3>
<table>
<thead>
<tr>
<th>命令名</th>
<th>功能描述</th>
<th>使用举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>uname</td>
<td>显示操作系统的有关信息</td>
<td>uname -a</td>
</tr>
<tr>
<td>clear</td>
<td>清除屏幕或窗口内容</td>
<td>clear</td>
</tr>
<tr>
<td>env</td>
<td>显示当前所有设置过的环境变量</td>
<td>env</td>
</tr>
<tr>
<td>who</td>
<td>列出当前登录的所有用户</td>
<td>who</td>
</tr>
<tr>
<td>whoami</td>
<td>显示当前正进行操作的用户名</td>
<td>whoami</td>
</tr>
<tr>
<td>tty</td>
<td>显示终端或伪终端的名称</td>
<td>tty</td>
</tr>
<tr>
<td>stty</td>
<td>显示或重置控制键定义</td>
<td>stty</td>
</tr>
<tr>
<td>du</td>
<td>查询磁盘使用情况</td>
<td>du -k subdir</td>
</tr>
<tr>
<td>df</td>
<td>显示文件系统的总空间和可用空间</td>
<td>df /tmp</td>
</tr>
<tr>
<td>w</td>
<td>显示当前系统活动的总信息</td>
<td>w</td>
</tr>
</tbody>
</table>
<br>
<h2 id="tree"><a class="markdownIt-Anchor" href="#tree"></a> Tree</h2>
<ul>
<li>🔗：<a href="https://learnku.com/articles/37357">Linux Tree命令安装和使用</a></li>
</ul>
<br>
<p>最常用的命令：<code>tree -a -L 2</code></p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>mac</tag>
        <tag>ssh</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac配置PyTorch完整版教程(M2芯片)</title>
    <url>/2023/10/12/Mac%E9%85%8D%E7%BD%AEPyTorch%E5%AE%8C%E6%95%B4%E7%89%88%E6%95%99%E7%A8%8B-M2%E8%8A%AF%E7%89%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1下载anconda"><a class="markdownIt-Anchor" href="#1下载anconda"></a> 1.下载Anconda</h2>
<p>去<a href="https://www.anaconda.com/download#Downloads">Anaconda官网</a>安装ARM版本的Anconda</p>
<p><img src="https://pbs.twimg.com/media/F8LNUrMbUAA_sKT?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="2检查anconda是否安装完成"><a class="markdownIt-Anchor" href="#2检查anconda是否安装完成"></a> 2.检查Anconda是否安装完成</h2>
<p>输入下面指令：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda info</span><br></pre></td></tr></table></figure>
<p>若出现以下内容则安装成功：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % conda info</span><br><span class="line"></span><br><span class="line">     active environment : base</span><br><span class="line">    active env location : /Users/chenyubin/anaconda3</span><br><span class="line">            shell level : <span class="number">1</span></span><br><span class="line">       user config file : /Users/chenyubin/.condarc</span><br><span class="line"> populated config files : /Users/chenyubin/.condarc</span><br><span class="line">          conda version : <span class="number">23</span>.<span class="number">5</span>.<span class="number">0</span></span><br><span class="line">    conda-build version : <span class="number">3</span>.<span class="number">25</span>.<span class="number">0</span></span><br><span class="line">         python version : <span class="number">3</span>.<span class="number">11</span>.<span class="number">3</span>.final.<span class="number">0</span></span><br><span class="line">       virtual packages : __archspec=<span class="number">1</span>=arm64</span><br><span class="line">                          __osx=<span class="number">13</span>.<span class="number">6</span>=<span class="number">0</span></span><br><span class="line">                          __unix=<span class="number">0</span>=<span class="number">0</span></span><br><span class="line">       base environment : /Users/chenyubin/anaconda3  (writable)</span><br><span class="line">      conda av data <span class="built_in">dir</span> : /Users/chenyubin/anaconda3/etc/conda</span><br><span class="line">  conda av metadata url : None</span><br><span class="line">           channel URLs : https://repo.anaconda.com/pkgs/main/osx-arm64</span><br><span class="line"><span class="function">                          https://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">main</span>/<span class="title">noarch</span></span></span><br><span class="line"><span class="function">                          <span class="title">https</span>://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">r</span>/<span class="title">osx</span>-<span class="title">arm64</span></span></span><br><span class="line"><span class="function">                          <span class="title">https</span>://<span class="title">repo.anaconda.com</span>/<span class="title">pkgs</span>/<span class="title">r</span>/<span class="title">noarch</span></span></span><br><span class="line"><span class="function">          <span class="title">package</span> <span class="title">cache</span> : /<span class="title">Users</span>/<span class="title">chenyubin</span>/<span class="title">anaconda3</span>/<span class="title">pkgs</span></span></span><br><span class="line"><span class="function">                          /<span class="title">Users</span>/<span class="title">chenyubin</span>/.<span class="title">conda</span>/<span class="title">pkgs</span></span></span><br><span class="line"><span class="function">       <span class="title">envs</span> <span class="title">directories</span> : /<span class="title">Users</span>/<span class="title">chenyubin</span>/<span class="title">anaconda3</span>/<span class="title">envs</span></span></span><br><span class="line"><span class="function">                          /<span class="title">Users</span>/<span class="title">chenyubin</span>/.<span class="title">conda</span>/<span class="title">envs</span></span></span><br><span class="line"><span class="function">               <span class="title">platform</span> : <span class="title">osx</span>-<span class="title">arm64</span></span></span><br><span class="line"><span class="function">             <span class="title">user</span>-<span class="title">agent</span> : <span class="title">conda</span>/23.5.0 <span class="title">requests</span>/2.29.0 <span class="title">CPython</span>/3.11.3 <span class="title">Darwin</span>/22.6.0 <span class="title">OSX</span>/13.6</span></span><br><span class="line"><span class="function">                <span class="title">UID:GID</span> : 501:20</span></span><br><span class="line"><span class="function">             <span class="title">netrc</span> <span class="title">file</span> : <span class="title">None</span></span></span><br><span class="line"><span class="function">           <span class="title">offline</span> <span class="title">mode</span> : <span class="title">False</span></span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="3检查安装anconda的版本是否正确"><a class="markdownIt-Anchor" href="#3检查安装anconda的版本是否正确"></a> 3.检查安装Anconda的版本是否正确</h2>
<p>输入指令：<strong>(一行一行输入)</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="built_in">print</span>(platform.platform())</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % python</span><br><span class="line">Python <span class="number">3</span>.<span class="number">11</span>.<span class="number">3</span> (main, Apr <span class="number">19</span> <span class="number">2023</span>, <span class="number">18</span>:<span class="number">49</span>:<span class="number">55</span>) [Clang <span class="number">14</span>.<span class="number">0</span>.<span class="number">6</span> ] on darwin</span><br><span class="line"><span class="built_in">Type</span> &quot;<span class="built_in">help</span>&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; <span class="keyword">for</span> <span class="built_in">more</span> information.</span><br><span class="line">&gt;&gt;&gt; import platform</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">print</span>(platform.platform())</span><br><span class="line">macOS-<span class="number">13</span>.<span class="number">6</span>-arm64-arm-<span class="number">64</span>bit</span><br></pre></td></tr></table></figure>
<br>
<h2 id="4创建虚拟环境"><a class="markdownIt-Anchor" href="#4创建虚拟环境"></a> 4.创建虚拟环境</h2>
<p>输入指令: （注意此处的<code>MSResNet</code>和python版本号应该换成你需要的内容）</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda create -n MSResNet python=<span class="number">3</span>.<span class="number">9</span></span><br></pre></td></tr></table></figure>
<p>激活这个环境：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda activate MSResNet</span><br></pre></td></tr></table></figure>
<br>
<h2 id="5安装pytorch"><a class="markdownIt-Anchor" href="#5安装pytorch"></a> 5.安装PyTorch</h2>
<p>PyTorch的GPU训练加速是使用苹果Metal Performance Shaders（MPS）作为后端来实现的。<strong>注意Mac OS版本要大于等于12.3</strong>。</p>
<p>去PyTorch官网获取命令。<strong>这里注意要选取Nightly版本，才支持GPU加速，Package选项中选择Pip</strong>。(这里若使用conda安装有一定概率无法安装到预览版，建议使用pip3安装)</p>
<p><img src="https://pbs.twimg.com/media/F8MsDqAacAAnGCH?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>输入命令安装：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"># MPS acceleration is available on MacOS <span class="number">12</span>.<span class="number">3</span>+</span><br><span class="line">pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu</span><br></pre></td></tr></table></figure>
<p>得到结果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(MSResNet) chenyubin@chenyubindeMacBook-Pro ~ % pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu</span><br><span class="line">Looking <span class="keyword">in</span> indexes: https://download.pytorch.org/whl/nightly/cpu</span><br><span class="line">Collecting torch</span><br><span class="line">  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-<span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span>.dev20231011-cp39-none-macosx_11_0_arm64.whl (<span class="number">58</span>.<span class="number">3</span> MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class="number">58</span>.<span class="number">3</span>/<span class="number">58</span>.<span class="number">3</span> MB <span class="number">16</span>.<span class="number">7</span> MB/s eta <span class="number">0</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line">Collecting torchvision</span><br><span class="line">  Downloading https://download.pytorch.org/whl/nightly/cpu/torchvision-<span class="number">0</span>.<span class="number">17</span>.<span class="number">0</span>.dev20231011-cp39-cp39-macosx_11_0_arm64.whl (<span class="number">1</span>.<span class="number">6</span> MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class="number">1</span>.<span class="number">6</span>/<span class="number">1</span>.<span class="number">6</span> MB <span class="number">6</span>.<span class="number">8</span> MB/s eta <span class="number">0</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line">Collecting torchaudio</span><br><span class="line">  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-<span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span>.dev20231011-cp39-cp39-macosx_11_0_arm64.whl (<span class="number">1</span>.<span class="number">8</span> MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class="number">1</span>.<span class="number">8</span>/<span class="number">1</span>.<span class="number">8</span> MB <span class="number">5</span>.<span class="number">9</span> MB/s eta <span class="number">0</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line">Collecting filelock (from torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/filelock-<span class="number">3</span>.<span class="number">9</span>.<span class="number">0</span>-py3-none-any.whl (<span class="number">9</span>.<span class="number">7</span> kB)</span><br><span class="line">Collecting typing-extensions (from torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/typing_extensions-<span class="number">4</span>.<span class="number">4</span>.<span class="number">0</span>-py3-none-any.whl (<span class="number">26</span> kB)</span><br><span class="line">Collecting sympy (from torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/sympy-<span class="number">1</span>.<span class="number">11</span>.<span class="number">1</span>-py3-none-any.whl (<span class="number">6</span>.<span class="number">5</span> MB)</span><br><span class="line">Collecting networkx (from torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/networkx-<span class="number">3</span>.<span class="number">0</span>rc1-py3-none-any.whl (<span class="number">2</span>.<span class="number">0</span> MB)</span><br><span class="line">Collecting jinja2 (from torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/Jinja2-<span class="number">3</span>.<span class="number">1</span>.<span class="number">2</span>-py3-none-any.whl (<span class="number">133</span> kB)</span><br><span class="line">Collecting fsspec (from torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/fsspec-<span class="number">2023</span>.<span class="number">4</span>.<span class="number">0</span>-py3-none-any.whl (<span class="number">153</span> kB)</span><br><span class="line">Collecting numpy (from torchvision)</span><br><span class="line">  Downloading https://download.pytorch.org/whl/nightly/numpy-<span class="number">1</span>.<span class="number">24</span>.<span class="number">1</span>-cp39-cp39-macosx_11_0_arm64.whl (<span class="number">13</span>.<span class="number">9</span> MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class="number">13</span>.<span class="number">9</span>/<span class="number">13</span>.<span class="number">9</span> MB <span class="number">18</span>.<span class="number">5</span> MB/s eta <span class="number">0</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line">Collecting requests (from torchvision)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/requests-<span class="number">2</span>.<span class="number">28</span>.<span class="number">1</span>-py3-none-any.whl (<span class="number">62</span> kB)</span><br><span class="line">Collecting pillow!=<span class="number">8</span>.<span class="number">3</span>.*,&gt;=<span class="number">5</span>.<span class="number">3</span>.<span class="number">0</span> (from torchvision)</span><br><span class="line">  Downloading https://download.pytorch.org/whl/nightly/Pillow-<span class="number">9</span>.<span class="number">3</span>.<span class="number">0</span>-cp39-cp39-macosx_11_0_arm64.whl (<span class="number">2</span>.<span class="number">9</span> MB)</span><br><span class="line">     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class="number">2</span>.<span class="number">9</span>/<span class="number">2</span>.<span class="number">9</span> MB <span class="number">10</span>.<span class="number">9</span> MB/s eta <span class="number">0</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line">Collecting MarkupSafe&gt;=<span class="number">2</span>.<span class="number">0</span> (from jinja2-&gt;torch)</span><br><span class="line">  Downloading https://download.pytorch.org/whl/nightly/MarkupSafe-<span class="number">2</span>.<span class="number">1</span>.<span class="number">2</span>-cp39-cp39-macosx_10_9_universal2.whl (<span class="number">17</span> kB)</span><br><span class="line">Collecting charset-normalizer&lt;<span class="number">3</span>,&gt;=<span class="number">2</span> (from requests-&gt;torchvision)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/charset_normalizer-<span class="number">2</span>.<span class="number">1</span>.<span class="number">1</span>-py3-none-any.whl (<span class="number">39</span> kB)</span><br><span class="line">Collecting idna&lt;<span class="number">4</span>,&gt;=<span class="number">2</span>.<span class="number">5</span> (from requests-&gt;torchvision)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/idna-<span class="number">3</span>.<span class="number">4</span>-py3-none-any.whl (<span class="number">61</span> kB)</span><br><span class="line">Collecting urllib3&lt;<span class="number">1</span>.<span class="number">27</span>,&gt;=<span class="number">1</span>.<span class="number">21</span>.<span class="number">1</span> (from requests-&gt;torchvision)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/urllib3-<span class="number">1</span>.<span class="number">26</span>.<span class="number">13</span>-py2.py3-none-any.whl (<span class="number">140</span> kB)</span><br><span class="line">Collecting certifi&gt;=<span class="number">2017</span>.<span class="number">4</span>.<span class="number">17</span> (from requests-&gt;torchvision)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/certifi-<span class="number">2022</span>.<span class="number">12</span>.<span class="number">7</span>-py3-none-any.whl (<span class="number">155</span> kB)</span><br><span class="line">Collecting mpmath&gt;=<span class="number">0</span>.<span class="number">19</span> (from sympy-&gt;torch)</span><br><span class="line">  Using cached https://download.pytorch.org/whl/nightly/mpmath-<span class="number">1</span>.<span class="number">2</span>.<span class="number">1</span>-py3-none-any.whl (<span class="number">532</span> kB)</span><br><span class="line">Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, jinja2, torch, torchvision, torchaudio</span><br><span class="line">Successfully installed MarkupSafe-<span class="number">2</span>.<span class="number">1</span>.<span class="number">2</span> certifi-<span class="number">2022</span>.<span class="number">12</span>.<span class="number">7</span> charset-normalizer-<span class="number">2</span>.<span class="number">1</span>.<span class="number">1</span> filelock-<span class="number">3</span>.<span class="number">9</span>.<span class="number">0</span> fsspec-<span class="number">2023</span>.<span class="number">4</span>.<span class="number">0</span> idna-<span class="number">3</span>.<span class="number">4</span> jinja2-<span class="number">3</span>.<span class="number">1</span>.<span class="number">2</span> mpmath-<span class="number">1</span>.<span class="number">2</span>.<span class="number">1</span> networkx-<span class="number">3</span>.<span class="number">0</span>rc1 numpy-<span class="number">1</span>.<span class="number">24</span>.<span class="number">1</span> pillow-<span class="number">9</span>.<span class="number">3</span>.<span class="number">0</span> requests-<span class="number">2</span>.<span class="number">28</span>.<span class="number">1</span> sympy-<span class="number">1</span>.<span class="number">11</span>.<span class="number">1</span> torch-<span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span>.dev20231011 torchaudio-<span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span>.dev20231011 torchvision-<span class="number">0</span>.<span class="number">17</span>.<span class="number">0</span>.dev20231011 typing-extensions-<span class="number">4</span>.<span class="number">4</span>.<span class="number">0</span> urllib3-<span class="number">1</span>.<span class="number">26</span>.<span class="number">13</span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="6验证是否安装成功与是否支持pytorch加速"><a class="markdownIt-Anchor" href="#6验证是否安装成功与是否支持pytorch加速"></a> 6.验证是否安装成功与是否支持PyTorch加速</h2>
<p>输入指令：<strong>(一行一行输入)</strong></p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">python</span><br><span class="line">import torch</span><br><span class="line">torch.__version__</span><br><span class="line">torch.device(&quot;mps&quot;)</span><br></pre></td></tr></table></figure>
<p>出现结果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(MSResNet) chenyubin@chenyubindeMacBook-Pro ~ % python</span><br><span class="line">import torch</span><br><span class="line">torch.__version__</span><br><span class="line">torch.device(&quot;mps&quot;)</span><br><span class="line">Python <span class="number">3</span>.<span class="number">9</span>.<span class="number">18</span> (main, Sep <span class="number">11</span> <span class="number">2023</span>, <span class="number">08</span>:<span class="number">25</span>:<span class="number">10</span>) </span><br><span class="line">[Clang <span class="number">14</span>.<span class="number">0</span>.<span class="number">6</span> ] :: Anaconda, Inc. on darwin</span><br><span class="line"><span class="built_in">Type</span> &quot;<span class="built_in">help</span>&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; <span class="keyword">for</span> <span class="built_in">more</span> information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">torch.__&gt;&gt;&gt; torch.__version__</span><br><span class="line">&#x27;<span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span>.dev20231011&#x27;</span><br><span class="line">&gt;&gt;&gt; torch.device(&quot;mps&quot;)</span><br><span class="line">device(<span class="built_in">type</span>=&#x27;mps&#x27;)</span><br></pre></td></tr></table></figure>
<br>
<h2 id="7pycharm配置"><a class="markdownIt-Anchor" href="#7pycharm配置"></a> 7.PyCharm配置</h2>
<p>打开PyCharm，点击setting -&gt; 项目:xxx -&gt; Python解释器 -&gt; 添加解释器 -&gt; 添加本地解释器 -&gt; conda环境，选择自己刚才创建的环境即可：</p>
<p><img src="https://pbs.twimg.com/media/F8MvJo-boAAuYPt?format=jpg&amp;name=medium" alt="" /></p>
<p>如果找不到python版本路径，可以打开终端输入：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">which python</span><br></pre></td></tr></table></figure>
<p>得到以下结果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(MSResNet) chenyubin@chenyubindeMacBook-Pro ~ % which python</span><br><span class="line">/Users/chenyubin/anaconda3/envs/MSResNet/bin/python</span><br></pre></td></tr></table></figure>
<br>
<h2 id="8test"><a class="markdownIt-Anchor" href="#8test"></a> 8.test</h2>
<p>新建python文件输入以下内容：</p>
<p><img src="https://pbs.twimg.com/media/F8Mys8bbUAAFml4?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>Mac</tag>
        <tag>M2</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Missing Semester of CS:Lecture01-课程概览与shell</title>
    <url>/2023/10/07/Missing-Semester-of-CS/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li>🔗：<a href="https://missing-semester-cn.github.io">The Missing Semester of Your CS Education 中文版</a></li>
<li>🔗：<a href="https://missing.csail.mit.edu/2020/">The Missing Semester of Your CS Education</a></li>
<li>🔗：<a href="https://space.bilibili.com/518734451?spm_id_from=333.337.search-card.all.click">课程中文字幕视频</a></li>
<li>🔗：<a href="https://abinzzz.github.io/2024/02/26/Terminal-VS-Shell/">Terminal VS Shell</a></li>
<li>🔗：<a href="https://zhuanlan.zhihu.com/p/146560479">MIT: Missing Semester of CS Education - Lecture 1</a></li>
<li>🔗：<a href="https://abinzzz.github.io/2024/02/26/chmod%E5%91%BD%E4%BB%A4/">chmod指令</a></li>
<li>🔗：<a href="https://blog.csdn.net/qq_39411709/article/details/118023587">Missing-Semester of CS Education 第一次作业</a></li>
</ul>
<br>
<h2 id="what-is-the-shell"><a class="markdownIt-Anchor" href="#what-is-the-shell"></a> What is the shell?</h2>
<p>The shell is a program that takes commands from the keyboard and gives them to the operating system to perform.</p>
<p>When launching the terminal, we see a prompt, that is the main textual interface to the shell.</p>
<br>
<p>为了更清楚地展示高亮要求，我会在下面的文本中将英文名词和符号用<code>高亮</code>表示：</p>
<h2 id="using-the-shell"><a class="markdownIt-Anchor" href="#using-the-shell"></a> Using the shell</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">missing:~$</span><br></pre></td></tr></table></figure>
<p>这是 <code>shell</code> 最主要的文本接口。它告诉你，你的主机名是 <code>missing</code> 并且您当前的工作目录（”<code>current working directory</code>”）或者说您当前所在的位置是 <code>~</code> (表示 “<code>home</code>”)</p>
<Br>
<h3 id="date"><a class="markdownIt-Anchor" href="#date"></a> <code>date</code></h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">date</span></span><br><span class="line">2024年 2月26日 星期一 21时25分04秒 `CST`</span><br></pre></td></tr></table></figure>
<p>这里，我们执行了 <code>date</code> 这个程序，不出意料地，它打印出了当前的日期和时间</p>
<br>
<h3 id="echo"><a class="markdownIt-Anchor" href="#echo"></a> <code>echo</code></h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">echo</span> hellop</span><br><span class="line">hellop</span><br></pre></td></tr></table></figure>
<p><code>echo</code> 程序将该参数打印出来。 <code>shell</code> 基于空格分割命令并进行解析，然后执行第一个单词代表的程序，并将后续的单词作为程序可以访问的参数.</p>
<br>
<h3 id="path"><a class="markdownIt-Anchor" href="#path"></a> <code>PATH</code></h3>
<p><code>shell</code> 是如何知道去哪里寻找 <code>date</code> 或 <code>echo</code> 的呢？其实，类似于 <code>Python</code> 或 <code>Ruby</code>，<code>shell</code> 是一个编程环境，所以它具备变量、条件、循环和函数（下一课进行讲解）。当你在 <code>shell</code> 中执行命令时，您实际上是在执行一段 <code>shell</code> 可以解释执行的简短代码。如果你要求 <code>shell</code> 执行某个指令，但是该指令并不是 <code>shell</code> 所了解的编程关键字，那么它会去咨询 环境变量 <code>$PATH</code>，它会列出当 <code>shell</code> 接到某条指令时，进行程序搜索的路径</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line">/Users/chenyubin/anaconda3/bin:/Users/chenyubin/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.11/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion.app/Contents/Public:/usr/local/share/dotnet:~/.dotnet/tools:/Library/Apple/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/usr/local/mysql/bin</span><br></pre></td></tr></table></figure>
<p>当我们执行 <code>echo</code> 命令时，<code>shell</code> 了解到需要执行 <code>echo</code> 这个程序，随后它便会在 <code>$PATH</code> 中搜索由 <code>:</code> 所分割的一系列目录，基于名字搜索该程序。当找到该程序时便执行</p>
<br>
<h3 id="which"><a class="markdownIt-Anchor" href="#which"></a> <code>which</code></h3>
<p>确定某个程序名代表的是哪个具体的程序，可以使用 <code>which</code> 程序,<code>MacOS</code>中为<code>where</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">where</span> <span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span>: shell built-in <span class="built_in">command</span></span><br><span class="line">/bin/echo</span><br></pre></td></tr></table></figure>
<br>
<h2 id="shell中导航"><a class="markdownIt-Anchor" href="#shell中导航"></a> Shell中导航</h2>
<p><code>shell</code> 中的路径是一组被分割的目录，在 <code>Linux</code> 和 <code>macOS</code> 上使用 <code>/</code> 分割，而在<code>Windows</code>上是 <code>\</code>。路径 <code>/</code> 代表的是系统的根目录，所有的文件夹都包括在这个路径之下，在<code>Windows</code>上每个盘都有一个根目录（例如： <code>C:\</code>）。</p>
<p><code>Linux</code> 文件系统下，如果某个路径以 <code>/</code> 开头，那么它是一个 <code>绝对路径</code>，其他的都是 <code>相对路径</code> 。相对路径是指相对于当前工作目录的路径</p>
<p>在路径中，<code>.</code> 表示的是当前目录，而 <code>..</code> 表示上级目录</p>
<p>。</p>
<br>
<h3 id="pwd"><a class="markdownIt-Anchor" href="#pwd"></a> <code>pwd</code></h3>
<p>你可以使用 <code>pwd</code> （print working directory）来查看当前的工作目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">pwd</span></span><br><span class="line">/Users/chenyubin</span><br></pre></td></tr></table></figure>
<br>
<h3 id="ls"><a class="markdownIt-Anchor" href="#ls"></a> <code>ls</code></h3>
<p>要列出一个目录中的文件，可以使用 <code>ls</code> 程序。如果不带任何参数，<code>ls</code> 会列出当前目录中的文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">ls</span></span><br><span class="line">Applications		Library			Public</span><br><span class="line">Desktop			Movies			chromedriver</span><br><span class="line">Documents		Music			docker-compose.yml</span><br><span class="line">Downloads		Pictures		postman</span><br></pre></td></tr></table></figure>
<p>除非我们利用第一个参数指定目录，否则 ls 会打印当前目录下的文件。大多数的命令接受标记和选项（带有值的标记），它们以 - 开头，并可以改变程序的行为。</p>
<br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">ls</span> -l</span><br><span class="line">total 3226936</span><br><span class="line">drwx------@  5 chenyubin  staff         160  7 17  2023 Applications</span><br><span class="line">drwxr-xr-x@  4 chenyubin  staff         128  9 22 01:24 CLionProjects</span><br><span class="line">drwx------@ 16 chenyubin  staff         512  2 26 21:36 Desktop</span><br><span class="line">drwx------@  4 chenyubin  staff         128  2  3 01:14 Documents</span><br><span class="line">drwx------+ 47 chenyubin  staff        1504  2 17 20:33 Downloads</span><br><span class="line">drwx------@ 98 chenyubin  staff        3136 11 18 19:49 Library</span><br><span class="line">drwx------   4 chenyubin  staff         128  7 10  2023 Movies</span><br><span class="line">drwx------+  5 chenyubin  staff         160  7 11  2023 Music</span><br><span class="line">lrwxr-xr-x   1 chenyubin  staff          53  7 12  2023 OneDrive - kvz8wq -&gt; /Users/chenyubin/Library/CloudStorage/OneDrive-kvz8wq</span><br><span class="line">drwx------+  4 chenyubin  staff         128  7 10  2023 Pictures</span><br><span class="line">drwxr-xr-x+  5 chenyubin  staff         160  9 22 13:46 Public</span><br><span class="line">drwxr-xr-x@ 17 chenyubin  staff         544  1  6 21:01 PycharmProjects</span><br><span class="line">drwxr-xr-x   5 chenyubin  staff         160  1  9 20:14 Virtual Machines.localized</span><br><span class="line">drwxr-xr-x  25 chenyubin  staff         800  7 12  2023 anaconda3</span><br><span class="line">-rw-------@  1 chenyubin  staff        2655  7 13  2023 chenyubin</span><br><span class="line">-rw-r--r--@  1 chenyubin  staff         571  7 13  2023 chenyubin.pub</span><br><span class="line">drwxr-xr-x@  4 chenyubin  staff         128 10  8 03:21 dumps</span><br><span class="line">drwx------   4 chenyubin  staff         128  7 14  2023 iCloud云盘（归档）</span><br><span class="line">-rw-------@  1 chenyubin  staff  1651750569  7 23  2023 java_error_in_pycharm.hprof</span><br><span class="line">drwxr-xr-x@  4 chenyubin  staff         128 12  4 18:40 nltk_data</span><br><span class="line">drwxr-xr-x  53 root       staff        1696  7 30  2023 node_modules</span><br><span class="line">-rw-r--r--   1 root       staff       19405  7 30  2023 package-lock.json</span><br><span class="line">-rw-r--r--   1 root       staff          94  7 30  2023 package.json</span><br><span class="line">drwxr-xr-x@  4 chenyubin  staff         128 12 16 23:09 scikit_learn_data</span><br><span class="line">-rw-r--r--@  1 chenyubin  staff         590  7 23  2023 未命名.ipynb</span><br><span class="line">-rw-r--r--@  1 chenyubin  staff      389418  8 17  2023 未命名1.ipynb</span><br><span class="line">-rw-r--r--@  1 chenyubin  staff        6118 11 24 20:38 未命名2.ipynb</span><br></pre></td></tr></table></figure>
<p>这个参数可以更加详细地列出目录下文件或文件夹的信息。首先，本行第一个字符 d 表示 当前 是一个目录。</p>
<p>然后接下来的九个字符，每三个字符构成一组。 （rwx）. 它们分别代表了文件所有者（当前目录），用户组（users） 以及其他所有人具有的权限。其中 - 表示该用户不具备相应的权限。为了进入某个文件夹，用户需要具备该文件夹以及其父文件夹的“搜索”权限（以“可执行”：x）权限表示。为了列出它的包含的内容，用户必须对该文件夹具备读权限（r）。对于文件来说，权限的意义也是类似的。</p>
<br>
<h3 id="cd"><a class="markdownIt-Anchor" href="#cd"></a> <code>cd</code></h3>
<p>要改变当前工作目录，使用 <code>cd</code> （change directory）命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">cd</span> Desktop</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro Desktop % </span><br></pre></td></tr></table></figure>
<br>
<p>为了更清楚地展示高亮要求，我会在下面的文本中将英文名词和符号用<code>高亮</code>表示：</p>
<h3 id="man"><a class="markdownIt-Anchor" href="#man"></a> <code>man</code></h3>
<p>如果您想要知道关于程序参数、输入输出的信息，亦或是想要了解它们的工作方式，请试试 <code>man</code> 这个程序。它会接受一个程序名作为参数，然后将它的文档（用户手册）展现给您。注意，使用 <code>q</code> 可以退出该程序</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % man <span class="built_in">ls</span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="程序间的连接"><a class="markdownIt-Anchor" href="#程序间的连接"></a> 程序间的连接</h2>
<p>在 <code>shell</code> 中，程序有两个主要的“流”：它们的输入流和输出流。 当程序尝试读取信息时，它们会从输入流中进行读取，当程序打印信息时，它们会将信息输出到输出流中。 通常，一个程序的输入输出流都是您的终端。也就是，您的键盘作为输入，显示器作为输出。 但是，我们也可以重定向这些流！</p>
<h3 id="file-和-file"><a class="markdownIt-Anchor" href="#file-和-file"></a> <code>&lt; file</code> 和 <code>&gt; file</code></h3>
<p>最简单的重定向是 <code>&lt; file</code> 和 <code>&gt; file</code>。这两个命令可以将程序的输入输出流分别重定向到文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro desktop % <span class="built_in">echo</span> hello &gt; hello.txt</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro desktop % <span class="built_in">cat</span> hello.txt</span><br><span class="line">hello</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro desktop % <span class="built_in">cat</span> &lt; hello.txt &gt; hello2.txt</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro desktop % <span class="built_in">cat</span> hello2.txt</span><br><span class="line">hello</span><br></pre></td></tr></table></figure>
<br>
<h3 id=""><a class="markdownIt-Anchor" href="#"></a> <code>|</code></h3>
<p>使用管道（<code>pipes</code>），我们能够更好的利用文件重定向。 <code>|</code> 操作符允许我们将一个程序的输出和另外一个程序的输入连接起来：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro desktop % <span class="built_in">ls</span> -l / | <span class="built_in">tail</span> -n1</span><br><span class="line">lrwxr-xr-x@  1 root  wheel    11  9 16 15:48 var -&gt; private/var</span><br></pre></td></tr></table></figure>
<br>
<h2 id="sudo"><a class="markdownIt-Anchor" href="#sudo"></a> <code>sudo</code></h2>
<p>顾名思义，它的作用是让您可以以 <code>su</code>（<code>super user</code> 或 <code>root</code> 的简写）的身份执行一些操作。 当您遇到拒绝访问（<code>permission denied</code>）的错误时，通常是因为此时您必须是根用户才能操作。然而，请再次确认您是真的要执行此操作。</p>
<br>
<h2 id="课后练习"><a class="markdownIt-Anchor" href="#课后练习"></a> 课后练习</h2>
<h3 id="在-tmp-下新建一个名为-missing-的文件夹"><a class="markdownIt-Anchor" href="#在-tmp-下新建一个名为-missing-的文件夹"></a> 在 <code>/tmp</code> 下新建一个名为 <code>missing</code> 的文件夹</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro desktop % <span class="built_in">cd</span> /tmp</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro /tmp % <span class="built_in">mkdir</span> missing</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro /tmp % tree -L 1</span><br><span class="line">.</span><br><span class="line">├── SangforSSL.lock</span><br><span class="line">├── SangforSSLJava.lock</span><br><span class="line">├── Sublime Text.4cff18d2bab96a93366319a9e0fa060d.5350f1748b9ec3b47b154263c0cfdaa7.sock</span><br><span class="line">├── com.adobe.acrobat.rna.0.1f5.DC</span><br><span class="line">├── com.adobe.acrobat.rna.131c.1f5</span><br><span class="line">├── com.apple.launchd.viWeL6VPPz</span><br><span class="line">├── com.sangfor.ca.sha</span><br><span class="line">├── com.sangfor.ca.verification</span><br><span class="line">├── com.sangfor.lockcert</span><br><span class="line">├── com.sangfor.lockecagent</span><br><span class="line">├── ko.2f4b4ffd.325bc6c2.0</span><br><span class="line">├── ko.d87db22f.668d0007.1</span><br><span class="line">├── missing</span><br><span class="line">├── mysql.sock</span><br><span class="line">├── mysqlx.sock</span><br><span class="line">├── resolv.bak.conf</span><br><span class="line">├── sangfor.ec.rundata</span><br><span class="line">└── stop_easyconnect.sh</span><br><span class="line"></span><br><span class="line">3 directories, 16 files</span><br></pre></td></tr></table></figure>
<Br>
<h3 id="用-man-查看程序-touch-的使用手册"><a class="markdownIt-Anchor" href="#用-man-查看程序-touch-的使用手册"></a> 用 <code>man</code> 查看程序 <code>touch</code> 的使用手册。</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro /tmp % man <span class="built_in">touch</span></span><br></pre></td></tr></table></figure>
<p>touch和mkdir区别：</p>
<ul>
<li>touch新建文件</li>
<li>mkdir新建目录/文件夹（directory)</li>
</ul>
<br>
<h3 id="用-touch-在-missing-文件夹中新建一个叫-semester-的文件"><a class="markdownIt-Anchor" href="#用-touch-在-missing-文件夹中新建一个叫-semester-的文件"></a> 用 <code>touch</code> 在 <code>missing</code> 文件夹中新建一个叫 <code>semester</code> 的文件。</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro /tmp % <span class="built_in">cd</span> missing</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">touch</span> semester</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % tree -L 1</span><br><span class="line">.</span><br><span class="line">└── semester</span><br><span class="line"></span><br><span class="line">1 directory, 1 file</span><br></pre></td></tr></table></figure>
<Br>
<h3 id="将以下内容一行一行地写入-semester-文件"><a class="markdownIt-Anchor" href="#将以下内容一行一行地写入-semester-文件"></a> 将以下内容一行一行地写入 <code>semester</code> 文件：</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`#!/bin/sh`  </span><br><span class="line">`curl --head --silent https://missing.csail.mit.edu`</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">echo</span> \<span class="comment">#&#x27;!&#x27;/bin/sh &gt; semester</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">cat</span> semester</span><br><span class="line"><span class="comment">#!/bin/sh</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">echo</span> cur; --<span class="built_in">head</span> --silent http://github.com/siyuanluo &gt;&gt; semester</span><br><span class="line">cur</span><br><span class="line">zsh: <span class="built_in">command</span> not found: --<span class="built_in">head</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">cat</span> semester</span><br><span class="line"><span class="comment">#!/bin/sh</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">echo</span> curl --<span class="built_in">head</span> --silent http://github.com/siyuanluo &gt;&gt; semester</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">cat</span> semester</span><br><span class="line"><span class="comment">#!/bin/sh</span></span><br><span class="line">curl --<span class="built_in">head</span> --silent http://github.com/siyuanluo</span><br></pre></td></tr></table></figure>
<br>
<h3 id="尝试执行这个文件-例如将该脚本的路径semester输入到您的shell中并回车-如果程序无法执行请使用-ls-命令来获取信息并理解其不能执行的原因"><a class="markdownIt-Anchor" href="#尝试执行这个文件-例如将该脚本的路径semester输入到您的shell中并回车-如果程序无法执行请使用-ls-命令来获取信息并理解其不能执行的原因"></a> 尝试执行这个文件。例如，将该脚本的路径（<code>./semester</code>）输入到您的<code>shell</code>中并回车。如果程序无法执行，请使用 <code>ls</code> 命令来获取信息并理解其不能执行的原因。</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % ./semester</span><br><span class="line">zsh: permission denied: ./semester</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">ls</span> -l</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r--@ 1 chenyubin  wheel  59  2 26 22:13 semester</span><br></pre></td></tr></table></figure>
<p>无法执行，原因是文件所有者无执行权限（权限为rw-，只可读写）</p>
<br>
<h3 id="查看-chmod-的手册例如使用-man-chmod-命令"><a class="markdownIt-Anchor" href="#查看-chmod-的手册例如使用-man-chmod-命令"></a> 查看 <code>chmod</code> 的手册(例如，使用 <code>man chmod</code> 命令)</h3>
<h3 id="使用-chmod-命令改变权限使-semester-能够成功执行不要使用-sh-semester-来执行该程序-您的-shell-是如何知晓这个文件需要使用-sh-来解析呢更多信息请参考shebang"><a class="markdownIt-Anchor" href="#使用-chmod-命令改变权限使-semester-能够成功执行不要使用-sh-semester-来执行该程序-您的-shell-是如何知晓这个文件需要使用-sh-来解析呢更多信息请参考shebang"></a> 使用 <code>chmod</code> 命令改变权限，使 <code>./semester</code> 能够成功执行，不要使用 <code>sh semester</code> 来执行该程序。您的 <code>shell</code> 是如何知晓这个文件需要使用 <code>sh</code> 来解析呢？更多信息请参考：<code>shebang</code></h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">ls</span> -l</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r--@ 1 chenyubin  wheel  59  2 26 22:13 semester</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % man <span class="built_in">chmod</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">chmod</span> 777 semester</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro missing % <span class="built_in">ls</span> -l</span><br><span class="line">total 8</span><br><span class="line">-rwxrwxrwx@ 1 chenyubin  wheel  59  2 26 22:13 semester</span><br></pre></td></tr></table></figure>
<Br>
<h3 id="使用-和-将-semester-文件输出的最后更改日期信息写入主目录下的-last-modifiedtxt-的文件中"><a class="markdownIt-Anchor" href="#使用-和-将-semester-文件输出的最后更改日期信息写入主目录下的-last-modifiedtxt-的文件中"></a> 使用 <code>|</code> 和 <code>&gt;</code> ，将 <code>semester</code> 文件输出的最后更改日期信息，写入主目录下的 <code>last-modified.txt</code> 的文件中</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./semester | grep -i &quot;last-modified&quot; &gt; /home/last-modified.txt</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>project</category>
        <category>Missing Semester of CS</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>Missing Semester</tag>
        <tag>课程概览</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL命令(完整)</title>
    <url>/2023/11/21/MySQL%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="mysql常用命令"><a class="markdownIt-Anchor" href="#mysql常用命令"></a> MySQL常用命令</h1>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li>1.启动与停止MySQL服务</li>
<li>2.登录MySQL</li>
<li>3.添加新用户</li>
<li>4.数据库操作</li>
<li>5.数据导出与导入</li>
<li>6.退出MySQL命令</li>
</ul>
<hr />
<h2 id="1-启动与停止mysql服务"><a class="markdownIt-Anchor" href="#1-启动与停止mysql服务"></a> 1. 启动与停止MySQL服务</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net stop mysql</span><br><span class="line">net start mysql</span><br></pre></td></tr></table></figure>
<p><em>注意：</em> 如果启动失败，请使用快捷键<code>win+R</code>，输入<code>services.msc</code>，然后按名称启动MySQL服务器。</p>
<br>
<h2 id="2-登录mysql"><a class="markdownIt-Anchor" href="#2-登录mysql"></a> 2. 登录MySQL</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql (-h) -u 用户名 -p 密码</span><br></pre></td></tr></table></figure>
<p><em>注意：</em> 使用<code>-h</code>选项连接到不同的机器。</p>
<br>
<h2 id="3-添加新用户"><a class="markdownIt-Anchor" href="#3-添加新用户"></a> 3. 添加新用户</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grant [权限] on 数据库.* to &#x27;用户名&#x27;@&#x27;主机&#x27; identified by &#x27;密码&#x27;;</span><br></pre></td></tr></table></figure>
<p>示例：添加具有查询、插入、更新和删除权限的用户到所有数据库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grant select, insert, update, delete on *.* to &#x27;user&#x27;@&#x27;localhost&#x27; identified by &#x27;password&#x27;;</span><br></pre></td></tr></table></figure>
<p>将’localhost’更改为’%'以允许从任何机器登录。</p>
<br>
<h2 id="4-数据库操作"><a class="markdownIt-Anchor" href="#4-数据库操作"></a> 4. 数据库操作</h2>
<p>登录到mysql中，然后在mysql的提示符下运行下列命令，每个命令以分号结束。</p>
<p>选择你所创建的数据库</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">use 数据库名</span><br></pre></td></tr></table></figure>
<p>导入.sql文件命令(例D:/mysql.sql):</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span>use 数据库名;</span><br><span class="line">mysql<span class="operator">&gt;</span>source d:<span class="operator">/</span>mysql.sql;</span><br></pre></td></tr></table></figure>
<h3 id="i-数据库列表"><a class="markdownIt-Anchor" href="#i-数据库列表"></a> I. 数据库列表</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">show databases;</span><br></pre></td></tr></table></figure>
<h3 id="ii-数据库中的表列表"><a class="markdownIt-Anchor" href="#ii-数据库中的表列表"></a> II. 数据库中的表列表</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">use [数据库名];</span><br><span class="line">show tables;</span><br></pre></td></tr></table></figure>
<h3 id="iii-表结构"><a class="markdownIt-Anchor" href="#iii-表结构"></a> III. 表结构</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">describe [表名];</span><br></pre></td></tr></table></figure>
<h3 id="iv-创建与删除数据库"><a class="markdownIt-Anchor" href="#iv-创建与删除数据库"></a> IV. 创建与删除数据库</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create database [数据库名];</span><br><span class="line">drop database [数据库名];</span><br></pre></td></tr></table></figure>
<h3 id="v-创建与删除表"><a class="markdownIt-Anchor" href="#v-创建与删除表"></a> V. 创建与删除表</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">use [数据库名];</span><br><span class="line">create table [表名] ([列定义]);</span><br><span class="line">drop table [表名];</span><br></pre></td></tr></table></figure>
<h3 id="vi-清空表中记录"><a class="markdownIt-Anchor" href="#vi-清空表中记录"></a> VI. 清空表中记录</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">delete from [表名];</span><br></pre></td></tr></table></figure>
<h3 id="vii-显示表中的记录"><a class="markdownIt-Anchor" href="#vii-显示表中的记录"></a> VII. 显示表中的记录</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from [表名];</span><br></pre></td></tr></table></figure>
<h3 id="viii-向表中添加记录"><a class="markdownIt-Anchor" href="#viii-向表中添加记录"></a> VIII. 向表中添加记录</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">insert into [表名] values ([列值]);</span><br></pre></td></tr></table></figure>
<h3 id="ix-更新表中的数据"><a class="markdownIt-Anchor" href="#ix-更新表中的数据"></a> IX. 更新表中的数据</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">update [表名] set [列] = &#x27;值&#x27; where [条件];</span><br></pre></td></tr></table></figure>
<br>
<h2 id="5-数据导出与导入"><a class="markdownIt-Anchor" href="#5-数据导出与导入"></a> 5. 数据导出与导入</h2>
<h3 id="i-导出数据"><a class="markdownIt-Anchor" href="#i-导出数据"></a> I. 导出数据</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysqldump --opt [数据库名] &gt; [文件名];</span><br></pre></td></tr></table></figure>
<h3 id="ii-导入数据"><a class="markdownIt-Anchor" href="#ii-导入数据"></a> II. 导入数据</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysqlimport -u [用户名] -p[密码] &lt; [文件名];</span><br></pre></td></tr></table></figure>
<h3 id="iii-将文本数据导入数据库"><a class="markdownIt-Anchor" href="#iii-将文本数据导入数据库"></a> III. 将文本数据导入数据库</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">load data local infile &#x27;[文件名]&#x27; into table [表名];</span><br></pre></td></tr></table></figure>
<br>
<h2 id="6-退出mysql命令"><a class="markdownIt-Anchor" href="#6-退出mysql命令"></a> 6. 退出MySQL命令</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>N-Gram</title>
    <url>/2024/03/16/N-Gram/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2>
<p>N-Gram是一种基于统计语言模型的算法，思想是<strong>将文本里的内容按照字节进行大小为N的滑动窗口操作</strong>，形成了长度为N的字节片段序列。<br />
每一个字节片段称为gram，对所有gram进行频度统计，过阈值，形成<strong>gram列表</strong></p>
<p><strong>假设</strong>：第n次的出现只与前N-1个词相关，与其他词不相关。</p>
<p><strong>举例</strong>：<br />
<strong>Bi-gram</strong>：｛（I，love），（love，you）｝<br />
<strong>Tri-gram</strong>：｛（I，love，you）｝</p>
<br>
<h2 id="举例"><a class="markdownIt-Anchor" href="#举例"></a> 举例</h2>
<p><strong>词和词频见下表</strong>：</p>
<table>
<thead>
<tr>
<th>I</th>
<th>want</th>
<th>to</th>
<th>eat</th>
<th>Chinese</th>
<th>food</th>
<th>lunch</th>
</tr>
</thead>
<tbody>
<tr>
<td>3437</td>
<td>1215</td>
<td>3256</td>
<td>938</td>
<td>213</td>
<td>1506</td>
<td>459</td>
</tr>
</tbody>
</table>
<br>
<p>语料库中一些单词的词频，统计出各个单词与其他单词的前后联系的频次，组成一个7*7的二维矩阵，如下图：</p>
<table>
<thead>
<tr>
<th></th>
<th>I</th>
<th>want</th>
<th>to</th>
<th>eat</th>
<th>Chinese</th>
<th>food</th>
<th>lunch</th>
</tr>
</thead>
<tbody>
<tr>
<td>I</td>
<td>8</td>
<td>1087</td>
<td>0</td>
<td>13</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>want</td>
<td>3</td>
<td>0</td>
<td>786</td>
<td>0</td>
<td>6</td>
<td>8</td>
<td>6</td>
</tr>
<tr>
<td>to</td>
<td>3</td>
<td>0</td>
<td>10</td>
<td>860</td>
<td>3</td>
<td>0</td>
<td>12</td>
</tr>
<tr>
<td>eat</td>
<td>0</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>19</td>
<td>2</td>
<td>52</td>
</tr>
<tr>
<td>Chinese</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>120</td>
<td>1</td>
</tr>
<tr>
<td>food</td>
<td>19</td>
<td>0</td>
<td>17</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>lunch</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<br>
<p class='katex-block katex-error' title='ParseError: KaTeX parse error: No such environment: align* at position 7: \begin{̲a̲l̲i̲g̲n̲*̲}̲
&amp;P(I \text{ wa…'>\begin{align*}
&amp;P(I \text{ want to eat Chinese food})  \\
&amp;=P(I) \times P(want|I) \times P(to|want) \times P(eat|to) \times P(Chinese|eat) \times P(food|Chinese) \\
&amp;= 0.25 \times \frac{1087}{3437} \times \frac{786}{1215} \times \frac{860}{3256} \times \frac{19}{938} \times \frac{120}{213} \\
&amp;= 0.000154171
\end{align*}
</p>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/32829048">忆臻的文章 - 自然语言处理中N-Gram模型介绍</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/351329085">杨沐白的文章 - 自然语言处理（NLP）的N-gram模型是什么？</a></li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
      </tags>
  </entry>
  <entry>
    <title>No such file or directory</title>
    <url>/2023/11/30/No-such-file-or-directory/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="出现的报错"><a class="markdownIt-Anchor" href="#出现的报错"></a> 出现的报错</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(pytorch) root@notebook-devenviron-<span class="number">1129</span>-<span class="number">193455</span>-j8m3xk-notebook-<span class="number">0</span>:/opt/code_chap_2_3/pycnnl/cnnl_python/swig<span class="comment"># bash build_pycnnl.sh</span></span><br><span class="line">bash: build_pycnnl.sh: No such file <span class="keyword">or</span> directory</span><br></pre></td></tr></table></figure>
<br>
<h2 id="操作步骤"><a class="markdownIt-Anchor" href="#操作步骤"></a> 操作步骤</h2>
<p><img src="https://pbs.twimg.com/media/GAJ8ob_WEAAaBj1?format=png&amp;name=900x900" alt="" /></p>
<br>
<h2 id="问题所在之处"><a class="markdownIt-Anchor" href="#问题所在之处"></a> 问题所在之处</h2>
<p>当我<code>pip install swig</code>之后，运行脚本找不到文件</p>
<p>原因：没有脚本执行权限</p>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<ol>
<li>
<p>打开你的终端。</p>
</li>
<li>
<p>使用<code>cd</code>命令更改当前目录到脚本所在的目录：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/code_chap_2_3/pycnnl/cnnl_python/</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>确保<code>build_pycnnl.sh</code>脚本具有执行权限。你可以通过运行以下命令来给予执行权限（如果尚未有执行权限）：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x build_pycnnl.sh</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>运行脚本：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./build_pycnnl.sh</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>智能计算系统</tag>
        <tag>2-2</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear Regression VS Logistic Regression</title>
    <url>/2024/03/11/Linear-Regression-VS-Logistic-Regression/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">线性回归</a></li>
<li><a href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92">逻辑回归</a></li>
<li><a href="#%E5%AF%B9%E6%AF%94">对比</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li>
</ul>
<br>
<h2 id="线性回归"><a class="markdownIt-Anchor" href="#线性回归"></a> 线性回归</h2>
<p>线性回归是一种统计方法，用于研究两个或多个变量之间的关系。在这种关系中，每个自变量都与因变量直接相关，而与其他自变量没有关系。这种直接相关的关系称为线性关系。因变量通常是连续值范围中的一个值。</p>
<p>线性回归模型的创建基于以下公式或线性函数：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>B</mi><mn>0</mn><mo>+</mo><mi>B</mi><mn>1</mn><mi>X</mi><mn>1</mn><mo>+</mo><mi>B</mi><mn>2</mn><mi>X</mi><mn>2</mn><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mi>B</mi><mi>n</mi><mi>X</mi><mi>n</mi><mo>+</mo><mi>ε</mi></mrow><annotation encoding="application/x-tex">y = B0 + B1X1 + B2X2 + ... + BnXn + ε
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ε</span></span></span></span></span></p>
<ul>
<li><code>y</code>:  表示预测的因变量。</li>
<li><code>B0</code>:  为y截距，即当所有输入自变量都等于0时，因变量的值。</li>
<li><code>B1X1</code>:  是第一个自变量（X1）的回归系数（B1），即第一个自变量对因变量的影响值。类似地，<code>BnXn</code> 是最后一个自变量（Xn）的回归系数（Bn）。</li>
<li><code>ε</code>:  为模型误差。</li>
</ul>
<br>
<h2 id="逻辑回归"><a class="markdownIt-Anchor" href="#逻辑回归"></a> 逻辑回归</h2>
<p>逻辑回归是一种用于预测因变量为二进制分类的统计方法。这些因变量的值通过使用有限类别列表得出，称为类别变量。例如，掷六面骰子的结果。这种因变量与自变量之间的关系称为逻辑关系。</p>
<p>逻辑回归公式对特定类别变量的成功或失败概率进行对数转换，即概率的自然对数。公式如下：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><msup><mi>e</mi><mrow><mo stretchy="false">(</mo><mi>B</mi><mn>0</mn><mo>+</mo><mi>B</mi><mn>1</mn><mi>X</mi><mn>1</mn><mo>+</mo><mi>B</mi><mn>2</mn><mi>X</mi><mn>2</mn><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mi>B</mi><mi>n</mi><mi>X</mi><mi>n</mi><mo>+</mo><mi>ε</mi><mo stretchy="false">)</mo></mrow></msup><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo stretchy="false">(</mo><mi>B</mi><mn>0</mn><mo>+</mo><mi>B</mi><mn>1</mn><mi>X</mi><mn>1</mn><mo>+</mo><mi>B</mi><mn>2</mn><mi>X</mi><mn>2</mn><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mi>B</mi><mi>n</mi><mi>X</mi><mi>n</mi><mo>+</mo><mi>ε</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y = e^{(B0 + B1X1 + B2X2 + ... + BnXn + ε)} / (1 + e^{(B0 + B1X1 + B2X2 + ... + BnXn + ε)})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mtight">0</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mtight">1</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mtight">2</span><span class="mbin mtight">+</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">ε</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mtight">0</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mtight">1</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mtight">2</span><span class="mbin mtight">+</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mord mtight">.</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">ε</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li><code>y</code> 表示y类别变量的成功概率。</li>
<li><code>e^(x)</code> 是欧拉数e的x次方，是自然对数函数或sigmoid函数的基础。</li>
<li><code>B0</code>、<code>B1X1</code>…<code>BnXn</code> 的含义与线性回归中相同，其中<code>B0</code>是截距，<code>B1X1</code>到<code>BnXn</code>表示各自变量对于因变量影响的权重。</li>
<li><code>ε</code> 代表模型误差。</li>
</ul>
<br>
<h2 id="对比"><a class="markdownIt-Anchor" href="#对比"></a> 对比</h2>
<table>
<thead>
<tr>
<th>特征</th>
<th>线性回归</th>
<th>逻辑回归</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>描述</strong></td>
<td>一种统计方法，用于通过一组输入值预测输出值</td>
<td>一种统计方法，用于通过一组类别变量预测输出值来自某一类别的可能性</td>
</tr>
<tr>
<td><strong>关系类型</strong></td>
<td>线性关系，以直线表示</td>
<td>逻辑关系或S形关系，以S形曲线表示</td>
</tr>
<tr>
<td><strong>函数类型</strong></td>
<td>线性</td>
<td>对数</td>
</tr>
<tr>
<td><strong>分析方法</strong></td>
<td>回归</td>
<td>分类</td>
</tr>
<tr>
<td><strong>分布类型</strong></td>
<td>正态/高斯</td>
<td>二项式</td>
</tr>
<tr>
<td><strong>应用场景</strong></td>
<td>需要通过量表预测连续因变量的任务</td>
<td>需要预测一组固定类别中出现某一类别因变量的可能性的任务</td>
</tr>
</tbody>
</table>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://aws.amazon.com/cn/compare/the-difference-between-linear-regression-and-logistic-regression/?nc1=h_ls">做出预测：线性回归 vs. 逻辑回归</a></li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>lr</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux服务器上解压缩文件</title>
    <url>/2023/12/03/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h2>
<p>解压缩是一个常用的操作，在 Linux 中通常比较常用的是 tar 命令，zip 和 rar 命令则是 Windows 中比较常用</p>
<br>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li>tar</li>
<li>rar</li>
<li>zip</li>
</ul>
<br>
<h2 id="1tar"><a class="markdownIt-Anchor" href="#1tar"></a> 1.<code>tar</code></h2>
<p><strong>示例</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">压缩文件 file1 和目录 dir2 到 test.tar.gz</span></span><br><span class="line">tar -zcvf test.tar.gz file1 dir2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压 test.tar.gz（将 c 换成 x 即可）</span></span><br><span class="line">tar -zxvf test.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">列出压缩文件的内容</span></span><br><span class="line">tar -ztvf test.tar.gz </span><br></pre></td></tr></table></figure>
<p><strong>释义</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-z : 使用 gzip 来压缩和解压文件</span><br><span class="line">-v : --verbose 详细的列出处理的文件</span><br><span class="line">-f : --file=ARCHIVE 使用档案文件或设备，这个选项通常是必选的</span><br><span class="line">-c : --create 创建一个新的归档（压缩包）</span><br><span class="line">-x : 从压缩包中解出文件</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：tar 命令其实并不是真的解压缩的处理者，而是使用了 gzip 或者 bzip2 等其它命令来达成，但是 gzip 等命令通常只能处理单个文件，并不方便，所以一般我们都是选择使用 tar 命令间接的完成解压缩。</p>
<br>
<h2 id="2rar"><a class="markdownIt-Anchor" href="#2rar"></a> 2.<code>rar</code></h2>
<p><strong>示例</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">压缩文件</span></span><br><span class="line">rar a -r test.rar file</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压文件</span></span><br><span class="line">unrar x test.rar</span><br></pre></td></tr></table></figure>
<p><strong>释义</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a : 添加到压缩文件</span><br><span class="line">-r : 递归处理</span><br><span class="line">x : 以绝对路径解压文件</span><br></pre></td></tr></table></figure>
<br>
<h2 id="3zip"><a class="markdownIt-Anchor" href="#3zip"></a> 3.<code>zip</code></h2>
<p><strong>示例</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">压缩文件</span></span><br><span class="line">zip -r test.zip file</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压文件</span></span><br><span class="line">unzip test.zip</span><br></pre></td></tr></table></figure>
<p>释义：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-r : 递归处理</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>Linux</tag>
        <tag>解压缩</tag>
      </tags>
  </entry>
  <entry>
    <title>OCR识别</title>
    <url>/2024/02/27/OCR%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考材料"><a class="markdownIt-Anchor" href="#参考材料"></a> 参考材料</h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/45376274">OCR技术简介</a></li>
</ul>
<br>
<h2 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h2>
<p>光学字符识别（Optical Character Recognition, OCR）是指对文本资料的图像文件进行分析识别处理，获取文字及版面信息的过程。亦即将图像中的文字进行识别，并以文本的形式返回。</p>
<br>
<h2 id="技术路线"><a class="markdownIt-Anchor" href="#技术路线"></a> 技术路线</h2>
<p>典型的OCR的技术路线如下图所示</p>
<p><img src="https://pbs.twimg.com/media/GHUWZLtXMAAMLTD?format=jpg&amp;name=large" alt="" /></p>
<p>其中影响识别准确率的技术瓶颈是文字检测和文本识别，而这两部分也是OCR技术的重中之重。</p>
<p>在传统OCR技术中，图像预处理通常是针对图像的成像问题进行修正。常见的预处理过程包括：几何变换（透视、扭曲、旋转等）、畸变校正、去除模糊、图像增强和光线校正等</p>
<p>文字检测即检测文本的所在位置和范围及其布局。通常也包括版面分析和文字行检测等。文字检测主要解决的问题是哪里有文字，文字的范围有多大。</p>
<p>文本识别是在文本检测的基础上，对文本内容进行识别，将图像中的文本信息转化为文本信息。文字识别主要解决的问题是每个文字是什么。识别出的文本通常需要再次核对以保证其正确性。文本校正也被认为属于这一环节。而其中当识别的内容是由词库中的词汇组成时，我们称作有词典识别(Lexicon-based)，反之称作无词典识别(Lexicon-free)</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>OCR</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch:nn.Parameter()</title>
    <url>/2024/03/16/PyTorch-nn-Parameter/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CLASS torch.nn.parameter.Parameter(data=<span class="literal">None</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>含义是：通过将一个固定不可训练的张量(<strong>Tensor</strong>)转换成可训练的类型<strong>Parameter</strong>，并将这个<strong>Parameter</strong>绑定到模块(<strong>Module</strong>)中（即在<strong>net.parameters()<strong>中可以找到这个绑定的</strong>Parameter</strong>），从而在参数优化时能够对其进行优化。因此，通过这种类型转换，<code>self.v</code>变成了模型的一部分，成为了模型中可以根据训练进行调整的参数。使用这个函数的目的是为了让某些变量在学习过程中能够不断地修改其值，以达到最优化。</p>
<br>
<p><strong>参数</strong>：</p>
<ul>
<li><strong>data</strong> (<strong>Tensor</strong>) - <strong>参数</strong>张量。</li>
<li><strong>requires_grad</strong> (<strong>bool</strong>, 可选) - 如果<strong>参数</strong>需要梯度。注意，<strong>torch.no_grad()<strong>上下文不影响</strong>Parameter</strong>创建的默认行为——即使在<strong>no_grad</strong>模式下，<strong>Parameter</strong>仍将有<strong>requires_grad=True</strong>。更多详情见局部禁用梯度计算。默认值：True</li>
</ul>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html">CLASS torch.nn.parameter.Parameter(data=None, requires_grad=True)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/170437891">PyTorch37.torch.nn.Parameter() - 科技猛兽的文章 - 知乎</a></li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyCharm学生授权免费申请指南</title>
    <url>/2024/01/10/PyCharm%E5%AD%A6%E7%94%9F%E6%8E%88%E6%9D%83%E5%85%8D%E8%B4%B9%E7%94%B3%E8%AF%B7%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<p><img src="https://blog.jetbrains.com/zh-hans/blog/2022/08/24/2022-jetbrains-student-program/" alt="" /></p>
<br>
<h2 id="1申请界面"><a class="markdownIt-Anchor" href="#1申请界面"></a> 1.申请界面</h2>
<p>首先，进入<a href="https://www.jetbrains.com/shop/eform/students">申请界面</a></p>
<br>
<h2 id="2完善所需信息"><a class="markdownIt-Anchor" href="#2完善所需信息"></a> 2.完善所需信息</h2>
<p><img src="https://pbs.twimg.com/media/GDe7vV4boAAr8RB?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="3提交证件"><a class="markdownIt-Anchor" href="#3提交证件"></a> 3.提交证件</h2>
<p>去<a href="https://my.chsi.com.cn/archive/bab/xj/show.action">学信网</a>申请学籍报告并完成填写：</p>
<p><img src="https://pbs.twimg.com/media/GDe8KXuaUAEDYKI?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>pycharm</tag>
        <tag>教育许可</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch:torch.cat()和torch.stack()</title>
    <url>/2024/01/13/PyTorch-torch-cat/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.cat.html">pytorch官方：TORCH.CAT</a></li>
</ul>
<br>
<h2 id="torchcat"><a class="markdownIt-Anchor" href="#torchcat"></a> torch.cat</h2>
<p><code>torch.cat(tensors, dim=0, *, out=None) → Tensor</code><br />
将给定序列中的 <code>seq</code> 张量在指定维度上进行连接。所有张量必须在连接维度之外具有相同的形状，或者是空张量。</p>
<p><code>torch.cat()</code> 可以被视为 <code>torch.split()</code> 和 <code>torch.chunk()</code> 的逆操作。</p>
<p>参数</p>
<ul>
<li>
<p><code>tensors</code>（张量序列）- 相同类型的张量的任何 Python 序列。提供的非空张量必须在 <code>cat</code> 维度上具有相同的形状。</p>
</li>
<li>
<p><code>dim</code>（int, 可选默认为0）- 张量连接的维度</p>
</li>
</ul>
<p>关键字参数</p>
<ul>
<li><code>out</code>（Tensor, 可选）- 输出张量。</li>
</ul>
<br>
<h2 id="与torchstack的区别"><a class="markdownIt-Anchor" href="#与torchstack的区别"></a> 与torch.stack的区别</h2>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建两个形状为 [2, 3] 的张量</span></span><br><span class="line">tensor1 = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">tensor2 = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.cat 在第一个维度（dim=0）上连接张量</span></span><br><span class="line">cat_result = torch.cat((tensor1, tensor2), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.stack 在一个新的维度（dim=0）上堆叠张量</span></span><br><span class="line">stack_result = torch.stack((tensor1, tensor2), dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果和它们的形状</span></span><br><span class="line"><span class="comment">#print(&quot;Result of torch.cat:&quot;)</span></span><br><span class="line"><span class="comment">#print(cat_result)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of cat_result:&quot;</span>, cat_result.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(&quot;\nResult of torch.stack:&quot;)</span></span><br><span class="line"><span class="comment">#print(stack_result)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of stack_result:&quot;</span>, stack_result.shape)</span><br></pre></td></tr></table></figure>
<br>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Shape of cat_result: torch.Size([<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">Shape of stack_result: torch.Size([<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>pytorch</tag>
        <tag>cat</tag>
      </tags>
  </entry>
  <entry>
    <title> Missing Semester of CS:Lecture02-Shell工具与脚本</title>
    <url>/2024/03/05/Missing-Semester-of-CS-Lecture02-Shell%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#shell%E8%84%9A%E6%9C%AC">Shell脚本</a>
<ul>
<li><a href="#%E5%8F%98%E9%87%8F%E8%B5%8B%E5%80%BC%E5%AD%97%E7%AC%A6%E4%B8%B2">变量、赋值、字符串</a></li>
<li><a href="#%E5%87%BD%E6%95%B0">函数</a></li>
<li><a href="#bool%E8%BF%90%E7%AE%97">bool运算</a></li>
<li><a href="#%E5%91%BD%E4%BB%A4%E6%9B%BF%E6%8D%A2command-substitution%E4%B8%8E%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2process-substitution">命令替换（command substitution）与进程替换（process substitution）</a></li>
<li><a href="#%E9%80%9A%E9%85%8D%E7%AC%A6">通配符</a></li>
<li><a href="#shell%E5%87%BD%E6%95%B0%E4%B8%8E%E8%84%9A%E6%9C%AC">shell函数与脚本</a></li>
</ul>
</li>
<li><a href="#shell%E5%B7%A5%E5%85%B7">Shell工具</a>
<ul>
<li><a href="#%E6%9F%A5%E7%9C%8B%E5%91%BD%E4%BB%A4%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8">查看命令如何使用</a></li>
<li><a href="#%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6-find">查找文件-find</a></li>
<li><a href="#%E6%9F%A5%E6%89%BE%E4%BB%A3%E7%A0%81-grep">查找代码-grep</a></li>
<li><a href="#%E6%9F%A5%E6%89%BEshell%E5%91%BD%E4%BB%A4">查找Shell命令</a></li>
<li><a href="#%E6%96%87%E4%BB%B6%E5%A4%B9%E5%AF%BC%E8%88%AA">文件夹导航</a></li>
</ul>
</li>
<li><a href="#%E4%BD%9C%E4%B8%9A">作业</a>
<ul>
<li><a href="#1-%E9%98%85%E8%AF%BB-man-ls%E5%B9%B6%E4%BD%BF%E7%94%A8-ls-%E5%91%BD%E4%BB%A4%E8%BF%9B%E8%A1%8C%E5%A6%82%E4%B8%8B%E6%93%8D%E4%BD%9C">1. 阅读 man ls，并使用 ls 命令进行如下操作：</a></li>
<li><a href="#2-%E7%BC%96%E5%86%99%E4%B8%A4%E4%B8%AAbash%E5%87%BD%E6%95%B0-marco-%E5%92%8C-polo-%E6%89%A7%E8%A1%8C%E4%B8%8B%E9%9D%A2%E7%9A%84%E6%93%8D%E4%BD%9C">2. 编写两个bash函数 <code>marco</code> 和 <code>polo</code> 执行下面的操作：</a></li>
<li><a href="#3%E5%81%87%E8%AE%BE%E6%82%A8%E6%9C%89%E4%B8%80%E4%B8%AA%E5%91%BD%E4%BB%A4%E5%AE%83%E5%BE%88%E5%B0%91%E5%87%BA%E9%94%99%E4%B8%BA%E4%BA%86%E5%9C%A8%E5%87%BA%E9%94%99%E6%97%B6%E8%83%BD%E5%A4%9F%E5%AF%B9%E5%85%B6%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95%E7%BC%96%E5%86%99%E4%B8%80%E6%AE%B5bash%E8%84%9A%E6%9C%AC">3.假设您有一个命令，它很少出错。为了在出错时能够对其进行调试，编写一段bash脚本：</a></li>
<li><a href="#4%E6%9C%AC%E8%8A%82%E8%AF%BE%E6%88%91%E4%BB%AC%E8%AE%B2%E8%A7%A3%E7%9A%84-find-%E5%91%BD%E4%BB%A4%E4%B8%AD%E7%9A%84--exec-%E5%8F%82%E6%95%B0%E9%9D%9E%E5%B8%B8%E5%BC%BA%E5%A4%A7%E5%AE%83%E5%8F%AF%E4%BB%A5%E5%AF%B9%E6%88%91%E4%BB%AC%E6%9F%A5%E6%89%BE%E7%9A%84%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E6%93%8D%E4%BD%9C%E6%82%A8%E7%9A%84%E4%BB%BB%E5%8A%A1%E6%98%AF">4.本节课我们讲解的 <code>find</code> 命令中的 <code>-exec</code> 参数非常强大，它可以对我们查找的文件进行操作。您的任务是：</a></li>
<li><a href="#5%E8%BF%9B%E9%98%B6%E7%BC%96%E5%86%99%E4%B8%80%E4%B8%AA%E5%91%BD%E4%BB%A4%E6%88%96%E8%84%9A%E6%9C%AC%E9%80%92%E5%BD%92%E7%9A%84%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E6%9C%80%E8%BF%91%E4%BD%BF%E7%94%A8%E7%9A%84%E6%96%87%E4%BB%B6">5.（进阶）编写一个命令或脚本递归的查找文件夹中最近使用的文件：</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li>
</ul>
<br>
<h2 id="shell脚本"><a class="markdownIt-Anchor" href="#shell脚本"></a> Shell脚本</h2>
<h3 id="变量-赋值-字符串"><a class="markdownIt-Anchor" href="#变量-赋值-字符串"></a> 变量、赋值、字符串</h3>
<p>bash中变量的<strong>赋值</strong>语法：<code>foo=bar</code><br />
<strong>访问</strong>变量中存储的数值：<code>&quot;$foo&quot;</code></p>
<p>单引号和双引号的区别如下：</p>
<ul>
<li><code>'</code>：表示原生字符</li>
<li><code>&quot;</code>：表示变量值</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">cd</span> /Users/chenyubin/Desktop/no_emo/github/MSofCS </span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % foo=bar</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$foo</span>&quot;</span></span><br><span class="line">bar</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">echo</span> <span class="string">&#x27;$foo&#x27;</span></span><br><span class="line"><span class="variable">$foo</span></span><br></pre></td></tr></table></figure>
<h3 id="函数"><a class="markdownIt-Anchor" href="#函数"></a> 函数</h3>
<p>bash会支持if，case，for等这些控制流关键字</p>
<p><code>mcd.sh</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">mcd</span></span> () &#123;</span><br><span class="line">    <span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$1</span>&quot;</span></span><br><span class="line">    <span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">touch</span> mcd.sh</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % vim mcd.sh</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">source</span> mcd.sh</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % mcd <span class="built_in">test</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro <span class="built_in">test</span> % </span><br></pre></td></tr></table></figure>
<p>bash使用了很多特殊的变量来表示参数、错误代码和相关变量:</p>
<ul>
<li><code>$0</code> - 脚本名</li>
<li><code>$1</code> 到 <code>$9</code> - 脚本的参数。<code>$1</code> 是第一个参数，依此类推。</li>
<li><code>$@</code> - 所有参数</li>
<li><code>$#</code> - 参数个数</li>
<li><code>$?</code> - 前一个命令的返回值</li>
<li><code>$$</code> - 当前脚本的进程识别码</li>
<li><code>!!</code> - 完整的上一条命令，包括参数。常见应用：当你因为权限不足执行命令失败时，可以使用 <code>sudo !!</code> 再尝试一次。</li>
<li><code>$_</code> - 上一条命令的最后一个参数。如果你正在使用的是交互式 shell，你可以通过按下 Esc 之后键入 <code>.</code> 来获取这个值。</li>
</ul>
<p>下面将用一个例子来展示这些指令的使用：<br />
<code>mcd.sh</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">mcd</span></span> () &#123;</span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出脚本名</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;脚本名是: <span class="subst">$(basename $0)</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否有至少一个参数传递给脚本</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;使用方法: <span class="subst">$(basename $0)</span> 目录名称&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建并切换到指定的目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$1</span>&quot;</span> &amp;&amp; <span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;已成功创建并切换到目录: <span class="variable">$1</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示所有传递给脚本的参数</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;所有参数: <span class="variable">$@</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示参数个数</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;参数个数: <span class="variable">$#</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示当前脚本的进程识别码</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;当前脚本的PID: $$&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以继续添加其他命令或逻辑...</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>指令信息如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">source</span> mcd.sh</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test2 % mcd test3</span><br><span class="line">脚本名是: mcd</span><br><span class="line">已成功创建并切换到目录: test3</span><br><span class="line">所有参数: test3</span><br><span class="line">参数个数: 1</span><br><span class="line">当前脚本的PID: 46932</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test3 % <span class="built_in">echo</span> $?</span><br><span class="line">0</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test3 % mcd test4</span><br><span class="line">脚本名是: mcd</span><br><span class="line">已成功创建并切换到目录: test4</span><br><span class="line">所有参数: test4</span><br><span class="line">参数个数: 1</span><br><span class="line">当前脚本的PID: 46932</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % <span class="built_in">echo</span> <span class="variable">$_</span></span><br><span class="line">test4</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % !!     </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$_</span></span><br><span class="line">test4</span><br></pre></td></tr></table></figure>
<h3 id="bool运算"><a class="markdownIt-Anchor" href="#bool运算"></a> bool运算</h3>
<ul>
<li><strong>返回值0表示正常执行，其他所有非0的返回值都表示有错误发生</strong>。</li>
<li>返回码可以搭配<code>&amp;&amp;</code>和<code>||</code>，用来进行条件判断。这两个操作符都具备<strong>short-circuiting</strong>属性：
<ul>
<li>使用<code>&amp;&amp;</code>时，如果左侧的命令成功执行（即返回值为0），则会继续执行右侧的命令；如果左侧的命令失败（返回值非0），则不执行右侧的命令。</li>
<li>使用<code>||</code>时，如果左侧的命令失败（返回值非0），则会执行右侧的命令；如果左侧的命令成功执行（返回值为0），则不执行右侧的命令。</li>
</ul>
</li>
<li>同一行中多个命令可以使用<code>;</code>分隔开来，允许在单一行内顺序执行多个命令，无论前一个命令执行成功与否。</li>
</ul>
<p>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % <span class="literal">false</span> || <span class="built_in">echo</span> <span class="string">&quot;Oops, fail&quot;</span></span><br><span class="line">Oops, fail</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % <span class="literal">true</span> || <span class="built_in">echo</span> <span class="string">&quot;Will not be printed&quot;</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % <span class="literal">true</span> &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;Things went well&quot;</span></span><br><span class="line">Things went well</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % <span class="literal">false</span> &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;Will not be printed&quot;</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro test4 % <span class="literal">false</span> ; <span class="built_in">echo</span> <span class="string">&quot;This will always run&quot;</span></span><br><span class="line">This will always run</span><br></pre></td></tr></table></figure>
<h3 id="命令替换command-substitution与进程替换process-substitution"><a class="markdownIt-Anchor" href="#命令替换command-substitution与进程替换process-substitution"></a> 命令替换（command substitution）与进程替换（process substitution）</h3>
<ul>
<li>命令替换<code>$()</code>：(做字符串)执行括号内的命令，并将标准输出替换到原位置。</li>
<li>进程替代<code>&lt;()</code>：(作临时文件)允许将命令的输出暂时当作文件来处理。感觉和上一个命令很像但是能把输出内容链接在一起</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">echo</span> <span class="string">&quot;We are in <span class="subst">$(pwd)</span>&quot;</span></span><br><span class="line">We are <span class="keyword">in</span> /Users/chenyubin/Desktop/no_emo/github/MSofCS</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">cat</span> &lt;(<span class="built_in">ls</span>) &lt;(<span class="built_in">ls</span> ..)</span><br><span class="line">mcd.sh</span><br><span class="line"><span class="built_in">test</span></span><br><span class="line">test1</span><br><span class="line">test2</span><br><span class="line">CS224N</span><br><span class="line">MSofCS</span><br><span class="line">Spike-Driven-Transformer</span><br><span class="line">SpikeBERT</span><br><span class="line">bert</span><br><span class="line">d2l</span><br><span class="line">data</span><br><span class="line">spike</span><br><span class="line">spikingjelly</span><br><span class="line">vit</span><br></pre></td></tr></table></figure>
<h3 id="通配符"><a class="markdownIt-Anchor" href="#通配符"></a> 通配符</h3>
<p>使用 <code>?</code> 和 <code>*</code> 来匹配一个或任意个字符</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> <span class="built_in">test</span>?</span><br><span class="line">test1:</span><br><span class="line"></span><br><span class="line">test2:</span><br><span class="line">test3</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> *.sh</span><br><span class="line">mcd.sh</span><br></pre></td></tr></table></figure>
<p>花括号<code>&#123;&#125;</code> - 当你有一系列的指令，其中包含一段公共子串时，可以用花括号来自动展开这些命令。这在批量移动或转换文件时非常方便。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro <span class="built_in">test</span> % <span class="built_in">mkdir</span> foo</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro <span class="built_in">test</span> % <span class="built_in">touch</span> foo/&#123;a..h&#125; </span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro <span class="built_in">test</span> % <span class="built_in">ls</span></span><br><span class="line">foo</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro <span class="built_in">test</span> % tree -L 2</span><br><span class="line">.</span><br><span class="line">└── foo</span><br><span class="line">    ├── a</span><br><span class="line">    ├── b</span><br><span class="line">    ├── c</span><br><span class="line">    ├── d</span><br><span class="line">    ├── e</span><br><span class="line">    ├── f</span><br><span class="line">    ├── g</span><br><span class="line">    └── h</span><br><span class="line"></span><br><span class="line">2 directories, 8 files</span><br></pre></td></tr></table></figure>
<h3 id="shell函数与脚本"><a class="markdownIt-Anchor" href="#shell函数与脚本"></a> shell函数与脚本</h3>
<table>
<thead>
<tr>
<th>特性</th>
<th>函数</th>
<th>脚本</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>使用的语言</strong></td>
<td>只能与shell使用相同的语言</td>
<td>可以使用任意语言，包含 shebang (<code>#!</code>) 很重要</td>
</tr>
<tr>
<td><strong>加载时机</strong></td>
<td>仅在定义时被加载，更改定义后需重新加载</td>
<td>每次执行时加载</td>
</tr>
<tr>
<td><strong>执行环境</strong></td>
<td>在当前的shell环境中执行，可以直接更改环境变量</td>
<td>在单独的进程中执行，需使用 <code>export</code> 导出环境变量以影响当前环境</td>
</tr>
<tr>
<td><strong>对环境的影响</strong></td>
<td>可以对环境变量进行更改，例如改变当前工作目录</td>
<td>通常不直接更改调用它的shell的环境，除非使用特定方法（如 <code>export</code>）</td>
</tr>
<tr>
<td><strong>代码模块性和复用</strong></td>
<td>可以提高代码模块性、代码复用性并创建清晰的结构，与其他编程语言的函数类似</td>
<td>虽然脚本是独立的程序，但往往也会包含它们自己的函数定义以提高代码模块性和复用</td>
</tr>
</tbody>
</table>
<br>
<h2 id="shell工具"><a class="markdownIt-Anchor" href="#shell工具"></a> Shell工具</h2>
<h3 id="查看命令如何使用"><a class="markdownIt-Anchor" href="#查看命令如何使用"></a> 查看命令如何使用</h3>
<ul>
<li>为对应的命令行添加<code>-h</code> 或 <code>--help</code> 标记。</li>
<li>使用<code>man</code> 命令。<code>man</code> 命令是手册（manual）的缩写，它提供了命令的用户手册。</li>
<li><a href="https://tldr.sh/"><code>tldr</code></a></li>
</ul>
<h3 id="查找文件-find"><a class="markdownIt-Anchor" href="#查找文件-find"></a> 查找文件-find</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查找所有名称为src的文件夹</span></span><br><span class="line">find . -name src -<span class="built_in">type</span> d</span><br><span class="line"><span class="comment"># 查找所有文件夹路径中包含test的python文件</span></span><br><span class="line">find . -path <span class="string">&#x27;*/test/*.py&#x27;</span> -<span class="built_in">type</span> f</span><br><span class="line"><span class="comment"># 查找前一天修改的所有文件</span></span><br><span class="line">find . -mtime -1</span><br><span class="line"><span class="comment"># 查找所有大小在500k至10M的tar.gz文件</span></span><br><span class="line">find . -size +500k -size -10M -name <span class="string">&#x27;*.tar.gz&#x27;</span></span><br></pre></td></tr></table></figure>
<p>不仅仅是进行查找还能进行操作：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除全部扩展名为.tmp 的文件</span></span><br><span class="line">find . -name <span class="string">&#x27;*.tmp&#x27;</span> -<span class="built_in">exec</span> <span class="built_in">rm</span> &#123;&#125; \;</span><br><span class="line"><span class="comment"># 查找全部的 PNG 文件并将其转换为 JPG</span></span><br><span class="line">find . -name <span class="string">&#x27;*.png&#x27;</span> -<span class="built_in">exec</span> convert &#123;&#125; &#123;&#125;.jpg \;</span><br></pre></td></tr></table></figure>
<p>更高效的工具：</p>
<ul>
<li><code>fd</code>：find的替代品</li>
<li><code>locate</code> ： 通过编译索引或建立数据库的方式来实现更加快速地搜索（不会用先不管了T.T）</li>
</ul>
<h3 id="查找代码-grep"><a class="markdownIt-Anchor" href="#查找代码-grep"></a> 查找代码-grep</h3>
<p>查看文件内容时，<code>grep</code> 命令是一个非常强大的工具，用于对输入文本进行模式匹配。下面是<code>grep</code>命令经常使用的一些选项：</p>
<ul>
<li>
<p><code>-C [num]</code>：获取查找结果的上下文（Context），即除了匹配行外，还显示匹配行前后的内容。[num] 指定上下文的行数。</p>
</li>
<li>
<p><code>-v</code>：将对结果进行反选（Invert），也就是输出不匹配的结果。</p>
</li>
<li>
<p><code>-R</code>：递归搜索子目录，对指定目录下的所有文件以及子目录中的文件执行搜索操作。</p>
</li>
</ul>
<p>示例：使用 grep 命令来搜索文件 <a href="http://mcd.sh">mcd.sh</a> 中包含字符串 “mcd” 的行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % grep mcd mcd.sh</span><br><span class="line"><span class="function"><span class="title">mcd</span></span> () &#123;</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % grep -r mcd .</span><br><span class="line">./mcd.sh:<span class="function"><span class="title">mcd</span></span> () &#123;</span><br></pre></td></tr></table></figure>
<p>更高效的工具：</p>
<ul>
<li><code>rg</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % rg foobar mcd.sh</span><br><span class="line"></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % rg mcd mcd.sh</span><br><span class="line">1:<span class="function"><span class="title">mcd</span></span> () &#123;</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % rg $ mcd.sh</span><br><span class="line">1:<span class="function"><span class="title">mcd</span></span> () &#123;</span><br><span class="line">2:<span class="comment">#!/bin/bash</span></span><br><span class="line">3:</span><br><span class="line">4:<span class="comment"># 输出脚本名</span></span><br><span class="line">5:<span class="built_in">echo</span> <span class="string">&quot;脚本名是: <span class="subst">$(basename $0)</span>&quot;</span></span><br><span class="line">6:</span><br><span class="line">7:<span class="comment"># 检查是否有至少一个参数传递给脚本</span></span><br><span class="line">8:<span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]; <span class="keyword">then</span></span><br><span class="line">9:    <span class="built_in">echo</span> <span class="string">&quot;使用方法: <span class="subst">$(basename $0)</span> 目录名称&quot;</span></span><br><span class="line">10:    <span class="built_in">exit</span> 1</span><br><span class="line">11:<span class="keyword">fi</span></span><br><span class="line">12:</span><br><span class="line">13:<span class="comment"># 创建并切换到指定的目录</span></span><br><span class="line">14:<span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$1</span>&quot;</span> &amp;&amp; <span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span></span><br><span class="line">15:<span class="built_in">echo</span> <span class="string">&quot;已成功创建并切换到目录: <span class="variable">$1</span>&quot;</span></span><br><span class="line">16:</span><br><span class="line">17:<span class="comment"># 显示所有传递给脚本的参数</span></span><br><span class="line">18:<span class="built_in">echo</span> <span class="string">&quot;所有参数: <span class="variable">$@</span>&quot;</span></span><br><span class="line">19:</span><br><span class="line">20:<span class="comment"># 显示参数个数</span></span><br><span class="line">21:<span class="built_in">echo</span> <span class="string">&quot;参数个数: <span class="variable">$#</span>&quot;</span></span><br><span class="line">22:</span><br><span class="line">23:<span class="comment"># 显示当前脚本的进程识别码</span></span><br><span class="line">24:<span class="built_in">echo</span> <span class="string">&quot;当前脚本的PID: $$&quot;</span></span><br><span class="line">25:</span><br><span class="line">26:<span class="comment"># 可以继续添加其他命令或逻辑...</span></span><br><span class="line">27:</span><br><span class="line">28:&#125;</span><br></pre></td></tr></table></figure>
<h3 id="查找shell命令"><a class="markdownIt-Anchor" href="#查找shell命令"></a> 查找Shell命令</h3>
<p>在使用Shell时，有多种方式可以帮助您快速找到并重新使用之前输入过的命令：</p>
<ul>
<li>
<p><strong>使用方向键</strong>：按向上的方向键会显示你使用过的上一条命令。如果继续按上键，则会遍历整个历史记录，这允许您快速找到并重新执行之前的命令。</p>
</li>
<li>
<p><strong><code>history</code> 命令</strong>：<code>history</code> 命令允许您以程序员的方式来访问Shell中输入的历史命令。</p>
</li>
<li>
<p><strong>使用 <code>Ctrl+R</code> 进行回溯搜索</strong>：在Shell中，您可以通过按下 <code>Ctrl+R</code> 开始对命令历史记录进行回溯搜索。输入您记得的命令的一部分，Shell会自动查找匹配的命令。反复按下 <code>Ctrl+R</code> 就会在所有搜索结果中循环，直到找到您需要的命令。</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Last login: Thu Mar  7 13:36:19 on ttys000</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro ~ % <span class="built_in">history</span></span><br><span class="line">  985  find . -path <span class="string">&#x27;*/test/*.sh&#x27;</span> -<span class="built_in">type</span> f</span><br><span class="line">  986  <span class="built_in">cd</span> <span class="built_in">test</span></span><br><span class="line">  987  find . -path <span class="string">&#x27;*/test/*.sh&#x27;</span> -<span class="built_in">type</span> f</span><br><span class="line">  988  <span class="built_in">cd</span> ..</span><br><span class="line">  989  locate MSofCS</span><br><span class="line">  990  sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.locate.plist</span><br><span class="line">  991  locate MSofCS</span><br><span class="line">  992  updatedb</span><br><span class="line">  993  locate /etc/sh</span><br><span class="line">  994  sudo launchctl load -w /System/Library/LaunchDaemons/com.apple.locate.plist</span><br><span class="line">  995  rg -t py <span class="string">&#x27;import requests&#x27;</span></span><br><span class="line">  996  brew install tldr</span><br><span class="line">  997  brew install ripgrep</span><br><span class="line">  998  grep foobar mcd.sh</span><br><span class="line">  999  grep mcd mcd.sh</span><br><span class="line"> 1000  grep -r mcd .</span><br></pre></td></tr></table></figure>
<h3 id="文件夹导航"><a class="markdownIt-Anchor" href="#文件夹导航"></a> 文件夹导航</h3>
<ul>
<li>
<p><strong><code>ls -R</code></strong>：</p>
</li>
<li>
<p><strong><code>tree</code></strong>：</p>
</li>
<li>
<p><strong><code>broot</code></strong>：</p>
</li>
<li>
<p><strong><code>nnn</code></strong>：</p>
</li>
</ul>
<h2 id="作业"><a class="markdownIt-Anchor" href="#作业"></a> 作业</h2>
<h3 id="1-阅读-man-ls并使用-ls-命令进行如下操作"><a class="markdownIt-Anchor" href="#1-阅读-man-ls并使用-ls-命令进行如下操作"></a> 1. 阅读 man ls，并使用 ls 命令进行如下操作：</h3>
<ul>
<li><strong>显示所有文件（包括隐藏文件）</strong></li>
<li><strong>文件打印以人类可以理解的格式输出</strong> （例如，使用454M 而不是 454279954）</li>
<li><strong>文件以最近访问顺序排序</strong></li>
<li><strong>以彩色文本显示输出结果</strong></li>
</ul>
<p>典型输出示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-rw-r--r--   1 user group 1.1M Jan 14 09:53 baz</span><br><span class="line">drwxr-xr-x   5 user group  160 Jan 14 09:53 .</span><br><span class="line">-rw-r--r--   1 user group  514 Jan 14 06:42 bar</span><br><span class="line">-rw-r--r--   1 user group 106M Jan 13 12:12 foo</span><br><span class="line">drwx------+ 47 user group 1.5K Jan 12 18:08 ..</span><br></pre></td></tr></table></figure>
<hr />
<p>解：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls [-alrtAFR] [name...]</span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>-a</code></strong> 显示所有文件及目录 (. 开头的隐藏文件也会列出)</li>
<li><strong><code>-d</code></strong> 只列出目录（不递归列出目录内的文件）</li>
<li><strong><code>-l</code></strong> 以长格式显示文件和目录信息，包括权限、所有者、大小、创建时间等</li>
<li><strong><code>-r</code></strong> 倒序显示文件和目录</li>
<li><strong><code>-t</code></strong> 将按照修改时间排序，最新的文件在最前面</li>
<li><strong><code>-A</code></strong> 同 <code>-a</code>，但不列出 “.” (当前目录) 及 “…” (父目录)</li>
<li><strong><code>-F</code></strong> 在列出的文件名称后加一符号；例如可执行档则加 “*”, 目录则加 “/”</li>
<li><strong><code>-R</code></strong> 递归显示目录中的所有文件和子目录</li>
</ul>
<p>具体实例如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -a</span><br><span class="line">.		.DS_Store	<span class="built_in">test</span>		test2</span><br><span class="line">..		mcd.sh		test1</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -d</span><br><span class="line">.</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -l</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r--@ 1 chenyubin  staff  553  3  7 11:56 mcd.sh</span><br><span class="line">drwxr-xr-x  3 chenyubin  staff   96  3  7 11:44 <span class="built_in">test</span></span><br><span class="line">drwxr-xr-x  2 chenyubin  staff   64  3  7 11:59 test1</span><br><span class="line">drwxr-xr-x  4 chenyubin  staff  128  3  7 12:00 test2</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -r</span><br><span class="line">test2	test1	<span class="built_in">test</span>	mcd.sh</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -t</span><br><span class="line">test2	test1	mcd.sh	<span class="built_in">test</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -A</span><br><span class="line">.DS_Store	mcd.sh		<span class="built_in">test</span>		test1		test2</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -F</span><br><span class="line">mcd.sh	<span class="built_in">test</span>/	test1/	test2/</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">ls</span> -R</span><br><span class="line">mcd.sh	<span class="built_in">test</span>	test1	test2</span><br><span class="line"></span><br><span class="line">./test:</span><br><span class="line">foo</span><br><span class="line"></span><br><span class="line">./test/foo:</span><br><span class="line">a	b	c	d	e	f	g	h</span><br><span class="line"></span><br><span class="line">./test1:</span><br><span class="line"></span><br><span class="line">./test2:</span><br><span class="line">test3</span><br><span class="line"></span><br><span class="line">./test2/test3:</span><br><span class="line">test4</span><br><span class="line"></span><br><span class="line">./test2/test3/test4:</span><br></pre></td></tr></table></figure>
<br>
<p><strong>1.1 显示所有文件（包括隐藏文件）:</strong> <code>ls- a</code><br />
<strong>1.2 文件打印以人类可以理解的格式输出:</strong> <code>ls -h</code><br />
<strong>1.3 文件以最近访问顺序排序:</strong> <code>ls-t</code><br />
<strong>1.4 以彩色文本显示输出结果</strong></p>
<h3 id="2-编写两个bash函数-marco-和-polo-执行下面的操作"><a class="markdownIt-Anchor" href="#2-编写两个bash函数-marco-和-polo-执行下面的操作"></a> 2. 编写两个bash函数 <code>marco</code> 和 <code>polo</code> 执行下面的操作：</h3>
<ul>
<li><strong>每当你执行 <code>marco</code> 时，当前的工作目录应当以某种形式保存</strong></li>
<li><strong>当执行 <code>polo</code> 时，无论现在处在什么目录下，都应当 <code>cd</code> 回到当时执行 <code>marco</code> 的目录</strong></li>
<li><strong>为了方便debug，你可以把代码写在单独的文件 <code>marco.sh</code> 中，并通过 <code>source marco.sh</code> 命令，（重新）加载函数</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env/ bash</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">macro</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">export</span> MACRO=$(<span class="built_in">pwd</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">polo</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">cd</span> <span class="string">&quot;<span class="variable">$MACRO</span>&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3假设您有一个命令它很少出错-为了在出错时能够对其进行调试编写一段bash脚本"><a class="markdownIt-Anchor" href="#3假设您有一个命令它很少出错-为了在出错时能够对其进行调试编写一段bash脚本"></a> 3.假设您有一个命令，它很少出错。为了在出错时能够对其进行调试，编写一段bash脚本：</h3>
<ul>
<li><strong>运行如下的脚本直到它出错，将它的标准输出和标准错误流记录到文件</strong></li>
<li><strong>加分项：报告脚本在失败前共运行了多少次</strong></li>
</ul>
<p>脚本示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash #使用bash来解释脚本</span></span><br><span class="line"></span><br><span class="line">n=$(( RANDOM % <span class="number">100</span> ))<span class="comment">#生成0~99的数字</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ n -eq 42 ]]; <span class="keyword">then</span>  <span class="comment">#检查n是否等于42，如果等于则执行下面的代码</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;Something went wrong&quot;</span> <span class="comment">#输出到标准输出</span></span><br><span class="line">   &gt;&amp;2 <span class="built_in">echo</span> <span class="string">&quot;The error was using magic numbers&quot;</span> <span class="comment">#输出到标准错误</span></span><br><span class="line">   <span class="built_in">exit</span> 1  <span class="comment">#n=42，以状态1推出</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Everything went according to plan&quot;</span> <span class="comment">#n不等于42就输出这段代码到标准输出</span></span><br></pre></td></tr></table></figure>
<p>解：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"> count=0</span><br><span class="line"> <span class="built_in">echo</span> &gt; out.log <span class="comment">#清空或创建log文件用来记录</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line"> <span class="keyword">do</span></span><br><span class="line">     ./buggy.sh &amp;&gt;&gt; out.log <span class="comment">#执行上面的文件，然后将标准输出和标准错误都写道out.log中</span></span><br><span class="line">     <span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span> <span class="comment">#执行程序返回的状态=0代表执行成功</span></span><br><span class="line">         <span class="built_in">cat</span> out.log <span class="comment">#打印out.log的内容到标准输出</span></span><br><span class="line">         <span class="built_in">echo</span> <span class="string">&quot;failed after <span class="variable">$count</span> times&quot;</span> <span class="comment">#告诉用户失败之前执行了多少次</span></span><br><span class="line">         <span class="built_in">break</span></span><br><span class="line">     <span class="keyword">fi</span></span><br><span class="line">     ((count++))</span><br><span class="line"></span><br><span class="line"> <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h3 id="4本节课我们讲解的-find-命令中的-exec-参数非常强大它可以对我们查找的文件进行操作-您的任务是"><a class="markdownIt-Anchor" href="#4本节课我们讲解的-find-命令中的-exec-参数非常强大它可以对我们查找的文件进行操作-您的任务是"></a> 4.本节课我们讲解的 <code>find</code> 命令中的 <code>-exec</code> 参数非常强大，它可以对我们查找的文件进行操作。您的任务是：</h3>
<ul>
<li><strong>编写一个命令，它可以递归地查找文件夹中所有的HTML文件，并将它们压缩成zip文件</strong></li>
<li><strong>注意，即使文件名中包含空格，您的命令也应该能够正确执行</strong></li>
</ul>
<p>提示：对于 MacOS 用户，使用 <code>find</code> 的 <code>-print0</code> 选项，并为 <code>xargs</code> 添加 <code>-0</code> 选项以正确处理文件名中的空格。</p>
<p>解：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">mkdir</span> html_root</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % <span class="built_in">cd</span> <span class="variable">$_</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % <span class="built_in">touch</span> &#123;1..10&#125;.html</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % <span class="built_in">ls</span> -a</span><br><span class="line">.	1.html	2.html	4.html	6.html	8.html</span><br><span class="line">..	10.html	3.html	5.html	7.html	9.html</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % <span class="built_in">mkdir</span> html</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % <span class="built_in">cd</span> <span class="variable">$_</span></span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html % <span class="built_in">touch</span> xxx.html</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html % <span class="built_in">cd</span> ..</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % <span class="built_in">ls</span> -a</span><br><span class="line">.	1.html	2.html	4.html	6.html	8.html	html</span><br><span class="line">..	10.html	3.html	5.html	7.html	9.html</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % tree -L 2</span><br><span class="line">.</span><br><span class="line">├── 1.html</span><br><span class="line">├── 10.html</span><br><span class="line">├── 2.html</span><br><span class="line">├── 3.html</span><br><span class="line">├── 4.html</span><br><span class="line">├── 5.html</span><br><span class="line">├── 6.html</span><br><span class="line">├── 7.html</span><br><span class="line">├── 8.html</span><br><span class="line">├── 9.html</span><br><span class="line">└── html</span><br><span class="line">    └── xxx.html</span><br><span class="line"></span><br><span class="line">2 directories, 11 files</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % find html_root -name <span class="string">&quot;*.html&quot;</span> -print0 | xargs -0 tar vcf html.zip</span><br><span class="line">find: html_root: No such file or directory</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro html_root % <span class="built_in">cd</span> ..</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % find html_root -name <span class="string">&quot;*.html&quot;</span> -print0 | xargs -0 tar vcf html.zip</span><br><span class="line"></span><br><span class="line">a html_root/9.html</span><br><span class="line">a html_root/5.html</span><br><span class="line">a html_root/4.html</span><br><span class="line">a html_root/8.html</span><br><span class="line">a html_root/3.html</span><br><span class="line">a html_root/html/xxx.html</span><br><span class="line">a html_root/2.html</span><br><span class="line">a html_root/1.html</span><br><span class="line">a html_root/10.html</span><br><span class="line">a html_root/7.html</span><br><span class="line">a html_root/6.html</span><br><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % tree -L 2</span><br><span class="line">.</span><br><span class="line">├── html.zip</span><br><span class="line">├── html_root</span><br><span class="line">│   ├── 1.html</span><br><span class="line">│   ├── 10.html</span><br><span class="line">│   ├── 2.html</span><br><span class="line">│   ├── 3.html</span><br><span class="line">│   ├── 4.html</span><br><span class="line">│   ├── 5.html</span><br><span class="line">│   ├── 6.html</span><br><span class="line">│   ├── 7.html</span><br><span class="line">│   ├── 8.html</span><br><span class="line">│   ├── 9.html</span><br><span class="line">│   └── html</span><br><span class="line">├── macro.sh</span><br><span class="line">├── mcd.sh</span><br><span class="line">├── <span class="built_in">test</span></span><br><span class="line">│   └── foo</span><br><span class="line">├── test1</span><br><span class="line">└── test2</span><br><span class="line">    └── test3</span><br><span class="line"></span><br><span class="line">8 directories, 13 files</span><br></pre></td></tr></table></figure>
<h3 id="5进阶编写一个命令或脚本递归的查找文件夹中最近使用的文件"><a class="markdownIt-Anchor" href="#5进阶编写一个命令或脚本递归的查找文件夹中最近使用的文件"></a> 5.（进阶）编写一个命令或脚本递归的查找文件夹中最近使用的文件：</h3>
<ul>
<li><strong>更通用的做法，你可以按照最近的使用时间列出文件吗？</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(base) chenyubin@chenyubindeMacBook-Pro MSofCS % find . -<span class="built_in">type</span> f -mmin -60 -print0 | xargs -0 <span class="built_in">ls</span> -lt | <span class="built_in">head</span> -10</span><br><span class="line">-rw-r--r--  1 chenyubin  staff  6656  3  9 16:10 ./html.zip</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:07 ./html_root/html/xxx.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/10.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/9.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/8.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/7.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/6.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/5.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/4.html</span><br><span class="line">-rw-r--r--  1 chenyubin  staff     0  3  9 16:06 ./html_root/3.html</span><br></pre></td></tr></table></figure>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://missing-semester-cn.github.io/2020/shell-tools/">Shell 工具和脚本</a></li>
<li><a href="https://www.cnblogs.com/klb561/p/9241228.html">Linux系统stat指令用法</a></li>
<li><a href="https://www.linuxcool.com/lgxzhgjcml">Linux高效转换工具：convert命令</a></li>
<li><a href="https://tldr.sh/">tldr pages</a></li>
<li><a href="https://www.cnblogs.com/cxl-/p/15314329.html">missing semester - Shell Tools and Scripting </a></li>
<li><a href="https://www.bilibili.com/video/BV1xa4y1g7sZ/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">[自制双语字幕] 计算机教育缺失的一课(2020) - 第2讲 - Shell 工具和脚本</a></li>
</ul>
]]></content>
      <categories>
        <category>project</category>
        <category>Missing Semester of CS</category>
      </categories>
      <tags>
        <tag>project</tag>
        <tag>Missing Semester</tag>
        <tag>Shell</tag>
        <tag>Script</tag>
        <tag>2</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch VS TensorFlow</title>
    <url>/2023/12/24/PyTorch-VS-TensorFlow/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://viso.ai/deep-learning/pytorch-vs-tensorflow/">https://viso.ai/deep-learning/pytorch-vs-tensorflow/</a></li>
</ul>
<h1 id="pytorch-vs-tensorflow"><a class="markdownIt-Anchor" href="#pytorch-vs-tensorflow"></a> PyTorch VS TensorFlow</h1>
<h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2>
<p>人工神经网络（ANNs）在多种监督学习任务中展现出卓越性能，但手动编程ANN具有挑战性。因此，出现了像TensorFlow和PyTorch这样的框架，旨在简化深度学习模型的创建、服务和扩展。随着近年来对深度学习的兴趣增加，出现了大量的机器学习工具。这些框架提供了神经网络单元、成本函数和优化器，用于组装和训练神经网络模型。在分析大型复杂数据集时，使用人工神经网络进行推断和预测是一种重要方法。TensorFlow和PyTorch是两个广泛使用的支持人工神经网络模型的机器学习框架。</p>
<p><img src="https://viso.ai/wp-content/uploads/2023/02/pytorch-vs-tensorflow-popularity-comparison.png" alt="" /></p>
<br>
<h2 id="文章内容"><a class="markdownIt-Anchor" href="#文章内容"></a> 文章内容</h2>
<p>文章基于最近的研究比较了PyTorch和TensorFlow两个框架在训练时间、内存使用和易用性方面的有效性和差异。你将了解到：</p>
<ul>
<li>PyTorch与TensorFlow的特点</li>
<li>性能、准确性、训练以及易用性的对比</li>
<li>两者的主要区别</li>
<li>一个完整的比较表</li>
</ul>
<br>
<h1 id="tensorflow-和-pytorch-的关键特性"><a class="markdownIt-Anchor" href="#tensorflow-和-pytorch-的关键特性"></a> TensorFlow 和 PyTorch 的关键特性</h1>
<h3 id="tensorflow-概述"><a class="markdownIt-Anchor" href="#tensorflow-概述"></a> TensorFlow 概述</h3>
<p>TensorFlow是一个广受欢迎的端到端开源机器学习平台，最初由谷歌大脑团队的研究人员和工程师开发。它支持多种执行平台如CPU、GPU、TPU和移动设备。TensorFlow被多个国际公司和大学采用，提供高层次API Keras以及为边缘设备设计的TensorFlow Lite。此外，TensorFlow Serving支持在生产环境中部署机器学习模型，而Viso Suite平台则为TensorFlow模型提供端到端的自动化服务。</p>
<br>
<h3 id="tensorflow优点"><a class="markdownIt-Anchor" href="#tensorflow优点"></a> TensorFlow优点</h3>
<ul>
<li>支持和库管理:TensorFlow由谷歌支持，并经常发布新功能。它在生产环境中被广泛使用。</li>
<li>开源:TensorFlow是一个非常流行的开源平台，广泛的用户都可以使用。</li>
<li>数据可视化:TensorFlow提供了一个名为TensorBoard的工具来图形化地可视化数据。它还允许轻松调试节点，减少查看整个代码的工作量，并有效地解决神经网络问题。- - Keras兼容性:TensorFlow与Keras兼容，这允许其用户编写一些高级功能部分，并向TensorFlow提供系统特定的功能(管道，估计器等)。</li>
<li>可扩展性强:TensorFlow部署在每台机器上的特点允许其用户开发任何类型的系统。</li>
<li>兼容性:TensorFlow与许多语言兼容，如c++、JavaScript、Python、c#、Ruby和Swift。这允许用户在他们感到舒适的环境中工作。</li>
<li>架构支持:由于工作模型的并行性，TensorFlow被用作硬件加速库。它在GPU和CPU系统中使用不同的分布策略。TensorFlow也有它的架构TPU，它的计算速度比GPU和CPU快。因此，使用TPU构建的模型可以很容易地以更便宜的速度部署在云上，并以更快的速度执行。然而，TensorFlow的架构TPU只允许执行模型，而不允许训练模型。</li>
</ul>
<br>
<h3 id="tensorflow缺点"><a class="markdownIt-Anchor" href="#tensorflow缺点"></a> TensorFlow缺点</h3>
<ul>
<li>基准测试:与竞争对手相比，计算速度是TensorFlow落后的地方。与其他框架相比，它的可用性较差。</li>
<li>依赖:尽管TensorFlow减少了代码的长度，使用户更容易访问它，但它增加了使用的复杂性。每一段代码都需要使用任何平台来执行，这增加了执行的依赖性。</li>
<li>符号循环:TensorFlow在为不定序列提供符号循环方面滞后。它可以用于确定的序列，这使它成为一个可用的系统。因此，它被称为低级API。</li>
<li>GPU支持:最初，TensorFlow只有NVIDIA支持GPU, Python支持GPU编程，这是一个缺点，因为在深度学习中有其他语言的增加。TensorFlow分布策略是一种TensorFlow API，用于在多个gpu、多台机器或tpu上分布训练。使用此API，您可以使用最小的代码更改来分发现有模型和训练代码。</li>
</ul>
<br>
<h3 id="pytorch-概述"><a class="markdownIt-Anchor" href="#pytorch-概述"></a> PyTorch 概述</h3>
<p>PyTorch于2016年首次引入，强调可用性和性能。它提供了一种命令式的python编程风格，支持代码作为模型，使调试变得容易，并且与其他流行的科学计算库保持一致，同时保持高效并支持硬件加速器(如gpu)。开源深度学习框架是一个Python库，可立即执行动态张量计算，并具有自动微分和GPU加速功能，同时保持与当前最快的深度学习库相当的性能。今天，它的大部分核心是用c++编写的，这是PyTorch与其他框架相比可以实现更低开销的主要原因之一。PyTorch 2.0标志着PyTorch框架的一个重大进步，在保持向后兼容性和以python为中心的方法的同时提供了增强的性能。对于移动部署，PyTorch提供了从Python到iOS和Android平台的实验性端到端工作流支持，包括用于移动ML集成和预处理任务的API扩展。PyTorch适合于自然语言处理(NLP)任务，以使用深度学习为智能语言应用提供支持。</p>
<p>此外，PyTorch为ONNX(开放神经网络交换)格式提供原生支持，允许无缝模型导出并与ONNX兼容的平台和工具兼容。多个流行的深度学习软件和面向研究的项目都是基于PyTorch构建的，包括Tesla Autopilot或Uber的Pyro。</p>
<br>
<h3 id="pytorch优势"><a class="markdownIt-Anchor" href="#pytorch优势"></a> PyTorch优势</h3>
<ul>
<li>PyTorch基于Python: PyTorch以Python为中心或“Python风格”，旨在与Python代码深度集成，而不是作为用其他语言编写的库的接口。Python是数据科学家最常用的语言之一，也是构建机器学习模型和ML研究最常用的语言之一。</li>
<li>更容易学习:因为它的语法类似于传统的编程语言，如Python, PyTorch比其他深度学习框架更容易学习。</li>
<li>调试:PyTorch可以使用许多广泛可用的Python调试工具之一进行调试(例如，Python的pdb和ipdb工具)。</li>
<li>动态计算图:PyTorch支持动态计算图，这意味着网络行为可以在运行时以编程方式更改。这使得优化模型更加容易，并使PyTorch比其他将神经网络视为静态对象的机器学习框架具有主要优势。</li>
<li>数据并行:数据并行特性允许PyTorch在多个CPU或GPU核心之间分配计算工作。虽然这种并行性可以在其他机器学习工具中完成，但在PyTorch中要容易得多。</li>
<li>社区:PyTorch有一个非常活跃的社区和论坛(<a href="http://discuss.pytorch.org">discuss.pytorch.org</a>)。它的文档(<a href="http://pytorch.org">pytorch.org</a>)非常有条理，对初学者很有帮助;它与PyTorch发布保持同步，并提供一组教程。PyTorch使用起来非常简单，这也意味着开发人员的学习曲线相对较短。</li>
<li>分布式训练:PyTorch为集体操作的异步执行和端到端通信提供原生支持，可从Python和c++访问。</li>
</ul>
<br>
<h3 id="pytorch的缺点"><a class="markdownIt-Anchor" href="#pytorch的缺点"></a> PyTorch的缺点:</h3>
<ul>
<li>缺乏在生产中服务的模型:虽然这在未来将会改变，但其他框架已经被更广泛地用于实际生产工作(即使PyTorch在研究社区中变得越来越流行)。因此，与其他框架相比，文档和开发者社区更小。</li>
<li>有限的监控和可视化界面:虽然TensorFlow也提供了一个强大的可视化工具来构建模型图(TensorBoard)，但PyTorch还没有这样的东西。因此，开发人员可以使用许多现有的Python数据可视化工具之一，或外部连接到TensorBoard。</li>
<li>没有TensorFlow那么广泛:PyTorch不是一个端到端的机器学习开发工具;实际应用程序的开发需要将PyTorch代码转换为另一个框架，如Caffe2，以便将应用程序部署到服务器、工作站和移动设备上。</li>
</ul>
<br>
<h2 id="tensorflow与pytorch的比较"><a class="markdownIt-Anchor" href="#tensorflow与pytorch的比较"></a> TensorFlow与PyTorch的比较</h2>
<h3 id="性能比较"><a class="markdownIt-Anchor" href="#性能比较"></a> 性能比较</h3>
<p>下面的性能基准测试旨在通过将PyTorch与流行的基于图的深度学习框架TensorFlow进行比较，来展示PyTorch的单机热切模式性能的整体比较。表中显示了使用32位浮点数的两个模型的训练速度。对于AlexNet、VGG-19、ResNet-50和MobileNet模型，吞吐率以每秒图像数为单位，对于GNMTv2模型，以每秒令牌数为单位，对于NCF模型，以每秒样本数为单位。基准测试表明，与TensorFlow相比，PyTorch的性能更好，这可以归因于这些工具将大部分计算卸载给了相同版本的cuDNN和cuBLAS库。</p>
<p><img src="https://viso.ai/wp-content/uploads/2021/03/performance-benchmark-pytorch-vs-tensorflow-02.jpg" alt="" /></p>
<br>
<h3 id="精度"><a class="markdownIt-Anchor" href="#精度"></a> 精度</h3>
<p>PyTorch和Tensorflow的精度图(见下文)显示了两个框架的精度有多相似。对于这两个模型，随着模型开始记忆它们正在训练的信息，训练精度不断提高。验证精度表示模型在训练过程中实际学习的程度。对于这两个模型，经过20个epoch后，两个框架中的模型的验证精度平均约为78%。因此，两个框架都能够准确地实现神经网络，并能够在给定相同的模型和数据集进行训练的情况下产生相同的结果。<br />
<img src="https://viso.ai/wp-content/uploads/2021/03/pytorch-vs-tensorflow-accuracy.jpg" alt="" /></p>
<br>
<h3 id="训练时间和内存使用"><a class="markdownIt-Anchor" href="#训练时间和内存使用"></a> 训练时间和内存使用</h3>
<p>上图显示了TensorFlow和PyTorch的训练时间。这表明TensorFlow的训练时间明显更高(TensorFlow的平均训练时间为11.19秒，而PyTorch的平均训练时间为7.67秒)。虽然在谷歌协作实验室中，模型训练时间的持续时间每天都有很大变化，但TensorFlow和PyTorch之间的相对持续时间保持一致。TensorFlow训练期间的内存使用率(1.7 GB RAM)明显低于PyTorch的内存使用率(3.5 GB RAM)。然而，两个模型在训练期间的内存使用情况略有差异，并且在初始加载数据期间的内存使用较高:TensorFlow为4.8 GB, PyTorch为5 GB。</p>
<br>
<h3 id="易用性"><a class="markdownIt-Anchor" href="#易用性"></a> 易用性</h3>
<p>PyTorch更面向对象的风格使实现模型更耗时。此外，与TensorFlow相比，PyTorch的数据处理规范更直接。另一方面，由于神经网络结构的底层实现，TensorFlow的学习曲线略陡峭。因此，它的低级方法允许更自定义的方法来形成神经网络，允许更专门的特征。此外，非常高级的Keras库运行在TensorFlow之上。因此，作为一个教学工具，非常高级的Keras库可以用于教授基本概念，然后可以通过布局更多的结构来使用TensorFlow来进一步理解概念。</p>
<br>
<h2 id="pytorch与tensorflow的区别总结"><a class="markdownIt-Anchor" href="#pytorch与tensorflow的区别总结"></a> PyTorch与TensorFlow的区别——总结</h2>
<p>对于“PyTorch和TensorFlow，哪个更好?”取决于用例和应用，但有几个重要的方面需要考虑:一般来说，TensorFlow和PyTorch的实现表现出相同的准确性。然而，TensorFlow的训练时间明显更高，但内存使用量更低。PyTorch比TensorFlow允许更快地进行原型设计，但如果神经网络需要自定义功能，TensorFlow可能是更好的选择。TensorFlow将神经网络视为静态对象;如果你想改变模型的行为，你必须从头开始。使用PyTorch，神经网络可以在运行时进行调整，使其更容易优化模型。另一个主要区别在于开发人员如何进行调试。使用TensorFlow进行有效调试需要一个特殊的调试器工具，使您能够检查网络节点在每个步骤中如何进行计算。PyTorch可以使用许多广泛可用的Python调试工具之一进行调试。PyTorch和TensorFlow都提供了加速模型开发和减少样板代码数量的方法。然而，PyTorch和TensorFlow之间的核心区别在于PyTorch更“python化”，基于面向对象的方法。同时，TensorFlow提供了更多的选项供选择，从而通常具有更高的灵活性。对于许多熟悉Python的开发人员来说，这是Pytorch比TensorFlow更好的一个重要原因。</p>
<Br>
<h2 id="特性比较表"><a class="markdownIt-Anchor" href="#特性比较表"></a> 特性比较表</h2>
<table>
<thead>
<tr>
<th>特性</th>
<th>PyTorch</th>
<th>TensorFlow</th>
</tr>
</thead>
<tbody>
<tr>
<td>易用性</td>
<td>语法更符合Python，调试更容易</td>
<td>学习曲线较陡，需要更多模板代码</td>
</tr>
<tr>
<td>动态计算图</td>
<td>运行时更容易修改</td>
<td>需要重新编译才能修改</td>
</tr>
<tr>
<td>GPU 支持</td>
<td>设置和使用多GPU更简单</td>
<td>多GPU支持更复杂，需要更多设置，有专门的TF API</td>
</tr>
<tr>
<td>社区支持</td>
<td>相对较新，发展迅速</td>
<td>大型且活跃，资源丰富</td>
</tr>
<tr>
<td>生态系统</td>
<td>与TensorFlow相比库和工具较少</td>
<td>拥有广泛的预构建模型和工具库</td>
</tr>
<tr>
<td>调试</td>
<td>由于Python语法和动态计算图，调试更容易</td>
<td>由于静态计算图，调试可能更具挑战性</td>
</tr>
<tr>
<td>研究应用</td>
<td>由于其灵活性和易用性，常用于研究</td>
<td>由于速度和可扩展性，常用于生产应用</td>
</tr>
<tr>
<td>数学库</td>
<td>使用TorchScript进行张量操作，NumPy进行数值计算</td>
<td>使用自有数学库进行张量操作和数值计算</td>
</tr>
<tr>
<td>Keras 集成</td>
<td>没有原生Keras集成</td>
<td>有原生Keras集成，简化模型构建和训练</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch:torch.nn.Embedding()</title>
    <url>/2024/01/19/PyTorch-torch-nn-Embedding/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">EMBEDDING</a></li>
</ul>
<br>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<h3 id="类定义"><a class="markdownIt-Anchor" href="#类定义"></a> 类定义</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.nn.Embedding(num_embeddings, embedding_dim, </span><br><span class="line">                         padding_idx=<span class="literal">None</span>, max_norm=<span class="literal">None</span>, norm_type=<span class="number">2.0</span>, scale_grad_by_freq=<span class="literal">False</span>, </span><br><span class="line">                         sparse=<span class="literal">False</span>, _weight=<span class="literal">None</span>, </span><br><span class="line">                         _freeze=<span class="literal">False</span>, device=<span class="literal">None</span>, </span><br><span class="line">                         dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>给一个编号，嵌入层就能返回这个编号对应的嵌入向量，嵌入向量反映了各个编号代表的符号之间的语义关系。</p>
<h3 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h3>
<ul>
<li><code>num_embeddings</code> (int): 嵌入字典的大小</li>
<li><code>embedding_dim</code> (int): 每个嵌入向量的大小</li>
<li><code>padding_idx</code> (int, 可选): 如果指定，padding_idx处的条目不会贡献梯度；因此，训练期间padding_idx处的嵌入向量不会更新。它保持为固定的“填充”。对于新构建的Embedding，padding_idx处的嵌入向量将默认为全零。</li>
<li><code>max_norm</code> (float, 可选): 如果给定，每个嵌入向量的范数大于max_norm时，将被重新标准化为范数max_norm。</li>
<li><code>norm_type</code> (float, 可选): 用于计算max_norm选项的p-范数的p。默认为2。</li>
<li><code>scale_grad_by_freq</code> (bool, 可选): 如果给定，这将按照小批量中单词的频率的倒数缩放梯度。默认为False。</li>
<li><code>sparse</code> (bool, 可选): 如果为True，权重矩阵的梯度将是一个稀疏张量。</li>
</ul>
<h3 id="变量"><a class="markdownIt-Anchor" href="#变量"></a> 变量</h3>
<ul>
<li><code>weight</code> (Tensor): 模块的可学习权重，形状为<code>(num_embeddings, embedding_dim)</code>，从<code>N(0,1)</code>初始化。</li>
</ul>
<h3 id="形状"><a class="markdownIt-Anchor" href="#形状"></a> 形状</h3>
<ul>
<li>输入: <code>(*)</code>, 包含要提取索引的任意形状的IntTensor或LongTensor</li>
<li>输出: <code>(*, H)</code>, 其中 * 是输入形状，<code>H = embedding_dim</code></li>
</ul>
<br>
<p>官方解释nn.embedding是什么：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A simple lookup table that stores embeddings of a fixed dictionary and size.</span><br><span class="line"></span><br><span class="line">This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.</span><br></pre></td></tr></table></figure>
<p>什么是simple lookup table？我没有训练过这个东西，到底哪来的word embedding？底下到底是word2vec、GloVe，还是什么pretrained的东西？</p>
<p><strong>答案其实很简单</strong>：都不是。实际上就是“随机”。我们再看一次这个文档，实际上，num_embeddings，第一个参数的意思就是，随便给定一个vocabulary size，比方说3，那么<code>nn.Embedding</code>就会帮你准备3个空位。第二个参数embedding_dim会直接帮你决定他帮你准备的随机的representation要有几个dimensions，你比如说5。</p>
<p>那么你可以想成实际上就是这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="number">0</span>: [<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>], <span class="comment"># 五个随机的floats来代表0这个token</span></span><br><span class="line"><span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>], <span class="comment"># 五个随机的floats来代表1这个token</span></span><br><span class="line"><span class="number">2</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>] <span class="comment"># 五个随机的floats来代表2这个token</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为什么是5个数字呢？因为你embedding_dim设成5，如果你设成384就会有384个随机数字对应到每一个id。</p>
<br>
<p>但是我想处理文字，又不是数字 - Tokenizer在干嘛？你可能接下来会感到困惑的点是…可是我想处理文字，又不是数字…所以…其实tokenizer就是在做这件事。假设你想要把&quot;你好吗&quot;这句话拿去配合什么东西训练，那么你就可能会有个tokenizer做这件事：{你: 0, 好:1, 吗:2}。你的文字input经过tokenizer之后就会变成一串数字，比方说&quot;你好好吗吗&quot;就会变成[0, 1, 1, 2, 2]，&quot;你吗吗好&quot;就会变成[0,2,2,1]。</p>
<p>然后经过<code>nn.Embedding</code>的时候他就把刚刚的随机数字塞进去。</p>
<p>所以&quot;你好好吗吗&quot;会被转成这样（就只是去查[0, 1, 1, 2, 2]）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="number">0</span>: [<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&quot;你吗吗好&quot;就会变成（就只是去查[0,2,2,1]）（我们这边先不管padding）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="number">0</span>: [<span class="number">.123123</span>,<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>],</span><br><span class="line">  <span class="number">2</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>],</span><br><span class="line">  <span class="number">2</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>],</span><br><span class="line">  <span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>更新参数：接下来你会有一个task可能是要训练model来分类什么东西，比方说听起来像不像脏话。那么，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[[<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>], </span><br><span class="line">[<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>], </span><br><span class="line">[<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>]]</span><br></pre></td></tr></table></figure>
<p>可能会对应到类别0（不像），</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">[<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>], </span><br><span class="line">[<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>可能会对应到类比1（有点像）等等。</p>
<br>
<p><strong>Vocabulary Size的影响</strong>：你的第一个参数(num_embeddings)会影响到你有几个place holders可以用。刚刚我们设3，所以只有三个不同的tokens可以用。所以一旦传进去的index超过2(<strong>0,1,2三个参数</strong>)，就会出错（list out of range)。所以大部分的语言模型都会设一个很大的数字，像是80000，再搭配tokenizer。</p>
<br>
<h3 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 包含10个尺寸为3的张量的Embedding模块</span></span><br><span class="line">embedding = nn.Embedding(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 2个样本的批量，每个样本有4个索引</span></span><br><span class="line"><span class="built_in">input</span> = torch.LongTensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">9</span>]])<span class="comment">#torch.Size([2, 4])</span></span><br><span class="line">embedding(<span class="built_in">input</span>)<span class="comment">##torch.Size([2, 4,3])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 带padding_idx的示例</span></span><br><span class="line">embedding = nn.Embedding(<span class="number">10</span>, <span class="number">3</span>, padding_idx=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.LongTensor([[<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">5</span>]])<span class="comment">#torch.Size([1, 4])</span></span><br><span class="line">embedding(<span class="built_in">input</span>)<span class="comment">#torch.Size([1, 4],3)</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>pytorch</tag>
        <tag>embedding</tag>
      </tags>
  </entry>
  <entry>
    <title>Python:yeild</title>
    <url>/2024/03/16/Python-yeild/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="yeild与return"><a class="markdownIt-Anchor" href="#yeild与return"></a> yeild与return</h2>
<p>在编程的世界里，理解各种概念往往是进步的阶梯。今天，我们来探讨一个在 Python 中相当有趣且强大的关键字：<code>yield</code>。如果你对它还感到陌生，不妨将 <code>yield</code> 视作 <code>return</code> 的同胞兄弟。是的，它们都承担着在函数中返回某种结果的重要职责。但事实上，<code>yield</code> 和 <code>return</code> 在功能上有着本质的不同。</p>
<ul>
<li>
<p><strong>使用 <code>return</code> 的函数</strong>：这类函数在执行到 <code>return</code> 语句时，会直接返回所有结果。一旦返回结果，程序便终止运行，并且局部变量被销毁。这种方式简单直接，但在处理大量数据时可能会导致内存问题。</p>
</li>
<li>
<p><strong>搭载 <code>yield</code> 的函数</strong>：相较于 <code>return</code>，<code>yield</code> 提供了一种优雅的机制，允许函数返回一个可迭代的生成器（generator）对象。这意味着函数的执行可以在 <code>yield</code> 处被暂停，并在需要的时候继续从上次离开的地方执行。你可以通过 <code>for</code> 循环或 <code>next()</code> 方法遍历这个生成器对象，逐一提取结果，这种方式大大节约了内存使用。</p>
</li>
</ul>
<p>那么，<strong>生成器</strong>到底是什么呢？简单来说，在 Python 中，<strong>任何使用了 <code>yield</code> 的函数</strong> 都会被视为一个生成器。这听起来可能有点像是语言的套娃游戏，但这正是其魅力所在。通过调用含有 <code>yield</code> 的函数，你实际上得到的是一个生成器对象。这个对象背后隐藏着强大的潜力，能够以极低的内存消耗处理大量数据。</p>
<p><strong>为什么使用生成器？</strong> 使用生成器的一个主要原因是其高效的内存利用特性。想象一下处理一个庞大的数据集合，如果一次性加载进内存，无疑会给系统带来巨大的压力。而生成器则允许我们逐步处理数据，只在需要时才生成下一个元素，这种“按需获取”的策略显著降低了内存的使用。</p>
<br>
<h2 id="举例说明"><a class="markdownIt-Anchor" href="#举例说明"></a> 举例说明</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">return_example</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;This is the first line.&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Return statement&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;This line will not be executed.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yield_example</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;This is the first line.&quot;</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="string">&quot;Yield statement&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;This line will be executed after the first yield.&quot;</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="string">&quot;Second yield statement&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;This line will be executed after the second yield.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用return关键字</span></span><br><span class="line">result_return = return_example()</span><br><span class="line"><span class="built_in">print</span>(result_return)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用yield关键字</span></span><br><span class="line">result_yield = yield_example()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(result_yield))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(result_yield))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(d2l) (base) chenyubin@chenyubindeMacBook-Pro d2l % /Users/chenyubin/anaconda3/envs/d2l/<span class="built_in">bin</span>/python /Users/chenyubin/Desktop/no_emo/gi</span><br><span class="line">thub/d2l/test.py</span><br><span class="line">This <span class="keyword">is</span> the first line.</span><br><span class="line">Return statement</span><br><span class="line">This <span class="keyword">is</span> the first line.</span><br><span class="line">Yield statement</span><br><span class="line">This line will be executed after the first <span class="keyword">yield</span>.</span><br><span class="line">Second <span class="keyword">yield</span> statement</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>yeild</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch:torch.utils.data.DataLoader</title>
    <url>/2023/12/24/Pytorch-torch-utils-data-DataLoader/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/data.html">pytorch官方</a></li>
<li><a href="https://blog.csdn.net/zfhsfdhdfajhsr/article/details/116836851">【Pytorch基础】torch.utils.data.DataLoader方法的使用</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/489756252">Pytorch】torch.utils.data.DataLoader使用方法</a></li>
<li><a href="https://blog.csdn.net/buziran/article/details/106804428">torch.utils.data.DataLoader使用方法</a></li>
</ul>
<br>
<h2 id="torchutilsdatadataloader"><a class="markdownIt-Anchor" href="#torchutilsdatadataloader"></a> <code>torch.utils.data.DataLoader</code></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">CLASS torch.utils.data.DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">None</span>, sampler=<span class="literal">None</span>, batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>, pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>, worker_init_fn=<span class="literal">None</span>, multiprocessing_context=<span class="literal">None</span>, generator=<span class="literal">None</span>, *, prefetch_factor=<span class="literal">None</span>, persistent_workers=<span class="literal">False</span>, pin_memory_device=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>数据加载器。结合了一个数据集和一个采样器，并提供对给定数据集的可迭代访问。</p>
<p>数据加载器支持映射样式和可迭代样式的数据集，可以使用单进程或多进程加载，自定义加载顺序，并可选择自动批处理（整理）和内存固定。</p>
<p>查看<a href="https://pytorch.org/docs/stable/data.html">torch.utils.data文档页面</a>以获取更多详细信息。</p>
<br>
<h2 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h2>
<ul>
<li>
<p><code>dataset</code>（数据集）：要从中加载数据的数据集。</p>
</li>
<li>
<p><code>batch_size</code>（int，可选）：每批加载多少个样本（默认：1）。</p>
</li>
<li>
<p><code>shuffle</code>（bool，可选）：设置为True以在每个时期重新洗牌数据（默认：False）。</p>
</li>
<li>
<p><code>sampler</code>（采样器或可迭代对象，可选）：定义从数据集中抽取样本的策略。可以是任何实现了<code>__len__</code>的可迭代对象。如果指定了<code>sampler</code>，则不能指定<code>shuffle</code>。</p>
</li>
<li>
<p><code>batch_sampler</code>（采样器或可迭代对象，可选）：类似于<code>sampler</code>，但一次返回一批索引。与<code>batch_size</code>、<code>shuffle</code>、<code>sampler</code>和<code>drop_last</code>相互排斥。</p>
</li>
<li>
<p><code>num_workers</code>（int，可选）：用于数据加载的子进程数。0表示数据将在主进程中加载（默认：0）。</p>
</li>
<li>
<p><code>collate_fn</code>（可调用对象，可选）：将样本列表合并成一个小批量的张量。在从映射样式数据集进行批量加载时使用。</p>
</li>
<li>
<p><code>pin_memory</code>（bool，可选）：如果为True，则数据加载器将在返回数据之前将张量复制到设备/CUDA固定内存中。如果你的数据元素是自定义类型，或者你的<code>collate_fn</code>返回的批次是自定义类型，请参考下面的示例。</p>
</li>
<li>
<p><code>drop_last</code>（bool，可选）：设置为True以丢弃最后一个不完整的批次，如果数据集大小不能被批次大小整除。如果为False，并且数据集的大小不能被批次大小整除，则最后一个批次将较小（默认：False）。</p>
</li>
<li>
<p><code>timeout</code>（数值，可选）：如果为正数，则为从工作进程收集批次的超时值。应始终为非负数（默认：0）。</p>
</li>
<li>
<p><code>worker_init_fn</code>（可调用对象，可选）：如果不为None，则将在每个工作进程上调用，以工作进程ID（一个位于[0，num_workers - 1]的整数）作为输入，在种子生成和数据加载之后（默认：None）。</p>
</li>
<li>
<p><code>multiprocessing_context</code>（str或multiprocessing.context.BaseContext，可选）：如果为None，则将使用操作系统的默认多进程上下文（默认：None）。</p>
</li>
<li>
<p><code>generator</code>（torch.Generator，可选）：如果不为None，则RandomSampler将使用此RNG生成随机索引，而多进程将生成工作进程的base_seed。 （默认：None）</p>
</li>
<li>
<p><code>prefetch_factor</code>（int，可选，仅限关键字参数）：每个工作进程提前加载的批次数。2表示所有工作进程将预取2 * <code>num_workers</code>批次（默认值取决于<code>num_workers</code>的设置值。如果<code>num_workers=0</code>，则默认值为None。否则，如果<code>num_workers &gt; 0</code>，则默认值为2）。</p>
</li>
<li>
<p><code>persistent_workers</code>（bool，可选）：如果为True，则数据加载器将在数据集被消耗一次后不会关闭工作进程。这允许保持工作进程的数据集实例处于活动状态（默认：False）。</p>
</li>
<li>
<p><code>pin_memory_device</code>（str，可选）：如果<code>pin_memory</code>为True，将数据固定到的设备。</p>
</li>
</ul>
<br>
<h2 id="示例代码"><a class="markdownIt-Anchor" href="#示例代码"></a> 示例代码</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    torch.manual_seed(<span class="number">1</span>)  <span class="comment"># reproducible</span></span><br><span class="line"></span><br><span class="line">    BATCH_SIZE = <span class="number">5</span>  <span class="comment"># 批训练的数据个数</span></span><br><span class="line"></span><br><span class="line">    x = torch.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)  <span class="comment"># x data (torch tensor)</span></span><br><span class="line">    y = torch.linspace(<span class="number">10</span>, <span class="number">1</span>, <span class="number">10</span>)  <span class="comment"># y data (torch tensor)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 先转换成 torch 能识别的 Dataset</span></span><br><span class="line">    torch_dataset = Data.TensorDataset(x, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把 dataset 放入 DataLoader</span></span><br><span class="line">    loader = Data.DataLoader(</span><br><span class="line">        dataset=torch_dataset,</span><br><span class="line">        batch_size=BATCH_SIZE,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=<span class="number">2</span>,  <span class="comment"># 注意: 在Windows和MacOS上，可能需要将num_workers设置为0来避免问题</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">enumerate</span>(loader))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        <span class="keyword">for</span> step, (batch_x, batch_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">            <span class="comment">#step只有0，1是因为，batchsize=5， 10个数据点，两次循环就用完了所有数据</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#x27;</span>, epoch, <span class="string">&#x27;| Step: &#x27;</span>, step, <span class="string">&#x27;| batch x: &#x27;</span>, batch_x.numpy(), <span class="string">&#x27;| batch y: &#x27;</span>, batch_y.numpy())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>pytorch</tag>
        <tag>dataloader</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch:nn.Conv2d()</title>
    <url>/2023/11/24/Pytorch-nn-Conv2d/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li>🔗：<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#">torch.nn.Conv2d</a></li>
</ul>
<h2 id="1pytorch官方文档"><a class="markdownIt-Anchor" href="#1pytorch官方文档"></a> 1.pytorch官方文档</h2>
<p>应用一个2D卷积在由多个输入平面组成的输入信号上。</p>
<p>在最简单的情况下，具有输入大小 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><mi>H</mi><mo separator="true">,</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C_{in}, H, W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span> 和输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C_{out}, H_{out}, W_{out})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的层的输出值可以精确描述为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>N</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><msub><mi>t</mi><mi>j</mi></msub></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><msub><mi>t</mi><mi>j</mi></msub></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>−</mo><mn>1</mn></mrow></munderover><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><msub><mi>t</mi><mi>j</mi></msub></mrow></msub><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>N</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">out(N_i, C_{out_j}) = bias(C_{out_j}) + \sum_{k=0}^{C_{in}-1} weight(C_{out_j}, k) * input(N_i, k)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0973199999999999em;vertical-align:-0.34731999999999996em;"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0973199999999999em;vertical-align:-0.34731999999999996em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal">i</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.1415490000000004em;vertical-align:-1.302113em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.839436em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.311105em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34731999999999996em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li>*是有效的2D互相关运算符</li>
<li>N 是批大小</li>
<li>C 表示通道数</li>
<li>H 是像素中输入平面的高度</li>
<li>W 是像素中的宽度。</li>
</ul>
<br>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>, device=<span class="literal">None</span>, dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>stride</code>: 控制交叉相关的步长，可以是一个数字或一个元组。</li>
<li><code>padding</code>: 控制应用于输入的填充量。可以是字符串 <code>&#123;'valid', 'same'&#125;</code> 或一个整数/整数元组，指定在两侧应用的隐式填充量。</li>
<li><code>dilation</code>: 控制核心点之间的间距；也称为à trous算法。这个比较难描述，但是这个<a href="#">链接</a>有一个很好的视觉化示例，展示了<code>dilation</code>的作用。</li>
<li><code>groups</code>: 控制输入和输出之间的连接。<code>in_channels</code> 和 <code>out_channels</code> 必须都能被 <code>groups</code> 整除。例如：
<ul>
<li>当 <code>groups=1</code> 时，所有输入都与所有输出进行卷积。</li>
<li>当 <code>groups=2</code> 时，操作相当于并行地拥有两个卷积层，每个层看到一半的输入通道并产出一半的输出通道，然后将两者的输出连接起来。</li>
<li>当 <code>groups=in_channels</code> 时，每个输入通道都与其自己的一组滤波器（尺寸为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mfrac><mrow><mi>o</mi><mi>u</mi><msub><mi>t</mi><mo>−</mo></msub><mi>c</mi><mi>h</mi><mi>a</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi></mrow><mrow><mi>i</mi><msub><mi>n</mi><mo>−</mo></msub><mi>c</mi><mi>h</mi><mi>a</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\frac{out_-channels}{in_-channels})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4246379999999998em;vertical-align:-0.486765em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.937873em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2736642857142857em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.20252142857142857em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.451765em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2736642857142857em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">−</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.20252142857142857em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.486765em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span> 进行卷积。</li>
</ul>
</li>
</ul>
<br>
<p>参数 <code>kernel_size</code>、<code>stride</code>、<code>padding</code>、<code>dilation</code> 可以是：</p>
<ul>
<li>一个 <code>int</code> 单个整数 - 在这种情况下，相同的值用于高度和宽度维度</li>
<li>一个由两个整数组成的 <code>tuple</code> 元组 - 在这种情况下，第一个 <code>int</code> 用于高度维度，第二个 <code>int</code> 用于宽度维度</li>
</ul>
<br>
<h3 id="11-注意"><a class="markdownIt-Anchor" href="#11-注意"></a> 1.1 <code>注意</code></h3>
<ul>
<li>
<p>注意：当 <code>groups == in_channels</code> 且 <code>out_channels == K * in_channels</code>，其中K是一个正整数时，该操作也被称为“深度可分卷积”。</p>
<ul>
<li>换句话说，对于输入大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C_{in}, L_{in})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的情况，可以使用深度乘数K进行深度可分卷积，其参数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>=</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><mi>K</mi><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>s</mi><mo>=</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C_{in} = C_{in}, C_{out} = C_{in} \times K, ..., groups = C_{in})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li>
</ul>
</li>
<li>
<p>注意：在某些情况下，当在CUDA设备上给定张量并使用CuDNN时，此操作可能选择一个非确定性算法以提高性能。如果这不可取，你可以尝试通过设置 <code>torch.backends.cudnn.deterministic = True</code> 来使操作变为确定性（可能以牺牲性能为代价）。更多信息请参见<a href="#">可重现性</a>。</p>
</li>
<li>
<p>注意：<code>padding='valid'</code> 相当于无填充。<code>padding='same'</code> 会填充输入，使输出具有与输入相同的形状。然而，这种模式不支持步长值不为1的任何情况。</p>
</li>
<li>
<p>注意：该模块支持复杂的数据类型，即 <code>complex32</code>，<code>complex64</code>，<code>complex128</code>。</p>
</li>
</ul>
<br>
<h3 id="12-参数"><a class="markdownIt-Anchor" href="#12-参数"></a> 1.2 <code>参数</code></h3>
<ul>
<li><code>in_channels</code> (int) - 输入图像的通道数。</li>
<li><code>out_channels</code> (int) - 卷积产生的通道数。</li>
<li><code>kernel_size</code> (int 或 tuple) - 卷积核的大小。</li>
<li><code>stride</code> (int 或 tuple, 可选) - 卷积的步长。默认值：1。</li>
<li><code>padding</code> (int, tuple 或 str, 可选) - 填充到输入的所有四边。默认值：0。</li>
<li><code>padding_mode</code> (str, 可选) - <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> 或 <code>'circular'</code>。默认：<code>'zeros'</code>。</li>
<li><code>dilation</code> (int 或 tuple, 可选) - 核元素之间的间距。默认值：1。</li>
<li><code>groups</code> (int, 可选) - 从输入通道到输出通道的阻塞连接数。默认值：1。</li>
<li><code>bias</code> (bool, 可选) - 如果为 <code>True</code>，则向输出添加可学习的偏置。默认值：<code>True</code>。</li>
</ul>
<br>
<h2 id="13-形状"><a class="markdownIt-Anchor" href="#13-形状"></a> 1.3 <code>形状</code></h2>
<ul>
<li>输入：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C_{in}, H_{in}, W_{in})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C_{in}, H_{in}, W_{in})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li>输出：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C_{out}, H_{out}, W_{out})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C_{out}, H_{out}, W_{out})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中</li>
</ul>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><mn>2</mn><mo>×</mo><mi>p</mi><mi>a</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>−</mo><mi>d</mi><mi>i</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>×</mo><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn></mrow><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">H_{out} = \frac{H_{in} + 2 \times padding[0] - dilation[0] \times (kernel\_size[0] - 1) - 1}{stride[0]} + 1 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.386em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6999999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.08125em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><mn>2</mn><mo>×</mo><mi>p</mi><mi>a</mi><mi>d</mi><mi>d</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>−</mo><mi>d</mi><mi>i</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>×</mo><mo stretchy="false">(</mo><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn></mrow><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">W_{out} = \frac{W_{in} + 2 \times padding[1] - dilation[1] \times (kernel\_size[1] - 1) - 1}{stride[1]} + 1 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.386em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6999999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord mathnormal">e</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></span></p>
<br>
<h2 id="14-变量"><a class="markdownIt-Anchor" href="#14-变量"></a> 1.4 <code>变量</code></h2>
<ul>
<li><code>weight</code> (Tensor): 模块可学习的权重，其形状为 (out_channels, in_channels / groups, kernel_size[0], kernel_size[1])。这些权重的值是从均匀分布 U(-√k, √k) 中采样的，其中 k = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>∗</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>s</mi></mrow></msubsup><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{C_{in} * \prod_{i=0}^{groups} kernel\_size[i]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4345679999999998em;vertical-align:-0.5894599999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.63614em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7912285714285714em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-2.9836857142857145em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3222857142857143em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mopen mtight">[</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">]</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5894599999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
<li><code>bias</code> (Tensor): 如果 <code>bias</code> 为 <code>True</code>，则模块形状为 (out_channels) 的可学习偏置。这些权重的值是从 U(-√k, √k) 中采样的，其中 k = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>∗</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>s</mi></mrow></msubsup><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{C_{in} * \prod_{i=0}^{groups} kernel\_size[i]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4345679999999998em;vertical-align:-0.5894599999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.63614em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.07153em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">∗</span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7912285714285714em;"><span style="top:-2.177714285714286em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-2.9836857142857145em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3222857142857143em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mathnormal mtight">e</span><span class="mopen mtight">[</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">]</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5894599999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
</ul>
<br>
<h2 id="15-示例"><a class="markdownIt-Anchor" href="#15-示例"></a> 1.5 <code>示例</code></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用正方形核和相同步长</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 使用非正方形核、不同步长和填充</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 使用非正方形核、不同步长、填充和扩张</span></span><br><span class="line">m = nn.Conv2d(<span class="number">16</span>, <span class="number">33</span>, (<span class="number">3</span>, <span class="number">5</span>), stride=(<span class="number">2</span>, <span class="number">1</span>), padding=(<span class="number">4</span>, <span class="number">2</span>), dilation=(<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 输入张量</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">20</span>, <span class="number">16</span>, <span class="number">50</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># 输出张量</span></span><br><span class="line">output = m(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>
<br>
<br>
<h2 id="2测试"><a class="markdownIt-Anchor" href="#2测试"></a> 2.测试</h2>
<h3 id="21-nnconv2d类式接口"><a class="markdownIt-Anchor" href="#21-nnconv2d类式接口"></a> 2.1 <code>nn.Conv2d(类式接口)</code></h3>
<p>基本用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2维的卷积层,用于图片的卷积</span></span><br><span class="line"><span class="comment"># 输入图像的通道数=1(灰度图像),卷积核的种类数=3</span></span><br><span class="line"><span class="comment"># 卷积核的shape是3乘3的,扫描步长为1,不加padding</span></span><br><span class="line">layer = nn.Conv2d(<span class="number">1</span>, <span class="number">3</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 要输入的原始图像</span></span><br><span class="line"><span class="comment"># 样本数=1,通道数=1,图像的shape是28乘28的</span></span><br><span class="line">x = torch.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用上面定义的卷积层layer和输入x,完成一次卷积的前向运算</span></span><br><span class="line">out = layer.forward(x)</span><br><span class="line"><span class="comment"># 得到的还是1张图片,因为用了3种kernel所以输出的通道数变成3了</span></span><br><span class="line"><span class="comment"># 因为没加padding,原来28乘28的图像在3乘3卷积下得到的边长是28-3+1=26</span></span><br><span class="line"><span class="built_in">print</span>(out.shape)  <span class="comment"># torch.Size([1, 3, 26, 26])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加padding看看</span></span><br><span class="line"><span class="comment"># 这次使用padding为1.所以原始图像上下左右都加了一层0</span></span><br><span class="line">layer = nn.Conv2d(<span class="number">1</span>, <span class="number">3</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(layer.forward(x).shape)  <span class="comment"># torch.Size([1, 3, 28, 28])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步长设置为2看看</span></span><br><span class="line"><span class="comment"># stride设置为2,也就是每次移动2格子(向上或者向右)</span></span><br><span class="line">layer = nn.Conv2d(<span class="number">1</span>, <span class="number">3</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 相当于每次跳1个像素地扫描,输出的Feature Map直接小了一半</span></span><br><span class="line"><span class="built_in">print</span>(layer.forward(x).shape)  <span class="comment"># torch.Size([1, 3, 14, 14])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实际使用时,应该这样用!</span></span><br><span class="line">out = layer(x)</span><br><span class="line"><span class="built_in">print</span>(out.shape)  <span class="comment"># torch.Size([1, 3, 14, 14])</span></span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>, <span class="number">26</span>, <span class="number">26</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>, <span class="number">14</span>, <span class="number">14</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>, <span class="number">14</span>, <span class="number">14</span>])</span><br></pre></td></tr></table></figure>
<br>
<p>特别注意，在使用时应该直接使用<code>layer(x)</code>而不是<code>layer.forward(x)</code>，因为前者实际是调用了<code>__call__()</code>，而PyTorch在这个函数中定义了一些hooks，如果要使用这些钩子的功能就只能用前者了！它会先运行hooks再运行<code>.forward()</code>函数。</p>
<br>
<br>
<p>在前面定义的卷积层的基础上，查看一下卷积层的权重（即卷积核）信息和偏置信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(layer.weight)</span><br><span class="line"><span class="built_in">print</span>(layer.bias)</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[[[ 0.1277, -0.1672,  0.1102],</span><br><span class="line">          [ 0.3176,  0.0236,  0.2537],</span><br><span class="line">          [ 0.0737,  0.0904,  0.0261]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ 0.0349, -0.2042,  0.1766],</span><br><span class="line">          [-0.0938, -0.0470,  0.2011],</span><br><span class="line">          [-0.2460,  0.0876,  0.3124]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[-0.2361, -0.0971, -0.1031],</span><br><span class="line">          [-0.0756, -0.3073,  0.3227],</span><br><span class="line">          [-0.1951, -0.2395, -0.0769]]]], requires_grad=True)</span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([ 0.0790, -0.3261,  0.0697], requires_grad=True)</span><br></pre></td></tr></table></figure>
<br>
<br>
<p>查看一下shape：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(layer.weight.shape)</span><br><span class="line"><span class="built_in">print</span>(layer.bias.shape)</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<br>
<br>
<h3 id="22-fconv2d函数式接口"><a class="markdownIt-Anchor" href="#22-fconv2d函数式接口"></a> 2.2 <code>F.conv2d(函数式接口)</code></h3>
<p>PyTorch里一般小写的都是函数式的接口，相应的大写的是类式接口。函数式的更加low-level一些，如果不需要做特别复杂的配置只要用类式接口就够了。</p>
<p>可以这样理解：<code>nn.Conv2d</code>是[2D卷积层]，而<code>F.conv2d</code>是[2D卷积操作]。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动定义卷积核(weight)和偏置</span></span><br><span class="line">w = torch.rand(<span class="number">16</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">5</span>)  <span class="comment"># 16种3通道的5乘5卷积核</span></span><br><span class="line">b = torch.rand(<span class="number">16</span>)  <span class="comment"># 和卷积核种类数保持一致(不同通道共用一个bias)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入样本</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">28</span>, <span class="number">28</span>)  <span class="comment"># 1张3通道的28乘28的图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2D卷积得到输出</span></span><br><span class="line">out = F.conv2d(x, w, b, stride=<span class="number">1</span>, padding=<span class="number">1</span>)  <span class="comment"># 步长为1,外加1圈padding</span></span><br><span class="line"><span class="built_in">print</span>(out.shape)</span><br><span class="line"></span><br><span class="line">out = F.conv2d(x, w, b, stride=<span class="number">2</span>, padding=<span class="number">2</span>)  <span class="comment"># 步长为2,外加2圈padding</span></span><br><span class="line"><span class="built_in">print</span>(out.shape)</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([1, 16, 26, 26])</span><br><span class="line">torch.Size([1, 16, 14, 14])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>pytorch</tag>
        <tag>conv2d</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch中的显存利用问题</title>
    <url>/2024/01/11/Pytorch%E4%B8%AD%E7%9A%84%E6%98%BE%E5%AD%98%E5%88%A9%E7%94%A8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="pytorch中的显存利用问题"><a class="markdownIt-Anchor" href="#pytorch中的显存利用问题"></a> Pytorch中的显存利用问题</h1>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://github.com/Oldpan/Pytorch-Memory-Utils">Pytorch-Memory-Utils</a></li>
</ul>
<br>
<h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h2>
<p>之前在<strong>计算模型以及中间变量的显存占用大小</strong>和<strong>在Pytorch中精细化利用显存</strong>中我们已经谈论过了平时使用中显存的占用来自于哪里,以及如何在Pytorch中更好地使用显存。在这篇文章中,我们借用<strong>Pytorch-Memory-Utils</strong>这个工具来检测我们在训练过程中关于显存的变化情况,分析出我们如何正确释放多余的显存。</p>
<p>在深度探究前先了解下我们的输出信息,通过Pytorch-Memory-Utils工具,我们在使用显存的代码中间插入检测函数(如何使用见工具github页面和下文部分),就可以输出类似于下面的信息,At <strong>main</strong> <module>: line 13 Total Used Memory:696.5 Mb表示在当前行代码时所占用的显存,即在我们的代码中执行到13行的时候所占显存为695.5Mb。At <strong>main</strong> <module>: line 15 Total Used Memory:1142.0 Mb表示程序执行到15行时所占的显存为1142.0Mb。两条数据之间表示所占显存的tensor变量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 12-Sep-18-21:48:45-gpu_mem_track.txt</span><br><span class="line"></span><br><span class="line">GPU Memory Track | 12-Sep-18-21:48:45 | Total Used Memory:696.5  Mb  </span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 13                        Total Used Memory:696.5  Mb</span><br><span class="line"></span><br><span class="line">+ | 7 * Size:(512, 512, 3, 3)     | Memory: 66.060 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(512, 256, 3, 3)     | Memory: 4.7185 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(64, 64, 3, 3)       | Memory: 0.1474 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(128, 64, 3, 3)      | Memory: 0.2949 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(128, 128, 3, 3)     | Memory: 0.5898 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 8 * Size:(512,)               | Memory: 0.0163 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 3 * Size:(256, 256, 3, 3)     | Memory: 7.0778 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(256, 128, 3, 3)     | Memory: 1.1796 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(64,)                | Memory: 0.0005 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 4 * Size:(256,)               | Memory: 0.0040 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(128,)               | Memory: 0.0010 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(64, 3, 3, 3)        | Memory: 0.0069 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 15                        Total Used Memory:1142.0 Mb</span><br><span class="line"></span><br><span class="line">+ | 1 * Size:(60, 3, 512, 512)    | Memory: 188.74 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(30, 3, 512, 512)    | Memory: 94.371 M | &lt;class &#x27;torch.Tensor&#x27;&gt; </span><br><span class="line">+ | 1 * Size:(40, 3, 512, 512)    | Memory: 125.82 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 21                        Total Used Memory:1550.9 Mb</span><br><span class="line"></span><br><span class="line">+ | 1 * Size:(120, 3, 512, 512)   | Memory: 377.48 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(80, 3, 512, 512)    | Memory: 251.65 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 26                        Total Used Memory:2180.1 Mb</span><br><span class="line"></span><br><span class="line">- | 1 * Size:(120, 3, 512, 512)   | Memory: 377.48 M | &lt;class &#x27;torch.Tensor&#x27;&gt;  </span><br><span class="line">- | 1 * Size:(40, 3, 512, 512)    | Memory: 125.82 M | &lt;class &#x27;torch.Tensor&#x27;&gt;  </span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 32                        Total Used Memory:1676.8 Mb</span><br></pre></td></tr></table></figure>
<p>使用Pytorch-Memory-Utils得到的显存跟踪结果。</p>
<p>当然这个检测工具不仅适用于Pytorch,其他的深度学习框架也同样可以使用,不过需要注意下静态图和动态图在实际运行过程中的区别。</p>
<br>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<p>了解了Pytorch-Memory-Utils工具如何使用后,接下来我们通过若干段程序代码来演示在Pytorch训练中:</p>
<ul>
<li>平时的显存是如何变化的,到底是什么占用了显存。</li>
<li>如何去释放不需要的显存。</li>
</ul>
<p>首先,我们在下段代码中导入我们需要的库,随后开始我们的显存检测程序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> gpu_mem_track <span class="keyword">import</span> MemTracker  <span class="comment"># 引用显存跟踪代码  </span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">frame = inspect.currentframe()      </span><br><span class="line">gpu_tracker = MemTracker(frame)      <span class="comment"># 创建显存检测对象</span></span><br><span class="line"></span><br><span class="line">gpu_tracker.track()                  <span class="comment"># 开始检测</span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="预训练权重模型"><a class="markdownIt-Anchor" href="#预训练权重模型"></a> 预训练权重模型</h2>
<p>首先我们检测一下神经网络模型权重所占用的显存信息,下面代码中我们尝试加载VGG19这个经典的网络模型,并且导入预训练好的权重。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gpu_tracker.track()</span><br><span class="line">cnn = models.vgg19(pretrained=<span class="literal">True</span>).to(device)  <span class="comment"># 导入VGG19模型并且将数据转到显存中</span></span><br><span class="line">gpu_tracker.track()</span><br></pre></td></tr></table></figure>
<p>然后可以发现程序运行过程中的显存变化(第一行是载入前的显存,最后一行是载入后的显存):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">At __main__ &lt;module&gt;: line 13                        Total Used Memory:472.2  Mb</span><br><span class="line"></span><br><span class="line">+ | 1 * Size:(128, 64, 3, 3)      | Memory: 0.2949 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(256, 128, 3, 3)     | Memory: 1.1796 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(64, 64, 3, 3)       | Memory: 0.1474 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(4096,)              | Memory: 0.0327 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(512, 256, 3, 3)     | Memory: 4.7185 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(128,)               | Memory: 0.0010 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(1000, 4096)         | Memory: 16.384 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 6 * Size:(512,)               | Memory: 0.0122 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(64, 3, 3, 3)        | Memory: 0.0069 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(4096, 25088)        | Memory: 411.04 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(4096, 4096)         | Memory: 67.108 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 5 * Size:(512, 512, 3, 3)     | Memory: 47.185 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(64,)                | Memory: 0.0005 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 3 * Size:(256,)               | Memory: 0.0030 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(128, 128, 3, 3)     | Memory: 0.5898 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(256, 256, 3, 3)     | Memory: 4.7185 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(1000,)              | Memory: 0.004 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 15                        Total Used Memory:1387.5 Mb</span><br></pre></td></tr></table></figure>
<p>通过上面的报告,很容易发现一个问题。</p>
<p>首先我们知道VGG19所有层的权重大小加起来大约是548M(这个数值来源于Pytorch官方提供的VGG19权重文件大小),我们将上面报告打印的Tensor-Memory也都加起来算下来也差不多551.8Mb。但是,我们算了两次打印的显存实际占用中:1387.5 – 472.2 = 915.3 MB。</p>
<p>唉,怎么多用了差不多400Mb呢?是不是报告出什么问题了。</p>
<p>这样,我们再加点Tensor试一下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">gpu_tracker.track()</span><br><span class="line">cnn = models.vgg19(pretrained=<span class="literal">True</span>).to(device)  </span><br><span class="line">gpu_tracker.track()</span><br><span class="line"><span class="comment"># 上方为之前的代码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 新增加的tensor</span></span><br><span class="line">dummy_tensor_1 = torch.randn(<span class="number">30</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">512</span>).<span class="built_in">float</span>().to(device)  <span class="comment"># 30*3*512*512*4/1000/1000 = 94.37M</span></span><br><span class="line">dummy_tensor_2 = torch.randn(<span class="number">40</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">512</span>).<span class="built_in">float</span>().to(device)  <span class="comment"># 40*3*512*512*4/1000/1000 = 125.82M</span></span><br><span class="line">dummy_tensor_3 = torch.randn(<span class="number">60</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">512</span>).<span class="built_in">float</span>().to(device)  <span class="comment"># 60*3*512*512*4/1000/1000 = 188.74M</span></span><br><span class="line"></span><br><span class="line">gpu_tracker.track()   <span class="comment"># 再次打印</span></span><br></pre></td></tr></table></figure>
<p>如上面的代码,我们又加入了三个Tensor,全部放到显存中。报告如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">At __main__ &lt;module&gt;: line 15                        Total Used Memory:1387.5 Mb  </span><br><span class="line"></span><br><span class="line">+ | 1 * Size:(30, 3, 512, 512)    | Memory: 94.371 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(40, 3, 512, 512)    | Memory: 125.82 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(60, 3, 512, 512)    | Memory: 188.74 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 21                        Total Used Memory:1807.0 Mb</span><br></pre></td></tr></table></figure>
<p>上面的报告就比较正常了:94.3 + 125.8 + 188.7 = 408.8 约等于 1807.0 – 1387.5 = 419.5,误差可以忽略,因为肯定会存在一些开销使用的显存。</p>
<p>那之前是什么情况?是不是模型的权重信息占得显存就稍微多一点?</p>
<p>这样,我们将载入VGG19模型的代码注释掉,只对后面的三个Tensor进行检测。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">gpu_tracker.track() </span><br><span class="line"><span class="comment"># cnn = models.vgg19(pretrained=True).to(device)   注释掉读权重代码</span></span><br><span class="line">gpu_tracker.track()</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>可以发现:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GPU Memory Track | 15-Sep-18-13:59:03 | Total Used Memory:513.3  Mb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 13                        Total Used Memory:513.3  Mb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 15                        Total Used Memory:513.3  Mb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 18                        Total Used Memory:513.3  Mb</span><br><span class="line"></span><br><span class="line">+ | 1 * Size:(60, 3, 512, 512)    | Memory: 188.74 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(30, 3, 512, 512)    | Memory: 94.371 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(40, 3, 512, 512)    | Memory: 125.82 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 24                        Total Used Memory:1271.3 Mb</span><br></pre></td></tr></table></figure>
<p>同样,显存占用比所列出来的Tensor占用大,我们暂时将次归结为Pytorch在开始运行程序时需要额外的显存开销,这种额外的显存开销与我们实际使用的模型权重显存大小无关。</p>
<br>
<h2 id="pytorch使用的显存策略"><a class="markdownIt-Anchor" href="#pytorch使用的显存策略"></a> Pytorch使用的显存策略</h2>
<p>Pytorch已经可以自动回收我们“不用的”显存,类似于python的引用机制,当某一内存内的数据不再有任何变量引用时,这部分的内存便会被释放。但有一点需要注意,当我们有一部分显存不再使用的时候,这部分释放后的显存通过Nvidia-smi命令是看不到的,举个例子:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"><span class="comment"># 定义两个tensor</span></span><br><span class="line">dummy_tensor_4 = torch.randn(<span class="number">120</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">512</span>).<span class="built_in">float</span>().to(device)  <span class="comment"># 120*3*512*512*4/1000/1000 = 377.48M</span></span><br><span class="line">dummy_tensor_5 = torch.randn(<span class="number">80</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">512</span>).<span class="built_in">float</span>().to(device)  <span class="comment"># 80*3*512*512*4/1000/1000 = 251.64M</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后释放</span></span><br><span class="line">dummy_tensor_4 = dummy_tensor_4.cpu()  </span><br><span class="line">dummy_tensor_2 = dummy_tensor_2.cpu()</span><br><span class="line"><span class="comment"># 这里虽然将上面的显存释放了,但是我们通过Nvidia-smi命令看到显存依然在占用</span></span><br><span class="line">torch.cuda.empty_cache()</span><br><span class="line"><span class="comment"># 只有执行完上面这句,显存才会在Nvidia-smi中释放</span></span><br></pre></td></tr></table></figure>
<p>Pytorch的开发者也对此进行说明了,这部分释放后的显存可以用,只不过不在Nvidia-smi中显示罢了。</p>
<br>
<h2 id="关于模型调用"><a class="markdownIt-Anchor" href="#关于模型调用"></a> 关于模型调用</h2>
<p>torch.no_grad()是Pytorch-0.4版本时候更新的功能,在此语句的作用域下,所有的tensor运算不会保存梯度值,特别适合在inference的时候使用,代替旧版本的volatile。</p>
<p>用一段代码演示下,这里我们根据VGG19网络构造一个特征提取器,分别提取content_image和style_image的特征图,然后将提取的特征图存在两个list中,我们使用了with torch.no_grad()语句(在没使用no_grad之前占用的显存更多,不过这里不进行展示了):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gpu_tracker.track()</span><br><span class="line"></span><br><span class="line">layers = [<span class="string">&#x27;relu_1&#x27;</span>, <span class="string">&#x27;relu_3&#x27;</span>, <span class="string">&#x27;relu_5&#x27;</span>, <span class="string">&#x27;relu_9&#x27;</span>]    <span class="comment"># 提取的层数</span></span><br><span class="line">layerIdx = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">content_image = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">500</span>, <span class="number">500</span>).<span class="built_in">float</span>().to(device)  </span><br><span class="line">style_image = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">500</span>, <span class="number">500</span>).<span class="built_in">float</span>().to(device)</span><br><span class="line">feature_extractor = nn.Sequential().to(device)           <span class="comment"># 特征提取器</span></span><br><span class="line">cnn = models.vgg19(pretrained=<span class="literal">True</span>).features.to(device)  <span class="comment"># 采取VGG19</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_features = []      <span class="comment"># 保存提取出的features</span></span><br><span class="line">target_features = []     <span class="comment"># 保存提取出的features</span></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="comment"># 如果不加下面这一句,那么显存的占用提升,因为保存了中间计算的梯度值</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> cnn.children():</span><br><span class="line">        <span class="keyword">if</span> layerIdx &lt; <span class="built_in">len</span>(layers):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, nn.Conv2d):</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                name = <span class="string">&quot;conv_&quot;</span> + <span class="built_in">str</span>(i)</span><br><span class="line">                feature_extractor.add_module(name, layer)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(layer, nn.MaxPool2d):</span><br><span class="line">                name = <span class="string">&quot;pool_&quot;</span> + <span class="built_in">str</span>(i)</span><br><span class="line">                feature_extractor.add_module(name, layer)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(layer, nn.ReLU):</span><br><span class="line">                name = <span class="string">&quot;relu_&quot;</span> + <span class="built_in">str</span>(i)</span><br><span class="line">                feature_extractor.add_module(name, nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">if</span> name == layers[layerIdx]:</span><br><span class="line">                <span class="built_in">input</span> = feature_extractor(content_image)</span><br><span class="line">                gpu_tracker.track()</span><br><span class="line">                target = feature_extractor(style_image)</span><br><span class="line">                gpu_tracker.track()</span><br><span class="line"></span><br><span class="line">                input_features.append(<span class="built_in">input</span>)</span><br><span class="line">                target_features.append(target)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">del</span> <span class="built_in">input</span></span><br><span class="line">                <span class="keyword">del</span> target</span><br><span class="line"></span><br><span class="line">                layerIdx += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">gpu_tracker.track()</span><br></pre></td></tr></table></figure>
<p>进行GPU跟踪后，观察下显存变化：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">At __main__ &lt;module&gt;: line 33                        Total Used Memory:1313.3 Mb</span><br><span class="line"></span><br><span class="line">+ | 2 * Size:(64,)                | Memory: 0.0005 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(1, 3, 500, 500)     | Memory: 6.0 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(64, 64, 3, 3)       | Memory: 0.1474 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(128, 64, 3, 3)      | Memory: 0.2949 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(128,)               | Memory: 0.0010 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(1, 256, 125, 125)   | Memory: 32.0 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(128, 128, 3, 3)     | Memory: 0.5898 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 7 * Size:(512, 512, 3, 3)     | Memory: 66.060 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 3 * Size:(256, 256, 3, 3)     | Memory: 7.0778 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(1, 512, 62, 62)     | Memory: 15.745 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(64, 3, 3, 3)        | Memory: 0.0069 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(1, 128, 250, 250)   | Memory: 64.0 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ | 8 * Size:(512,)               | Memory: 0.0163 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 4 * Size:(256,)               | Memory: 0.0040 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(256, 128, 3, 3)     | Memory: 1.1796 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 1 * Size:(512, 256, 3, 3)     | Memory: 4.7185 M | &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ | 2 * Size:(1, 64, 500, 500)    | Memory: 128.0 M | &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 76                        Total Used Memory:1932.0 Mb</span><br></pre></td></tr></table></figure>
<p>上表中4*2个&lt;class ‘torch.Tensor’&gt;是提取出的特征图，其他的&lt;class ‘torch.nn.parameter.Parameter’&gt;则是模型的权重值，但是发现，所有的值加起来，与总显存变化又不同，那究竟多了哪些占用显存的东西？</p>
<p>其实原因很简单，除了在程序运行时的一些额外显存开销，另外一个占用显存的东西就是我们在计算时候的临时缓冲值，这些零零总总也会占用一部分显存，并且这些缓冲值通过Python的垃圾收集是收集不到的。</p>
<Br>
<h2 id="asynchronous-execution"><a class="markdownIt-Anchor" href="#asynchronous-execution"></a> Asynchronous execution</h2>
<p>做过并行计算或者操作系统的同学可能知道，GPU的计算方式一般是异步的。异步运算不像同步运算那样是按照顺序一步一步来，异步是同时进行的，异步计算中，两种不一样的操作可能会发生同时触发的情况，这是处理两者间的前后关系、依赖关系或者冲突关系就比较重要了。</p>
<p>有一个众所周知的小技巧，在执行训练程序的时候将环境变量CUDA_LAUNCH_BLOCKING=1设为1(强制同步)可以准确定位观察到我们显存操作的错误代码行数。</p>
<br>
<h2 id="后记"><a class="markdownIt-Anchor" href="#后记"></a> 后记</h2>
<p>暂时就说这些，Pytorch的显存优化除了以上这些，更多的应该交给底层处理了，期待一下Pytorch的再次更新吧——另外，Pytorch-1.0的dev版已经出来，大家可以尝尝鲜了！</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>memory</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Prompt Engineering</title>
    <url>/2024/06/05/Prompt-Engineering/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1清晰明确的描述词"><a class="markdownIt-Anchor" href="#1清晰明确的描述词"></a> 1.清晰明确的描述词</h2>
<ul>
<li><code>写的短一点</code>-&gt; <code>3 to 5 sentence</code></li>
<li>使用<code>###</code>或者<code>“”“</code>将指令和待处理内容分开</li>
<li>指定输出格式：<code>Output as JSON format</code></li>
<li>角色扮演：<code>Act as</code>
<ul>
<li><a href="https://github.com/PlexPt/awesome-chatgpt-prompts-zh">chatgpt-prompts-zh</a></li>
<li><a href="https://github.com/f/awesome-chatgpt-prompts">chatgpt-prompts</a></li>
</ul>
</li>
<li>自己是什么：<code>Tell GPT who you are？</code></li>
</ul>
<table>
<thead>
<tr>
<th>Element</th>
<th>Description</th>
<th>Examples</th>
<th>Tips</th>
</tr>
</thead>
<tbody>
<tr>
<td>Instruction 指令词</td>
<td>a specific task or instruction you want the model to perform 想要模型执行的特定任务或指令。</td>
<td>简述, 解释, 翻译, 总结, 生成代码 …</td>
<td>clear and specific</td>
</tr>
<tr>
<td>Context 背景</td>
<td>external information or additional context that can steer the model to better responses 包含外部信息或额外的上下文信息，引导语言模型更好地响应。</td>
<td>我是一个小学生; 你是苏格拉底…</td>
<td>Act as 扮演</td>
</tr>
<tr>
<td>Input Data 输入</td>
<td>the input or question that we are interested to find a response for 用户输入的内容或问题</td>
<td>总结时提供的文本; 编写SQL代码时提供的数据库/表结构信息…</td>
<td></td>
</tr>
<tr>
<td>Output Indicator 输出要求</td>
<td>the type or format of the output. 指定输出的类型或格式。</td>
<td>50字; 4句话; 以JSON格式输出</td>
<td>use ## or “”“”</td>
</tr>
</tbody>
</table>
<br>
<h2 id="2-zero-shot-few-shot"><a class="markdownIt-Anchor" href="#2-zero-shot-few-shot"></a> 2. Zero-shot -&gt; Few-shot</h2>
<p>让GPT做事情之前可以扔几个例子</p>
<Br>
<h2 id="3-chain-of-thought"><a class="markdownIt-Anchor" href="#3-chain-of-thought"></a> 3. Chain of Thought</h2>
<p>思维链：引导模型去推理</p>
<p>神秘咒语:<code>Let's think side by side</code></p>
<h2 id="4-search-gpt"><a class="markdownIt-Anchor" href="#4-search-gpt"></a> 4. Search + GPT</h2>
<p>先用search API去搜索，将搜索的结果返回给GPT</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WEBSEARCH_PROMPT_TEMPLATE =</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Web search results: </span><br><span class="line">&#123;web_results&#125;</span><br><span class="line"></span><br><span class="line">Current date: &#123;current_date&#125;</span><br><span class="line"></span><br><span class="line">**Instructions:** Using the provided web search results, write a comprehensive reply to the given query.</span><br><span class="line"></span><br><span class="line">Make sure to cite results using [\[number\](URL)] notation after the reference.</span><br><span class="line"></span><br><span class="line">**Query:** &#123;query&#125;</span><br><span class="line"></span><br><span class="line">Reply in &#123;reply_language&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<br>
<h2 id="5-react"><a class="markdownIt-Anchor" href="#5-react"></a> 5. ReAct</h2>
<p><img src="https://pic.imgdb.cn/item/6660135f5e6d1bfa0574b8dc.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">尽可能的去回答以下问题，你可以使用以下的工具：</span><br><span class="line">【工具名和描述】</span><br><span class="line"></span><br><span class="line">请使用以下格式回答：</span><br><span class="line"></span><br><span class="line">问题: 你必须回答的问题</span><br><span class="line"></span><br><span class="line">思考: 你应该一直保持思考，思考要怎么解决问题</span><br><span class="line">动作: &lt;工具名&gt;。每次动作只选择一个工具。工具列表【工具名和描述】</span><br><span class="line">输入: &lt;调用工具时需要传入的参数&gt;</span><br><span class="line">观察: &lt;第三方工具返回的结果&gt;</span><br><span class="line"></span><br><span class="line">... 这个“思考-动作-输入-观察”的循环可以重复N次</span><br><span class="line"></span><br><span class="line">思考: 最后，你应该知道最终结果了</span><br><span class="line">最终结果: 针对你开始的问题，输出最终结果</span><br><span class="line"></span><br><span class="line">开始！</span><br><span class="line"></span><br><span class="line">问题: [问题]</span><br><span class="line">思考:</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>Python:@registry.register_model</title>
    <url>/2024/03/08/Python-registry-register-model/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li>
<li><a href="#%E4%BA%8B%E5%8F%91%E7%8E%B0%E5%9C%BA">事发现场</a></li>
<li><a href="#%E7%AE%80%E4%BB%8B">简介</a></li>
<li><a href="#%E5%AE%9E%E4%BE%8B%E8%A7%A3%E6%9E%90">实例解析</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li>
</ul>
<br>
<h2 id="事发现场"><a class="markdownIt-Anchor" href="#事发现场"></a> 事发现场</h2>
<p><img src="https://pbs.twimg.com/media/GIHsbkmaYAAh2JQ?format=jpg&amp;name=medium" alt="" /></p>
<p>这到底啥玩意啊哥，O.o?</p>
<br>
<h2 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h2>
<p>由于函数也是一个对象，而且函数对象可以被赋值给变量，所以，通过变量也能调用该函数.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">now</span>():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;2015-3-25&#x27;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = now</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f()</span><br><span class="line"><span class="number">2015</span>-<span class="number">3</span>-<span class="number">25</span></span><br></pre></td></tr></table></figure>
<p>函数对象有一个__name__属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>now.__name__</span><br><span class="line"><span class="string">&#x27;now&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.__name__</span><br><span class="line"><span class="string">&#x27;now&#x27;</span></span><br></pre></td></tr></table></figure>
<p>假设我们要增强<code>now()</code>函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改<code>now()</code>函数的定义，这种在代码运行期间动态增加功能的方式，称之为 <strong>“装饰器”（Decorator）</strong> 。</p>
<br>
<h2 id="实例解析"><a class="markdownIt-Anchor" href="#实例解析"></a> 实例解析</h2>
<p>本质上，decorator就是一个返回函数的高阶函数。log是一个能打印日志的函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;call %s():&#x27;</span> % func.__name__)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kw)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure>
<p>上面的log函数接受一个函数作为参数，然会一个函数</p>
<p>执行代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@log</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">now</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;2015-3-25&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果如下，我们可以看到在执行<code>now</code>函数的同时页执行了<code>log</code>函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>now()</span><br><span class="line">call now():</span><br><span class="line"><span class="number">2015</span>-<span class="number">3</span>-<span class="number">25</span></span><br></pre></td></tr></table></figure>
<Br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017451662295584">装饰器</a></li>
<li><a href="https://www.cnblogs.com/wanger-sjtu/p/15013460.html">python 装饰器</a></li>
<li><a href="https://blog.csdn.net/danger2/article/details/135256367">@MODELS.register_module()函数装饰器</a></li>
<li><a href="https://blog.csdn.net/qq_41368074/article/details/127113284">OpenMMLab之Registry机制</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/350787676">PyTorch 76.Python中的注册器模块</a></li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>python</tag>
        <tag>register</tag>
      </tags>
  </entry>
  <entry>
    <title>RuntimeError: Parent directory /model1/ does not exist.</title>
    <url>/2023/12/28/RuntimeError-Parent-directory-model1-does-not-exist/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="问题描述"><a class="markdownIt-Anchor" href="#问题描述"></a> 问题描述</h2>
<p>其实就是文件不存在，所以没找到存放模型的文件夹，导致模型没有保存：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RuntimeError: Parent directory /model1/ does <span class="keyword">not</span> exist.</span><br></pre></td></tr></table></figure>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果目录不存在，则创建该目录</span></span><br><span class="line">os.makedirs(args.model_path, exist_ok=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>file</tag>
      </tags>
  </entry>
  <entry>
    <title>The Road to Diffusion and Flow Matching | DDPM</title>
    <url>/2025/08/02/The-Road-to-Diffusion-and-Flow-Matching-DDPM/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h2>
<p>DDPM, which stands for “<a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a>” is considered a foundational paper that popularized modern diffusion models.</p>
<p>Here are some awesome link as follows:</p>
<ul>
<li>Arxiv Link: <a href="https://arxiv.org/abs/2006.11239">https://arxiv.org/abs/2006.11239</a></li>
<li>Github Link: <a href="https://github.com/hojonathanho/diffusion">https://github.com/hojonathanho/diffusion</a></li>
<li>Tutorial in bilibili: <a href="https://www.bilibili.com/video/BV1yA41167Dg">https://www.bilibili.com/video/BV1yA41167Dg</a></li>
</ul>
]]></content>
      <categories>
        <category>Diffusion</category>
      </categories>
  </entry>
  <entry>
    <title>Train VS Eval</title>
    <url>/2024/03/25/Train-VS-Eval/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<!-- omit in toc -->
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#train-vs-eval">Train VS Eval</a>
<ul>
<li><a href="#%E8%AE%BE%E7%BD%AE%E6%A8%A1%E5%9E%8B%E7%8A%B6%E6%80%81">设置模型状态</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B">训练流程</a></li>
<li><a href="#%E9%AA%8C%E8%AF%81%E6%B5%8B%E8%AF%95%E6%B5%81%E7%A8%8B">验证/测试流程</a></li>
<li><a href="#%E5%AF%B9%E6%AF%94">对比</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B%E6%8C%87%E6%A0%87">计算模型指标</a></li>
</ul>
</li>
<li><a href="#%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86">训练集、验证集和测试集</a>
<ul>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1">模型设计</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8F%82%E6%95%B0">模型训练的参数</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E7%B1%BB">数据集分类</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E4%BD%9C%E7%94%A8%E4%B8%8E%E7%89%B9%E7%82%B9">数据集的作用与特点</a></li>
<li><a href="#%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E4%BA%92%E7%9B%B8%E8%BD%AC%E5%8C%96">验证集和测试集的互相转化</a></li>
<li><a href="#%E9%AA%8C%E8%AF%81%E9%9B%86%E7%9A%84%E4%BD%9C%E7%94%A8">验证集的作用</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li>
</ul>
<hr />
<h2 id="train-vs-eval"><a class="markdownIt-Anchor" href="#train-vs-eval"></a> Train VS Eval</h2>
<p>在完成模型的训练后，我们需要在测试集/验证集上完成模型的验证，以确保模型具有泛化能力、不会出现过拟合等问题。在PyTorch中，训练和评估的流程基本一致，区别在于训练过程需要更新模型的参数，而评估过程则不需要更新参数。</p>
<h3 id="设置模型状态"><a class="markdownIt-Anchor" href="#设置模型状态"></a> 设置模型状态</h3>
<ul>
<li>训练状态：模型的参数应该支持反向传播的修改。  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.train()</span><br></pre></td></tr></table></figure>
</li>
<li>验证/测试状态：不应该修改模型参数。  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="训练流程"><a class="markdownIt-Anchor" href="#训练流程"></a> 训练流程</h3>
<ol>
<li>读取数据：使用<code>for</code>循环从<code>DataLoader</code>中读取全部数据。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br></pre></td></tr></table></figure>
</li>
<li>将数据转移到GPU上（以<code>.cuda()</code>为例）： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data, label = data.cuda(), label.cuda()</span><br></pre></td></tr></table></figure>
</li>
<li>初始化优化器的梯度： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer.zero_grad()</span><br></pre></td></tr></table></figure>
</li>
<li>将数据输入模型进行训练，并计算损失函数： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">output = model(data)</span><br><span class="line">loss = criterion(output, label)</span><br></pre></td></tr></table></figure>
</li>
<li>将损失反向传播回网络，并更新模型参数： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="验证测试流程"><a class="markdownIt-Anchor" href="#验证测试流程"></a> 验证/测试流程</h3>
<p>与训练流程基本一致，但有以下不同：</p>
<ul>
<li>预先设置<code>torch.no_grad()</code>，并将模型调至eval模式。</li>
<li>不需要将<strong>优化器的梯度置零</strong>。</li>
<li>不需要将<strong>损失反向传播回网络</strong>。</li>
<li>不需要<strong>更新优化器</strong>。</li>
</ul>
<h3 id="对比"><a class="markdownIt-Anchor" href="#对比"></a> 对比</h3>
<p><strong>训练过程示例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        data, label = data.cuda(), label.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = criterion(output, label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        train_loss += loss.item() * data.size(<span class="number">0</span>)</span><br><span class="line">    train_loss /= <span class="built_in">len</span>(train_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tTraining Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, train_loss))</span><br></pre></td></tr></table></figure>
<p><strong>验证过程示例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">val</span>(<span class="params">epoch</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_loss = <span class="number">0</span></span><br><span class="line">    running_accu = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, label <span class="keyword">in</span> val_loader:</span><br><span class="line">            data, label = data.cuda(), label.cuda()</span><br><span class="line">            output = model(data)</span><br><span class="line">            preds = torch.argmax(output, <span class="number">1</span>)</span><br><span class="line">            loss = criterion(output, label)</span><br><span class="line">            val_loss += loss.item() * data.size(<span class="number">0</span>)</span><br><span class="line">            running_accu += torch.<span class="built_in">sum</span>(preds == label.data)</span><br><span class="line">    val_loss /= <span class="built_in">len</span>(val_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125; \tValidation Loss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, val_loss))</span><br></pre></td></tr></table></figure>
<h3 id="计算模型指标"><a class="markdownIt-Anchor" href="#计算模型指标"></a> 计算模型指标</h3>
<p>可以使用<code>sklearn.metrics</code>中的<code>classification_report</code>函数来计算模型的准确率、召回率、F1值等指标：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换以下代码中的labels和preds为模型预测出来的所有label和preds</span></span><br><span class="line"><span class="comment"># target_names替换为类别名称，即可得到模型的分类报告</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(labels.cpu(), preds.cpu(), target_names=class_names))</span><br></pre></td></tr></table></figure>
<br>
<h2 id="训练集-验证集和测试集"><a class="markdownIt-Anchor" href="#训练集-验证集和测试集"></a> 训练集、验证集和测试集</h2>
<h3 id="模型设计"><a class="markdownIt-Anchor" href="#模型设计"></a> 模型设计</h3>
<ul>
<li><strong>模型架构</strong>：包括模型的层数以及每层的神经元数量。</li>
<li><strong>可训练权重参数</strong>：模型内置的可训练参数。</li>
</ul>
<h3 id="模型训练的参数"><a class="markdownIt-Anchor" href="#模型训练的参数"></a> 模型训练的参数</h3>
<p>这些是模型外置参数，如学习率、优化策略等。</p>
<h3 id="数据集分类"><a class="markdownIt-Anchor" href="#数据集分类"></a> 数据集分类</h3>
<ul>
<li><strong>训练集（Train Set）</strong>：用于模型拟合的数据样本，用于通过梯度下降进行学习。</li>
<li><strong>验证集（Validation Set）</strong>：在模型训练过程中单独留出的样本集，用于调整模型的超参数和进行初步评估。
<ul>
<li>可以用来发现模型或参数问题，如模型在验证集上的发散、奇怪的结果、mAP不增等情况。</li>
<li>有助于验证模型的泛化能力，并通过对比不同模型来选择最优模型。</li>
<li>通常在几个epoch后运行一次，以观察效果，但过于频繁会影响训练速度。</li>
</ul>
</li>
<li><strong>测试集（Test Set）</strong>：用来评估模型最终的泛化能力，不应用于调参或特征选择等。</li>
</ul>
<p>测试集的分类：</p>
<ul>
<li>
<p>“test-dev” 代表开发测试集（Development Test Set），通常用于开发和调试阶段，用来评估模型的表现，并且通常会反复使用以进行参数调整和模型改进。</p>
</li>
<li>
<p>“test-std” 代表标准测试集（Standard Test Set），通常用于最终评估模型的性能，并且不会用于模型的开发或者调整。它可以看作是一个独立的、固定的测试集，用于评估模型在真实场景下的表现。</p>
</li>
</ul>
<h3 id="数据集的作用与特点"><a class="markdownIt-Anchor" href="#数据集的作用与特点"></a> 数据集的作用与特点</h3>
<table>
<thead>
<tr>
<th>类别</th>
<th>是否被训练到</th>
<th>作用</th>
<th>使用次数</th>
<th>缺陷</th>
</tr>
</thead>
<tbody>
<tr>
<td>验证集</td>
<td>否</td>
<td>调超参数</td>
<td>多次使用</td>
<td>可能低估泛化误差</td>
</tr>
<tr>
<td>测试集</td>
<td>否</td>
<td>验证泛化性能</td>
<td>仅一次使用</td>
<td>数据量大，测试耗时</td>
</tr>
</tbody>
</table>
<h3 id="验证集和测试集的互相转化"><a class="markdownIt-Anchor" href="#验证集和测试集的互相转化"></a> 验证集和测试集的互相转化</h3>
<ul>
<li>验证集是必需的，用于“人工调参”过程。</li>
<li>训练集、验证集和测试集应遵循相同的数据分布，以进行有效的调参。</li>
<li>测试集存在的目的是为了验证模型的泛化能力。</li>
</ul>
<h3 id="验证集的作用"><a class="markdownIt-Anchor" href="#验证集的作用"></a> 验证集的作用</h3>
<ul>
<li>使用提前终止（early stopping）策略，基于validation_data的分类精度来防止过拟合。</li>
<li>通过validation_data而非test_data设置超参数，避免对test_data过拟合。</li>
<li>validation_data被视为帮助学习合适超参数的训练数据，与test_data分离开，采用分离法（hold out method）。</li>
</ul>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E4%B8%89%E7%AB%A0/3.7%20%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0.html">3.7 训练和评估</a></li>
<li><a href="https://blog.csdn.net/katrina1rani/article/details/113889183">训练集、验证集、测试集的作用和区别</a></li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
      </tags>
  </entry>
  <entry>
    <title>Tmux使用教程</title>
    <url>/2024/03/26/Tmux%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<!-- omit in toc -->
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#1tmux-%E6%98%AF%E4%BB%80%E4%B9%88">1.Tmux 是什么</a>
<ul>
<li><a href="#11-%E4%BC%9A%E8%AF%9D%E4%B8%8E%E8%BF%9B%E7%A8%8B">1.1 会话与进程</a></li>
<li><a href="#12-tmux-%E7%9A%84%E4%BD%9C%E7%94%A8">1.2 Tmux 的作用</a></li>
</ul>
</li>
<li><a href="#2%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95">2.基本用法</a>
<ul>
<li><a href="#21-tmux-%E5%AE%89%E8%A3%85">2.1 Tmux 安装</a></li>
<li><a href="#22-tmux-%E5%90%AF%E5%8A%A8%E4%B8%8E%E9%80%80%E5%87%BA">2.2 Tmux 启动与退出</a></li>
<li><a href="#23-%E5%89%8D%E7%BC%80%E9%94%AE">2.3 前缀键</a></li>
</ul>
</li>
<li><a href="#3%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86">3.会话管理</a>
<ul>
<li><a href="#31-%E6%96%B0%E5%BB%BA%E4%BC%9A%E8%AF%9D">3.1 新建会话</a></li>
<li><a href="#32-%E5%88%86%E7%A6%BB%E4%BC%9A%E8%AF%9D">3.2 分离会话</a></li>
<li><a href="#33-%E6%8E%A5%E5%85%A5%E4%BC%9A%E8%AF%9D">3.3 接入会话</a></li>
<li><a href="#34-%E6%9D%80%E6%AD%BB%E4%BC%9A%E8%AF%9D">3.4 杀死会话</a></li>
<li><a href="#35-%E5%88%87%E6%8D%A2%E4%BC%9A%E8%AF%9D">3.5 切换会话</a></li>
<li><a href="#36-%E9%87%8D%E5%91%BD%E5%90%8D%E4%BC%9A%E8%AF%9D">3.6 重命名会话</a></li>
<li><a href="#37-%E4%BC%9A%E8%AF%9D%E5%BF%AB%E6%8D%B7%E9%94%AE">3.7 会话快捷键</a></li>
</ul>
</li>
<li><a href="#4%E6%9C%80%E7%AE%80%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B">4.最简操作流程</a></li>
<li><a href="#5%E7%AA%97%E6%A0%BC%E6%93%8D%E4%BD%9C">5.窗格操作</a>
<ul>
<li><a href="#51-%E5%88%92%E5%88%86%E7%AA%97%E6%A0%BC">5.1 划分窗格</a></li>
<li><a href="#52-%E7%A7%BB%E5%8A%A8%E5%85%89%E6%A0%87">5.2 移动光标</a></li>
<li><a href="#53-%E4%BA%A4%E6%8D%A2%E7%AA%97%E6%A0%BC%E4%BD%8D%E7%BD%AE">5.3 交换窗格位置</a></li>
<li><a href="#54-%E7%AA%97%E6%A0%BC%E5%BF%AB%E6%8D%B7%E9%94%AE">5.4 窗格快捷键</a></li>
</ul>
</li>
<li><a href="#6%E7%AA%97%E5%8F%A3%E7%AE%A1%E7%90%86">6.窗口管理</a>
<ul>
<li><a href="#61-%E6%96%B0%E5%BB%BA%E7%AA%97%E5%8F%A3">6.1 新建窗口</a></li>
<li><a href="#62-%E5%88%87%E6%8D%A2%E7%AA%97%E5%8F%A3">6.2 切换窗口</a></li>
<li><a href="#63-%E9%87%8D%E5%91%BD%E5%90%8D%E7%AA%97%E5%8F%A3">6.3 重命名窗口</a></li>
<li><a href="#64-%E7%AA%97%E5%8F%A3%E5%BF%AB%E6%8D%B7%E9%94%AE">6.4 窗口快捷键</a></li>
</ul>
</li>
<li><a href="#7%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4">7.其他命令</a></li>
<li><a href="#8%E6%BC%94%E7%A4%BA%E8%BF%87%E7%A8%8B">8.演示过程</a></li>
<li><a href="#%E9%99%84%E5%BD%95">附录</a>
<ul>
<li><a href="#%E8%A1%A8%E4%B8%80%E7%B3%BB%E7%BB%9F%E6%8C%87%E4%BB%A4">表一：系统指令</a></li>
<li><a href="#%E8%A1%A8%E4%BA%8C%E7%AA%97%E5%8F%A3window%E6%8C%87%E4%BB%A4">表二：窗口（Window）指令</a></li>
<li><a href="#%E8%A1%A8%E4%B8%89%E9%9D%A2%E6%9D%BFpane%E6%8C%87%E4%BB%A4">表三：面板（Pane）指令</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">参考链接</a></li>
</ul>
<br>
<h2 id="1tmux-是什么"><a class="markdownIt-Anchor" href="#1tmux-是什么"></a> 1.Tmux 是什么</h2>
<h3 id="11-会话与进程"><a class="markdownIt-Anchor" href="#11-会话与进程"></a> 1.1 会话与进程</h3>
<p><strong>会话（session）</strong>：用户与计算机之间的一种临时交互。</p>
<p>会话的核心特征在于<strong>窗口与其内启动的进程紧密相连</strong>。开启窗口意味着会话的开始；关闭窗口则标志着会话的结束，随之，会话中的进程不论是否执行完毕都将被终止。<br />
以<strong>SSH 远程登录计算机</strong>为例，若在执行命令时网络突然中断，重新登录后将无法找回先前的命令。这是因为之前的SSH会话已终止，其进程也随之消失。<br />
为了克服这一挑战，可以实现<strong>会话与窗口的解绑</strong>：即使窗口关闭，会话也不会结束，而是继续运行，待需要时可重新绑定至其他窗口。</p>
<h3 id="12-tmux-的作用"><a class="markdownIt-Anchor" href="#12-tmux-的作用"></a> 1.2 Tmux 的作用</h3>
<p><strong>Tmux</strong>：一个实现会话与窗口解绑的工具。</p>
<ul>
<li>（1）支持在单一窗口内<strong>同时访问多个会话</strong>，适用于并行运行多个命令行程序。</li>
<li>（2）允许<strong>新窗口接入已存在会话</strong>。</li>
<li>（3）支持每个会话拥有<strong>多个连接窗口</strong>，便于多人实时共享会话。</li>
<li>（4）提供<strong>灵活的窗口垂直和水平拆分</strong>功能。</li>
</ul>
<br>
<h2 id="2基本用法"><a class="markdownIt-Anchor" href="#2基本用法"></a> 2.基本用法</h2>
<h3 id="21-tmux-安装"><a class="markdownIt-Anchor" href="#21-tmux-安装"></a> 2.1 Tmux 安装</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对于 Ubuntu 或 Debian</span></span><br><span class="line">sudo apt-get install tmux</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于 CentOS 或 Fedora</span></span><br><span class="line">sudo yum install tmux</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于 Mac</span></span><br><span class="line">brew install tmux</span><br></pre></td></tr></table></figure>
<h3 id="22-tmux-启动与退出"><a class="markdownIt-Anchor" href="#22-tmux-启动与退出"></a> 2.2 Tmux 启动与退出</h3>
<p>安装完成后，通过输入 <code>tmux</code> 命令即可进入 Tmux 窗口。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux</span><br></pre></td></tr></table></figure>
<p>此命令将打开 Tmux 窗口，并在底部展示一个状态栏。状态栏左侧显示窗口信息（编号和名称），右侧显示系统信息。</p>
<p>按下 <code>Ctrl+d</code> 或输入 <code>exit</code> 命令即可退出 Tmux 窗口。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<h3 id="23-前缀键"><a class="markdownIt-Anchor" href="#23-前缀键"></a> 2.3 前缀键</h3>
<p>Tmux 窗口支持众多快捷键，所有快捷键均需通过前缀键激活。默认前缀键为 <code>Ctrl+b</code>，即首先按下 <code>Ctrl+b</code>，随后输入的快捷键才有效。</p>
<p>例如，显示帮助信息的快捷键是 <code>Ctrl+b ?</code>。在 Tmux 窗口中，先按 <code>Ctrl+b</code>，再按 <code>?</code> 即可展示帮助信息。</p>
<p>按 <code>ESC</code> 键或 <code>q</code> 键退出帮助界面。</p>
<br>
<h2 id="3会话管理"><a class="markdownIt-Anchor" href="#3会话管理"></a> 3.会话管理</h2>
<h3 id="31-新建会话"><a class="markdownIt-Anchor" href="#31-新建会话"></a> 3.1 新建会话</h3>
<p>当首个 Tmux 窗口启动时，其编号为 0，随后启动的窗口编号依次增加。相应的会话也被称作 0 号会话、1 号会话等。</p>
<p>为了便于识别，推荐为会话命名：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux new -s &lt;session-name&gt;</span><br></pre></td></tr></table></figure>
<p>以上命令新建一个带有指定名称的会话。</p>
<h3 id="32-分离会话"><a class="markdownIt-Anchor" href="#32-分离会话"></a> 3.2 分离会话</h3>
<p>在 Tmux 窗口中，通过按下 <code>Ctrl+b d</code> 或输入 <code>tmux detach</code> 命令可以实现当前会话与窗口的分离。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux detach</span><br></pre></td></tr></table></figure>
<p>执行以上命令后，将退出当前 Tmux 窗口，但会话及其进程仍在后台运行。</p>
<p>使用 <code>tmux ls</code> 命令查看当前所有 Tmux 会话：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux <span class="built_in">ls</span></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">tmux list-session</span><br></pre></td></tr></table></figure>
<h3 id="33-接入会话"><a class="markdownIt-Anchor" href="#33-接入会话"></a> 3.3 接入会话</h3>
<p><code>tmux attach</code> 命令允许重新接入某个已存在的会话。</p>
<ul>
<li>
<p>使用会话编号接入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux attach -t 0</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用会话名称接入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux attach -t &lt;session-name&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="34-杀死会话"><a class="markdownIt-Anchor" href="#34-杀死会话"></a> 3.4 杀死会话</h3>
<p><code>tmux kill-session</code> 命令用于终止指定会话。</p>
<ul>
<li>
<p>使用会话编号杀死：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux kill-session -t 0</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用会话名称杀死：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux kill-session -t &lt;session-name&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="35-切换会话"><a class="markdownIt-Anchor" href="#35-切换会话"></a> 3.5 切换会话</h3>
<p><code>tmux switch</code> 命令用于切换到另一个会话。</p>
<ul>
<li>
<p>使用会话编号切换：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux switch -t 0</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>使用会话名称切换：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux switch -t &lt;session-name&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="36-重命名会话"><a class="markdownIt-Anchor" href="#36-重命名会话"></a> 3.6 重命名会话</h3>
<p><code>tmux rename-session</code> 命令允许为会话设置新名称。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tmux rename-session -t 0 &lt;new-name&gt;</span><br></pre></td></tr></table></figure>
<p>以上命令将 0 号会话重命名。</p>
<h3 id="37-会话快捷键"><a class="markdownIt-Anchor" href="#37-会话快捷键"></a> 3.7 会话快捷键</h3>
<p>以下是一些与会话管理相关的快捷键操作：</p>
<ul>
<li><code>Ctrl+b d</code>：分离当前会话。</li>
<li><code>Ctrl+b s</code>：列出所有会话。</li>
<li><code>Ctrl+b $</code>：重命名当前会话。</li>
</ul>
<br>
<h2 id="4最简操作流程"><a class="markdownIt-Anchor" href="#4最简操作流程"></a> 4.最简操作流程</h2>
<p>综上所述，以下是 Tmux 的最简操作流程：</p>
<ol>
<li>新建会话：<code>tmux new -s my_session</code>。</li>
<li>在 Tmux 窗口运行所需的程序。</li>
<li>按下快捷键 <code>Ctrl+b d</code> 将会话分离。</li>
<li>下次使用时，重新连接到会话：<code>tmux attach-session -t my_session</code>。</li>
</ol>
<br>
<h2 id="5窗格操作"><a class="markdownIt-Anchor" href="#5窗格操作"></a> 5.窗格操作</h2>
<p>Tmux 可以将窗口分成多个窗格（pane），每个窗格运行不同的命令。以下命令都是在 Tmux 窗口中执行。</p>
<h3 id="51-划分窗格"><a class="markdownIt-Anchor" href="#51-划分窗格"></a> 5.1 划分窗格</h3>
<ul>
<li>划分上下两个窗格：<code>tmux split-window</code></li>
<li>划分左右两个窗格：<code>tmux split-window -h</code></li>
</ul>
<h3 id="52-移动光标"><a class="markdownIt-Anchor" href="#52-移动光标"></a> 5.2 移动光标</h3>
<ul>
<li>光标切换到上方窗格：<code>tmux select-pane -U</code></li>
<li>光标切换到下方窗格：<code>tmux select-pane -D</code></li>
<li>光标切换到左边窗格：<code>tmux select-pane -L</code></li>
<li>光标切换到右边窗格：<code>tmux select-pane -R</code></li>
</ul>
<h3 id="53-交换窗格位置"><a class="markdownIt-Anchor" href="#53-交换窗格位置"></a> 5.3 交换窗格位置</h3>
<ul>
<li>当前窗格上移：<code>tmux swap-pane -U</code></li>
<li>当前窗格下移：<code>tmux swap-pane -D</code></li>
</ul>
<h3 id="54-窗格快捷键"><a class="markdownIt-Anchor" href="#54-窗格快捷键"></a> 5.4 窗格快捷键</h3>
<ul>
<li><code>Ctrl+b %</code>：划分左右两个窗格。</li>
<li><code>Ctrl+b &quot;</code>：划分上下两个窗格。</li>
<li><code>Ctrl+b &lt;arrow key&gt;</code>：光标切换到其他窗格。<code>&lt;arrow key&gt;</code> 指向要切换到的窗格方向键。</li>
<li><code>Ctrl+b ;</code>：光标切换到上一个窗格。</li>
<li><code>Ctrl+b o</code>：光标切换到下一个窗格。</li>
<li><code>Ctrl+b &#123;</code> 和 <code>Ctrl+b &#125;</code>：当前窗格与相邻窗格交换位置。</li>
<li><code>Ctrl+b Ctrl+o</code> 和 <code>Ctrl+b Alt+o</code>：所有窗格顺序调整。</li>
<li><code>Ctrl+b x</code>：关闭当前窗格。</li>
<li><code>Ctrl+b !</code>：将当前窗格拆分为一个独立窗口。</li>
<li><code>Ctrl+b z</code>：当前窗格全屏显示，再按恢复。</li>
<li><code>Ctrl+b Ctrl+&lt;arrow key&gt;</code>：调整窗格大小。</li>
<li><code>Ctrl+b q</code>：显示窗格编号。</li>
</ul>
<Br>
<h2 id="6窗口管理"><a class="markdownIt-Anchor" href="#6窗口管理"></a> 6.窗口管理</h2>
<p>除了划分窗格，Tmux 也允许新建多个窗口。</p>
<h3 id="61-新建窗口"><a class="markdownIt-Anchor" href="#61-新建窗口"></a> 6.1 新建窗口</h3>
<ul>
<li>新建窗口：<code>tmux new-window</code></li>
<li>新建指定名称的窗口：<code>tmux new-window -n &lt;window-name&gt;</code></li>
</ul>
<h3 id="62-切换窗口"><a class="markdownIt-Anchor" href="#62-切换窗口"></a> 6.2 切换窗口</h3>
<ul>
<li>切换到指定编号的窗口：<code>tmux select-window -t &lt;window-number&gt;</code></li>
<li>切换到指定名称的窗口：<code>tmux select-window -t &lt;window-name&gt;</code></li>
</ul>
<h3 id="63-重命名窗口"><a class="markdownIt-Anchor" href="#63-重命名窗口"></a> 6.3 重命名窗口</h3>
<ul>
<li>为当前窗口起名或重命名：<code>tmux rename-window &lt;new-name&gt;</code></li>
</ul>
<h3 id="64-窗口快捷键"><a class="markdownIt-Anchor" href="#64-窗口快捷键"></a> 6.4 窗口快捷键</h3>
<ul>
<li><code>Ctrl+b c</code>：创建新窗口。</li>
<li><code>Ctrl+b p</code> 和 <code>Ctrl+b n</code>：切换窗口。</li>
<li><code>Ctrl+b &lt;number&gt;</code>：切换到指定编号的窗口。</li>
<li><code>Ctrl+b w</code>：从列表中选择窗口。</li>
<li><code>Ctrl+b ,</code>：窗口重命名。</li>
</ul>
<br>
<h2 id="7其他命令"><a class="markdownIt-Anchor" href="#7其他命令"></a> 7.其他命令</h2>
<p>以下是一些额外的 Tmux 命令：</p>
<ul>
<li>列出所有快捷键：<code>tmux list-keys</code></li>
<li>列出所有 Tmux 命令及参数：<code>tmux list-commands</code></li>
<li>列出当前所有 Tmux 会话信息：<code>tmux info</code></li>
<li>重新加载 Tmux 配置：<code>tmux source-file ~/.tmux.conf</code></li>
</ul>
<br>
<h2 id="8演示过程"><a class="markdownIt-Anchor" href="#8演示过程"></a> 8.演示过程</h2>
<p>我们输入 <code>tmux new -s work</code> 创建一个 session：<br />
<img src="https://pic.imgdb.cn/item/6652c66ed9c307b7e9d5de08.png" alt="" /></p>
<p>可以看到后台已经启动了 tmux 的 server 进程，因此即使关闭你的 terminal，session 仍然在运行：<br />
<img src="https://pic.imgdb.cn/item/6652c708d9c307b7e9d682b1.png" alt="" /></p>
<p>输入 <code>prefix + d</code> 可以分离 session（注意：一定要松开 <code>prefix</code> 再按 <code>d</code>）：<br />
<img src="https://pic.imgdb.cn/item/6652d6bad9c307b7e9e8ce4d.png" alt="" /></p>
<p>如果想要重新连接已分离的 session，可以输入 <code>tmux attach -t [session-name]</code>。在上例中，session 名为 <code>work</code>，因此指令为 <code>tmux attach -t work</code>：<br />
<img src="https://pic.imgdb.cn/item/6652d71fd9c307b7e9e94344.png" alt="" /></p>
<p>若需重新命名 session，可以按下 <code>prefix + $</code>：<br />
<img src="https://pic.imgdb.cn/item/6652d798d9c307b7e9e9cab2.png" alt="" /></p>
<p>要查看所有 session，可以按下 <code>prefix + s</code>：<br />
<img src="https://pic.imgdb.cn/item/6652d7fad9c307b7e9ea320d.png" alt="" /></p>
<p>或者使用 <code>tmux ls</code> 查看所有 session：<br />
<img src="https://pic.imgdb.cn/item/6652d8d7d9c307b7e9eb1a1d.png" alt="" /></p>
<p>一个 session 可以包含多个窗口。创建 session 时会默认生成一个窗口，使用 <code>prefix + c</code> 可以创建新窗口（每个窗口前面有编号，当前窗口标记为 <code>*</code>，上一个窗口标记为 <code>-</code>）：<br />
<img src="https://pic.imgdb.cn/item/6652d98fd9c307b7e9ebded8.png" alt="" /></p>
<p>调整窗口：</p>
<ul>
<li><code>prefix + p</code>：切换到上一个窗口</li>
<li><code>prefix + n</code>：切换到下一个窗口</li>
<li><code>prefix + &lt;number&gt;</code>：跳转到指定编号的窗口</li>
</ul>
<p>按下 <code>prefix + w</code> 可以显示所有窗口列表：<br />
<img src="https://pic.imgdb.cn/item/6652da25d9c307b7e9ec72db.png" alt="" /></p>
<p>按下 <code>prefix + ,</code> 可以为窗口命名，左下角会显示更改后的名字：<br />
<img src="https://pic.imgdb.cn/item/6652dafdd9c307b7e9ed5991.png" alt="" /></p>
<p>在窗口中可以进行分割，按下 <code>prefix + &quot;</code> 可以水平分割，按下 <code>prefix + %</code> 可以垂直分割：<br />
<img src="https://pic.imgdb.cn/item/6652db73d9c307b7e9edd2e4.png" alt="" /></p>
<p><img src="https://pic.imgdb.cn/item/6652db8fd9c307b7e9edf1a1.png" alt="" /></p>
<p>移动窗格：</p>
<ul>
<li><code>prefix + &lt;方向键&gt;</code>：按方向键移动</li>
<li><code>prefix + ;</code>：切换到上一个窗格</li>
<li><code>prefix + o</code>：切换到下一个窗格</li>
</ul>
<p>要关闭当前窗格，可以按下 <code>prefix + x</code>：<br />
<img src="https://pic.imgdb.cn/item/6652dc5dd9c307b7e9eec7e4.png" alt="" /></p>
<p>将窗格转换为窗口（pane -&gt; window）：按下 <code>prefix + !</code>，可以看到窗口数量增加：<br />
<img src="https://pic.imgdb.cn/item/6652dcd2d9c307b7e9ef35ab.png" alt="" /></p>
<p>要最大化窗格，可以按下 <code>prefix + z</code>，左下角会提示已最大化，再按一次可以恢复：<br />
<img src="https://pic.imgdb.cn/item/6652dd49d9c307b7e9efb16b.png" alt="" /></p>
<h2 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h2>
<h3 id="表一系统指令"><a class="markdownIt-Anchor" href="#表一系统指令"></a> 表一：系统指令</h3>
<table>
<thead>
<tr>
<th>前缀</th>
<th>指令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>?</code></td>
<td>显示快捷键帮助文档</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>d</code></td>
<td>断开当前会话</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>D</code></td>
<td>选择要断开的会话</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>Ctrl+z</code></td>
<td>挂起当前会话</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>r</code></td>
<td>强制重载当前会话</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>s</code></td>
<td>显示会话列表用于选择并切换</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>:</code></td>
<td>进入命令行模式，此时可直接输入命令</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>[</code></td>
<td>进入复制模式，按<code>q</code>退出</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>]</code></td>
<td>粘贴复制模式中复制的文本</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>~</code></td>
<td>列出提示信息缓存</td>
</tr>
</tbody>
</table>
<h3 id="表二窗口window指令"><a class="markdownIt-Anchor" href="#表二窗口window指令"></a> 表二：窗口（Window）指令</h3>
<table>
<thead>
<tr>
<th>前缀</th>
<th>指令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>c</code></td>
<td>新建窗口</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>&amp;</code></td>
<td>关闭当前窗口（关闭前需输入<code>y</code> or <code>n</code>确认）</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>0~9</code></td>
<td>切换到指定窗口</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>p</code></td>
<td>切换到上一窗口</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>n</code></td>
<td>切换到下一窗口</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>w</code></td>
<td>打开窗口列表，用于选择切换窗口</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>,</code></td>
<td>重命名当前窗口</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>.</code></td>
<td>修改当前窗口编号（适用于窗口重新排序）</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>f</code></td>
<td>快速定位到窗口（输入关键字匹配窗口名称）</td>
</tr>
</tbody>
</table>
<h3 id="表三面板pane指令"><a class="markdownIt-Anchor" href="#表三面板pane指令"></a> 表三：面板（Pane）指令</h3>
<table>
<thead>
<tr>
<th>前缀</th>
<th>指令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>&quot;</code></td>
<td>当前面板上下一分为二，下`</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>Ctrl+方向键</code></td>
<td>以1个单元格为单位调整当前面板边缘（Mac下被系统快捷键覆盖）</td>
</tr>
<tr>
<td><code>Ctrl+b</code></td>
<td><code>t</code></td>
<td>显示时钟</td>
</tr>
</tbody>
</table>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.ruanyifeng.com/blog/2019/10/tmux.html">Tmux 使用教程 // 作者： 阮一峰 // 日期： 2019年10月21日</a></li>
<li><a href="https://louiszhai.github.io/2017/09/30/tmux/">Tmux使用手册</a></li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer、CNN、RNN复杂度比较</title>
    <url>/2024/02/28/Transformer%E3%80%81CNN%E3%80%81RNN%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考材料"><a class="markdownIt-Anchor" href="#参考材料"></a> 参考材料</h2>
<ul>
<li><a href="https://blog.csdn.net/Jerry_Lu_ruc/article/details/107690998">Transformer vs CNN vs RNN 时间复杂度比较</a></li>
<li><a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/264749298">Transformer/CNN/RNN的对比（时间复杂度，序列操作数，最大路径长度）</a></li>
<li><a href="https://blog.csdn.net/mumujia_/article/details/124934648">self-attention RNN CNN时间复杂度</a></li>
</ul>
<br>
<h2 id="说在前面"><a class="markdownIt-Anchor" href="#说在前面"></a> 说在前面</h2>
<p>本篇文章仅仅是为了解释这三者的复杂度比较，而对比结构等问题不做比较</p>
<p>n：输入序列长度</p>
<p>d：embedding的大小</p>
<br>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<table>
<thead>
<tr>
<th>Layer Type</th>
<th>Complexity per Layer</th>
<th>Sequential Operations</th>
<th>Maximum Path Length</th>
</tr>
</thead>
<tbody>
<tr>
<td>Self-Attention</td>
<td>O(n^2 · d)</td>
<td>O(1)</td>
<td>O(1)</td>
</tr>
<tr>
<td>Recurrent</td>
<td>O(n · d^2)</td>
<td>O(n)</td>
<td>O(n)</td>
</tr>
<tr>
<td>Convolutional</td>
<td>O(k · n · d^2)</td>
<td>O(1)</td>
<td>O(log_k(n))</td>
</tr>
<tr>
<td>Self-Attention (restricted)</td>
<td>O(r · n · d)</td>
<td>O(1)</td>
<td>O(n/r)</td>
</tr>
</tbody>
</table>
<br>
<h3 id="complexity-per-layer"><a class="markdownIt-Anchor" href="#complexity-per-layer"></a> Complexity per Layer</h3>
<p><strong>Transformer：</strong><br />
说在前面：对于矩阵乘法的时间复杂度计算=<strong>行 x 列 x 共享维度</strong></p>
<p><strong>n</strong>×d的矩阵Q和 d×<strong>n</strong>的矩阵KT相乘的时间复杂度 为 O(n^2 d)</p>
<p>n×n的矩阵softamx(Q*KT)和 n×d的矩阵V相乘的时间复杂度 为 O(n^2 d)</p>
<p>而softmax(n×n)的时间复杂度为 O(n^2)</p>
<p>所以self-attention最终的时间复杂度为 O(n^2 d)（选最大的）</p>
<br>
<p><strong>RNN:</strong><br />
考虑到矩阵（维度为𝑛 x 𝑛）和输入向量相乘，因此RNN每层计算复杂度为𝑂(𝑛 x 𝑑^2)</p>
<p><img src="https://pbs.twimg.com/media/GHZcLjDX0AA2JtW?format=png&amp;name=900x900" alt="" /></p>
<br>
<p><strong>CNN：</strong><br />
注：这里保证估计输入输出都是一样的，即均为 n × d</p>
<p>需要对输入进行padding操作，因为这里kernel size为 k，（实际kernel的形状为 k × d）如果不padding的话，那么输出的每一个维度为 n − k + 1，因为这里stride是为1的。对于保证估计输入输出相同，则需要对序列的前后分别padding长度为 (k − 1) / 2。</p>
<p><strong>大小为 k × d 的卷积核在一次运算的复杂度是： O(kd)，这里直接理解为一维卷积</strong></p>
<p>一共做了 n 次(每个数据都要卷积，所以是n次)，故复杂度为 O(nkd)</p>
<p>对于证估计一维维度在每一个维度都相同，故需要 d 个卷积核 <strong>(输出通道数=卷积核个数)</strong> ，所以总体来看操作是的时间复杂度为 O(nkd²)</p>
<br>
<h2 id="sequential-operations"><a class="markdownIt-Anchor" href="#sequential-operations"></a> Sequential Operations</h2>
<p>表明三种模型的并行程度：从计算方式上看，只有RNN才需要串行地完成<br />
次序列操作，而self-attention和convolution <strong>(因为我们计算是按顺序计算的，但是实际计算机计算是可以并行计算的)</strong> 的n次序列操作均可以并行完成。因为RNN还需要依赖于上一个时间步的隐藏层输出，而其他模型仅仅依赖于输入。</p>
<br>
<h2 id="maximum-path-length"><a class="markdownIt-Anchor" href="#maximum-path-length"></a> Maximum Path Length</h2>
<p><img src="https://pbs.twimg.com/media/GHZiFpoX0AAsRq7?format=jpg&amp;name=medium" alt="" /></p>
<p><strong>RNN：</strong><br />
长度为 n的序列中，节点之间的最大路径长度为n，即o(n)。第一个token的信息需要经过n次迭代才能传到最后一个时间步的状态中，信息丢失严重，很难建立节点间的长距离依赖。</p>
<br>
<p><strong>CNN:</strong><br />
通过convolution layer来逐渐扩大感知域，扩大感知域可以理解为增大每个“看到”的local context的大小/取值区间的能力。在一次卷积操作中，感知域L的CNN中，能看到最大的local context的大小/取值区间 L(k − 1) + 1，最大增长长度为</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mo fence="true">[</mo><mfrac><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></mfrac><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mfrac><mi>n</mi><mi>k</mi></mfrac><mo fence="true">]</mo></mrow><mtext>，</mtext></mrow><annotation encoding="application/x-tex">\left[ \frac{n-1}{k-1} \right] = \left[ \frac{n}{k} \right] ，
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.8359999999999999em;vertical-align:-0.686em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">，</span></span></span></span></span></p>
<p>例如图(b)中是一个两层的卷积核大小为3的CNN，顶层节点能看到的最大local context为2*2+1=5个token的范围。根据这样，上图可以得出一个 k 大小，深度为 h 的树，叶子节点总数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mi>h</mi></msup></mrow><annotation encoding="application/x-tex">k^h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span></span></span></span></span></span></span> = n，解得最大深度树的深度 h = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mi>k</mi></msub><mi>n</mi></mrow><annotation encoding="application/x-tex">log_k n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">n</span></span></span></span>，即 O(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mi>k</mi></msub><mi>n</mi></mrow><annotation encoding="application/x-tex">log_k n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">n</span></span></span></span>)</p>
<br>
<p><strong>Transformer:</strong><br />
Self-attention: 任意两个位置都可以直接相连，即任意两个位置之间的距离为1</p>
<p>受限的self-attention: 类似于考虑大小为 r 的CNN, 最大路径长度为 O(n/r)</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>CNN</tag>
        <tag>Transformer</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch中的继承以及nn.Moudle</title>
    <url>/2024/05/05/Pytorch%E4%B8%AD%E7%9A%84%E7%BB%A7%E6%89%BF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h3 id="1继承是什么"><a class="markdownIt-Anchor" href="#1继承是什么"></a> 1.继承是什么？</h3>
<p>如下定义一个动物类Animal为基类，它基本两个实例属性name和age、一个方法call。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>(<span class="title class_ inherited__">object</span>):  <span class="comment">#  python3中所有类都可以继承于object基类</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, age</span>):</span><br><span class="line">       self.name = name</span><br><span class="line">       self.age = age</span><br><span class="line"></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self</span>):</span><br><span class="line">       <span class="built_in">print</span>(self.name, <span class="string">&#x27;会叫&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">######</span></span><br><span class="line"><span class="comment"># 现在我们需要定义一个Cat 猫类继承于Animal，猫类比动物类多一个sex属性。 </span></span><br><span class="line"><span class="comment">######</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cat</span>(<span class="title class_ inherited__">Animal</span>):</span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,age,sex</span>):</span><br><span class="line">       <span class="built_in">super</span>(Cat, self).__init__(name,age)  <span class="comment"># 不要忘记从Animal类引入属性</span></span><br><span class="line">       self.sex=sex</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  <span class="comment"># 单模块被引用时下面代码不会受影响，用于调试</span></span><br><span class="line">   c = Cat(<span class="string">&#x27;喵喵&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;男&#x27;</span>)  <span class="comment">#  Cat继承了父类Animal的属性</span></span><br><span class="line">   c.call()  <span class="comment"># 输出 喵喵 会叫 ，Cat继承了父类Animal的方法 </span></span><br><span class="line">```  </span><br><span class="line">注意：一定要用 <span class="built_in">super</span>(Cat, self).__init__(name,age) 去初始化父类，否则，继承自 Animal的 Cat子类将没有 name和age两个属性。</span><br><span class="line"></span><br><span class="line">函数<span class="built_in">super</span>(Cat, self)将返回当前类继承的父类，即 Animal，然后调用__init__()方法，注意self参数已在<span class="built_in">super</span>()中传入，在__init__()中将隐式传递，不能再写出self。</span><br><span class="line"></span><br><span class="line">注意当`call`函数没有被定义的时候，会使用父类的`call`函数，而子类已经定义`call`函数的时候会优先使用自身定义的`call`函数。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 2. `nn.Moudle`详解</span></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Module</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *<span class="built_in">input</span></span>):</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_module</span>(<span class="params">self, name, module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cuda</span>(<span class="params">self, device=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cpu</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *<span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parameters</span>(<span class="params">self, recurse=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">named_parameters</span>(<span class="params">self, prefix=<span class="string">&#x27;&#x27;</span>, recurse=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">children</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">named_children</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">modules</span>(<span class="params">self</span>):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">named_modules</span>(<span class="params">self, memo=<span class="literal">None</span>, prefix=<span class="string">&#x27;&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, mode=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">zero_grad</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">有一部分没有完全列出来</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>解释：</p>
<ul>
<li>training (bool) - 指示模块当前是训练还是评估模式</li>
<li>add_module() - 添加子模块</li>
<li>apply() - 递归地将函数应用于所有子模块</li>
<li>buffers() - 返回模块 buffer 的迭代器</li>
<li>children() - 返回直接子模块的迭代器</li>
<li>cpu()/cuda()/etc. - 将模块移动到相应设备</li>
<li>double()/float()/etc. - 将模块参数和 buffer 转换为相应数据类型</li>
<li>eval() - 将模块设为评估模式</li>
<li>forward() - 定义前向传播计算,所有子类需要重写</li>
<li>register_buffer() - 向模块添加 buffer</li>
<li>register_parameter() - 向模块添加参数</li>
<li>state_dict() - 返回模块状态的字典表示</li>
<li>load_state_dict() - 从字典中加载模块状态</li>
<li>parameters()/named_parameters() - 返回可训练参数的迭代器</li>
<li>modules()/named_modules() - 返回所有子模块的迭代器</li>
<li>zero_grad() - 将所有参数的梯度设为0</li>
<li>train()/eval() - 设置模块为训练/评估模式</li>
</ul>
<h3 id="3注意技巧"><a class="markdownIt-Anchor" href="#3注意技巧"></a> 3.注意技巧</h3>
<p>我们一般定义自己的网络的时候，会继承这个<code>nn.Moudle</code>,并重新构造<code>__init__</code>和<code>forward</code>这两个def，但有一些技巧需要注意：</p>
<ul>
<li>将具有<strong>可学习参数的层</strong>放在构造函数<code>__init__</code>中</li>
<li>foward方法必须重写，实现各个层连接</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyNet</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyNet, self).__init__()  <span class="comment"># 第一句话，调用父类的构造函数</span></span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.relu1=torch.nn.ReLU()</span><br><span class="line">        self.max_pooling1=torch.nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.relu2=torch.nn.ReLU()</span><br><span class="line">        self.max_pooling2=torch.nn.MaxPool2d(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line">        self.dense1 = torch.nn.Linear(<span class="number">32</span> * <span class="number">3</span> * <span class="number">3</span>, <span class="number">128</span>)</span><br><span class="line">        self.dense2 = torch.nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.relu1(x)</span><br><span class="line">        x = self.max_pooling1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.relu2(x)</span><br><span class="line">        x = self.max_pooling2(x)</span><br><span class="line">        x = self.dense1(x)</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"> </span><br><span class="line">model = MyNet()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;运行结果为：</span></span><br><span class="line"><span class="string">MyNet(</span></span><br><span class="line"><span class="string">  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span><br><span class="line"><span class="string">  (relu1): ReLU()</span></span><br><span class="line"><span class="string">  (max_pooling1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="string">  (conv2): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span></span><br><span class="line"><span class="string">  (relu2): ReLU()</span></span><br><span class="line"><span class="string">  (max_pooling2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="string">  (dense1): Linear(in_features=288, out_features=128, bias=True)</span></span><br><span class="line"><span class="string">  (dense2): Linear(in_features=128, out_features=10, bias=True)</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h3>
<ul>
<li><a href="https://blog.csdn.net/qq_27825451/article/details/90550890">pytorch教程之nn.Module类详解——使用Module类来自定义模型</a></li>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">Module</a></li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>继承</tag>
      </tags>
  </entry>
  <entry>
    <title>Undergraduate VS Graduate</title>
    <url>/2024/01/25/Undergraduate-VS-Graduate/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="本科生-vs-研究生"><a class="markdownIt-Anchor" href="#本科生-vs-研究生"></a> 本科生 VS 研究生</h1>
<p>如果你有实际开发工作经验，感觉自己的水平和实力进入了一个高原期，迫切需要从理论上提高，那么计算机学院是唯一选择。因为计算机学院才能让你在理论上更上一层楼。软件学院从教学计划上就没有把你往这方面带。当然能不能更上一层楼最终还是完全取决于你自己。需要特别说明的是，工作经验并不一定等于开发经验，我见过很多工作2-3年的人，但是没有一点开发经验。</p>
<p>你说：“他们都有很强的开发能力,只是不太喜欢读书,也只是希望混个学历对今后在岗位上晋升有好处”，我可以向你保证，你所说的人绝对不是开发能力很强的人。因为</p>
<ul>
<li>1）高手不可能不喜欢读书；</li>
<li>2）高手不可能想去混一个学历；</li>
<li>3）高手不可能认为晋升是因为学历的原因。</li>
</ul>
<p>还需要说明的是，考计算机的人未必个个都是高手，严格来说，大部分都不会编程序。也就是说，庸庸碌碌之辈仍然占绝大多数。研究生毕业的师兄只拿2500元左右的比比皆是，所以不要寄希望于拿一张研究生文凭出去赚高薪。但是，对于有实际开发工作经验的人，要想自己在3年之中有一个真正的提高的话，计算机学院提供了广阔的平台。就我所知，每一个月拿2万以上的也有（上海育碧，图形特效算法设计）。所以，同为研究生毕业，能力的差距是极大的。所以，不要去问“研究生毕业能拿多少？”，要问“像我这种水平的人，研究生毕业能拿多少钱？”这样人家才能够准确地回答你。</p>
<p>所谓“有实际开发工作经验”是指你目前已经具备下列能力：</p>
<ul>
<li>（1. 你已经认为C++和汇编语言都是很简单的语言，并能够自如地运用；</li>
<li>（2. 你能够在30分钟之内想到正确的五子棋AI算法设计思路和方向；</li>
<li>（3. 你完全理解STL为什么这么重要；</li>
<li>（4. 你能够独立地解决所有的编译与链接问题，哪怕你从来没有遇到的问题，你也不需要询问任何人；</li>
<li>（5. 英文网站是你的首要信息来源；</li>
<li>（6. 能够读懂英语写成的国际标准，比如NTFS磁盘格式标准；</li>
<li>（7. 你经常站在集合论的角度思考算法问题；</li>
<li>（8. 能够理解一个简单的驱动程序，能够理解一个简单3D交互程序；</li>
<li>（9. 你能够认识到线性代数和概率论在实际编程工作中的极端重要性；</li>
<li>（10. 你完全理解COM的设计思想，尤其能够理解COM为什么要设计成这样；</li>
<li>（11. 当我说到虚函数的重要作用时，你不会急着去找书来翻；</li>
<li>（12. 你能够说出C++为什么比其他语言优秀的理由，记住这种理由应该来自于你的开发体会，而不是因为其他人都这么说。此外还有很多判断标准，但如果你同时具备5条以上，可以认为你已经具备相应的开发经验了。在这种状态下读研，你将取得读研效益的最大值。</li>
</ul>
<p>读研最重要的是要明白你自己要干什么，不能等导师来告诉你你应该干什么。研究生的优势在于理论功底深厚，思维具有穿透力，当然编程能力首先要过关，不要读完研究生还不知道MFC程序的WinMain函数在哪里。所以，研究生期间，你一定要做有理论深度的算法设计，比如大规模数据的搜索算法，性能是首要考虑因素，不要奢望SQL函数能够帮你解决问题，所有的问题你都必须自己解决，你必须解决内外存交换的性能瓶颈。再比如极品飞车的3D场景生成，图形变换，碰撞检测，物性模拟，纹理映射，灯光模型等等，这些都是可以保证你能拿到2万以上月薪的技术。如果你认为这些东西太难，不可能做得出来的话，那么你就不适合读研。真的，如果你认为读研之后还是要去搞一般的程序设计，如信息管理系统之类的件，那么你读研的价值就完全不会得到体现，因为这些工作根本就不需要读研。</p>
<p>软件学院宣称培养软件开发人才，恕我直言，我从来没有看见那个高手是培训成功的。成为软件开发高手的路只有一条：自学！软件开发中需要大量的编程实践和独立思考，只有在此过程中，你才能够逐步成长起来。软件学院宣称培养软件项目经理，这更是搞笑，在某种意义上这是欺骗行为。学院里面能够培养出软件开发经理更是十足的谎言，软件项目经理必须，或者说更强调从战争中学会战争。没有实践经验的项目经理就是绣花枕头一个。</p>
<p>实话实说，软件学院就是一个蒙钱的机构，公关工作做得很好，善于打广告，而且都是打着高薪的幌子，就如同外面的什么北大青鸟培训班一样。两个字：蒙钱！四个字：还是蒙钱！</p>
<p>总之一句话，如果你只想成为软件开发高手（比如认为会编驱动程序或杀毒软件就是高手的那种），建议工作，不要考研；完全没有工作经验的，也不建议考研，你进来了只有瞎混一通。如果你有上述工作经验且想成为高级软件工程师（能够独立理解并设计出快速傅立叶变换算法的那种软件工程师）的话，那么强烈建议考研。考研让你有3年放松思考的机会，也有3年让你思想和技术积累沉淀的机会。非常难得的机会。不考研的话，这种机会就是一种奢侈，可望而不可即的那么一种奢侈。</p>
<p>所以，不管你是哪一种情况，都不建议考软件学院。除非你是女生，把能够成为一个研究生当着一生最大满足的那种女生。</p>
<p>1）关于读书的机会成本问题。读研的机会成本的确是很高。任何人都可以简单地计算出来。所以，我也不赞成所有的人都去读研。读研只适合那些痛感数学在编程中的极端重要性的人。如果对理论工具和理论思维的极端重要性没有切肤的认识，那么读研的价值几乎为0；读研的好处在于：</p>
<ul>
<li>A，把你自己放在一个学术和工程的交叉点上；</li>
<li>B，让你具备了进入微软等世界顶级软件研发机构的可能性；记住只是可能性。但是不读研这种可能性为0；</li>
<li>C，如前所述，如果没有读研的机会，你也就没有静下心来好好钻研几年理论的机会；一边工作拿高薪，一边深入地学习各种理论，诸位认为这可能吗？我反正认为不可能，我觉得学习钻研理论最需要的就是一个长期安静独处的环境，一边工作一边读书是不可能有这样的环境的，你会觉得每天都在疲于奔命。而读研正好可以提供这样一个环境。我同时还反对整天跟着导师的屁股后面跑，这样会浪费很多时间。读计算机的研究生，主要依靠自己去查阅最新文献，自己去研读文献，和导师的口头交流一个月一次就足够了，前提还需要导师的水平足够牛。如果导师的水平不牛，这也没关系，不理他就是了，自己做好自己的事情即可。</li>
</ul>
<p>2）关于研究生教学质量问题。坦白地说，全国都是“洪桐县中无好人”，尤其在计算科学领域，大牛极少。那为什么还要去读研？大哉问！把读研的收获寄托在名校或名师的名气上，是注定要失败的。读研全靠自学，研究生之间的差距全部体现在自学能力上面。又有人问，既然是自学，为什么非要读研？回答是：因为读研就是为你买一份保险，就是买一份你自学三年之后不会失业的保险。这份保险主要是一种心理上的后盾，让你在自学过程中经得起诱惑，能够从容镇定地去追寻计算机理论发展的坚实足迹，从欧拉，费马，高斯，康托，图灵等巨匠那里寻找方法论的珠宝。倘若没有这份保证，你在家里面自学3个月，保证你会被失业的压力压得喘不过气来，何谈安心学习？</p>
<p>3）关于实战经验与理论学习的优劣问题。这没有定论，如前所述，管理信息系统，设备驱动开发，工具软件开发，软件病毒剖析等等这些工作不太需要创造性，需要的是耐心和经验，需要的是对既有规范的准确理解，这类开发工作最适合在实战中提高，理论学习没什么作用。但是在人工智能，模式识别，图像压缩，虚拟现实，巨量数据检索，自然语言理解，计算机图形学等等领域，理论学习就占据着绝对的统治地位！这些领域的突破对人类的生活的影响是极其巨大而深刻的。某些领域处于一个极其快速发展的态势之中，比如计算机图形学，相信诸君能够从众多3D游戏的灿烂辉煌中体认到我的这种说法。在这些领域，如果没有扎实的理论功底，一切都是那么遥远，不管你花了多少时间在编程上面。</p>
<p>4）关于高级研发人员的知识结构问题。首先声明，我不是一个纯粹理论激进分子，即认为除了理论之外，一切都不重要。我认为，纯熟的编程技能是最基本但也是最必不可少的技能。没有这个基础，一切计算机理论就是空谈（研究图灵可计算性理论的研究者除外）。有了这个基础之后，下列理论学习方向必须重点突破：</p>
<ul>
<li>
<ol>
<li>科学哲学。这是核心中的核心！可惜国内不开这门课。不但不开课，而且还作为批判对象来引用，实在是遗憾至极！这是一门教你如何“钓鱼”的学科，在一切科学研究中居于最核心的地位。它是古今科研方法和思维方法的集大成者，很难想象一个成熟的研究者没有一套自己的方法论体系。科学哲学最需要的是领会与总结，它的思想与启示会伴随我们的一生。</li>
</ol>
</li>
<li>
<ol start="2">
<li>康托集合论，矩阵方法，离散结构，图论方法，群论方法之间的紧密关系。最重要的认识这些理论对实践的重要启示和方法引导。我始终认为，如果你学了一门理论之后，却不知道这门理论有什么作用，那么你的理论就白学了，你什么东西都没有捞着。所以，学习任何理论之前，先问自己：它有什么用？在哪里用？如何用？带着这些问题去学习理论，你才会真正地学到东西。用这三个问题去问你的理论课老师，他的回答就是判断其实际水平的最佳标准。</li>
</ol>
</li>
<li>
<ol start="3">
<li>思维要有极强的穿透力，学会看透文献作者没有写出来的动机。绝大部分大师都有隐瞒自己最具有方法论启示意义的思考环节的习惯。牛顿和华罗庚先生都有这个坏习惯。这让大家认为他们是天才，因为很多问题他想到了，我们想不到。但是为什么他们能想到，我们想不到？他们是怎样想到的？没有人告诉我们牛顿发现万有引力定律时的思考过程，当然，牛顿可以慷慨地把他的思考结果告诉我们，但是，他那可以点石成金的“金手指”却没有教给我们。我们的任务就是要培养透过文章看穿作者背后意图和动机的能力，在这方面，台湾的侯捷和美国的Donbox是绝佳典范。这两只老狐狸（呵呵，是爱称）凭着其猎犬一般的嗅觉，抽丝剥茧，一个把COM背后的幕后设计动机揭开并暴露到了光天化日之下，另一个把MFC的宏观架构做了一次完美的外科手术。其非凡的思维穿透力令人惊叹。</li>
</ol>
</li>
<li>
<ol start="4">
<li>英语。英语本身不重要，但是用英语写成的文献就极其重要了。所以，专门把英语作为一个重头戏列出来。大家不要相信英语无用论的鬼话。对于搞计算机的而言，英语就是你的母语！</li>
</ol>
</li>
<li>
<ol start="5">
<li>其它的具体理论还有很多，但是都不如这三个方面重要，因为我觉得这三个方面是最具有根本性，全局性的能力培养环节。需要指出的是，很多高深理论对你的工作是无意义的，当心时间陷进去。一定要把效率最高的时间段用在最具有决定性意义的理论学习上。</li>
</ol>
</li>
</ul>
<p>5）关于读研之后的出路是否光明的问题。我们应该承认，读研之后，你的工作机会不是变多了，而是变少了。而且越是高手，他的工作机会和工作范围就越少。这是因为，越是搞前沿研发的公司，其数量越少，在这个圈子的人也就越少。你找工作的范围就越小，试问：如果微软的OS设计专家出来找工作，能够让他选择的公司能有几家？但是，这种公司数量的减少是以工资待遇的急剧上升为补偿的，同时，你在工作中所受到的充分尊重也是在一般公司中体会不到的。所以不要担心学了高科技用不上，呵呵，你只会越来越感觉自己学的不够用。相信接到过猎头公司电话的人会体会得到。真正的高手从来就不会担心工作的问题，也从来不会到人才市场上去找工作。既然选择了理论深入，那么就应该把眼光放得更远。</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>Undergraduate</tag>
        <tag>Graduate</tag>
      </tags>
  </entry>
  <entry>
    <title>University-Recommendation</title>
    <url>/2023/07/23/University-Recommendation/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="recommendation-list"><a class="markdownIt-Anchor" href="#recommendation-list"></a> recommendation list</h1>
<h2 id="1香港"><a class="markdownIt-Anchor" href="#1香港"></a> 1.香港🇭🇰</h2>
<h3 id="ahku"><a class="markdownIt-Anchor" href="#ahku"></a> a.HKU</h3>
<p>HKU-香港大学：通常短学制，项目很多，有的很难、有的很简单，对北邮比较友好（国院有计算机项目提前批，申请季之前就发offer，2022年港大计算机给国院提前批就发了33个offer，可作定心丸使用，不过大家一般都有更好的去处，不管怎样，先拿个offer保底再说）</p>
<h3 id="bhkust"><a class="markdownIt-Anchor" href="#bhkust"></a> b.HKUST</h3>
<p>HKUST-香港科技大学：通常短学制，项目很多，有的很难、有的很简单，对北邮友好程度不如HKU和CUHK，新开广州校区可能是机会</p>
<h3 id="ccuhk"><a class="markdownIt-Anchor" href="#ccuhk"></a> c.CUHK</h3>
<p>CUHK-香港中文大学：通常短学制，项目很多，有的很难、有的很简单，深圳校区地位尴尬，是否算境外留学生尚有疑问。对北邮比较友好</p>
<h2 id="2新加坡"><a class="markdownIt-Anchor" href="#2新加坡"></a> 2.新加坡🇸🇬</h2>
<h3 id="anus"><a class="markdownIt-Anchor" href="#anus"></a> a.NUS</h3>
<p>NUS-新加坡国立大学：项目很多，有的很难、有的很简单。北邮近几年有不少选手申请，和计算机院有本硕联培，但不是每年都有，具体请留意信息门户通知</p>
<h3 id="bntu"><a class="markdownIt-Anchor" href="#bntu"></a> b.NTU</h3>
<p>NTU-南洋理工大学：项目很多，有的很难、有的很简单。北邮近几年有不少选手申请</p>
<h2 id="香港和新加坡的总结"><a class="markdownIt-Anchor" href="#香港和新加坡的总结"></a> 香港和新加坡的总结</h2>
<p>性价比还行，成本比英国低一些，留学中介非常喜欢推荐这俩地方和英国，中介的首要目标是保证你有书读、而不是读什么书，这俩地方和英国的短学制项目都不少。有些人觉得香港留学很奇怪，没有留学的感觉，体验很一般，这个不同人需求不同吧，不过要是真想好好留学，且预算比较充足的话，还是建议远离华人文化圈去留学，体验更好、学到的东西也更多（不只是学业方面）。如果只是想读个书然后火速回到国内就业，那么港新可以说是首选。另外，如果想要去新加坡工作，一定要先去新加坡读书，新加坡读书毕业之后两年可以拿永居（近两年好像有所变化），这个永居很重要，相当于把你看成是自己人，没有永居在新加坡求职市场上寸步难行，大部分好公司只招具备永居权的人士</p>
<h2 id="3加拿大"><a class="markdownIt-Anchor" href="#3加拿大"></a> 3.加拿大🇨🇦</h2>
<h3 id="auoft"><a class="markdownIt-Anchor" href="#auoft"></a> a.UOFT</h3>
<p>多伦多大学：多数项目介于长学制和短学制之间，项目很多，录取难度不一。北邮近几年申请非常多，应该是北邮中上等学生在去不了美国之后的首选，近几年连年扩招，北邮最后去这的很多。缺点是学费不便宜，以及学校规模太大</p>
<h3 id="buwaterloo"><a class="markdownIt-Anchor" href="#buwaterloo"></a> b.UWaterloo</h3>
<p>滑铁卢大学：难度稍低于UofT，项目太多，总体不好评价，有很不错的精品项目。北邮近几年申请人数很多，最后去的也不少</p>
<h3 id="cmcgill"><a class="markdownIt-Anchor" href="#cmcgill"></a> c.McGill</h3>
<p>麦吉尔大学：当地声誉很好，学术声誉很好，项目很多，录取难度不好评价。近几年北邮有人申请，但是最后似乎去的人不是很多</p>
<h3 id="dubc"><a class="markdownIt-Anchor" href="#dubc"></a> d.UBC</h3>
<p>英属哥伦比亚大学：录取难度很迷，有的项目难出天际、有的又是有手就行。同样是北邮去不了美国之后的热门选项，除了名字比较野鸡以外，挺好的。学费是多伦多的一半，比较亲民</p>
<h3 id="emcmaster"><a class="markdownIt-Anchor" href="#emcmaster"></a> e.McMaster</h3>
<p>麦克马斯特大学：难度略低于上述几所</p>
<h2 id="加拿大特别说明"><a class="markdownIt-Anchor" href="#加拿大特别说明"></a> 加拿大特别说明</h2>
<p>适合移民，适合加拿大读研、美国工作。研究生毕业如有雇主担保即可排队拿身份，速度很快，拿到身份之后可给配偶/父母排队，同样非常快，有全家移民想法的可优先考虑加拿大。加拿大身份几乎等同于美国身份，在去不了美国的情况下不妨曲线救国。一般而言加拿大费用比欧洲高，但加拿大有些第二梯队学校硕士有时会有丰厚经学金，论坛见过相关信息。加拿大回国认可度也行</p>
<h2 id="4爱尔兰"><a class="markdownIt-Anchor" href="#4爱尔兰"></a> 4.爱尔兰🇮🇪</h2>
<p>TCD-圣三一学院：适合找工/移民选手，录取难度低，属于中等学生都可以拿来保底的那种，极其不适合回国。没听说北邮谁最后去了这里，可能是北邮学历去TCD有些浪费</p>
<h2 id="5英国"><a class="markdownIt-Anchor" href="#5英国"></a> 5.英国🇬🇧</h2>
<h3 id="aoxcam"><a class="markdownIt-Anchor" href="#aoxcam"></a> a.OX&amp;Cam</h3>
<p>牛津&amp;剑桥：啥都不用说，天花板级别，一个字，难，在美国对中国学生越发不欢迎的前提下，顶尖选手转投牛剑的越来越多。近几年北邮本科也有牛剑选手，牛剑电子、通信近几年有一些北邮人，北邮本清北硕倒是年年有牛剑博</p>
<h3 id="bic"><a class="markdownIt-Anchor" href="#bic"></a> b.IC</h3>
<p>帝国理工学院：名字挺唬人，在国内知名度也很大，但是实力也就那样，每个领域都好、但都不是英国最好的，地位有些尴尬，项目很多，水项目也很多，录取难度视项目而定。简要概括，是北邮申英中上等选手的常见选择，有不少去的，几乎它的所有项目都有北邮人（除了生化环材之类的没有北邮人）</p>
<h3 id="cucl"><a class="markdownIt-Anchor" href="#cucl"></a> c.UCL</h3>
<p>伦敦大学学院：项目很多，水项目也很多，录取难度视项目而定。简要概括，是北邮申英中上选手的常见选择，和IC地位差不多，但是综合性更强，北邮近几年去的人和IC也差不多，大概是各持所需吧</p>
<h3 id="dedinburgh"><a class="markdownIt-Anchor" href="#dedinburgh"></a> d.Edinburgh</h3>
<p>爱丁堡大学：人工智能&amp;计算机规模极大、实力极强，人工智能科研水平很高，难度自然也是不低，能申到肯定是值得去。北邮中上选手近几年申英常见选项，最后也有一些去的。另，它也有一些比较好录的专业，但不太推荐</p>
<h3 id="ekcl"><a class="markdownIt-Anchor" href="#ekcl"></a> e.KCL</h3>
<p>伦敦国王学院：镀金常见选择，计算机&amp;数据相关项目比较卷，其他还好，近几年北邮有一些去的</p>
<h3 id="flse"><a class="markdownIt-Anchor" href="#flse"></a> f.LSE</h3>
<p>伦敦政治经济学院：和北邮气质不合，除了商科大佬还是略过吧</p>
<h3 id="glbs"><a class="markdownIt-Anchor" href="#glbs"></a> g.LBS</h3>
<p>伦敦商学院：不懂行的人或许认为是野鸡，但实际上和沃顿商学院齐名，在金融业内横扫一切的存在。LBS不提供本科，仅提供硕士与博士教育，学费贵、难度大，近乎无敌的就业辅导中心，可以不限次数直接联系顶级大佬聊天、可以直推顶级金融机构。2022年有北邮人申到LBS（还是最好的专业），仅凭其录取通知就拿到了软银赛富的实习岗位</p>
<h3 id="hmachester"><a class="markdownIt-Anchor" href="#hmachester"></a> h.Machester</h3>
<p>曼彻斯特大学：难度不高，计算机相关项目都还行，近几年有北邮人去</p>
<h3 id="ibristol"><a class="markdownIt-Anchor" href="#ibristol"></a> i.Bristol</h3>
<p>布里斯托大学：国院中等学生主申选项之一，难度不高，项目录取难度不一</p>
<h3 id="jwarwick"><a class="markdownIt-Anchor" href="#jwarwick"></a> j.Warwick</h3>
<p>华威大学：综合性比LSE强那么一点点，但主打还是商科，计算机也还行，北邮人比较少</p>
<h3 id="ksouthampton"><a class="markdownIt-Anchor" href="#ksouthampton"></a> k.Southampton</h3>
<p>南安普顿大学：南安太经典了，难度不高，可能是北邮人最多的学校（之一？），大概是国院申英的主力吧</p>
<h3 id="lglasgow"><a class="markdownIt-Anchor" href="#lglasgow"></a> l.Glasgow</h3>
<p>格拉斯哥大学：成电国院的合作院校，人家的合作院校从qs100之外进了qs100以内，比咱们的QM争气多了，不过地理位置比QM差多了。北邮近几年也有去的，似乎不多</p>
<h3 id="mdurham"><a class="markdownIt-Anchor" href="#mdurham"></a> m.Durham</h3>
<p>杜伦大学：比较陌生，似乎北邮人很少</p>
<h3 id="nsheffield"><a class="markdownIt-Anchor" href="#nsheffield"></a> n.Sheffield</h3>
<p>谢菲尔德大学：谢菲也很经典，难度不高，北邮人多（应该比南安少一些），水分视具体项目而定</p>
<h3 id="oqm"><a class="markdownIt-Anchor" href="#oqm"></a> o.QM</h3>
<p>伦敦大学玛丽女王学院：北邮专用保底校，号称点击就送，北邮国院学生甚至没有语言要求，要是连QM都申不到，还是别出国了，QM常年在世界100出头，能不能争争气进前一百啊，这样咱们也能躺平去前一百了，不过QM位置不错，而且计算机领域水平也挺好的</p>
<h2 id="英国特别说明"><a class="markdownIt-Anchor" href="#英国特别说明"></a> 英国特别说明</h2>
<p>学校太多，且多数研究生项目是短学制（说是一年，其实只有十个月，再去掉假期和论文，时间更短了），就是把本科阶段部分课程用英语再上一遍，毕业即回国（留英国非常难，目标移民的选手请申欧洲或加拿大），学费贵（比欧洲贵，和加拿大互有高低但加拿大项目没那么水），生活成本也高（但是也就一年，花销也大不到哪去）。如果不是G5+爱丁堡，几乎对未来就业没有太大帮助。除了短学制外，有研究型硕士，但是坑位少，难度大。近几年北邮也有不少去英国（国院选手居多），去不了美国之后，北邮整体去英国最多</p>
<h2 id="6澳大利亚"><a class="markdownIt-Anchor" href="#6澳大利亚"></a> 6.澳大利亚🇦🇺</h2>
<h3 id="aanu"><a class="markdownIt-Anchor" href="#aanu"></a> a.ANU</h3>
<p>澳洲国立大学：从名字上看可能不少人会认为是澳洲第一校，其实不然，ANU也属于是大而不强，各个项目认可度和含金量都算是中等偏上，推荐程度还可以。近几年北邮有一些去的</p>
<h3 id="bunsw"><a class="markdownIt-Anchor" href="#bunsw"></a> b.UNSW</h3>
<p>新南威尔士大学：澳洲计算机&amp;商科第一校，地域也是澳洲最好的悉尼，综合程度和世界排名不如ANU，在当地认可度高于ANU，但似乎回国认可度不如ANU（回国认可度这种东西最终还是看你自己强不强），北邮人似乎比较少</p>
<h3 id="cunimelb"><a class="markdownIt-Anchor" href="#cunimelb"></a> c.UniMelb</h3>
<p>墨尔本大学：自称南半球第一学府，笑笑就行了，不必当真，大概和ANU和UNSW是一个级别的，都算是南半球第一梯队。是知名的镀金院校，北邮人不多，但是文科见长的大学的毕业生很喜欢去UniMelb读个教育学硕士之类的东西</p>
<h3 id="dusyd"><a class="markdownIt-Anchor" href="#dusyd"></a> d.USYD</h3>
<p>悉尼大学：申请难度中等，但是意义不是很大，除了地域好以外，似乎没有太突出的优点，近几年北邮人似乎较少</p>
<h3 id="euq"><a class="markdownIt-Anchor" href="#euq"></a> e.UQ</h3>
<p>昆士兰大学：地域一般般，学校也是很典型的澳洲大学，特色不明显，北邮人较少，推荐程度也还行，看你的成绩如何了，好学生当然看不上UQ</p>
<h3 id="fmonash"><a class="markdownIt-Anchor" href="#fmonash"></a> f.Monash</h3>
<p>莫纳什大学：偏商科，有零星的几个北邮人，感觉很是陌生</p>
<h3 id="guts"><a class="markdownIt-Anchor" href="#guts"></a> g.UTS</h3>
<p>悉尼科技大学：澳洲传统计算机学校，综排一般，计算机实力不错，不过，从国内的合作院校就能推断出它的档次怎么样了：它和东北大学、杭电、上海大学之类的一直搞得有来有回，可以推测它也不咋地</p>
<h2 id="澳大利亚特别说明"><a class="markdownIt-Anchor" href="#澳大利亚特别说明"></a> 澳大利亚特别说明</h2>
<p>大致和英国差不多（但是似乎水分低一些？），同样是短学制，但生活成本好像比英国低。地域首选悉尼和墨尔本。一句话概括，和英国推荐程度差不多，但是纯镀金的话不如英国（毕竟大英更贵、排名更好、水项目更多啊），居留难度比英国好些，回国认可度也还行。不过总感觉留学澳洲有些非主流，看个人选择吧。补一句，澳洲环境是真好</p>
<h2 id="7德国"><a class="markdownIt-Anchor" href="#7德国"></a> 7.德国🇩🇪</h2>
<h3 id="atum"><a class="markdownIt-Anchor" href="#atum"></a> a.TUM</h3>
<p>慕尼黑工业大学：综排好，专排好，无学费，计算机项目是英语，地域也好，但慕尼黑作为西欧枢纽，生活成本不低，长学制学习踏实，尤其方便有读博意向的同学。近几年北邮有不少去的。TUM虽说在德国，但是教育模式却是英美化的，往好听了说这叫国际化、往不好听了说就是学生多导致质量不高（不过肯定还是比英国那种一年制高多了）</p>
<h3 id="brwth"><a class="markdownIt-Anchor" href="#brwth"></a> b.RWTH</h3>
<p>亚琛工业大学：专排好，无学费，综合排名和知名度低于TUM，计算机项目是英语（或者德英双语），亚琛的生活成本显著低于慕尼黑，同样长学制，课程难度高于TUM。近几年北邮有不少去的，并且人数多于TUM。和TUM不同，RWTH的课程难度是很有德国特色的，质量也高，以考试难、毕业难而著称</p>
<h3 id="ckit"><a class="markdownIt-Anchor" href="#ckit"></a> c.KIT</h3>
<p>卡尔斯鲁厄理工学院：计算机专排高，综排一般，所在地区是德国唯一收学费的地方（但依旧不贵），卡城太安逸了，放中国就是个风景优美的大县城，欧洲认可度显著强于国内认可度。没听说北邮谁去。KIT全校计算机风气非常浓，<br />
但是和北邮偏向就业不同，KIT的计算机氛围浓郁在科研方面，课程理论性比TUM和RWTH都高，似乎有些鄙视人工智能这种新兴学科的研究，及其重视计算机本质的研究，在理论计算机领域非常有名气。KIT总的来说就是非常德式：最严谨、最理论、课程最难</p>
<h3 id="dtub"><a class="markdownIt-Anchor" href="#dtub"></a> d.TUB</h3>
<p>柏林工业大学：不如上述三者，比较适合低绩点选手。没听说北邮谁去</p>
<h3 id="etuebingen"><a class="markdownIt-Anchor" href="#etuebingen"></a> e.Tuebingen</h3>
<p>图宾根大学：原来不咋地，近几年背靠马普所这颗大树，机器学习领域崛起速度飞快，他的机器学习项目申请难度不低，名教授很多。在德国，只有图宾根是把机器学习单独列出来招生的，其他学校都是算信息学的一部分，正因如此，图宾根机器学习项目的申请热度水涨船高。北邮申请者少，似乎近几年没<br />
有</p>
<h3 id="fsaarlandes"><a class="markdownIt-Anchor" href="#fsaarlandes"></a> f.Saarlandes</h3>
<p>萨尔大学：德国AI第一校，同样背靠马普所，和马普所的计算机所二位一体，各种AI的研究中心都有，可惜名气小了点、排名也差，而且除了AI方向也不怎么样，不太适合读硕士，比较适合读博士</p>
<h3 id="gdarmstadt"><a class="markdownIt-Anchor" href="#gdarmstadt"></a> g.Darmstadt</h3>
<p>达姆施塔德工业大学：偏科非常严重，密码学/网络安全领域在世界范围内难觅敌手，其他方向烂，综合排名也一般般，同样是适合读博不适合读硕。北邮本科近几年没有申请的，北邮硕士有几位申了这里的网安方向的博士</p>
<h2 id="德国特别说明"><a class="markdownIt-Anchor" href="#德国特别说明"></a> 德国特别说明</h2>
<p>德校申请难度比较友好，打分制录取：匹配度、绩点、其他材料重要程度大概各占三分之一，科班+看得过去的绩点基本上稳录。适合想躺平的申请者，计算机专业研究生毕业后，在当地工作几年即可申请德国身份，速度很快；也适合想深造的申请者，长学制方便学习，并且德国境内遍地都是研究所，马克思普朗克学会、亥姆霍兹学会、莱布尼兹学会、弗劳恩霍夫协会，规模都非常大，考虑到德国那么小的体量，这么多研究所甚至可以说科研立国也不为过。缺点是不太适合回国。注意：APS审核需要提前办理，否则拿到录取也去不了。德国还有一些综合类院校，排名很不错，但是考虑到北邮都是工科申请者，就不再介绍了，像是慕尼黑大学、海德堡大学、哥廷根大学等等，一般北邮人都不会考虑的（虽然他们也有计算机项目）</p>
<h2 id="8瑞典"><a class="markdownIt-Anchor" href="#8瑞典"></a> 8.瑞典🇸🇪</h2>
<h3 id="akth"><a class="markdownIt-Anchor" href="#akth"></a> a.KTH</h3>
<p>皇家理工学院：网红学校，录取难度时高时低，但总体上是逐年变难，比较让人疑惑的是它的计算机项目，录取难度波动非常大，听说是浙大一帮人卷起来的，其他计算机交叉项目难度还好。KTH的控制科学项目是世界顶级的申请难度，一定要避开。近几年北邮申欧洲选手几乎人手一申，去的人也有一些</p>
<h3 id="bcth"><a class="markdownIt-Anchor" href="#bcth"></a> b.CTH</h3>
<p>查尔姆斯理工大学：欧洲知名度和认可度稍高于KTH，信息专业稍强于KTH，工程领域影响力大于KTH，但综合排名低于KTH。近几年北邮欧洲选手几乎人手一申，去的人少于KTH</p>
<h2 id="瑞典特别说明"><a class="markdownIt-Anchor" href="#瑞典特别说明"></a> 瑞典特别说明</h2>
<p>瑞典所有大学研究生统一申请，类似高考，有一志愿二志愿之分，一志愿录取则二志愿作废，有学费，但也有奖学金（比如著名的沃尔沃奖学金，学费+生活费+实习全包，保姆级别的奖学金），但一般只有第一志愿有奖学金，如果第一志愿是KTH且有奖学金会提前通知。这种志愿排序的制度就说明在填报的时候，如果不是对自己的实力充分自信的话，请一定避开卷中卷项目</p>
<h2 id="9芬兰"><a class="markdownIt-Anchor" href="#9芬兰"></a> 9.芬兰🇫🇮</h2>
<h3 id="aaalto"><a class="markdownIt-Anchor" href="#aaalto"></a> a.Aalto</h3>
<p>阿尔托大学：新兴大学，录取难度逐年递增，计算机和艺术领域欧洲知名，科研强。近几年北邮申请比较热门，录取也有一些，但最后去的人不多</p>
<h3 id="bhelsinki"><a class="markdownIt-Anchor" href="#bhelsinki"></a> b.Helsinki</h3>
<p>赫尔辛基大学：综合性强，计算机相关项目都不错，值得申请，不过北邮人不怎么喜欢这个学校，北邮人提芬兰估计第一个想到的是Aalto</p>
<h2 id="10荷兰"><a class="markdownIt-Anchor" href="#10荷兰"></a> 10.荷兰🇳🇱</h2>
<h3 id="atud"><a class="markdownIt-Anchor" href="#atud"></a> a.TUD</h3>
<p>代尔夫特理工大学：综合程度强于TU/e，计算机/电子领域不如TU/e，但综合排名很高，缺点是欧洲第一档的学费。似乎对北邮友好（有待更详细的数据支持，但目前我看到某个项目中，本科专业一样的前提下，哈工同济90分均被拒、北邮88分被录取），如果不考虑学费较贵的问题，它在欧洲大陆的推荐等级仅次于瑞士的两所天花板学校</p>
<h3 id="btue"><a class="markdownIt-Anchor" href="#btue"></a> b.TU/e</h3>
<p>埃因霍芬理工大学：俗称荷兰北邮，计算机/电子领域欧洲知名，适合找工/移民选手，所在城市优于TUD所在城市，学费低于TUD但也不便宜。近几年北邮申荷兰必申，最后去的人不多（比去TUD的人少）</p>
<h2 id="ctwente"><a class="markdownIt-Anchor" href="#ctwente"></a> c.Twente</h2>
<p>屯特大学：不如上述二者，好学生不妨保底使用</p>
<h2 id="荷兰特别说明"><a class="markdownIt-Anchor" href="#荷兰特别说明"></a> 荷兰特别说明</h2>
<p>适合想躺平的申请者，小国家内不同地域没差别，生活工作都舒服，移民速度也快，回国认可度也好，除了稍贵以外基本没什么硬伤</p>
<h2 id="11瑞士"><a class="markdownIt-Anchor" href="#11瑞士"></a> 11.瑞士🇨🇭</h2>
<h3 id="aepfl"><a class="markdownIt-Anchor" href="#aepfl"></a> a.EPFL</h3>
<p>洛桑联邦理工学院：全世界法语区最高理工学府，综排世界前十、CS世界前五，无学费，难度比ETH友好，均分需90+，北邮往年顶级选手会申请（尤其是信通，感觉EPFL通信似乎对北邮信通院学生友好，我校信通院老师历来也常有去EPFL访问的）。就近几年的情况来看，北邮本科近几年能做到每年都有5个左右申请到EPFL的硕士，挺不错的成绩了</p>
<h3 id="beth"><a class="markdownIt-Anchor" href="#beth"></a> b.ETH</h3>
<p>苏黎世联邦理工学院：爱因斯坦母校，全世界德语区最高理工学府，综排世界前五、CS世界前十，无学费，难度极大。纯计算机项目上，北邮本科生近几年只有周学长申请成功，从他的经验来看，热门项目需要均分95+并且需要其他经历，纯计算机项目，目前的申请难度比斯坦福稍高、比麻省理工稍低；其他计算机交叉项目，北邮部分同学有可能申到，但是这部分同学都去了其他地区,没申请ETH。北邮本北大硕有不少读博去了ETH</p>
<h3 id="cuzh"><a class="markdownIt-Anchor" href="#cuzh"></a> c.UZH</h3>
<p>苏黎世大学：在ETH隔壁，无学费，在ETH光环之下的小透明，在欧洲认可度显著高于国内，不过UZH综合性是瑞士最强的，规模不小，除了工科不如那两所之外，其他专业都很好，在瑞士国民眼中UZH才是大学，ETH和EPFL顶多是学院。UZH不太适合回国。去年听说一同学在UZH和HKU之间纠结，不知最后去了何处。题外话，UZH的官网真古典，感觉他们这个网页至少用了二十年，这么朴素（落后）的网页也是少见</p>
<h2 id="瑞士特别说明"><a class="markdownIt-Anchor" href="#瑞士特别说明"></a> 瑞士特别说明</h2>
<p>居留难度极高，如果不是ETH和EPFL的话，不太建议去，生活成本也大、也留不下。在去不了美国的情况下，清北读硕、瑞士二所读博是北邮顶级方案（当然，如果直博瑞士二所，那当然是顶中顶，去年计算机院传说有一位从清华叉院退学去了epfl直博，不过还是醒醒吧，清北本科能去瑞士二所直博的也没几个）。对于本科生申请硕士的情况，瑞士两所天花板学校，北邮国院、计算机院、信通院大把人年年冲、年年冲不上（或者冲上的很少），但是估计在他们那混个脸熟肯定是没问题的，至少知道了有北邮这么个学校。如果申请这两所学校的硕士，硬指标：均分必须90+，否则一定是炮灰，不论是什么专业。补充：如果对瑞士二所有极强的执念，硕士阶段建议去德国，瑞士对强德校的硕士认可度大于清北硕</p>
<h2 id="12比利时"><a class="markdownIt-Anchor" href="#12比利时"></a> 12.比利时🇧🇪</h2>
<h3 id="ku-leuven"><a class="markdownIt-Anchor" href="#ku-leuven"></a> KU Leuven</h3>
<p>荷语区鲁汶大学：综排好、专排好，录取难度还行，全球科研圈子内很知名，但国内就业市场上知名度一般。又有俗称欧洲衡水，课业压力比较大。北邮申欧一般捎带申请该校，最后去的人比较少</p>
<h2 id="13挪威"><a class="markdownIt-Anchor" href="#13挪威"></a> 13.挪威🇳🇴</h2>
<h3 id="ntnu"><a class="markdownIt-Anchor" href="#ntnu"></a> NTNU</h3>
<p>挪威科技大学：值得特别提一下，一直搞不懂为什么这学校的CS专业有逆天的录取难度，CS专业的报录比几十比一，彩票程度堪比瑞士二所，很奇怪。如果感兴趣可以深入了解，反正我看到这学校的CS连上海交大88分的计科人都申不上，难道是因为坑位太少？北邮近几年申请也比较少，具体情况不了解</p>
<h2 id="14丹麦"><a class="markdownIt-Anchor" href="#14丹麦"></a> 14.丹麦🇩🇰</h2>
<h3 id="dtu"><a class="markdownIt-Anchor" href="#dtu"></a> DTU</h3>
<p>丹麦科技大学：在北邮人圈子里存在感比较低，但却是中国人近几年欧洲申请的热门之一，北邮有几个申请的，但是最后都没去这里。典型的欧洲学校，在欧洲认可度大于国内，对学生科研支持比较大，可以独享实验室资源，并且可以拿实验室经历抵学分</p>
<h2 id="15欧盟"><a class="markdownIt-Anchor" href="#15欧盟"></a> 15.欧盟🇪🇺</h2>
<h3 id="aeit"><a class="markdownIt-Anchor" href="#aeit"></a> a.EIT</h3>
<p>欧洲创新与技术学院：是欧盟联合项目，如果欧洲经济情况好的话，欧盟给这个项目拨款超级多，非常好拿奖学金，但是如果欧洲经济不景气的话，可能就少奖学金。申请者可根据自己需求定制项目，两年内选择若干欧盟大学修读硕<br />
士课程，最后拿多个毕业证，可选高校水平不错，且可能有奖学金，目前还不是很卷，缺点是不少项目偏商科方向，有些计算机项目也要写商业计划书、修几十个商科学分，而且两年内辗转多国，对纯技术申请者不友好。北邮近几年每年都有人申请该项目，但人数不多</p>
<h3 id="berasmus"><a class="markdownIt-Anchor" href="#berasmus"></a> b.Erasmus</h3>
<p>除了上面介绍的EIT，欧盟内部还有一个伊拉斯谟（Erasmus）项目，也是定制项目，从儿童文学到信息安全都可以定制，选择若干欧盟内大学就读，最后拿多个毕业证，和EIT感觉有些类似</p>
<h2 id="欧盟特别说明"><a class="markdownIt-Anchor" href="#欧盟特别说明"></a> 欧盟特别说明</h2>
<p>申欧洲就别看世界排名了，没有完美的选择，较低的成本和较高的质量已经很难得了，低排名可能回国不占优，但懂行的人都知道欧洲大陆无水硕，而且认可度这种东西还是看你自己有没有能力、而不是毕业于哪所大学。题外话，去不了美国的前一年（2019），就有一位A学长申遍全欧洲，为我们提供了不少参考，后来北邮人去欧洲多是在他的基础上进行申请，他的指标是：专业计算机科学与技术，排名136/315，托福101，有GRE，申请结果为：</p>
<ul>
<li>德国亚琛工大2个项目（信息学、数据科学）：AD，最后去向是亚琛工大<br />
信息学</li>
<li>比利时鲁汶（计算机科学）：offer，减免85%学费</li>
<li>荷兰代尔夫特（嵌入式系统）：AD</li>
<li>荷兰埃因霍芬（计算机数学-数据科学联合项目）：AD</li>
<li>荷兰阿自由（计算机科学）：AD，保底校</li>
<li>欧盟EIT项目（定制瑞典皇家理工+荷兰埃因霍芬）（数据科学）：AD</li>
<li>瑞士苏黎世大学（计算语言学）：AD</li>
<li>英国爱丁堡（语言与计算机）：彩票项目，拒</li>
<li>丹麦哥本哈根（IT与认知）：AD</li>
<li>爱尔兰圣三一（计算机科学）：AD，保底校</li>
<li>欧盟伊拉斯谟项目（定制芬兰阿尔托+法国巴黎高等电信）（安全和云计<br />
算）：拒</li>
<li>芬兰阿尔托（机器学习）：拒</li>
<li>瑞士洛桑联邦理工学院（数字人类学）：显然是彩票项目，拒（如果没拒<br />
就有鬼了）</li>
<li>慕尼黑大学（数据科学）：拒</li>
<li>瑞典皇家理工3个项目（机器学习、计算机科学、计算机模拟）：拒</li>
<li>瑞典查尔姆斯（数据科学-人工智能联合项目）：拒</li>
</ul>
<p>他的申请名单几乎就是北邮申欧洲的范本，对于申欧洲格外具有参考意义，故列出于此。但是，近几年欧洲各校难度水涨船高，一定要注意！可以看到，欧洲还是十分重视专业匹配度的，他总结说到：最后录取的多是 “ 计算机 ” 项目。欧洲有些大学听起来不知名，这是因为欧洲大学不像英美大学那样喜欢满世界打广告，像北欧5TU、荷兰3TU、德国9TU等等，都是值得申请的</p>
<h2 id="16法国"><a class="markdownIt-Anchor" href="#16法国"></a> 16.法国🇫🇷</h2>
<p>之所以把法国放在欧洲大陆之后才说，是因为它实在是有点奇葩，如非法国爱好者，建议远离。大致来说，其研究生学制分为综合型和工程师，工程师学位学制比较长，在法国当地就是鄙视链顶端，横扫一切行业（比如金融），但是出了法国就是个鸡肋，很容易被认为是野鸡，工程师学位和我们常说的研究生学位其实有不小的差别，大概是在不进行科研的情况下修习难度较高的数学、物理、计算机等内容，目标是培养工程领导者，精英气质比较浓，坑位少、时间长。大名鼎鼎的巴黎X，法式精英教育的殿堂，地位极高，坑位极少，它的工程师学位需要单独笔试面试，且必须在巴黎当地进行（近几年由于疫情似乎有所变化），笔试难，考的都是数学系的那些东西。北邮去年有去巴黎X的同学，但并不是那个极难的工程师项</p>
<h2 id="法国特别说明"><a class="markdownIt-Anchor" href="#法国特别说明"></a> 法国特别说明</h2>
<p>其实北邮人曾经是有留法的传统的，1997、1998年前后，北邮南邮西电三校和法国高等通信联盟弄了一个规模很大的项目，彼此之间交流非常频繁。在21世纪早期，北邮人通过这条路非常多奔赴法国的，以至于阿尔卡特等法企至今仍有不少北邮人活跃，在法国通信科研领域的存在感也不低。但是后来留美大潮兴起之后，这个项目也没续签，加上和QM的合作办学规模不断扩大、在英国申请方向结果越来越好之后，渐渐去法国就少了。这个故事的结局是，在北邮完全拥抱英美的同时，西电留美并不顺畅，因而留法传统比北邮保留的好不少。近几年，北邮重新有留法学生了，只不过数量很少，而且好学生不再喜欢法国，哪怕是巴黎X，都不太能吸引到北邮的好学生，二十多年前，对北邮人的吸引力是法国大于西欧其他地区，现在是西欧任何其他地区都大于法国了</p>
<h2 id="17美国"><a class="markdownIt-Anchor" href="#17美国"></a> 17.美国🇺🇸</h2>
<h2 id="目前仍能去的美国项目"><a class="markdownIt-Anchor" href="#目前仍能去的美国项目"></a> 目前仍能去的美国项目</h2>
<p>NYU的上海校区，似乎可选整个研究生在上海（但是算纽约NYU的学生），但意义不大，不太值得去；Gatech的深圳校区，似乎可选整个研究生阶段在深圳（但是算亚特兰大Gatech的学生），但意义不大，不太值得去。众所周知，读美国学校的本质是去美国工作，既然无法去美国工作，那根本没必要交那么多的学费</p>
<h2 id="18其他"><a class="markdownIt-Anchor" href="#18其他"></a> 18.其他</h2>
<p>以上是往年北邮人申请时筛出的学校和项目，应该是比较靠谱的，但是每年都有同学发现新的好去处，如果有时间，不妨多多研究。和国内非常直白的高校优劣不同，境外高校的优劣对比是十分不明显的，一些很普通的学校也可能性价比超高，只能说水确实很深</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>University</tag>
      </tags>
  </entry>
  <entry>
    <title>ViT变种</title>
    <url>/2024/02/27/ViT%E5%8F%98%E7%A7%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p>ViT-H，ViT-L和ViT-B是指不同规模和复杂度的Vision Transformer模型变体。</p>
<ul>
<li>
<p><strong>ViT-H（High resolution）</strong>:<br />
ViT-H是Vision Transformer模型中的高分辨率变体。它通常适用于处理高分辨率图像或更具挑战性的视觉任务。由于处理高分辨率图像可能需要更多的计算资源和内存，因此ViT-H模型可能更庞大和复杂。</p>
</li>
<li>
<p><strong>ViT-L（Low resolution）</strong>:<br />
ViT-L是Vision Transformer模型中的低分辨率变体。它通常用于处理低分辨率图像或资源受限的环境。ViT-L模型可能比ViT-H模型更小、更轻量级，适合在资源受限的设备或场景中部署。</p>
</li>
<li>
<p><strong>ViT-B（Base resolution）</strong>:<br />
ViT-B是Vision Transformer模型中的基准分辨率变体。它可以被视为ViT模型的中间规模。ViT-B通常是指在资源充足但不需要处理过高或过低分辨率图像时使用的模型。</p>
</li>
</ul>
<p>需要注意的是，具体的ViT-H、ViT-L和ViT-B模型的规模和特征可以因不同的研究论文、实现和应用而有所不同。这些命名约定通常是为了区分不同规模和复杂度的模型变体，并在不同的视觉任务和计算资源约束下选择合适的模型。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>ViT</tag>
      </tags>
  </entry>
  <entry>
    <title>author</title>
    <url>/2023/07/28/author/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="关于论文的作者"><a class="markdownIt-Anchor" href="#关于论文的作者"></a> 关于论文的作者</h1>
<p>设SCI论文的作者如果有N个人，依作者排名的顺序叫做一作，二作，三作……N作，这个大家都明白的常识。但是作者的顺序往往是至关重要的 ——排在第一（首席研究员）和最后的作者（通常是责任作者或资深）的位置，意味着他们会获得最多的褒奖。那么一作、通讯作者、以及最后的作者意味着什么呢？</p>
<h2 id="1论文中的作者顺序是怎样规定的"><a class="markdownIt-Anchor" href="#1论文中的作者顺序是怎样规定的"></a> 1.论文中的作者顺序是怎样规定的？</h2>
<h3 id="11-一般说来作者排名主要是依据对本论文的实际贡献大小来执行"><a class="markdownIt-Anchor" href="#11-一般说来作者排名主要是依据对本论文的实际贡献大小来执行"></a> 1.1 一般说来，作者排名主要是依据对本论文的实际贡献大小来执行</h3>
<p>排名靠在前面的作者对论文的贡献越大</p>
<h3 id="12-特殊情况有的sci论文作者实际排名操作中可能会受到各种非客观的其他因素所影响"><a class="markdownIt-Anchor" href="#12-特殊情况有的sci论文作者实际排名操作中可能会受到各种非客观的其他因素所影响"></a> 1.2 特殊情况：有的SCI论文作者实际排名操作中可能会受到各种非客观的其他因素所影响</h3>
<p>比如：在我国申请博士学位和学术职称时，对论文作者的排名常常有严格的规定。</p>
<p>比如，某些高校理工科的博士生学位论文答辩条件之一是发表SCI论文，发表的SCI论文必须满足第一作者为博士生或者导师第一作者博士生第二作者才算数，否则发表多少篇论文都是白搭。</p>
<p>又比如，晋升副教授时，相关副高职称的文件会规定申请条件之一为申请者第一作者论文至少多少篇等等。</p>
<h2 id="2一作-通讯作者-以及最后的作者意味着什么呢"><a class="markdownIt-Anchor" href="#2一作-通讯作者-以及最后的作者意味着什么呢"></a> 2.一作、通讯作者、以及最后的作者意味着什么呢？</h2>
<h3 id="21-第一作者"><a class="markdownIt-Anchor" href="#21-第一作者"></a> 2.1 第一作者</h3>
<p>显而易见，第一作者是被认为论文所述工作的主要完成人，科研项目的主要承担者，能见度极高。</p>
<p>比如，当某篇论文被引用，该文的第一作者在所有的科技刊物中被忽略过去，因为参考文献规则可以规定非第一作者全都被“et al.”缩写掉。这时候，第一作者就像电影或者电视剧里不会早早去领盒饭的主角一个待遇。</p>
<p>按惯例，理工科论文的第一作者是撰写论文的那个人，而撰写论文的那个人应该具备撰写论文内容的资格，也就是说第一作者亲自参与科研项目或者实验，采集数据、动手做实验和分析结果，ta应该是该课题的主要完成者。</p>
<p>没有做过某项科研项目，在没有经过完成人、同意的情况下，却拿着别人的工作撰写论文的行为也算是剽窃行为的一种。</p>
<p>作为论文的第一作者，通常是课题的主要完成人也是写出第一轮草稿的那个人。完成科研项目而愿意让别人撰写相关的科技论文，通常这种情况是极少的。在自然界，几乎找不到一个自己怀孕了N个月，却让别人下蛋的老母鸡。由完成论文主要工作的人自己执笔，写出论文初稿并作为第一作者是合理的。</p>
<p>但实际如何按具体情况操作，本文就不做展开了。</p>
<h3 id="22-通讯作者"><a class="markdownIt-Anchor" href="#22-通讯作者"></a> 2.2 通讯作者</h3>
<p>按照通常认为，通讯作者为导师、研究决策者或主要组织者，是课题的总负责人，承担课题的经费、设计、文章的把关者。</p>
<p>我写过的SCI论文中，如果第一作者和通讯作者不是一个人，那么通讯作者往往放在作者信息中最后一个。有的相关资料说，通讯作者可以是任何一个位置，换句话，可以是第一、第二到第N个作者。正式出版的论文中，常常以类似“⁎Corresponding author E-mail addresses:XXXX”或“Author to whom correspondence shouldbe addressed.”等字样标明哪个作者为通讯作者。</p>
<p>通讯作者，顾名思义，就是可以与之通讯的作者，主要在投稿与期刊编辑联系的作者（论文未正式录用前，有些期刊编辑还是以投稿系统中的联系方式为主，进行审稿等工作的联系），并在论文发表后读者联系的那个作者。</p>
<p>论文通讯作者的身份不仅光荣，也有其实际的作用， 文章发表后， 一旦有“问题”， 或者要“获奖”， 该作者就是第一联系人。要是获奖还好办，要是论文出现问题， 该作者首当其冲，是主要的意见回复人。</p>
<p>历史性，通讯作者最重要的义务是，担负着论文可靠性的责任，负责与编辑部的一切通信联系和接受读者的咨询等。通讯作者的能够是能和外界建立更广泛的联系，因此可以获得很多学术资源和声望。</p>
<h3 id="23-最后作者"><a class="markdownIt-Anchor" href="#23-最后作者"></a> 2.3 最后作者</h3>
<p>除了First author, Corresponding author,还有最后作者(Lastauthor)。所谓的Last author，就是最后一个作者，这个作者一般为导师、研究决策者或主要调查员。如果是一名博士生写的SCI论文，通行的Last author署名做法是写上自己导师的名字，只要导师不是第一作者。当然，导师也可以作为Corresponding author，只需要标注一下即可。</p>
<p>以上的第一作者(First author)与通讯作者(Corresponding author)没有互斥关系，最后作者(Last author)与通讯作者(Correspondingauthor)也不是互斥关系；第一作者(First author)和最后作者(Last author)肯定是互斥关系。</p>
<p>简而言之，SCI论文需要根据各类相应规则决定署名次序，不能随便。最好在论文草稿起草前，论文的撰写者就决定合著作者们的提成名顺序。</p>
<h3 id="24第一作者与通讯作者的区别"><a class="markdownIt-Anchor" href="#24第一作者与通讯作者的区别"></a> 2.4第一作者与通讯作者的区别</h3>
<p>从做科研项目的过程来看，那么，第一作者就像是冲锋陷阵的将军（对研究成果的实现贡献最大，且是论文初稿的撰写者），通讯作者就像是运筹帷幄的元帅（出项目，规划大致研究方向和路线,统筹安排，出资金，出实验室和实验器材等），或者说第一作者有点像是具体干苦活的乙方，通讯作者有点像出钱出资源的甲方。</p>
<p>如果第一作者和通讯作者是同一人，那就可以忽略区分两者的问题；只有当第一作者和通讯作者不为同一人时，才要特别强调第一作者和通讯作者区分的问题。</p>
<p>据我所知道的，博士生的SCI论文作者署名时，可能第一作者是学生，而通讯作者是导师或者可能第一作者是导师，第二作者是学生，通讯作者为副导师或者也可能第一作者是副导师，第二作者是学生，通讯作者为导师。</p>
<p>如果有对SCI论文有帮助或作出过贡献但不足成为作者的人，可以放在论文结尾的Acknowledgments表示感谢。论文署名确定以后，就是具体的SCI论文作者信息的撰写了，这需要遵循约定俗成的规则。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>author</tag>
      </tags>
  </entry>
  <entry>
    <title>ML:RNN与LSTM</title>
    <url>/2023/11/16/RNN%E4%B8%8ELSTM/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1应用实例为什么需要rnn"><a class="markdownIt-Anchor" href="#1应用实例为什么需要rnn"></a> 1.应用实例（为什么需要RNN？）</h2>
<p><strong>槽位填充问题：</strong></p>
<p><img src="https://pbs.twimg.com/media/F_Db4fWakAAAiaX?format=png&amp;name=900x900" alt="" /></p>
<br>
<p><strong>通过Feedforward网络解决槽位填充问题？</strong></p>
<p>我们有两个句子:</p>
<ul>
<li>“arrive Taipei on November 2nd”</li>
<li>“leave Taipei on November 2nd”</li>
</ul>
<p>我们可以发现在第一个句子中，Taipei是destination，而第二个句子中Taipei是departure。</p>
<p>如果我们不去考虑Taipei前一个词的话，Taipei的vector只有一个，那么同样的vector进来吐出的predict就是一致的。所以我们在做的时候就需要把前一个的结果存起来，在下一个词进来的时候用了参考。所以这样我们就在neuron中设计一个hidden layer来存储这个值，如下图中a1,a2所示，相当于让神经网络拥有记忆能力</p>
<p><img src="https://pbs.twimg.com/media/F_G0BRHbIAAdldq?format=png&amp;name=small" alt="" /></p>
<br>
<h2 id="2rnn的基本概念"><a class="markdownIt-Anchor" href="#2rnn的基本概念"></a> 2.RNN的基本概念</h2>
<p>假设我们每个<strong>weigh</strong>t都是1，<strong>bias</strong>=0，每个<strong>activation</strong>都是<strong>linear</strong>的。</p>
<p>那么我们现在有一个序列(1,1)，(1,1)，(2,2)，那么一开始memory里面的值是(a1=0,a2=0)，现在将序列第一个值传入network，我们得到(x1=1,x2=1)，因为<strong>active function</strong>都是linear的，所以经过第一个<strong>hidden layer</strong>，我们输出的就是<strong>1×a1+1×a2+1×x1+1×x2</strong>，其中<strong>a1=a2=0</strong>，两个节点一致。</p>
<p>所以第一个hidden layer得到(2,2)（绿色方块所示），同时我们将(2,2)保存起来，更新一下得到(a1=2,a2=2)，output layer是(4,4)，所以得到第一个(y1=4,y2=4)。第二个input (1,1)，同样计算一下，hidden layer得到的是(6,6)和(a1=6,a2=6)，output layer是(12,12)。同理第三个input最后得到的output是(32,32)，所最后得到的三个output序列是(4,4),(12,12),(32,32)。以此类推。</p>
<p><img src="https://pbs.twimg.com/media/F_G1ZasaAAAzc83?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p><strong>思考</strong>：那么我们可以想一下，如果现在的序列顺序变化一下，结果是否会不一致？如果现在的序列是(1,1),(2,2),(1,1)，我们得到的是(4,4),(16,16),(36,36)。结果发生了变化。所以RNN对序列是敏感的，这样的特性就表示，在slot filling的task里面，我们前面的arrive和leave将会影响后面接着的Taipei的结果。</p>
<br>
<br>
<p><strong>深度RNN</strong>:<br />
<img src="https://pbs.twimg.com/media/F_G2Sn9aEAABBw0?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p><strong>艾尔曼(Elman)网络和约旦(Jordan)网络(有更好的表现)</strong>:<br />
<img src="https://pbs.twimg.com/media/F_G3E_oa8AACYat?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p><strong>双向RNN</strong>：<br />
<img src="https://pbs.twimg.com/media/F_G3GtwaUAAFySI?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="3long-short-term-memory-lstm"><a class="markdownIt-Anchor" href="#3long-short-term-memory-lstm"></a> 3.Long Short-term Memory (LSTM)</h2>
<p><img src="https://pbs.twimg.com/media/F_G32_KbMAAK9Xq?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>仔细来看，LSTM形式如下：</p>
<p><img src="https://pbs.twimg.com/media/F_G334WbMAA6L95?format=png&amp;name=900x900" alt="" /><br />
C表示Memory中存储的原始值，C’表示新的存储值。</p>
<p>可以看到，一个<strong>output</strong>受到三个<strong>gate</strong>的影响:</p>
<ul>
<li><strong>input gate</strong>决定一个<strong>input</strong>是否可以进入<strong>memory cell</strong></li>
<li><strong>forget gate</strong>决定是否要忘记之前的<strong>memory</strong></li>
<li><strong>output gate</strong>决定最后是否可以输出。这样一个非常复杂的<strong>neuron</strong></li>
</ul>
<br>
<p>-------------------- <strong>LSTM·过程·expmale·BEGIN</strong> --------------------</p>
<p>那么实作上这个<strong>neuron</strong>是如何工作的呢？假设我们现在有一个最简单的LSTM，每个<strong>gate</strong>的<strong>input</strong>都是一样的<strong>vector</strong>，那么我们这边在做的时候就是每一个<strong>input</strong>乘以每个<strong>gate</strong>的<strong>matrix</strong>，然后通过<strong>active function</strong>进行计算。这里做一个最简单的人肉LSTM。假设我们有一个序列是：</p>
<p>假设：</p>
<ul>
<li>当x2=1的时候，我们将x1加入memory中</li>
<li>当x2=−1的时候，memory重置为0</li>
<li>当x3=1的时候，我们输出结果</li>
</ul>
<p><img src="https://pbs.twimg.com/media/F_G5AyLbkAAE1jV?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>-------------------- <strong>LSTM·过程·expmale·END</strong> --------------------</p>
<br>
<br>
<p>-------------------- <strong>LSTM·过程·expmale·详细·BEGIN</strong> --------------------</p>
<p>现在，将第一个元素放进来，我们得到是3，input gate部分的结果是90，经过<strong>activate function</strong>得到的是1，所以允许通过进入<strong>memory cell</strong>。<strong>forget gate</strong>这里计算的结果是110，经过<strong>activate function（Sigmoid）<strong>是1，所以我们记住这个值（这里要注意，虽然这个</strong>gate</strong>叫<strong>forget gate</strong>，但是当取值是1的时候其实是记住，0的时候是遗忘）。然后到<strong>output gate</strong>这里，<strong>output gate</strong>计算是-10，<strong>activate function</strong>输出是0，所以我们不output结果。<br />
<img src="https://pbs.twimg.com/media/F_G58XKbkAATCOE?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>输入下一个元素（4，1，0）。直接输入计算是4，经过<strong>input gate</strong>，得到的是4。因为原来<strong>memory cell</strong>里面已经存了3，所以这一轮的计算是原来的<strong>memory</strong>加上新进入的4，得到7。然后<strong>output gate</strong>依然关闭，所以<strong>memory cell</strong>还是存7。<br />
<img src="https://pbs.twimg.com/media/F_G6MYubwAADX5g?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>第三个元素类似的计算，发现<strong>input gate</strong>关闭，所以没法进入<strong>memory cell</strong>，因此<strong>memory cell</strong>没有更新。同时<strong>output gat</strong>e关闭，没有输出。<br />
<img src="https://pbs.twimg.com/media/F_G6hXYaUAAaB7L?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>第四个元素进入，<strong>input gate</strong>关闭，<strong>memory cell</strong>不更新，但是这时候<strong>output gate</strong>的<strong>activate function</strong>得到1，所以开放输出结果。因为之前<strong>memory cell</strong>里面存放的是7，所以输出7。但是要注意一点，虽然<strong>memory cell</strong>的值输出了，里面的值并没有被清空，仍然保留着，所以这个时候的<strong>memory cell</strong>还是7。<br />
<img src="https://pbs.twimg.com/media/F_G63mxbsAA7QB9?format=jpg&amp;name=900x900" alt="" /></p>
<br>
<p>最后一个元素进入，<strong>input gate</strong>关闭，<strong>memory cell</strong>不更新，这时候，<strong>forget gate</strong>的<strong>activate function</strong>得到的是0，所以我们清空记忆，<strong>memory cell</strong>里面现在是0。<strong>output gate</strong>仍然关闭，所以没有<strong>output</strong>.</p>
<p><img src="https://pbs.twimg.com/media/F_G63m6aoAEPSU0?format=jpg&amp;name=900x900" alt="" /></p>
<br>
<p>-------------------- <strong>LSTM·过程·expmale·详细·END</strong> --------------------</p>
<br>
<p><strong>LSTM和以前学的神经网络有什么关系呢？</strong></p>
<p><strong>原网络</strong>：<br />
<img src="https://pbs.twimg.com/media/F_G9KqzaYAA6lak?format=png&amp;name=small" alt="" /></p>
<br>
<p>只需要将神经元替换为LSTM即可：<br />
<img src="https://pbs.twimg.com/media/F_G9KqzaYAA6lak?format=png&amp;name=small" alt="" /></p>
<br>
<br>
<p>那时做的时候，一个<strong>简化的LSTM</strong>是：</p>
<p>如图中，我们输入一个原始的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">x^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span></span></span>，会通过四个<strong>linear transform</strong>变成四个<strong>vector</strong>，然后每个<strong>vector</strong>输入到<strong>LSTM</strong>对应的<strong>gate</strong>。这里要注意的是，转换后的z有多少个维度，那么我们就需要建立多少个<strong>LSTM</strong>的<strong>cell</strong>，同时，每次进入<strong>cell</strong>训练的只是z的一个维度。<br />
<img src="https://pbs.twimg.com/media/F_G-svbbQAA_hiC?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>实际的运算过程：<br />
<img src="https://pbs.twimg.com/media/F_G_uWGboAAoxPH?format=jpg&amp;name=medium" alt="" /></p>
<br>]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>专业知识</tag>
        <tag>ML</tag>
        <tag>李宏毅</tag>
        <tag>rnn</tag>
        <tag>lstm</tag>
      </tags>
  </entry>
  <entry>
    <title>chmod命令</title>
    <url>/2024/02/26/chmod%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h2>
<p>chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。</p>
<p>该命令有两种用法:</p>
<ul>
<li>一种是包含字母和操作符表达式的文字设定法</li>
<li>另一种是包含数字的数字设定法。</li>
</ul>
<p>Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。<br />
　　<br />
文件或目录的访问权限分为只读，只写和可执行三种。以文件为例:只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。</p>
<p>有三种不同类型的用户可对文件或目录进行访问：</p>
<ul>
<li>文件所有者</li>
<li>同组用户</li>
<li>其他用户</li>
</ul>
<p>所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。</p>
<p>每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。当用ls -l命令显示文件或目录的详细信息时，最左边的一列为文件的访问权限。</p>
<br>
<p>------------ 举例说明 ------------</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ll -al</span></span><br><span class="line"></span><br><span class="line">总计 316lrwxrwxrwx 1 root root     11 11-22 06:58 linklog.log -&gt; log2012.log</span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log</span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root     61 11-13 06:03 log2013.log</span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root      0 11-13 06:03 log2014.log</span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root      0 11-13 06:06 log2015.log</span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root      0 11-16 14:41 log2016.log</span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root      0 11-16 14:43 log2017.log</span><br></pre></td></tr></table></figure>
<br>
<p>我们以log2012.log为例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log</span><br></pre></td></tr></table></figure>
<p>第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行</p>
<Br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">- rw- r-- r--</span><br></pre></td></tr></table></figure>
<p>表示log2012.log是一个普通文件；log2012.log的属主有读写权限；与log2012.log属主同组的用户只有读权限；其他用户也只有读权限。</p>
<p>------------ 举例说明 ------------</p>
<br>
<h2 id="chmod命令"><a class="markdownIt-Anchor" href="#chmod命令"></a> chmod命令</h2>
<h3 id="1-命令格式"><a class="markdownIt-Anchor" href="#1-命令格式"></a> 1. 命令格式:</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> [-cfvR] [--<span class="built_in">help</span>] [--version] mode file  </span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 2. 命令功能：</span></span><br><span class="line"></span><br><span class="line">用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 3. 命令参数：</span></span><br><span class="line"></span><br><span class="line">**必要参数**：</span><br><span class="line">- -c 当发生改变时，报告处理信息</span><br><span class="line">- -f 错误信息不输出</span><br><span class="line">- -R 处理指定目录以及其子目录下的所有文件</span><br><span class="line">- -v 运行时显示详细处理信息</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**选择参数**：</span><br><span class="line">--reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限</span><br><span class="line"></span><br><span class="line">--version 显示版本信息</span><br><span class="line"></span><br><span class="line">&lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限  </span><br><span class="line">&lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限  </span><br><span class="line">&lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值  </span><br><span class="line"></span><br><span class="line">**权限范围**：</span><br><span class="line">- -u ：目录或者文件的当前的用户</span><br><span class="line">- -g ：目录或者文件的当前的群组</span><br><span class="line">- -o ：除了目录或者文件的当前用户或群组之外的用户或者群组</span><br><span class="line">- -a ：所有的用户及群组</span><br><span class="line"></span><br><span class="line">**权限代号**：</span><br><span class="line">- -r ：读权限，用数字4表示</span><br><span class="line">- -w ：写权限，用数字2表示</span><br><span class="line">- -x ：执行权限，用数字1表示</span><br><span class="line">- \- ：删除权限，用数字0表示</span><br><span class="line">- -s ：特殊权限 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;br&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用方法</span></span><br><span class="line">该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 文字设定法</span></span><br><span class="line">```bash</span><br><span class="line"> <span class="built_in">chmod</span> ［<span class="built_in">who</span>］ ［+ | - | =］ ［mode］ 文件名</span><br></pre></td></tr></table></figure>
<br>
<h3 id="数字设定法"><a class="markdownIt-Anchor" href="#数字设定法"></a> 数字设定法</h3>
<p>数字设定法的一般形式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod ［mode］ 文件名</span><br></pre></td></tr></table></figure>
<p>我们必须首先了解用数字表示的属性的含义：0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。</p>
<p>例如，如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。</p>
<p>数字与字符对应关系如下：r=4，w=2，x=1</p>
<ul>
<li>若要rwx属性则4+2+1=7</li>
<li>若要rw-属性则4+2=6；</li>
<li>若要r-x属性则4+1=5</li>
</ul>
<br>
<h2 id="举例说明"><a class="markdownIt-Anchor" href="#举例说明"></a> 举例说明</h2>
<h3 id="增加文件所有用户组可执行权限"><a class="markdownIt-Anchor" href="#增加文件所有用户组可执行权限"></a> 增加文件所有用户组可执行权限</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ls -al log2012.log </span></span><br><span class="line"></span><br><span class="line">-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log</span><br><span class="line"></span><br><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># chmod a+x log2012.log </span></span><br><span class="line"></span><br><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ls -al log2012.log </span></span><br><span class="line"></span><br><span class="line">-rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log</span><br></pre></td></tr></table></figure>
<p>即设定文件log2012.log的属性为：文件属主（u） 增加执行权限；与文件属主同组用户（g） 增加执行权限；其他用户（o） 增加执行权限</p>
<br>
<h3 id="删除文件权限"><a class="markdownIt-Anchor" href="#删除文件权限"></a> 删除文件权限</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ls -al log2012.log </span></span><br><span class="line"></span><br><span class="line">-rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log</span><br><span class="line"></span><br><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># chmod a-x log2012.log </span></span><br><span class="line"></span><br><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ls -al log2012.log </span></span><br><span class="line"></span><br><span class="line">-rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log</span><br></pre></td></tr></table></figure>
<p>删除所有用户的可执行权限</p>
<br>
<h3 id="使用设置权限"><a class="markdownIt-Anchor" href="#使用设置权限"></a> 使用“=”设置权限</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ls -al log2012.log </span></span><br><span class="line"></span><br><span class="line">-rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log</span><br><span class="line"></span><br><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># chmod u=x log2012.log </span></span><br><span class="line"></span><br><span class="line">[root@localhost <span class="built_in">test</span>]<span class="comment"># ls -al log2012.log </span></span><br><span class="line"></span><br><span class="line">---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log</span><br></pre></td></tr></table></figure>
<p>撤销原来所有的权限，然后使拥有者具有可读权限</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>chmod</tag>
      </tags>
  </entry>
  <entry>
    <title>epoch、batch、batch size、step、iteration</title>
    <url>/2024/01/26/epoch%E3%80%81batch%E3%80%81batch-size%E3%80%81step%E3%80%81iteration/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="名词的具体含义介绍"><a class="markdownIt-Anchor" href="#名词的具体含义介绍"></a> 名词的具体含义介绍</h2>
<p>本文介绍在机器学习、深度学习的神经网络模型中，<strong>epoch</strong>、<strong>batch</strong>、<strong>batch size</strong>、<strong>step</strong>与<strong>iteration</strong>等名词的具体含义。</p>
<p><strong>epoch</strong>：表示将训练数据集中的所有样本都过一遍（且仅过一遍）的训练过程。在一个epoch中，训练算法会按照设定的顺序将所有样本输入模型进行前向传播、计算损失、反向传播和参数更新。一个epoch通常包含多个<strong>step</strong>。</p>
<p><strong>batch</strong>：一般翻译为“批次”，表示一次性输入模型的一组样本。在神经网络的训练过程中，训练数据往往是很多的，比如几万条甚至几十万条——如果我们一次性将这上万条的数据全部放入模型，对计算机性能、神经网络模型学习能力等的要求太高了；那么就可以将训练数据划分为多个<strong>batch</strong>，并随后分批将每个batch的样本一起输入到模型中进行前向传播、损失计算、反向传播和参数更新。但要注意，一般batch这个词用的不多，多数情况大家都是只关注<strong>batch size</strong>的。</p>
<p><strong>batch size</strong>：一般翻译为“批次大小”，表示训练过程中一次输入模型的一组样本的具体样本数量。前面提到了，我们在神经网络训练过程中，往往需要将训练数据划分为多个<strong>batch</strong>；而具体每一个batch有多少个样本，那么就是batch size指定的了。</p>
<p><strong>step</strong>：一般翻译为“步骤”，表示在一个epoch中模型进行一次参数更新的操作。通俗地说，在神经网络训练过程中，每次完成对一个batch数据的训练，就是完成了一个<strong>step</strong>。很多情况下，step和<strong>iteration</strong>表示的是同样的含义。</p>
<p><strong>iteration</strong>：一般翻译为“迭代”，多数情况下就表示在训练过程中经过一个<strong>step</strong>的操作。一个iteration包括了一个step中前向传播、损失计算、反向传播和参数更新的流程。当然，在某些情况下，step和iteration可能会有细微的区别——有时候iteration是指完成一次前向传播和反向传播的过程，而step是指通过优化算法对模型参数进行一次更新的操作。但是绝大多数情况下，我们就认为二者是一样的即可。</p>
<br>
<h2 id="实例分析"><a class="markdownIt-Anchor" href="#实例分析"></a> 实例分析</h2>
<p>以上是对这些名词的解释，我们将他们带入实际的例子就更好理解了。</p>
<p>假设我们现在有一个训练数据集（这个数据集不包括测试集），其中数据的样本数量为1500。那么，我们将这1500条数据全部训练1次，就是一个<strong>epoch</strong>。其中，由于数据量较大（其实1500个样本在神经网络研究中肯定不算大，但是我们这里只是一个例子，大家理解即可），因此我们希望将其分为多个<strong>batch</strong>，分批加以训练；我们决定每1批训练100条数据，那么为了将这些数据全部训练完，就需要训练15批——在这里，<strong>batch size</strong>就是100，而<strong>batch</strong>就是15。而前面我们提到，每次完成对一个batch数据的训练，就是完成了一个<strong>step</strong>，那么<strong>step</strong>和<strong>iteration</strong>就也都是15。</p>
<p>以上是我们对这一数据集加以1次训练（1个<strong>epoch</strong>）的情况，而一般情况下我们肯定是需要训练多次的，也就是多个<strong>epoch</strong>。我们假设我们需要训练3个epoch，相当于需要将这1500个样本训练3次。那么，<strong>step</strong>和<strong>iteration</strong>都会随着epoch的改变而发生改变——二者都变为45，因为15 * 3。但是，<strong>batch</strong>依然是15，因为其是在每一个epoch的视角内来看待的，和epoch的具体大小没有关系。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title>iTerm2+oh-my-zsh</title>
    <url>/2023/11/23/iTerm2-oh-my-zsh/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="shell"><a class="markdownIt-Anchor" href="#shell"></a> shell</h2>
<p>在操作系统内核外有一层壳，而这层壳就是 shell，它是用户和操作系统交互的桥梁。这很好理解，shell 包住了系统，用户想要跟系统交互，就必须经过shell。</p>
<p>后来，shell 还慢慢变成了内核与用户交互的脚本语言的总称。我们常见的 shell 有：bash、zsh、csh、ksh、ash 等等。</p>
<p>Linux 下默认的是 bash ，macOS 在 Catalina 之前的版本默认也是 bash ，后面随着 zsh 越来越流行，macOS 开始将 zsh 作为默认的解释器了。</p>
<p>但是默认的 zsh 配置有点烦，于是有个大牛在 Github 上制作了一个配置文件 oh-my-zsh ，从此免去了我们一顿复杂的配置，这也让 oh-my-zsh 成为了目前最流行的 zsh 配置。</p>
<br>
<h2 id="iterm2"><a class="markdownIt-Anchor" href="#iterm2"></a> iTerm2</h2>
<p>shell 作为系统内核的壳，是一种抽象的概念，是一个解释器，但作为用户并不能很好的操作。于是有了终端这样的软件，macOS 系统的默认终端是 terminal，这些终端不再是抽象的概念，是一个可视化的软件，很方便用户操作。而 iTerm2 也是这样的一款软件。它们既可以让我们输入 shell 命令，也能反馈输出结果给我们看。</p>
<br>
<h2 id="不同点"><a class="markdownIt-Anchor" href="#不同点"></a> 不同点</h2>
<ul>
<li><strong>iTerm2</strong> 主要关注于提供一个功能丰富的终端模拟器，它提供了改善视觉体验和交互体验的高级功能。</li>
<li><strong>Oh My Zsh</strong> 则专注于增强 Zsh 命令行解释器的功能，它通过插件和主题来扩展命令行的功能和外观。</li>
</ul>
<br>
<h2 id="1-vim基操"><a class="markdownIt-Anchor" href="#1-vim基操"></a> 1. Vim基操</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim &lt;file name&gt;   打开文件</span><br><span class="line">i                         insert 编辑模式</span><br><span class="line">esc                     退出编辑模式</span><br><span class="line">shift+zz               保存并退出</span><br></pre></td></tr></table></figure>
<br>
<h2 id="2-安装iterm2"><a class="markdownIt-Anchor" href="#2-安装iterm2"></a> 2. 安装iTerm2</h2>
<p>官网地址： <a href="http://iterm2.com/downloads.html">http://iterm2.com/downloads.html</a></p>
<br>
<h2 id="3-安装-oh-my-zsh"><a class="markdownIt-Anchor" href="#3-安装-oh-my-zsh"></a> 3. 安装 oh-my-zsh</h2>
<p>oh-my-zsh 的官网地址：<a href="https://ohmyz.sh/">https://ohmyz.sh/</a></p>
<br>
<h2 id="4-修改默认的shell"><a class="markdownIt-Anchor" href="#4-修改默认的shell"></a> 4. 修改默认的shell</h2>
<br>
<hr />
<p>鼓捣了一下午也没弄好，真tm来气!!</p>
<p>傻逼玩意！</p>
<hr />
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>iterm2</tag>
        <tag>ohmyzsh</tag>
      </tags>
  </entry>
  <entry>
    <title>LossFlow</title>
    <url>/2023/12/18/loss%E6%BC%82%E6%B5%AE%E4%B8%8D%E5%AE%9A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="问题描述"><a class="markdownIt-Anchor" href="#问题描述"></a> 问题描述</h2>
<p>发现训练出来的loss忽大忽小的<br />
<img src="https://pbs.twimg.com/media/GBnlpgcaAAA6rb3?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="问题所在"><a class="markdownIt-Anchor" href="#问题所在"></a> 问题所在</h2>
<p>每个epoch计算得出的loss是最后一个batch的loss，而不是整个epoch的平均loss</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">        img, _ = data</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        output = autoencoder(img)</span><br><span class="line">        loss = criterion(output, img)</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/50], Loss: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, loss.item()))</span><br></pre></td></tr></table></figure>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>将每个epoch中的所有batch的loss求和，然后求平均即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    total_loss=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">        img, _ = data</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        output = autoencoder(img)</span><br><span class="line">        loss = criterion(output, img)</span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">    avg_loss = total_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/50], Average Loss: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, avg_loss))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>loss</tag>
      </tags>
  </entry>
  <entry>
    <title>mac的输入法问题</title>
    <url>/2023/11/11/mac%E7%9A%84%E8%BE%93%E5%85%A5%E6%B3%95%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p>设备：MacBook Pro M2</p>
<p>问题描述：<a href="https://discussionschinese.apple.com/thread/254338716">系统经常性的卡死，鼠标不是指针，而是彩虹圈圈一直在转</a></p>
<p>解决方法：更换输入法</p>
<p>推荐输入法：<a href="https://github.com/KyleBing/rime-wubi86-jidian">Rime 输入法</a></p>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>mac</tag>
        <tag>输入法</tag>
      </tags>
  </entry>
  <entry>
    <title>nvidia-smi</title>
    <url>/2023/12/03/nvidia-smi/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1简介"><a class="markdownIt-Anchor" href="#1简介"></a> 1.简介</h2>
<p>nvidia-smi是常用的GPU命令</p>
<br>
<h2 id="2nvidia-smi输出解析"><a class="markdownIt-Anchor" href="#2nvidia-smi输出解析"></a> 2.nvidia-smi输出解析</h2>
<p><img src="https://pic3.zhimg.com/80/v2-0254d0c6569aa0c826cd6d2591a0031a_1440w.webp" alt="" /></p>
<br>
<h2 id="3示例"><a class="markdownIt-Anchor" href="#3示例"></a> 3.示例</h2>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">(sbert) root@<span class="number">3090</span>_0002:/data10/sqy/spikeBert_Sqy# nvidia-smi</span><br><span class="line">Sun Dec  <span class="number">3</span> <span class="number">19</span>:<span class="number">41</span>:<span class="number">18</span> <span class="number">2023</span>       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI <span class="number">470</span>.<span class="number">141</span>.<span class="number">03</span>   Driver Version: <span class="number">470</span>.<span class="number">141</span>.<span class="number">03</span>   CUDA Version: <span class="number">11</span>.<span class="number">4</span>     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   <span class="number">0</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:<span class="number">35</span>:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">30</span>%   <span class="number">38</span>C    P8    <span class="number">30</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">1</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:<span class="number">36</span>:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">30</span>%   <span class="number">40</span>C    P8    <span class="number">25</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">2</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:<span class="number">39</span>:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">30</span>%   <span class="number">39</span>C    P8    <span class="number">22</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">3</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:<span class="number">3</span>D:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">30</span>%   <span class="number">38</span>C    P8    <span class="number">25</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">4</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:<span class="number">9</span>C:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">30</span>%   <span class="number">37</span>C    P8    <span class="number">25</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">5</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:<span class="number">9</span>D:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">32</span>%   <span class="number">41</span>C    P8    <span class="number">30</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">6</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:A0:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">34</span>%   <span class="number">41</span>C    P8    <span class="number">27</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">|   <span class="number">7</span>  NVIDIA GeForce ...  On   | <span class="number">00000000</span>:A4:<span class="number">00</span>.<span class="number">0</span> Off |                  N/A |</span><br><span class="line">| <span class="number">33</span>%   <span class="number">41</span>C    P8    <span class="number">31</span>W / <span class="number">350</span>W |      <span class="number">1</span>MiB / <span class="number">24268</span>MiB |      <span class="number">0</span>%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   <span class="built_in">Type</span>   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<br>
<p><strong>NVIDIA-SMI版本和CUDA版本</strong>：</p>
<ul>
<li><code>NVIDIA-SMI 470.141.03</code>：这是NVIDIA系统管理接口（System Management Interface）的版本号。</li>
<li><code>Driver Version: 470.141.03</code>：这是当前安装的NVIDIA GPU驱动程序的版本。</li>
<li><code>CUDA Version: 11.4</code>：这是当前安装的CUDA版本。CUDA是NVIDIA的并行计算平台和编程模型。</li>
</ul>
<p><strong>GPU列表</strong>：</p>
<ul>
<li>您的系统有8个NVIDIA GeForce GPU，每个GPU的具体信息如下：
<ul>
<li><code>Persistence-M</code>：显示GPU的持久模式状态。当开启时，持久模式会保持GPU初始化状态，有助于减少启动延迟。</li>
<li><code>Bus-Id</code>：GPU在PCI总线上的地址。</li>
<li><code>Disp.A</code>：显示活动状态。<code>On</code>表示有显示输出，<code>Off</code>表示没有。</li>
<li><code>Volatile Uncorr. ECC</code>：显示易失性未更正错误计数（适用于支持ECC的GPU）。</li>
</ul>
</li>
</ul>
<p><strong>每个GPU的使用情况</strong>：</p>
<ul>
<li><code>Fan</code>：风扇速度百分比。</li>
<li><code>Temp</code>：GPU的当前温度（摄氏度）。</li>
<li><code>Perf</code>：性能状态，通常为 <code>P0</code>（最高性能）到 <code>P12</code>（最低性能）之间的某个值。<code>P8</code>通常表示空闲状态。</li>
<li><code>Pwr:Usage/Cap</code>：当前功率使用量和最大功率容量（瓦特）。</li>
<li><code>Memory-Usage</code>：GPU内存的使用情况，显示当前使用量和总容量（MiB）。</li>
<li><code>GPU-Util</code>：GPU使用率百分比。</li>
<li><code>Compute M.</code>：计算模式，通常为 <code>Default</code> 或 <code>Exclusive</code>。</li>
</ul>
<p><strong>进程信息</strong>：</p>
<ul>
<li>此部分列出了当前在每个GPU上运行的进程。在输出中，没有进程在任何GPU上运行。</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>nvidia</tag>
        <tag>显存</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title>RuntimeError: CUDA error: device-side assert triggered</title>
    <url>/2023/12/28/RuntimeError-CUDA-error-device-side-assert-triggered/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="报错说明"><a class="markdownIt-Anchor" href="#报错说明"></a> 报错说明</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RuntimeError: CUDA error: device-side <span class="keyword">assert</span> triggered</span><br><span class="line">CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.</span><br><span class="line">For debugging consider passing CUDA_LAUNCH_BLOCKING=<span class="number">1.</span></span><br><span class="line">Compile <span class="keyword">with</span> `TORCH_USE_CUDA_DSA` to enable device-side assertions.</span><br></pre></td></tr></table></figure>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<p>在代码最上面加上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_LAUNCH_BLOCKING&#x27;</span>] = <span class="string">&quot;1&quot;</span></span><br></pre></td></tr></table></figure>
<br>
<p>然后运行文件，即可查找到错误的位置：<br />
错误问题大概率分为以下几种情况：</p>
<ul>
<li>分类问题：标签个数不对应</li>
<li>loss为nan</li>
<li>超出索引范围等</li>
</ul>
<br>
<p>我的是因为索引超过了max_length才导致报错的，索引将max_length增大即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.pos_embedding = nn.Embedding(max_length, hid_dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----</span><br><span class="line"></span><br><span class="line"><span class="comment">#pos=[16,102]</span></span><br><span class="line"><span class="comment">#pos_embedding(max_length,768) ,max_length=100</span></span><br><span class="line">trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>cuda</tag>
      </tags>
  </entry>
  <entry>
    <title>outlook</title>
    <url>/2023/07/25/outlook/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="如何配置邮件客户端使用imap协议"><a class="markdownIt-Anchor" href="#如何配置邮件客户端使用imap协议"></a> 如何配置邮件客户端使用IMAP协议</h2>
<p>首先确定您的客户端支持IMAP协议<br />
配置的方法：</p>
<ul>
<li>接收邮件服务器：<a href="http://imap.exmail.qq.com">imap.exmail.qq.com</a>,使用SSL，端口993</li>
<li>发送邮件服务器：<a href="http://smtp.exmail.qq.com">smtp.exmail.qq.com</a>,使用SSL，端口465</li>
<li>帐户名：企业邮箱帐户名</li>
<li>密码：企业邮箱密码</li>
<li>电子邮件地址：企业邮箱的完整邮件地址</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>outlook</tag>
        <tag>email</tag>
        <tag>imap</tag>
      </tags>
  </entry>
  <entry>
    <title>Terminal VS Shell</title>
    <url>/2024/02/26/Terminal-VS-Shell/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.ihewro.com/archives/933/">终端与shell的区别</a></li>
</ul>
<br>
<h2 id="终端"><a class="markdownIt-Anchor" href="#终端"></a> 终端</h2>
<p>很久很久以前，<a href="https://zh.wikipedia.org/wiki/%E7%B5%82%E7%AB%AF">终端</a>这个<strong>概念</strong>是这样的：是一种硬件，是一种输入输出设备，用于和计算机交换信息。</p>
<p><strong>终端的工作</strong>：用户通过终端输入命令，终端将命令传入计算机，执行后，并把结果输入到终端上显示。</p>
<p>从这个概念不难可以看到电传打印机符合这个概念：</p>
<p>但是现在计算机硬件一体化程度越来越高，硬件质量也越来越强，输入输出设备完全没必要单独用一个硬件和计算机进行交换信息了，取而代之使用软件终端和计算机进行交互信息。</p>
<p>这就是<strong>终端模拟器 (Terminal Emulator)</strong>，也就是我们现在所讨论的终端。除了它不是硬件，它符合终端的概念和工作流程。</p>
<p>举个例子，下面这些软件都是终端：</p>
<ul>
<li>GNU/Linux：gnome-terminal、Konsole；</li>
<li>macOS：Terminal.app、iTerm2；</li>
<li>Windows：Win32 控制台、ConEmu 等。</li>
</ul>
<br>
<h2 id="shell"><a class="markdownIt-Anchor" href="#shell"></a> shell</h2>
<p>有了终端就足够了吗？Shell是用来做什么的？</p>
<p><strong>终端的工作范围</strong>：接受输入，显示输出，图形化界面</p>
<p>而<strong>Shell的核心工作</strong>是操控计算机内核，即访问OS中某个具有一定功能，可以处理具体事务或包含一定内容的文件。</p>
<p>Shell包括：</p>
<ul>
<li>图形化 shell（图形化的桌面环境），如Windows Explorer （文件管理器）、 Linux的桌面环境有：KDE、GNOME、CDE、 XFCE等。</li>
<li>命令行 shell。如bash 、sh 、csh 、ksh</li>
</ul>
<br>
<h2 id="切换shell"><a class="markdownIt-Anchor" href="#切换shell"></a> 切换Shell</h2>
<p>输入<code>cat /etc/shells</code>,可以查看本机上的所有Shell</p>
<br>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>终端就是软件，是最外层的，shell = shell脚本语言解析器+编辑、外观等额外功能</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>Terminal</tag>
      </tags>
  </entry>
  <entry>
    <title>paper:Transformer</title>
    <url>/2024/01/25/paper-Transformer/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a></li>
<li><a href="https://abinzzz.github.io/2024/01/25/%E5%85%B3%E4%BA%8ETransformer%E7%9A%84%E9%97%AE%E9%A2%98/">面试：关于Transformer的问题</a></li>
<li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
<li><a href="https://arxiv.org/abs/1308.0850">Generating Sequences With Recurrent Neural Networks</a></li>
<li><a href="https://aclanthology.org/W18-2509.pdf">The Annotated Transformer</a></li>
<li><a href="https://blog.csdn.net/qq_56591814/article/details/127313216#Attention_is_All_You_Need_148">李沐论文精读系列一： ResNet、Transformer、GAN、BERT</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/452663865">一文浅析transformer–李沐带你深入浅出transformer</a></li>
</ul>
<br>
<h2 id="1abstract"><a class="markdownIt-Anchor" href="#1abstract"></a> 1.abstract</h2>
<p><strong>主流的序列转换模型都是基于复杂的循环或卷积神经网络</strong>，我们的模型包含一个编码器和一个解码器。具有<strong>最好性能的模型在编码和解码之间通过一个注意力机制链接编解码器</strong>。我们提出了一个新的简单网络结构——<code>Transformer</code>，其仅仅是基于注意力机制，而<strong>完全不需要之前的循环或卷积</strong>。在两个机器翻译任务上的实验表明，该模型具有更好的性能，同时并行度更好，并且训练时间更少。（泛化到其它任务效果也不错）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在WMT 2014英语到德语翻译任务上，我们的模型达到了28.4 BLEU，比之前最好的结果提高了2 BLEU。在WMT 2014英语到法语翻译任务上，我们的模型在8个GPU上训练3.5天后，所得到的单个模型获得了41.8 BLEU分数。我们在大型和有限的训练数据中，通过将其成功应用于英语句法解析，表明了Transformer可以很好地适用于其他任务。</span><br><span class="line"></span><br><span class="line">可以看到这篇文章最开始只是针对机器翻译来写的，transformer在机器翻译上效果也很好。但是随着bert、GPT等把这种架构用在更多的NLP任务上，甚至后面CV和video等也可以使用注意力机制，整个工作就火出圈了。</span><br></pre></td></tr></table></figure>
<br>
<h2 id="2结论"><a class="markdownIt-Anchor" href="#2结论"></a> 2.结论</h2>
<p>本文介绍了Transformer，这是第一个完全基于注意力的序列转换模型，用多头自注意力（<strong>multi-headed self-attention</strong>）代替了 <strong>encoder-decoder</strong> 架构中最常用的循环层。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">对于翻译任务，Transformer可以比基于循环或卷积层的体系结构训练更快。在WMT 2014 English-to-German和 WMT 2014 English-to-French翻译任务中，我们取得了最好的结果。在前面的任务中，我们最好的模型甚至胜过以前发表过的所有整合模型。</span><br></pre></td></tr></table></figure>
<p>我们对基于注意力的模型的未来感到兴奋，<strong>并计划将Transformer应用于文本之外的涉及输入和输出模式的问题中任务，以有效处理大型输入&amp;输出任务，如图像、音频和视频等,让生成不那么时序化是我们的另一个研究目标。</strong></p>
<p>我们用于训练和评估模型的代码可以在<a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a>上获得。</p>
<Br>
<h2 id="3导论"><a class="markdownIt-Anchor" href="#3导论"></a> 3.导论</h2>
<p>序列建模和转换问题（如机器翻译）最新方法是<code>LSTM</code>和<code>GRN</code>等。后面许多研究都围绕循环语言模型和编码器-解码器体系结构进行。</p>
<p><strong>循环网络模型通常是考虑了输入和输出序列的中字符位置的计算</strong>。当前时刻隐藏状态<code>ht</code>，是由上一时刻隐藏状态<code>ht−1</code>和 t时刻输入共同决定的。（把之前的信息都放在隐藏状态里，一个个传递下去，是RNN处理时序信息的关键）。这种固有的时序模型难以并行化处理，计算性能就很差。这些年做了一些并行化改进，但是问题依然存在。</p>
<p>另外还存在长距离衰减问题，解码阶段，越靠后的内容，翻译效果越差。除非你把ht维度设置的很高，可以把每一个时间步的信息都存下来。但这样会造成内存开销很大。</p>
<p>attention在此之前，已经成功的应用在encoder-decoder 架构中，但主要是用在如何把编码器的信息有效的传递给解码器，所以是和RNN一起使用的。</p>
<p>本文提出的Transformer，不再使用循环神经层，而是纯基于注意力机制，来构造输入和输出之间的全局依赖关系。Transformer可以进行更多的并行化，训练时间更短但翻译效果更好。</p>
<br>
<h2 id="4-背景"><a class="markdownIt-Anchor" href="#4-背景"></a> 4. 背景</h2>
<p>使用卷积神经网络替换循环神经网络，并行计算所有输入和输出位置的隐藏表示，是扩展神经GPU，ByteNet和ConvS2S的基础，因为这样可以减少时序计算。但是CNN对长序列难以建模（因为卷积计算时，<strong>卷积核/感受野比较小</strong>，如果序列很长，需要使用多层卷积才可以将两个比较远的位置关联起来）。但是<strong>使用Transformer的注意力机制的话，每次（一层）就能看到序列中所有的位置</strong>，就不存在这个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">关联来自两个任意输入或输出位置的数据所需的操作数量，随着距离增长，对于ConvS2S呈线性，对于ByteNet呈对数，而对于Transformer是常数，因为一次就看到了。</span><br></pre></td></tr></table></figure>
<p>但是卷积的好处是，输出可以有多个通道，每个通道可以认为是识别不同的模式，作者也<strong>想得到这种多通道输出的效果，所以提出了Multi-Head Attention多头注意力机制。</strong>（模拟卷积多通道输出效果）</p>
<p>Self-attention，有时称为intra-attention，是一种关联单个序列的不同位置以计算序列表示的关联机制。在此之前已成功用于多种任务。但据我们所知，Transformer是第一个完全依靠self-attention，而不使用卷积或循环的的<code>encoder-decoder</code> 转换模型。</p>
<br>
<h2 id="5-模型架构"><a class="markdownIt-Anchor" href="#5-模型架构"></a> 5. 模型架构</h2>
<p>大部分神经序列转换模型都使用<code>encoder-decoder</code>结构。编码器将一个输入序列<code>(x1, ..., xn)</code>映射到一个连续的表示<code>z = (z1, ..., zn)</code>中。解码器根据<code>z</code>中的每个元素，逐步生成输出序列<code>(y1, ..., ym)</code>，每个时间步生成一个元素。在每一步中，<strong>模型都是自回归的，在生成下一个结果时，会将先前生成的结果作为当前的输入</strong>。</p>
<p>编码器和解码器的序列可以不一样长，且编码器可以一次性看到整个序列，但解码器是逐步输出的。</p>
<p>Transformer遵循这种整体架构，但对编码器和解码器使用堆叠的自注意力和逐点全连接层，如下图所示:<br />
<img src="https://pbs.twimg.com/media/GEscybAbUAAdxSC?format=jpg&amp;name=medium" alt="" /></p>
<ul>
<li><strong>Outputs（shifted right）</strong>：解码器在初始时刻实际上没有输入，它的输入是编码器的输出。所以这里的&quot;Outputs&quot;表示输出序列，&quot;shifted right&quot;是指序列逐个右移的意思。</li>
<li><strong>Nx</strong>：表示模块堆叠了N次。</li>
</ul>
<p>图画得好，一张图能搞定所有东西，所以画图是一个基础技能。</p>
<br>
<h2 id="51-encoder"><a class="markdownIt-Anchor" href="#51-encoder"></a> 5.1 Encoder</h2>
<p>编码器由N=6个相同的encoder层堆叠组成。每层有两个子层：</p>
<ul>
<li><strong>multi-head self-attention</strong></li>
<li><strong>FFNN层</strong>（前馈神经网络层，Feed Forward Neural Network），实际上是MLP（多层感知器），为了更加专业，名称被设置得较长。每个子层都使用以下特点：
<ul>
<li><strong>残差连接(residual connection)</strong> 后进行层归一化（layer normalization）。</li>
<li>每个子层的输出是<code>LayerNorm(x + Sublayer(x))</code>，其中<code>Sublayer(x)</code>是当前子层的输出。</li>
<li>为简化模型，所有子层以及嵌入层的向量维度都是<code>d_model = 512</code>。如果输入输出维度不一样，残差连接会进行投影以映射到统一维度。这种做法不同于传统的CNN或MLP，它们通常会进行一些下采样。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这种各层统一维度使得模型结构相对简单，只有`N`和`d_model`这两个参数需要调整。这个设计也影响到后面一系列的网络发展，如BERT和GPT等。</span><br></pre></td></tr></table></figure>
<br>
<h2 id="52-decoder"><a class="markdownIt-Anchor" href="#52-decoder"></a> 5.2 Decoder</h2>
<p>解码器：解码器同样由 N=6个相同的decoder层堆栈组成，每个层有三个子层。</p>
<ul>
<li><strong>Masked multi-head self-attention</strong>：在解码器里，Self Attention 层只允许关注到输出序列中早于当前位置之前的单词。具体做法是：在 Self Attention 分数经过 Softmax 层之前，使用attention mask，屏蔽当前位置之后的那些位置。所以叫Masked multi-head self Attention。（对应masked位置使用一个很大的负数-inf，使得softmax之后其对应值为0）</li>
<li><strong>Encoder-Decoder Attention</strong> ：编码器输出最终向量，将会输入到每个解码器的Encoder-Decoder Attention层，用来帮解码器把注意力集中中输入序列的合适位置。</li>
<li><strong>FFNN</strong>: 与编码器类似，每个子层都使用残差连接，然后进行层归一化。假设一个 Transformer 是由 2 层编码器和两层解码器组成的</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GEv8pBNbsAA-GzK?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="53-ln-vs-bn"><a class="markdownIt-Anchor" href="#53-ln-vs-bn"></a> 5.3 LN VS BN</h2>
<p>参考该文章：<a href="https://abinzzz.github.io/2024/01/25/BatchNorm-VS-LayerNorm/">Normalization</a></p>
<br>
<h2 id="54-attention机制"><a class="markdownIt-Anchor" href="#54-attention机制"></a> 5.4 Attention机制</h2>
<p>attention函数可以被描述为将query和一组key-value对映射到输出，其中query、key、value和输出都是向量。输出被计算为value的加权求和，所以输出和value的维度一致。每个value的权重由query与对应key计算所得。（不同注意力机制有不同的算法）</p>
<br>
<h2 id="541-缩放的点积注意力scaled-dot-product-attention"><a class="markdownIt-Anchor" href="#541-缩放的点积注意力scaled-dot-product-attention"></a> 5.4.1 缩放的点积注意力（Scaled Dot-Product Attention）</h2>
<p><strong>缩放的点积注意力</strong>:</p>
<ul>
<li>其输入为<code>query</code>、<code>key</code>(维度是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)以及<code>values</code>(维度是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">d_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)</li>
<li>计算<code>query</code>和所有<code>key</code>的点积,得到两个向量的相似度(结果越大相似度越高);然后对每个点积结果除以<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span></li>
<li>点积结果输入<code>softmax</code>函数获得<code>value</code>的权重。最后对<code>value</code>进行加权求和。</li>
</ul>
<p>在实践中,我们同时计算一组<code>query</code>的attention函数,并将它们组合成一个矩阵<code>Q</code>。<code>key</code>和<code>value</code>也一起组成矩阵<code>K</code>和<code>V</code>。我们计算的输出矩阵为:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.089473em;"><span style="top:-2.5864385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622307142857143em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222307142857144em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9190928571428572em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></p>
<p><strong>注意</strong>： <code>K</code>、<code>V</code>矩阵的序列长度是一样的(加权求和),而<code>Q</code>矩阵的序列长度可以和前两者不一样;这种情况发生在:解码器部分的Encoder-Decoder Attention层中,<code>Q</code>矩阵是来自解码器输出<code>tgt</code>,而<code>K</code>、<code>V</code>矩阵则是来自编码器最后的输出<code>memory</code>。即<code>tgt2 = self.multihead_attn(tgt, memory,memory, attn_mask=memory_mask,key_padding_mask=memory_key_padding_mask)[0]</code>。</p>
<p>但是<code>Q</code>和<code>K</code>的维度必须一样,因为要计算点积。</p>
<Br>
<p><img src="https://pbs.twimg.com/media/GFlejmqbsAAtAmo?format=jpg&amp;name=medium" alt="" /></p>
<p>有两个最常用的attention函数:</p>
<p>1. <strong>加法attention</strong> (cite):</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup><mtext>Tanh</mtext><mo stretchy="false">(</mo><mi>q</mi><mi>W</mi><mo>+</mo><mi>k</mi><mi>U</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s = A^T \text{Tanh}(qW + kU)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord text"><span class="mord">Tanh</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mclose">)</span></span></span></span></p>
<p>使用具有单个隐层的前馈网络计算,`q`和`k`维度不一致也可以进行;</p>
<p>2. <strong>点积(乘法)attention</strong>:</p>
<p>除了缩放因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{d_k}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.383108em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5864385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622307142857143em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222307142857144em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 之外,点积Attention跟我们的算法一样(所以作者的注意力叫缩放点积注意力)。虽然理论上点积attention和加法attention复杂度相似,但在实践中,点积attention可以使用高度优化的矩阵乘法来实现,因此点积attention计算更快、更节省空间。</p>
<p>当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的值比较小的时候,这两个机制的性能相差相近,当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>比较大时,加法attention比不带缩放的点积attention性能好。我们怀疑,维度<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>很大时,点积结果也变得很大,将softmax函数推向具有极小梯度的区域。为了抵消这种影响,我们将点积缩小 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><mrow><mi>d</mi><mi mathvariant="normal">_</mi><mi>k</mi></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{d\_k}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.6747079999999999em;vertical-align:-0.8296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5046085em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9791307142857142em;"><span class="svg-align" style="top:-3.428571428571429em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="mord mtight" style="padding-left:1.19em;"><span class="mord mathnormal mtight">d</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.951130714285714em;"><span class="pstrut" style="height:3.428571428571429em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.5428571428571431em;"><svg width='400em' height='1.5428571428571431em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.47744071428571444em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8296em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>倍。</p>
<br>
<h2 id="542-多头注意力"><a class="markdownIt-Anchor" href="#542-多头注意力"></a> 5.4.2 多头注意力</h2>
<p>多头注意力的定义如下:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>MultiHead</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>Concat</mtext><mo stretchy="false">(</mo><msub><mtext>head</mtext><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mtext>head</mtext><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">MultiHead</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Concat</span></span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord">head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord text"><span class="mord">head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>where </mtext><msub><mtext>head</mtext><mi>i</mi></msub><mo>=</mo><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator="true">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator="true">,</mo><mi>V</mi><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{where}  \ \text{head}_i = \text{Attention}(QW^Q_i, KW^K_i, VW^V_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord text"><span class="mord">where</span></span><span class="mspace"> </span><span class="mord"><span class="mord text"><span class="mord">head</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.959239em;"><span style="top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>其中映射由权重矩阵完成: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mtext>model</mtext></msub><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W^Q_i \in \mathbb{R}^{d_{\text{model}} \times d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.959239em;"><span style="top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mtext>model</mtext></msub><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W^K_i \in \mathbb{R}^{d_{\text{model}} \times d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0999949999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mtext>model</mtext></msub><mo>×</mo><msub><mi>d</mi><mi>v</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W^V_i \in \mathbb{R}^{d_{\text{model}} \times d_v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0999949999999998em;vertical-align:-0.258664em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>h</mi><msub><mi>d</mi><mi>v</mi></msub><mo>×</mo><msub><mi>d</mi><mtext>model</mtext></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W^O \in \mathbb{R}^{hd_v \times d_{\text{model}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.880431em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>。</p>
<p><img src="https://pbs.twimg.com/media/GFlifvcb0AACeUL?format=jpg&amp;name=medium" alt="" /></p>
<p>我们采用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">h = 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span>个平行attention层或者叫head。对于这些head中的每一个,我们使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><msub><mi>d</mi><mi>v</mi></msub><mo>=</mo><msub><mi>d</mi><mtext>model</mtext></msub><mi mathvariant="normal">/</mi><mi>h</mi><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">d_k = d_v = d_{\text{model}}/h = 64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span></span></span></span>,总计算成本与具有全部维度的单个head attention相似。</p>
<p>输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span> 和8组权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span> 相乘,得到 8 组 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(Q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(K)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(V)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span> 矩阵。进行attention计算,得到 8 组 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(Z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span></span></span></span> 矩阵(假设head=8)。把8组矩阵拼接起来,乘以权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span>,将其映射回 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 维向量(相当于多维特征进行汇聚),得到最终的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(Z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span></span></span></span>。这个矩阵包含了所有 attention heads(注意力头)的信息。矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>会输入到 FFNN层(前馈神经网络层接收的也是 1 个矩阵,而不是8个。其中每行的向量表示一个词)。</p>
<p><strong>使用多头自注意力的好处:</strong></p>
<ul>
<li>
<p><strong>多语义匹配</strong>:本身缩放点积注意力是没什么参数可以学习的,就是计算点积、softmax、加权和而已。但是使用Multi-head attention之后,投影到低维的权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>Q</mi></msup></mrow><annotation encoding="application/x-tex">W^Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">Q</span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">W^K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding="application/x-tex">W^V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span></span></span></span></span></span></span></span></span></span></span> 是可以学习的,而且有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">h=8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span>次学习机会。使得模型可以在不同语义空间下学到不同的的语义表示,也扩展了模型关注不同位置的能力。类似卷积中多通道的感觉。</p>
<p>例如, <strong>“小明养了一只猫,它特别调皮可爱,他非常喜欢它”。“猫”从指代的角度看,与“它”的匹配度最高,但从属性的角度看,与“调皮”“可爱”的匹配度最高。标准的 Attention 模型无法处理这种多语义的情况</strong>。</p>
</li>
<li>
<p><strong>注意力结果互斥</strong>:自注意力结果需要经过softmax归一化,导致自注意力结果之间是互斥的,无法同时关注多个输入。<strong>使用多组自注意力模型产生多组不同的注意力结果,则不同组注意力模型可能关注到不同的输入,从而增强模型的表达能力。</strong></p>
</li>
</ul>
<br>
<h2 id="543-在模型中的应用"><a class="markdownIt-Anchor" href="#543-在模型中的应用"></a> 5.4.3 在模型中的应用</h2>
<p><img src="https://pbs.twimg.com/media/GFlifvcb0AACeUL?format=jpg&amp;name=medium" alt="" /></p>
<p>在Transformer中，multi-head attention以三种不同的方式使用：</p>
<ol>
<li>
<p><strong>multi-head self attention</strong>：标准的多头自注意力层，用在encoder的第一个多头自注意力层。所有key，value和query来自同一个地方，即encoder中前一层的输出。在这种情况下，encoder中的每个位置都可以关注到encoder上一层的所有位置。</p>
</li>
<li>
<p><strong>masked-self-attention</strong>：用在decoder中，序列的每个位置只允许看到当前位置之前的所有位置，这是为了保持解码器的自回归特性，防止看到未来位置的信息。</p>
</li>
<li>
<p><strong>encoder-decoder attention</strong>：用于encoder block的第二个多头自注意力层。query来自前面的decoder层，而keys和values来自encoder的输出memory。这使得decoder中的每个位置都能关注到输入序列中的所有位置。</p>
</li>
</ol>
<p>encoder-decoder attention层可以使解码器在每个时间步，把注意力集中到输入序列中感兴趣的位置。<br />
。</p>
<p>以句子“hello world”翻译为“你好 世界”为例，当解码器准备生成“你”这个字的时候，它的输入（query）会与输入序列中的所有单词（“hello&quot;和&quot;world”）进行比较。在这个特定的时间步骤里，如果解码器的输入query与“hello”的相似度最高，那么模型的注意力就会主要集中在“hello”上。这意味着，在生成“你”这个字时，模型认为“hello”是最相关的词，因此将更多的信息从“hello”传递到解码器，帮助它更准确地生成翻译。</p>
<br>
<h2 id="55-ffn"><a class="markdownIt-Anchor" href="#55-ffn"></a> 5.5 FFN</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV1pu411o7BE/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">Transformer论文逐段精读【论文精读】- 01:00:04</a></li>
</ul>
<p>编码器和解码器中的每个层都包含一个全连接的前馈网络，该前馈网络分别且相同地应用于每个位置。该前馈网络包括两个线性变换，并在两个线性变换中间有一个ReLU激活函数。</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>FFN</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\text{FFN}(x) = \max(0, xW_1 + b_1) W_2 + b_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">FFN</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>Position-wise的意思是，这个多层感知机（MLP）对序列中的每个token都独立地应用一次，且应用的是同一个MLP。这意味着MLP只作用于最后一个维度(d=512)。</p>
<p>因为前面的attention层已经捕获了输入序列的相关信息，并进行了一次汇聚（通过拼接后用(W)映射回(d)维）。所以attention层的结果已经包含了序列中我们感兴趣的信息，因此，在进行MLP映射到我们想要的语义空间时，只需对每个位置（token）单独进行MLP处理。</p>
<p>从attention层抽取序列信息到MLP映射到所需的语义空间的非线性变换，构成了transformer处理信息的基础过程。</p>
<p>尽管两层都是线性变换，但它们在层与层之间使用不同的参数。另一种描述方式是两个内核大小为1的卷积。输入和输出的维度都是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mtext>model</mtext></msub><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">d_{\text{model}} = 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span>，内层维度是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>f</mi><mi>f</mi></mrow></msub><mo>=</mo><mn>2048</mn></mrow><annotation encoding="application/x-tex">d_{ff} = 2048</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span><span class="mord">4</span><span class="mord">8</span></span></span></span>。（也就是第一层输入512维，输出2048维；第二层输入2048维，输出512维）。</p>
<p><img src="https://pbs.twimg.com/media/GFlqYStaEAABQmB?format=jpg&amp;name=medium" alt="" /></p>
<ul>
<li>RNN是把上一时刻信息作为输入（和t时刻输入一起），传递给当前时刻，并用MLP做语义转换。</li>
<li>Transformer是通过attention层直接关联到全局的序列信息，然后用MLP做语义转换。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MLP的作用是对输入信息进行进一步的加工和抽象，以便捕捉到更深层次的语义关系和模式。</span><br></pre></td></tr></table></figure>
<br>
<h2 id="56-词嵌入和softmax"><a class="markdownIt-Anchor" href="#56-词嵌入和softmax"></a> 5.6 词嵌入和Softmax</h2>
<p>我们使用学习到的嵌入将输入token和输出token转换为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mtext>model</mtext></msub></mrow><annotation encoding="application/x-tex">d_{\text{model}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 维的向量。我们还使用普通的线性变换和softmax函数将解码器输出转换为预测的下一个token的概率。在我们的模型中,输入输出两个嵌入层,和pre-softmax线性变换共享相同的权重矩阵(这样训练起来简单一些)。最后我们将这些权重乘以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mtext>model</mtext></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_{\text{model}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span> (比如512)。</p>
<p>这是因为一般会把一个向量的L2范数学到接近1,这样向量维度越大,学到的权重值就会很小。但是位置编码是不会这样学成L2范数接近1的。所以把权重乘上 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mtext>model</mtext></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_{\text{model}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span> 之后,token嵌入和位置编码(Positional Encoding)才接近统一量级。(都在-1到1之间)</p>
<h2 id="57-位置编码positional-encoding"><a class="markdownIt-Anchor" href="#57-位置编码positional-encoding"></a> 5.7 位置编码(Positional Encoding)</h2>
<p>Attention计算时本身是不考虑位置信息的,这样序列顺序变化结果也是一样的。所以我们必须在序列中加入关于词符相对或者绝对位置的一些信息。为此,我们将“位置编码”添加到token嵌入中。二者维度相同(例如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mspace linebreak="newline"></mspace><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></mrow></msub><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">d_{\\text{model}} = 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mspace mtight newline"></span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span></span></span></span>),所以可以相加。有多种位置编码可以选择,例如通过学习得到的位置编码和固定的位置编码。</p>
<p>在这项工作中,我们使用不同频率的正弦和余弦函数:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant="normal">/</mi><msub><mi>d</mi><mtext>model</mtext></msub></mrow></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">PE_{(pos,2i)} = \sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-0.3551999999999999em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mop">sin</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.564755em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8932071428571429em;"><span style="top:-2.893207142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">/</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43524499999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant="normal">/</mi><msub><mi>d</mi><mtext>model</mtext></msub></mrow></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">PE_{(pos,2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-0.3551999999999999em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mop">cos</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.564755em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight">0</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8932071428571429em;"><span style="top:-2.893207142857143em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5357142857142856em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span><span class="mord mtight">/</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.446108em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43524499999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">pos</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span> 是位置,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 是维度。也就是说,位置编码的每个维度对应于一个正弦曲线。这些波长形成一个从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>π</mi></mrow><annotation encoding="application/x-tex">2\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10000</mn><mo>⋅</mo><mn>2</mn><mi>π</mi></mrow><annotation encoding="application/x-tex">10000 \cdot 2\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> 的幂级数。我们选择这个函数是因为我们假设它会让模型很容易学习对相对位置的关注,因为对任意确定的偏移 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">PE_{pos+k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 可以表示为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">PE_{pos}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 的线性函数。最终编码向量每个元素值都是在-1到1之间。</p>
<p>此外,我们会将编码器和解码器堆栈中的嵌入和位置编码的和再加一个dropout。对于基本模型,我们使用的dropout比例是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>d</mi><mi>r</mi><mi>o</mi><mi>p</mi></mrow></msub><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P_{drop} = 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span>。</p>
<br>
<h2 id="58-为什么使用自注意力机制"><a class="markdownIt-Anchor" href="#58-为什么使用自注意力机制"></a> 5.8 为什么使用自注意力机制</h2>
<p>在本节中，我们比较了self-attention与循环层和卷积层的各个方面，选择使用self-attention是为了解决三个主要问题：</p>
<ol>
<li><strong>每层计算的总复杂度</strong>：我们希望这个复杂度尽可能低。</li>
<li><strong>顺序计算量</strong>：越少表示并行度越高。顺序计算量即下一步计算需要等待前面多少步骤完成。</li>
<li><strong>网络中长距离依赖之间的路径长度</strong>：影响长距离依赖性能力的一个关键因素是前向和后向信号在网络中传播的路径长度。输入和输出序列中任意位置之间的路径越短，学习长距离依赖性就越容易。</li>
</ol>
<p>我们还比较了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度。以下是关于attention的分析：</p>
<p><img src="https://pbs.twimg.com/media/GFlt_guacAA_W_7?format=png&amp;name=medium" alt="" /></p>
<ul>
<li><strong>计算复杂度</strong>：矩阵(Q*K)的计算，其中两个矩阵都是(n)行(d)列，复杂度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2 \cdot d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>，其他计算量相对较小；</li>
<li><strong>顺序计算量</strong>：矩阵内部并行度很高，整个计算主要是矩阵乘法，所以顺序计算量为(O(1))；</li>
<li><strong>最大路径长度</strong>：从一个点关联到任何一个点的路径长度。Attention能一次性看到整个序列，所以只需要一次操作，复杂度为(O(1))。</li>
</ul>
<p>在实际应用中，attention机制相比于RNN和CNN，对模型的假设更少，这意味着模型需要更多的数据和更大的模型尺寸才能达到类似的效果。因此，基于transformer的模型通常规模较大，训练成本较高。</p>
<hr />
<p><strong>attention的计算复杂度是如何得到的</strong>？：<br />
Attention机制的计算复杂度主要来源于它的核心操作,即计算查询(Queries)和键(Keys)之间的点积,并应用softmax函数来得到权重,然后这些权重被用于加权和值(Values)。具体地,对于一个输入序列,我们考虑以下几个维度:</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>: 序列的长度,即输入中的token数量。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span>: 每个token的维度,即Queries、Keys和Values的维度。</li>
</ul>
<p>在自注意力机制中,每个输入的token都会被转换成对应的Query、Key和Value。然后,对于序列中的每一个Query,都会与所有Keys进行点积操作来计算相似度分数,这个过程的复杂度是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2 \cdot d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>,因为:</p>
<ul>
<li>对于每个Query,都需要与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>个Key进行点积,每次点积操作的复杂度是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>。</li>
<li>序列中有<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span>个这样的Queries。</li>
</ul>
<p>因此,总的计算复杂度为所有Queries和所有Keys点积操作的总和,即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2 \cdot d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>。</p>
<hr />
<br>
<h2 id="6实验"><a class="markdownIt-Anchor" href="#6实验"></a> 6.实验</h2>
<h2 id="61-训练数据和批处理"><a class="markdownIt-Anchor" href="#61-训练数据和批处理"></a> 6.1 训练数据和批处理</h2>
<p>我们在标准的WMT 2014 English-German dataset上进行了训练,其中包含约450万个句子对。这些句子使用byte-pair编码(BPE)进行编码,源语句和目标语句共享大约37000个词符的词汇表。对于英语-法语翻译,我们使用更大的WMT 2014 English-French dataset,它包含3600万个句子,并将词符分成32000个word-piece词汇表。序列长度相近的句子一起进行批处理。每个训练批次的句子对包含大约25000个源词符和25000个目标词符。</p>
<p>BPE编码是因为英语/德语中有很多词根变化,如动词的不同形式等。BPE可以有效减小词表大小同时保留重要的语义信息。共用词表可以让编码器和解码器共享一个embedding,简化模型并共享权重。</p>
<h2 id="62-硬件和时间"><a class="markdownIt-Anchor" href="#62-硬件和时间"></a> 6.2 硬件和时间</h2>
<p>我们在一台配备了8个NVIDIA P100 GPU的机器上训练模型。使用本文描述的超参数的基础模型,每个训练步骤耗时约0.4秒。基础模型共训练了10万步或12小时。对于我们的大型模型(详见表3),每步耗时约1.0秒,共训练了30万步或3.5天。</p>
<p>后来,由于TPU非常适合进行大规模矩阵乘法,Google推荐使用TPU进行训练。</p>
<h2 id="63-优化器"><a class="markdownIt-Anchor" href="#63-优化器"></a> 6.3 优化器</h2>
<p>我们使用Adam优化器,其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">\beta_1=0.9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.98</mn></mrow><annotation encoding="application/x-tex">\beta_2=0.98</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">8</span></span></span></span> 并且 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\epsilon=10^{-9}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">9</span></span></span></span></span></span></span></span></span></span></span></span>。学习率按照以下公式动态调整:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>=</mo><msubsup><mi>d</mi><mtext>model</mtext><mrow><mo>−</mo><mn>0.5</mn></mrow></msubsup><mo>⋅</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi mathvariant="normal">_</mi><mi>n</mi><mi>u</mi><msup><mi>m</mi><mrow><mo>−</mo><mn>0.5</mn></mrow></msup><mo separator="true">,</mo><mi>s</mi><mi>t</mi><mi>e</mi><msub><mi>p</mi><mi>n</mi></msub><mi>u</mi><mi>m</mi><mo>⋅</mo><mi>w</mi><mi>a</mi><mi>r</mi><mi>m</mi><mi>u</mi><mi>p</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><msup><mi>s</mi><mrow><mo>−</mo><mn>1.5</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">lrate = d_{\text{model}}^{-0.5} \cdot \min(step\_num^{-0.5}, step_num \cdot warmup\_steps^{-1.5})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1555469999999999em;vertical-align:-0.3013079999999999em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.854239em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1241079999999999em;vertical-align:-0.31em;"></span><span class="mop">min</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.1241079999999999em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">m</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>这意味着学习率在前 <code>warmup_steps</code> 步中线性增加,之后与步数的平方根成反比减小。我们设置 <code>warmup_steps = 4000</code>。</p>
<h2 id="64-正则化"><a class="markdownIt-Anchor" href="#64-正则化"></a> 6.4 正则化</h2>
<p>训练期间我们采用两种正则化策略:</p>
<ul>
<li>
<p><strong>Residual Dropout</strong>:我们在每个子层的输出上应用dropout,即在子层输出进入残差连接和LayerNorm之前。此外,在编码器和解码器的token embedding加上Positional Encoding时也使用了dropout。对于基础模型,我们使用的dropout概率为0.1。</p>
</li>
<li>
<p><strong>Label Smoothing</strong>:训练过程中,我们使用了label smoothing,其值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace linebreak="newline"></mspace><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><msub><mi>n</mi><mrow><mi>l</mi><mi>s</mi></mrow></msub><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\\epsilon_{ls} = 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span></span></span></span>。这使模型变得不那么自信,虽然模型学到的信息更加不确定,但这提高了准确性和BLEU得分。</p>
</li>
</ul>
<hr />
<p>在没有使用Label Smoothing的情况下，如果我们有一个分类任务，真实的标签可能会被表示为一个one-hot向量。例如，在一个三分类任务中，第一个类的标签是[1, 0, 0]，这意味着模型被鼓励去预测绝对的置信度为100%属于第一类，0%属于其他类。这可能会导致模型过于自信，过拟合训练数据，对新的或略有差异的数据表现不佳。</p>
<p>使用Label Smoothing后，我们可能会将这个标签修改为如[0.9, 0.05, 0.05]。这样，即使模型最确信的预测是正确的，它也不能达到100%的置信度，这迫使模型学习到更加平滑的、不那么极端的概率分布，有助于提高模型对不见过的数据的泛化能力。</p>
<hr />
<br>
<h2 id="65-模型参数"><a class="markdownIt-Anchor" href="#65-模型参数"></a> 6.5 模型参数</h2>
<p><img src="https://pbs.twimg.com/media/GFlx4f7bsAQFueR?format=png&amp;name=medium" alt="" /></p>
<br>
<h2 id="7评价"><a class="markdownIt-Anchor" href="#7评价"></a> 7.评价</h2>
<p>Transformer（attention机制）几乎能用在所有NLP任务上，类CNN对整个CV领域的革新（不需要那么多的特征提取或者模型建模，学会CNN就行了）。Transformer也是一样，不需要那么多的文本预处理，不需要为每个任务设计不同的架构。<br />
  而且现在transformer在CV、语音、video等领域也广泛使用，等于一个架构可以适用所有领域，任何一点突破在别的领域都能被使用，减少技术的应用时间。 <strong>而且Transformer可以融合多模态的数据（文字、图片、语音等），大家都要同一个架构提取特征的话，可以都抽取到同一个语义空间，使得我们可以用文字、图片、语音等训练更大更好的模型。</strong></p>
<p>虽然Transformer效果这么好，但是对它的理解还在初级阶段。</p>
<p>最新的一些结果表明，<strong>attention在里面只是起到一个聚合序列信息的作用</strong> ，但是后面的MLP/残差连接是缺一不可的，如果去掉的话，模型是基本训练不出什么的</p>
<p>Attention不会对序列的顺序建模，为何能打败RNN？RNN可以显式地建模序列信息，不是应该比attention更好。现在大家觉得attention使用了更广泛的归纳偏置，使得他能处理更一般化的信息；这也是attention没有做空间上的假设吗，但是比CNN/RNN能做到更好的效果。代价就是假设更一般，所以抓取数据信息能力变差，必须使用更大的模型和更多的数据才能训练到一个比较好的效果。</p>
<h2 id="一introduction"><a class="markdownIt-Anchor" href="#一introduction"></a> 一.Introduction</h2>
<p>在过去的使用场景中，模型的输入通常只有一个单独的向量，而模型的输出则是预测的数值或类别,见下图：<br />
<img src="https://pbs.twimg.com/media/F9ga5sDWEAATK3N?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<p>但是假设输入的是一排向量（或序列），且向量的长度不是固定的，例如声音信号、语句、基因序列等，如下图：<br />
<img src="https://pbs.twimg.com/media/F9gbRiOWgAA37Ip?format=png&amp;name=small" alt="" /></p>
<br>
<p>而对于模型输出而言，可以分为如下图所示的三种类型，即输入输出序列长度不变，只有一个输出和输出长度不确定：<br />
<img src="https://pbs.twimg.com/media/F9gb-XnWkAASrfR?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p>以第一种类型为例，常规的想法是采取各个击破的方法，给每个向量添加一个全连接层，从而得到我们想要的输出，但是这样的方法并没有考虑到各个输入向量之间的关系:<br />
<img src="https://pbs.twimg.com/media/F9gcWpEW8AAQp0f?format=png&amp;name=small" alt="" /></p>
<Br>
<p>因此为了让全连接层能够考虑到上下文信息之间的关系，可以将多个相邻的输入向量或序列串联起来给到全连接层，但是到底需要多少个相邻的输入向量，以及如何能够把整个序列作为输入，这就是Self-attention所要做的工作。<br />
<img src="https://pbs.twimg.com/media/F9gcU_YWwAAiJUq?format=png&amp;name=900x900" alt="" /></p>
<Br>
<h2 id="二self-attention"><a class="markdownIt-Anchor" href="#二self-attention"></a> 二.Self-attention</h2>
<p><img src="https://pbs.twimg.com/media/F9gdH2ZWwAAHvJ9?format=png&amp;name=900x900" alt="" /><br />
<strong>Self-attention</strong>的内部机制大致如上图所示，每个输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">b^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>都考虑了所有的输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">a^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>。以单个输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">b^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>为例，<strong>Self-attention</strong>的具体操作流程如下：</p>
<br>
<p>---------- <strong>Self-attention流程·BEGIN</strong> ----------</p>
<ul>
<li><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></strong>: 两个输入向量之间的关联性</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>α</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">\alpha^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94248em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.94248em;margin-right:0.05em;"><span class="pstrut" style="height:2.57948em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>: 经过softmax后，两个输入向量之间的关联性</li>
<li>a：输入</li>
<li>b：输出</li>
<li>W：权重</li>
</ul>
<br>
<p><strong>Step1</strong>: 将两个输入向量各自乘以<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>q</mi></msup><mtext>和</mtext><msup><mi>W</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">W^q和W^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span>,得到<strong>q</strong>和<strong>k</strong>，再将<strong>q</strong>和<strong>k</strong>做点乘，从而得到两个输入向量之间的关联性，记作 <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></strong>:</p>
<p><img src="https://pbs.twimg.com/media/F9geSIyXEAASAsN?format=png&amp;name=small" alt="" /></p>
<br>
<p>如下图所示，分别得到输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">a^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">a^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>之间的关联性<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>2</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{1,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">a^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">a^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>之间的关联性<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>3</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{1,3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">a^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">a^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>之间的关联性<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>4</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{1,4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9gfBdbXsAAhxnX?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p><strong>Step2</strong>: 通常情况下，还需要考虑输入向量和自身的关联性，然后将计算得到的所有关联性<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>扔给<strong>softmax</strong>函数，得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>α</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">\alpha^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94248em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.94248em;margin-right:0.05em;"><span class="pstrut" style="height:2.57948em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9ggDgFW0AEZ98Z?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p><strong>Step3</strong>: 根据输入向量之间的关联性<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>α</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">\alpha^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94248em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.94248em;margin-right:0.05em;"><span class="pstrut" style="height:2.57948em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>进一步提取向量中的重要信息，即将每个输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">a^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>乘以<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>v</mi></msup></mrow><annotation encoding="application/x-tex">W^v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span></span></span></span>得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>v</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">v^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>,并与其相关的关联性分数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mi>i</mi></mrow><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup></mrow><annotation encoding="application/x-tex">\alpha^{&#x27;}_{1,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3372519999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.441336em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span>相乘，最后将结果累加得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">b^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9ghm8nWEAAYMrK?format=png&amp;name=900x900" alt="" /></p>
<p>这样一来，假设输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup><mtext>和</mtext><msup><mi>a</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">a^1和a^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>的关联性比较大，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>2</mn></mrow><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup></mrow><annotation encoding="application/x-tex">\alpha^{&#x27;}_{1,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3266959999999999em;vertical-align:-0.38421599999999995em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.4518920000000004em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.38421599999999995em;"><span></span></span></span></span></span></span></span></span></span>的值较大，根据累加得到的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">b^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>也会更接近<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>2</mn></mrow><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msubsup></mrow><annotation encoding="application/x-tex">\alpha_{1,2}^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3266959999999999em;vertical-align:-0.38421599999999995em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.4518920000000004em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.38421599999999995em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>---------- <strong>Self-attention流程·END</strong> ----------</p>
<br>
<p>实际上，<strong>Self-attention</strong>的输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mn>1</mn></msup><mtext>、</mtext><msup><mi>b</mi><mn>2</mn></msup><mtext>、</mtext><msup><mi>b</mi><mn>3</mn></msup><mtext>、</mtext><msup><mi>b</mi><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">b^1、b^2、b^3、b^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>可以同时得到。从矩阵运算的角度来说，<strong>Self-attention</strong>的具体操作流程如下:</p>
<p>---------- <strong>Self-attention流程·矩阵角度·BEGIN</strong> ----------</p>
<p><strong>Step1</strong>: 将输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup><mtext>、</mtext><msup><mi>a</mi><mn>2</mn></msup><mtext>、</mtext><msup><mi>a</mi><mn>3</mn></msup><mtext>、</mtext><msup><mi>a</mi><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">a^1、a^2、a^3、a^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span>按列组合成一个矩阵<strong>I</strong>，与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>q</mi></msup></mrow><annotation encoding="application/x-tex">W^q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span></span></span></span>相乘得到矩阵<strong>Q</strong>，其中矩阵<strong>Q</strong>包含了所有输入向量对应的<strong>query</strong>，同理可以得到<strong>key</strong>和<strong>value</strong>对应的矩阵<strong>K</strong>和<strong>V</strong>：</p>
<p><img src="https://pbs.twimg.com/media/F9gnaaWXsAAAt4b?format=png&amp;name=small" alt="" /></p>
<Br>
<p><strong>Step2</strong>: 将各个向量对应的key按行组合，与输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">a^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>相乘，得到与输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">a^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>之间的所有关联性分数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>3</mn></mrow></msub><mo separator="true">,</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator="true">,</mo><mn>4</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{1,1},\alpha_{1,2},\alpha_{1,3},\alpha_{1,4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9gogsNXMAAId0E?format=png&amp;name=small" alt="" /></p>
<br>
<p>由此可知，将矩阵<strong>K</strong>转置后，与矩阵<strong>Q</strong>相乘得到矩阵<strong>A</strong>，其中矩阵<strong>A</strong>包含了所有输入向量之间的关联性分数:</p>
<p><img src="https://pbs.twimg.com/media/F9go9LzXMAAdiWQ?format=png&amp;name=small" alt="" /></p>
<Br>
<p>然后再将矩阵<strong>A</strong>给到<strong>Softmax</strong>激活函数，得到矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">A^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94248em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.94248em;margin-right:0.05em;"><span class="pstrut" style="height:2.57948em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9gpKivWcAABybY?format=png&amp;name=900x900" alt="" /></p>
<BR>
<p><strong>Step3</strong>: 最后将各个输入向量对应的<strong>value</strong>按列组合成一个矩阵V，并与矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">A^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.94248em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.94248em;margin-right:0.05em;"><span class="pstrut" style="height:2.57948em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9gpf5DXwAAe8rb?format=png&amp;name=small" alt="" /></p>
<p>---------- <strong>Self-attention流程·矩阵角度·END</strong> ----------</p>
<br>
<h2 id="三multi-head-self-attention"><a class="markdownIt-Anchor" href="#三multi-head-self-attention"></a> 三.Multi-head Self-attention</h2>
<p><strong>Multi-head Self-attention</strong>就是由多个单独的<strong>Self-attention</strong>堆叠而成，每个<strong>Self-attention</strong>之间具有独立的参数矩阵，相互之间不共享参数。</p>
<p>以<strong>2 heads</strong>为例，首先通过输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">a^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>与矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>q</mi></msup></mrow><annotation encoding="application/x-tex">W^q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span></span></span></span>相乘得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">q^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>，再将向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">q^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>与2个不同的矩阵相乘得到两个参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">q^{i,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">q^{i,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>同理可以得到参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup><mtext>、</mtext><msup><mi>k</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup><mtext>、</mtext><msup><mi>v</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup><mtext>和</mtext><msup><mi>v</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">k^{i,1}、k^{i,2}、v^{i,1}和v^{i,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>。对于另一个输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">a^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>，同样可以得到两组参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>q</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup><mtext>和</mtext><msup><mi>q</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup><mtext>，</mtext><msup><mi>k</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup><mtext>和</mtext><msup><mi>k</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup><mtext>，</mtext><msup><mi>v</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup><mtext>和</mtext><msup><mi>v</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">q^{j,1}和q^{j,2}，k^{j,1}和k^{j,2}，v^{j,1}和v^{j,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>。<br />
在计算关联度分数时，只需先对第一类的参数进行计算，得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">b^{i,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><img src="https://pbs.twimg.com/media/F9gvXvFWkAA5byj?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>再对第二类的参数进行计算，得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">b^{i,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>，如下图所示:</p>
<p><img src="https://pbs.twimg.com/media/F9gwr33WAAAS6xK?format=png&amp;name=900x900" alt="" /></p>
<BR>
<p>最后将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">b^{i,1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">b^{i,2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>拼接起来，与矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span>相乘得到Multi-head Self-attention的第i个输出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>b</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">b^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9gy4kZWEAA85Tu?format=png&amp;name=360x360" alt="" /></p>
<br>
<h2 id="四position-encoding"><a class="markdownIt-Anchor" href="#四position-encoding"></a> 四.Position Encoding</h2>
<p>由于在<strong>Self-attention</strong>的计算中不包含位置信息，因此为了加入位置信息，需要在每个位置都定义一个位置向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>e</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">e^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>，并且直接加到输入向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">a^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>上</p>
<p><img src="https://pbs.twimg.com/media/F9g0EcuXgAAyMfh?format=png&amp;name=240x240" alt="" /></p>
<br>
<p>位置向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>e</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">e^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span>通常是手动设置，也可以通过学习得到:</p>
<p><img src="https://pbs.twimg.com/media/F9g0YWhXQAAJqFz?format=png&amp;name=900x900" alt="" /></p>
<Br>
<h2 id="五transformer"><a class="markdownIt-Anchor" href="#五transformer"></a> 五.Transformer</h2>
<p><strong>Transformer</strong>本质上是一个<strong>Sequence-to-sequence(Seq2seq)</strong> 的模型，它的输出序列长度不再是固定的，而是由模型自身决定：</p>
<p><img src="https://pbs.twimg.com/media/F9g1Kh2W8AAvcLR?format=png&amp;name=360x360" alt="" /></p>
<p><strong>Sequence-to-sequence(Seq2seq)<strong>的模型结构通常如上图所示，由</strong>Encoder</strong>对输入向量（或序列）进行处理，处理完之后给到<strong>Decoder</strong>，并由<strong>Decoder</strong>决定输出向量（或序列）</p>
<br>
<h2 id="51-encoder-2"><a class="markdownIt-Anchor" href="#51-encoder-2"></a> 5.1 Encoder</h2>
<p>其中<strong>Encoder</strong>部分的作用是给定一组向量（或序列），输出一组相同长度的向量（或序列）:</p>
<p><img src="https://pbs.twimg.com/media/F9g31TEWoAA2RVL?format=png&amp;name=small" alt="" /></p>
<Br>
<p>根据原论文<a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a>中的介绍，进一步拆解它的内部结构可以看到，输入向量<strong>b</strong>经过<strong>Self-attention</strong>得到向量<strong>a</strong>，同时由相应的输入向量<strong>b</strong>通过跳跃连接与向量<strong>a</strong>相加，经过一次<strong>Layer Norm</strong>操作后得到向量<strong>c</strong>。将向量<strong>c</strong>给到全连接层得到向量<strong>d</strong>，并与自身通过跳跃连接相加得到向量<strong>e</strong>，最后再做一次<strong>Layer Norm</strong>操作得到向量<strong>f</strong>:</p>
<p><img src="https://pbs.twimg.com/media/F9g45hmXQAANv5j?format=jpg&amp;name=900x900" alt="" /></p>
<br>
<h2 id="52-decoder-2"><a class="markdownIt-Anchor" href="#52-decoder-2"></a> 5.2 Decoder</h2>
<p>根据<a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a>中的介绍，Decoder的内部结构可以看到:</p>
<p><img src="https://pbs.twimg.com/media/F9g5UhxWMAAg0p5?format=png&amp;name=small" alt="" /></p>
<Br>
<p>在<strong>Decoder</strong>中，<strong>Encoder</strong>的输出在经过<strong>cross attention</strong>处理之后，来作为<strong>Decoder</strong>的输入，另外还需要给予一个<strong>one-hot</strong>形式的<strong>BEGIN</strong>信号让<strong>Decoder</strong>开始输出一个向量。</p>
<p>在NLP任务中，这个向量的长度由任务所需要的语言单词或短语的数量来决定，例如识别的语言是中文，那么这个向量可能就需要包含所有的中文汉字或常见字。同时为了让模型自己决定需要输出多长的序列，向量中还包含了一个<strong>END</strong>信号。向量中的每个单词或短语都带有对应的模型预测概率，概率最高的那一项才是最终的输出</p>
<p><img src="https://pbs.twimg.com/media/F9g6FILXUAAN6yt?format=png&amp;name=900x900" alt="" /></p>
<BR>
<p>接下来再将第一个输出给到<strong>Decoder</strong>，作为新的输入，从而得到第二个输出。以此为例，新的输出再次给到<strong>Decoder</strong>中，直到输出END信号表示向量输出的结束。</p>
<p>正是因为新的输入是由之前的输出所得到的，因此在<strong>Decoder</strong>中使用了<strong>Masked Multi-Head Attention</strong>，与<strong>Encoder</strong>中的<strong>Multi-Head Attention</strong>所不同的是，在计算输出的时候只考虑自身及其左边的输入向量，而不需要考虑右边那些还没得到的输入向量，如下图：</p>
<p><img src="https://pbs.twimg.com/media/F9hpOvaXQAAfmmT?format=png&amp;name=900x900" alt="" /></p>
<BR>
<h2 id="53-cross-attention"><a class="markdownIt-Anchor" href="#53-cross-attention"></a> 5.3 Cross Attention</h2>
<p><strong>Decoder</strong>部分不仅有自身的输入向量，还有<strong>Encoder</strong>部分的输出作为输入向量。而<strong>Encoder</strong>部分的输出与<strong>Decoder</strong>中<strong>Masked Multi-Head Attention</strong>的输出一起被送到<strong>Multi-Head Attetion</strong>进行处理，这部分就叫<strong>Cross Attention</strong>，如上图:</p>
<p><img src="https://pbs.twimg.com/media/F9hpoAjW4AA8YiK?format=png&amp;name=small" alt="" /></p>
<br>
<p><strong>Cross Attention</strong>的具体实现流程如下：</p>
<p>---------- <strong>Cross Attention流程·BEGIN</strong> ----------</p>
<p>1.<strong>Encoder</strong>的输出分别与各自对应的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">W^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span>相乘得到<strong>key</strong>值，<strong>Decoder</strong>中<strong>Masked Multi-Head Attention</strong>的输出与矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>q</mi></msup></mrow><annotation encoding="application/x-tex">W^q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span></span></span></span></span></span></span>相乘得到<strong>query</strong>值，然后两者做点乘得到关联性分数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>:</p>
<p><img src="https://pbs.twimg.com/media/F9hq6iJW0AEc9kT?format=png&amp;name=900x900" alt="" /></p>
<br>
<p>2.<strong>Encoder</strong>的输出分别与各自对应的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>v</mi></msup></mrow><annotation encoding="application/x-tex">W^v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span></span></span></span>相乘得到<strong>value</strong>值，然后与关联性分数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>相乘，并将所有的结果累加起来。累加后的结果再给到全连接层，得到最终的输出:</p>
<p><img src="https://pbs.twimg.com/media/F9hrsI_W0AAMfIx?format=png&amp;name=900x900" alt="" /></p>
<Br>
<p>---------- <strong>Cross Attention流程·END</strong> ----------</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>paper阅读工具</title>
    <url>/2024/01/10/paper%E9%98%85%E8%AF%BB%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1arxiv论文阅读技巧"><a class="markdownIt-Anchor" href="#1arxiv论文阅读技巧"></a> 1.arxiv论文阅读技巧</h2>
<p>介绍：<a href="http://arxiv.org">arxiv.org</a> 上的论文一般都是 PDF 格式的，最新的论文已经支持在HTML上进行阅读，但之前的论文仍然需要下载才能阅读，下面介绍几种技巧：</p>
<ul>
<li>将url中的域名中的“x”换成“5”，就能用 HTML5 的格式阅读，比如将<code>https://arxiv.org/abs/2301.00774</code>改成<code>https://ar5iv.org/abs/2301.00774</code>。</li>
<li>利用转换工具<code>https://www.arxiv-vanity.com</code>，可以将论文转为在线阅读的形式。</li>
<li>将url中的域名中的“v”换成“w”，即arxiw，可跳转到TXYZ网站，实现用户与论文对话交互。</li>
</ul>
<br>
<h2 id="2沉浸式翻译"><a class="markdownIt-Anchor" href="#2沉浸式翻译"></a> 2.沉浸式翻译</h2>
<p>链接：<a href="https://immersivetranslate.com/">https://immersivetranslate.com/</a></p>
<p>介绍：非常受欢迎的<strong>双语对照网页翻译插件</strong>，可以完全免费地使用它来实时翻译外语网页，PDF文档，ePub 电子书，字幕文件等。在手机上也可以随时随地用哦，支持10种以上的翻译服务，支持对 PDF 做对照翻译，可以加速论文的阅读效率。与ar5iv阅读技巧结合，简直是神器！！！</p>
<br>
<h2 id="3论文交互网站txyz"><a class="markdownIt-Anchor" href="#3论文交互网站txyz"></a> 3.论文交互网站TXYZ</h2>
<p>链接：<a href="https://www.txyz.ai">https://www.txyz.ai</a></p>
<p>介绍：TXYZ AI 是一款基于ChatGPT开发的一款插件，它可以帮助用户快速得到论文中想要的信息，可以<strong>实现用户与论文对话的场景</strong>。特别是对于专业名词较多的文章，而且可以问它关于这篇文章的任何问题，能够加快研究的进程。打开TXYZ AI  网页版，上传你的论文文档，然后就可以使用英文来问它关于论文内容的任何问题。与【沉浸式翻译】结合，真是YYDS!</p>
<br>
<h2 id="4学术信息挖掘平台aminer"><a class="markdownIt-Anchor" href="#4学术信息挖掘平台aminer"></a> 4.学术信息挖掘平台Aminer</h2>
<p>链接：<a href="https://www.aminer.cn/">https://www.aminer.cn/</a></p>
<p>介绍：由清华大学计算机系研发的学术信息挖掘平台，可以很大程度帮助降低检索和学习论文的门槛。如果你有一个明确的研究方向，可以在它的**「必读论文」模块中找到对应的优质论文集**，这些内容都是由 AI 初筛 + 学者复核后呈现出来的，可以为自己省去海量的信息挖掘时间。</p>
<br>
<h2 id="5论文知识网络"><a class="markdownIt-Anchor" href="#5论文知识网络"></a> 5.论文知识网络</h2>
<ul>
<li>Connected-papers：<a href="https://www.connectedpapers.com">https://www.connectedpapers.com</a></li>
<li>Researchrabbit：<a href="https://www.researchrabbit.ai">https://www.researchrabbit.ai</a></li>
<li>Litmaps：<a href="https://www.litmaps.com">https://www.litmaps.com</a></li>
<li>Openknowledgemaps：<a href="https://openknowledgemaps.org">https://openknowledgemaps.org</a></li>
</ul>
<br>
<h2 id="6学术研究平台openread"><a class="markdownIt-Anchor" href="#6学术研究平台openread"></a> 6.学术研究平台OpenRead</h2>
<p>链接：<a href="https://www.openread.academy/zh">https://www.openread.academy/zh</a></p>
<p>介绍：OpenRead是一个创新的学术研究平台，它通过人工智能技术为用户提供了一个全面的学术资源库，包括超过3亿篇论文，覆盖广泛的学科领域。用户可以通过自然语言搜索快速找到相关论文，并通过<strong>AI总结功能</strong>快速把握论文核心内容。此外，OpenRead还提供了<strong>阅读与笔记管理工具</strong>，如AI论文浓缩、AI问答和论文关系网，帮助用户高效地整理和理解复杂知识。平台鼓励学术社区的建立，通过高校联盟促进知识的自由流通。OpenRead的目标是简化研究流程，让用户能够专注于知识的探索和创新，而不受传统学术出版和研究工具的限制。</p>
<Br>
<h2 id="7paperswithcode"><a class="markdownIt-Anchor" href="#7paperswithcode"></a> 7.Paperswithcode</h2>
<p>链接：<a href="https://paperswithcode.com/">https://paperswithcode.com/</a></p>
<p>介绍：Papers With Code 是一个专注于机器学习领域的在线平台，<strong>它提供了最新的研究论文、代码实现、数据集和方法</strong>。这个平台旨在帮助研究人员和开发者了解和跟踪机器学习领域的最新进展，包括但不限于图像生成、自然语言处理、计算机视觉等方向。在找论文代码的时候经常用到，推荐！</p>
<br>
<h2 id="8学术短语库academic-phrasebank"><a class="markdownIt-Anchor" href="#8学术短语库academic-phrasebank"></a> 8.学术短语库Academic Phrasebank</h2>
<p>链接：<a href="https://www.phrasebank.manchester.ac.uk">https://www.phrasebank.manchester.ac.uk</a></p>
<p>介绍：曼彻斯特大学的学术短语库（Academic Phrasebank）是一个专为学术写作设计的在线资源。<strong>它提供了按研究论文结构组织的语言示例，涵盖引言、方法、结果、讨论和结论等部分，以及通用的学术写作功能</strong>，如比较、定义术语和因果关系等。这些短语旨在帮助作者思考和组织自己的写作内容，同时也可以直接用于论文中，但需要根据具体情况进行适当调整。短语库内容中立，旨在辅助非英语母语的学术作者，但也对英语母语作者有帮助。网站还提供PDF和Kindle格式的资源，方便用户下载</p>
<br>
<h2 id="9学术文献探索平台inciteful"><a class="markdownIt-Anchor" href="#9学术文献探索平台inciteful"></a> 9.学术文献探索平台Inciteful</h2>
<p>链接：<a href="https://inciteful.xyz">https://inciteful.xyz</a></p>
<p>介绍：Inciteful.xyz 是一个基于引文的学术文献探索平台，旨在帮助研究人员快速了解新领域、发现最新文献并揭示不同想法之间的联系。它提供两个主要工具：<strong>Paper Discovery 和 Literature Connector。Paper Discovery 通过分析引文网络，帮助用户找到相似、重要论文以及高产作者和机构。Literature Connector 则为跨学科研究者提供服务，通过输入两篇论文，展示它们在文献中的连接关系。</strong></p>
<br>
<h2 id="10readpaper"><a class="markdownIt-Anchor" href="#10readpaper"></a> 10.readpaper</h2>
<p>链接：<a href="https://readpaper.com">https://readpaper.com</a></p>
<p>介绍：ReadPaper是一个集成了<strong>翻译、阅读、搜索、管理和润色功能</strong>的AI科研平台。它提供专业学术翻译，帮助用户高效理解论文，并通过AI阅读器优化阅读体验。平台拥有丰富的学术知识图谱，实时更新研究进展。此外，它还提供文献管理工具，支持多种引用格式，并具备AI润色服务。</p>
<br>
<h2 id="11perplexity-ai"><a class="markdownIt-Anchor" href="#11perplexity-ai"></a> 11.perplexity ai</h2>
<p>链接：<a href="https://www.perplexity.ai/">https://www.perplexity.ai/</a></p>
<p>Perplexity AI是一款结合了搜索和聊天功能的在线工具，基于OpenAI API开发。其旨在为用户提供更全面、准确的答案和相关的网页链接和图片，以便更快、更便捷地获取所需信息。该网站是免费的，无需注册账号，同时也不会显示任何广告。只需在网站上输入问题，Perplexity AI就会利用其大型语言模型为您提供答案。此外，该工具还具有聊天功能，可以帮助您更好地表达您的问题或提出更多的细节或相关问题。</p>
<br>
<h2 id="12mendeley"><a class="markdownIt-Anchor" href="#12mendeley"></a> 12.Mendeley</h2>
<p>链接：<a href="https://www.mendeley.com/search/">https://www.mendeley.com/search/</a></p>
<p>Mendeley是一款免费的跨平台文献管理软件，同时也是一个在线的学术社交网络平台。可一键抓取网页上的文献信息添加到个人的library中。还可安装MS Word和Open Office插件，方便在文字编辑器中插入和管理参考文献。参考文献格式与Zotero一样用各种期刊格式的CLS文件。Mendeley还免费提供各2GB的文献存储和100MB的共享空间</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>reading</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch面经</title>
    <url>/2023/09/25/pytorch%E9%9D%A2%E7%BB%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1conv2d的参数以及含义"><a class="markdownIt-Anchor" href="#1conv2d的参数以及含义"></a> 1.conv2d的参数以及含义</h2>
<ul>
<li>1.in_channels (int) – 输入图像中的通道数</li>
<li>2.out_channels (int) – 由卷积产生的通道数=卷积核的数量</li>
<li>3.kernel_size (int or tuple) – 卷积核的大小</li>
<li>4.stride (int or tuple, optional) – 卷积的步幅. Default: 1</li>
<li>4.padding (int, tuple or str, optional) – 填充添加到输入的所有四个边，边界补0的层数. Default: 0 (控制卷积层输出;避免信息丢失)</li>
<li>5.padding_mode (str, optional) – ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’</li>
<li>6.dilation (int or tuple, optional) – 核元素间距. Default: 1</li>
<li>7.groups (int, optional) – 分组卷积的分组数量. Default: 1</li>
<li>8.bias (bool, optional) – 如果为True，则在输出中添加一个可学习的偏差. Default: True</li>
</ul>
<h2 id="2pytorch如何微调fine-tuning"><a class="markdownIt-Anchor" href="#2pytorch如何微调fine-tuning"></a> 2.pytorch如何微调fine tuning</h2>
<p>局部微调：加载了模型参数后，只想调节最后几层，其它层不训练，也就是不进行梯度计算，pytorch提供的requires_grad使得对训练的控制变得非常简单</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 替换最后的全连接层， 改为训练100类</span></span><br><span class="line"><span class="comment"># 新构造的模块的参数默认requires_grad为True</span></span><br><span class="line">model.fc = nn.Linear(<span class="number">512</span>, <span class="number">100</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 只优化最后的分类层</span></span><br><span class="line">optimizer = optim.SGD(model.fc.parameters(), lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<Br>
<p>全局微调：对全局微调时，只不过我们希望改换过的层和其他层的学习速率不一样，这时候把其它层和新层在optimizer中单独赋予不同的学习速率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ignored_params = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, model.fc.parameters()))</span><br><span class="line">base_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> ignored_params,</span><br><span class="line">                     model.parameters())</span><br><span class="line"> </span><br><span class="line">optimizer = torch.optim.SGD([</span><br><span class="line">            &#123;<span class="string">&#x27;params&#x27;</span>: base_params&#125;,</span><br><span class="line">            &#123;<span class="string">&#x27;params&#x27;</span>: model.fc.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">1e-3</span>&#125;</span><br><span class="line">            ], lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="3pytorch使用多gpu"><a class="markdownIt-Anchor" href="#3pytorch使用多gpu"></a> 3.pytorch使用多gpu</h2>
<p>model.gpu() 把模型放在gpu上</p>
<p>model = nn . DataParallel ( model ) 。DataParallel并行的方式，是将输入一个batch的数据均分成多份，分别送到对应的GPU进行计算，各个GPU得到的梯度累加。与Module相关的所有数据也都会以浅复制的方式复制多份，在此需要注意，在module中属性应该是只读的。<br />
对模型和相应的数据进行.cuda()处理，可以将内存中的数据复制到gpu显存中去</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Model(input_size, output_size)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Let&#x27;s use&quot;</span>, torch.cuda.device_count(), <span class="string">&quot;GPUs!&quot;</span>)</span><br><span class="line">  <span class="comment"># dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs</span></span><br><span class="line">  model = nn.DataParallel(model)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">   model.cuda()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="4torchnn"><a class="markdownIt-Anchor" href="#4torchnn"></a> 4.torch.nn</h2>
<p>torch.nn:</p>
<ul>
<li>核心数据结构是Module,抽象的概念，既可以表示神经网络某个层layer，也可以表示一个包含很多层的神经网络。常见做法是继承nn.Module,编写自己的层。</li>
<li>自定义层必须继承nn.Module，并且在其构造函数中需调用nn.Module的构造函数，super(xx,self).<strong>init</strong>()</li>
<li>在构造函数__init__中必须自定义可学习的参数，并封装成Parameter</li>
<li>forward函数实现前向传播过程，其输入可以是一个或者多个tensor。无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播，这比function简单的多</li>
<li>Module中可学习参数可以通过named_parameters()或者parameters()返回迭代器，前者会给每个parameter附上名字，使其更具有辨识度。</li>
<li>pytorch实现了大部分的layer,这些layer都继承于nn.Module
<ul>
<li>nn.conv2d卷积层</li>
<li>AvgPool,Maxpool,AdaptiveAvgPool</li>
<li>TransposeConv逆卷积</li>
<li>nn.Linear全连接层</li>
<li>nn.BatchNorm1d(1d,2d,3d)</li>
<li>nn.dropout</li>
<li>nn.ReLU</li>
<li>nn.Sequential</li>
</ul>
</li>
</ul>
<h2 id="5sequential的三种写法"><a class="markdownIt-Anchor" href="#5sequential的三种写法"></a> 5.Sequential的三种写法</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net1 = nn.Sequential()</span><br><span class="line">net1.add_module(<span class="string">&#x27;conv&#x27;</span>, nn.Conv2d(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">net1.add_module(<span class="string">&#x27;batchnorm&#x27;</span>, nn.BatchNorm2d(<span class="number">3</span>))</span><br><span class="line">net1.add_module(<span class="string">&#x27;activation_layer&#x27;</span>, nn.ReLU())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net2 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">3</span>),</span><br><span class="line">        nn.ReLU()</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">net3= nn.Sequential(OrderedDict([</span><br><span class="line">          (<span class="string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)),</span><br><span class="line">          (<span class="string">&#x27;bn1&#x27;</span>, nn.BatchNorm2d(<span class="number">3</span>)),</span><br><span class="line">          (<span class="string">&#x27;relu1&#x27;</span>, nn.ReLU())</span><br><span class="line">        ]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="6tips"><a class="markdownIt-Anchor" href="#6tips"></a> 6.tips</h2>
<ul>
<li>nn.ModuleList（），可以包含几个子module，可以像list一样使用它，但不能直接把输入传给MuduleList</li>
<li>nn.LSTM(4,3,1) 输入向量4维，隐藏元3,1层   nn.LSTMCell(4,3) 对应层数只能是一层</li>
<li>nn.Embedding(4,5)4个词，每个词使用5个向量表示</li>
<li>损失函数也是nn.Module的子类。nn.CrossEntropLoss()     loss = criterion(score,label)</li>
</ul>
<h2 id="7torchoptim"><a class="markdownIt-Anchor" href="#7torchoptim"></a> 7.torch.optim</h2>
<p>将深度学习常用优化方法全部封装在torch.optim中，所有优化方法继承基类optim.</p>
<ul>
<li>optimizer = optim.SGD(param=net.parameters(),lr=1)</li>
<li>optimizer.zero_grad() #梯度清零，等价于net.zero_grad()</li>
<li>input = t.randn(1,3,32,32)</li>
<li>output = net(input)</li>
<li>output.backward(output)</li>
<li>optimizer.step()</li>
</ul>
<h2 id="8对于不同网络设置不同的学习率"><a class="markdownIt-Anchor" href="#8对于不同网络设置不同的学习率"></a> 8.对于不同网络设置不同的学习率</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 只为两个全连接层设置较大的学习率，其余层的学习率较小</span></span><br><span class="line">special_layers = nn.ModuleList([net.classifier[<span class="number">0</span>], net.classifier[<span class="number">3</span>]])</span><br><span class="line">special_layers_params = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, special_layers.parameters()))</span><br><span class="line">base_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> special_layers_params,</span><br><span class="line">                     net.parameters())</span><br><span class="line"> </span><br><span class="line">optimizer = t.optim.SGD([</span><br><span class="line">            &#123;<span class="string">&#x27;params&#x27;</span>: base_params&#125;,</span><br><span class="line">            &#123;<span class="string">&#x27;params&#x27;</span>: special_layers.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.01</span>&#125;</span><br><span class="line">        ], lr=<span class="number">0.001</span> )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="9修改学习率的方法"><a class="markdownIt-Anchor" href="#9修改学习率的方法"></a> 9.修改学习率的方法</h2>
<ul>
<li>修改optimizer.param_groups中的lr</li>
<li>新建优化器</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法1: 调整学习率，新建一个optimizer</span></span><br><span class="line">old_lr = <span class="number">0.1</span></span><br><span class="line">optimizer1 =optim.SGD([</span><br><span class="line">                &#123;<span class="string">&#x27;params&#x27;</span>: net.features.parameters()&#125;,</span><br><span class="line">                &#123;<span class="string">&#x27;params&#x27;</span>: net.classifier.parameters(), <span class="string">&#x27;lr&#x27;</span>: old_lr*<span class="number">0.1</span>&#125;</span><br><span class="line">            ], lr=<span class="number">1e-5</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 方法2: 调整学习率, 手动decay, 保存动量</span></span><br><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">    param_group[<span class="string">&#x27;lr&#x27;</span>] *= <span class="number">0.1</span> <span class="comment"># 学习率为之前的0.1倍</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="10nnfunctional中的函数和nnmodule主要区别"><a class="markdownIt-Anchor" href="#10nnfunctional中的函数和nnmodule主要区别"></a> 10.nn.functional中的函数和nn.Module主要区别</h2>
<ul>
<li>nn.Module实现的layers是一个特殊的类，都是有class layer(nn.Module)定义，会自动提取可学习的参数</li>
<li>nn.functional中的函数更像是纯函数，由def function(input)定义<br />
也就是说如果模型有可学习的参数，最好用nn.Module否则使用哪个都可以，二者在性能上没多大差异，<br />
对于卷积，全连接等具有可学习参数的网络建议使用nn.Module<br />
激活函数（ReLU,sigmoid,tanh），池化等可以使用functional替代。对于不具有可学习参数的层，将他们用函数代替，这样可以不用放在构造函数__init__中。</li>
</ul>
<h2 id="11将module放在gpu上运行只需两步分别将模型与数据放在gpu上"><a class="markdownIt-Anchor" href="#11将module放在gpu上运行只需两步分别将模型与数据放在gpu上"></a> 11.将Module放在gpu上运行只需两步：分别将模型与数据放在gpu上</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=model.cuda()  <span class="comment">#将模型的所有参数转到gpu</span></span><br><span class="line"><span class="built_in">input</span>.cuda()   <span class="comment">#将输入数据也放置到GPU上</span></span><br></pre></td></tr></table></figure>
<h2 id="12在多个gpu上并行计算"><a class="markdownIt-Anchor" href="#12在多个gpu上并行计算"></a> 12.在多个gpu上并行计算</h2>
<h2 id="13torchvision"><a class="markdownIt-Anchor" href="#13torchvision"></a> 13.torchvision，</h2>
<p>视觉工具包，提供了很多视觉图像处理的工具，其中transforms模块提供了对PIL Image对象和Tensor对象的常用操作。主要包含三部分：</p>
<ul>
<li>models：提供深度学习中各种经典网络的网络结构以及预训练好的模型，包括AlexNet、VGG系列、ResNet系列、Inception系列等。</li>
<li>datasets： 提供常用的数据集加载，设计上都是继承torhc.utils.data.Dataset，主要包括MNIST、CIFAR10/100、ImageNet、COCO等。</li>
<li>transforms：提供常用的数据预处理操作，主要包括对Tensor以及PIL Image对象的操作。</li>
</ul>
<h2 id="14pil-image的操作"><a class="markdownIt-Anchor" href="#14pil-image的操作"></a> 14.PIL Image的操作</h2>
<ul>
<li>Scale:调整图片大小，长宽比保持不变</li>
<li>CenterCrop,RandomCrop,RandomResizedCrop : 裁剪图片</li>
<li>Pad：填充</li>
<li>ToTensor: 将PIL Image对象转成Tensor，会自动将[0,255]归一化至[0,1]</li>
</ul>
<h2 id="15imagefolder假设所有的文件按文件夹保存每个文件夹下存储同一个类别图片文件夹名为类名"><a class="markdownIt-Anchor" href="#15imagefolder假设所有的文件按文件夹保存每个文件夹下存储同一个类别图片文件夹名为类名"></a> 15.ImageFolder:假设所有的文件按文件夹保存，每个文件夹下存储同一个类别图片，文件夹名为类名</h2>
<p>ImageFolder(root, transform=None, target_transform=None, loader=default_loader)</p>
<ul>
<li>root：在root指定的路径下寻找图片</li>
<li>transform：对PIL Image进行的转换操作，transform的输入是使用loader读取图片的返回对象</li>
<li>target_transform：对label的转换</li>
<li>loader：给定路径后如何读取图片，默认读取为RGB格式的PIL Image对象</li>
</ul>
<h2 id="16dataloader函数对batch的数据进行操作同时还需要对数据进行shuffle和并行加速"><a class="markdownIt-Anchor" href="#16dataloader函数对batch的数据进行操作同时还需要对数据进行shuffle和并行加速"></a> 16.DataLoader函数：对batch的数据进行操作，同时还需要对数据进行shuffle和并行加速</h2>
<p>DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=default_collate, pin_memory=False, drop_last=False)</p>
<ul>
<li>dataset：加载的数据集(Dataset对象)</li>
<li>batch_size：batch size</li>
<li>shuffle:：是否将数据打乱</li>
<li>sampler： 样本抽样，后续会详细介绍</li>
<li>num_workers：使用多进程加载的进程数，0代表不使用多进程</li>
<li>collate_fn： 如何将多个样本数据拼接成一个batch，一般使用默认的拼接方式即可</li>
<li>pin_memory：是否将数据保存在pin memory区，pin memory中的数据转到GPU会快一些</li>
<li>drop_last：dataset中的数据个数可能不是batch_size的整数倍，drop_last为True会将多出来不足一个batch的数据丢弃</li>
</ul>
<h2 id="17pytorch数据增加一个维度用什么函数unsequeeze"><a class="markdownIt-Anchor" href="#17pytorch数据增加一个维度用什么函数unsequeeze"></a> 17.pytorch数据增加一个维度用什么函数：unsequeeze()</h2>
<h2 id="18pytorch是什么"><a class="markdownIt-Anchor" href="#18pytorch是什么"></a> 18.pytorch是什么</h2>
<p>PyTorch 是基于 Torch 库的计算机软件的一部分，它是 Python 的开源机器学习库。它是由 Facebook 人工智能研究小组开发的深度学习框架。它用于自然语言处理和计算机视觉等应用。</p>
<h2 id="19pytorch-的基本要素"><a class="markdownIt-Anchor" href="#19pytorch-的基本要素"></a> 19.PyTorch 的基本要素</h2>
<ul>
<li>PyTorch 张量</li>
<li>PyTorch NumPy</li>
<li>数学运算</li>
<li>Autograd 模块</li>
<li>优化模块</li>
<li>nn 模块</li>
</ul>
<h2 id="20张量"><a class="markdownIt-Anchor" href="#20张量"></a> 20.张量</h2>
<p>张量在 PyTorch 的深度学习中发挥着重要作用。简单来说，我们可以说，这个框架完全是基于张量的。张量被视为广义矩阵。它可以是 1D 张量（矢量）、2D 张量（矩阵）、3D 张量（立方体）或 4D 张量（立方体矢量）。</p>
<h2 id="21抽象级别"><a class="markdownIt-Anchor" href="#21抽象级别"></a> 21.抽象级别</h2>
<ul>
<li>张量：在gpu上运行的n维数组</li>
<li>变量：计算图中的一个节点，存储数据和梯度</li>
<li>模块：神经网络层讲存储状态</li>
</ul>
<h2 id="22mseloss-ctcloss-bceloss函数有什么用"><a class="markdownIt-Anchor" href="#22mseloss-ctcloss-bceloss函数有什么用"></a> 22.MSELoss、CTCLoss、BCELoss函数有什么用？</h2>
<ul>
<li>MSE 代表 Mean Squared Error，它用于创建衡量输入 x 和目标 y 中每个元素之间的均方误差的标准。</li>
<li>CTCLoss代表Connectionist Temporal Classification Loss，用于计算连续时间序列和目标序列之间的损失。</li>
<li>BCELoss(Binary Cross Entropy) 用于创建衡量目标和输出之间的二元交叉熵的标准。</li>
</ul>
<h2 id="23反向传播是什么"><a class="markdownIt-Anchor" href="#23反向传播是什么"></a> 23.反向传播是什么</h2>
<p>计算出输出与标签间的损失函数值，然后计算其相对于每个神经元的梯度，根据梯度方向更新权值。</p>
<ul>
<li>将训练集数据输入到ANN的输入层，经过隐藏层，最后达到输出层并输出结果，这是ANN的前向传播过程；</li>
<li>由于ANN的输出结果与实际结果有误差，则计算估计值与实际值之间的误差，并将该误差从输出层向隐藏层反向传播，直至传播到输入层；</li>
<li>在反向传播的过程中，根据误差调整各种参数的值；不断迭代上述过程，直至收敛。</li>
</ul>
<h2 id="24pytorch多卡训练原理"><a class="markdownIt-Anchor" href="#24pytorch多卡训练原理"></a> 24.pytorch多卡训练原理</h2>
<ul>
<li>（1）将模型加载到一个指定的主GPU上，然后将模型浅拷贝到其它的从GPU上；</li>
<li>（2）将总的batch数据等分到不同的GPU上（坑：需要先将数据加载到主GPU上）；</li>
<li>（3）每个GPU根据自己分配到的数据进行forward计算得到loss，并通过backward得到权重梯度；</li>
<li>（4）主GPU将所有从GPU得到的梯度进行合并并用于更新模型的参数。</li>
</ul>
<p>模型方面：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device_ids = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">model = Model(input_size, output_size)</span><br><span class="line">model = nn.DataParallel(model, device_ids=device_ids) <span class="comment">#单卡没有这行代码</span></span><br><span class="line">model = model.cuda(device_ids[<span class="number">1</span>]) <span class="comment">#指定哪块卡为主GPU，默认是0卡</span></span><br></pre></td></tr></table></figure>
<Br>
<p>数据方面：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">    input_var = Variable(data.cuda(device_ids[<span class="number">1</span>])) <span class="comment">#默认指定用0卡先加载数据就会报错</span></span><br><span class="line">    output = model(input_var)</span><br></pre></td></tr></table></figure>
<h2 id="25pytorch中train和eval有什么不同"><a class="markdownIt-Anchor" href="#25pytorch中train和eval有什么不同"></a> 25.pytorch中train和eval有什么不同</h2>
<ul>
<li>(1). model.train()——训练时候启用<br />
启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为True</li>
<li>(2). model.eval()——验证和测试时候启用<br />
不启用 BatchNormalization 和 Dropout，将BatchNormalization和Dropout置为False</li>
</ul>
<p>train模式会计算梯度，eval模式不会计算梯度。</p>
<h2 id="26如何确定cnn的卷积核通道数和卷积输出的通道数"><a class="markdownIt-Anchor" href="#26如何确定cnn的卷积核通道数和卷积输出的通道数"></a> 26.如何确定cnn的卷积核通道数和卷积输出的通道数</h2>
<p>cnn卷积核通道数=卷积输入层通道数</p>
<p>cnn卷积输出层通道数=卷积核个数</p>
<h2 id="27cnn的池化pool层"><a class="markdownIt-Anchor" href="#27cnn的池化pool层"></a> 27.cnn的池化pool层</h2>
<p>池化，简言之，即取区域平均或最大</p>
<h2 id="28生成对抗网络"><a class="markdownIt-Anchor" href="#28生成对抗网络"></a> 28.生成对抗网络</h2>
<p>GAN之所以是对抗的，是因为GAN的内部是竞争关系，一方叫generator，它的主要工作是生成图片，并且尽量使得其看上去是来自于训练样本的。另一方是discriminator，其目标是判断输入图片是否属于真实训练样本。</p>
<p>生成对抗网络的一个简单解释如下：假设有两个模型，一个是生成模型(Generative Model,下文简写为G)，一个是判别模型(Discriminative Model,下文简写为D)，判别模型(D)的任务就是判断一个实例是真实的还是由模型生成的，生成模型(G)的任务是生成一个实例来骗过判别模型(D) ，两个模型互相对抗，发展下去就会达到一个平衡，生成模型生成的实例与真实的没有区别，判别模型无法区分自然的还是模型生成的。</p>
<h2 id="29cnn"><a class="markdownIt-Anchor" href="#29cnn"></a> 29.cnn</h2>
<p>每个输入特征的组合特征</p>
<h2 id="30为什么引入非线性激励函数"><a class="markdownIt-Anchor" href="#30为什么引入非线性激励函数"></a> 30.为什么引入非线性激励函数</h2>
<p>深度学习的前提是神经网络的隐层加上了非线性激活函数，提升了模型的非线性表达能力，使得神经网络可以逼近任意复杂的函数。</p>
<h2 id="31batch_size如何影响正确率"><a class="markdownIt-Anchor" href="#31batch_size如何影响正确率"></a> 31.batch_size如何影响正确率</h2>
<p>运行时间确实随着批大小的增加而下降。然而，这导致了测试正确率的妥协，因为测试正确率随着批大小的增加而单调递减。</p>
<h2 id="32"><a class="markdownIt-Anchor" href="#32"></a> 32.</h2>
]]></content>
      <categories>
        <category>internship</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>internship</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh+vscode进行远程调试</title>
    <url>/2023/11/25/ssh-vscode%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1ssh及openssh简介"><a class="markdownIt-Anchor" href="#1ssh及openssh简介"></a> 1.SSH及OpenSSH简介</h2>
<p>SSH 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH在正确使用时可弥补网络中的漏洞。SSH客户端适用于多种平台。几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。</p>
<br>
<p>OpenSSH（OpenBSD Secure Shell）是SSH协议的一种实现，在计算机上安装完OpenSSH并开启服务后该计算机就可作为SSH服务器被远程访问和上传下载文件。</p>
<br>
<h2 id="2vscodessh进行远程开发调试"><a class="markdownIt-Anchor" href="#2vscodessh进行远程开发调试"></a> 2.Vscode+SSH进行远程开发调试</h2>
<p>首先你需要有两台电脑，一台手头的，一台远程的。远程的电脑我称之为服务器吧，你需要知道这台服务器的公网ip和端口号以及这台服务器的root密码</p>
<br>
<h2 id="21-安装openssh"><a class="markdownIt-Anchor" href="#21-安装openssh"></a> 2.1 安装OpenSSH</h2>
<p>好像电脑里本来就有？终端输入ssh没有报错即可<br />
<img src="https://pbs.twimg.com/media/F_xDsZIXQAAFvyZ?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="22-vscode结合remote-ssh进行远程调试开发"><a class="markdownIt-Anchor" href="#22-vscode结合remote-ssh进行远程调试开发"></a> 2.2 VSCode结合remote ssh进行远程调试开发</h2>
<p><img src="https://pbs.twimg.com/media/F_xEPm7XEAA3VOL?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>选择扩展程序，然后搜索Remote SSH并install,最后会出现箭头④所示的插件符。<br />
选择remote ssh,然后选择“+”号，添加主机<br />
<img src="https://pbs.twimg.com/media/F_xEPnEW4AA43hS?format=jpg&amp;name=small" alt="" /><br />
<img src="https://pbs.twimg.com/media/F_xEPnOXsAA3N8e?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>键入之前测试连接的命令，然后enter<br />
<img src="https://pbs.twimg.com/media/F_xEPnZWcAA80N_?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>选择ssh config的存放位置，选择第一个<br />
<img src="https://pbs.twimg.com/media/F_xERIrXUAAitdm?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>点击左下角的符号连接主机:<br />
<img src="https://pbs.twimg.com/media/F_xFd53XEAALuKD?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>选择刚才添加的主机，然后输入主机密码最后enter:<br />
<img src="https://pbs.twimg.com/media/F_xFd55XcAAniO0?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>出现红色箭头所示，表明我们已连上远程的服务器<br />
<img src="https://pbs.twimg.com/media/F_xFd51WgAAVirA?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>Explorer中打开你所在工程的文件目录:<br />
<img src="https://pbs.twimg.com/media/F_xHRCmXEAAErz2?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>打开我项目文件的所在目录<br />
<img src="https://pbs.twimg.com/media/F_xHRCmXsAAtPBl?format=jpg&amp;name=small" alt="" /></p>
<br>
<p>在Extensions中搜索python,安装python解释器;打开任意.py文件，按箭头位置选择你需要的python解释器<br />
<img src="https://pbs.twimg.com/media/F_xHRCkWgAANlPm?format=jpg&amp;name=small" alt="" /><br />
至此，所有操作已完成，你就可以在本地实现远程的代码调试和开发了。由于VS code远程连接需要两次握手，也即需要输入两次密码，可以使用ssh免密登录</p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>ssh</tag>
        <tag>vscode</tag>
        <tag>debug</tag>
      </tags>
  </entry>
  <entry>
    <title>voice、sound、noise</title>
    <url>/2024/02/27/voice%E3%80%81sound%E3%80%81noise/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p><strong>voice</strong>：是指人的嗓音（当然鸟之类的也行）。</p>
<p><strong>sound</strong>：是泛指各种声音。</p>
<p><strong>noise</strong>：指噪声，包括刺耳的那种，也包括在安静环境中出现的、并不一定刺耳的声音。</p>
]]></content>
      <tags>
        <tag>voice</tag>
      </tags>
  </entry>
  <entry>
    <title>vscode调试torch.distributed.run</title>
    <url>/2024/02/18/vscode%E8%B0%83%E8%AF%95torch-distributed-run/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="sh文件"><a class="markdownIt-Anchor" href="#sh文件"></a> .sh文件</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m torch.distributed.run --nproc_per_node=1 --master_port=2564 train.py --cfg-path lavis/projects/blip2/train/pretrain_stage1.yaml </span><br></pre></td></tr></table></figure>
<br>
<h2 id="launchjson文件"><a class="markdownIt-Anchor" href="#launchjson文件"></a> launch.json文件</h2>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: Distributed Torch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;debugpy&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/torch/distributed/run.py&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="comment">//&quot;module&quot;: &quot;torch.distributed.run&quot;,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;--nproc_per_node&quot;</span><span class="punctuation">,</span><span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--master_port&quot;</span><span class="punctuation">,</span><span class="string">&quot;2564&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--cfg-path&quot;</span><span class="punctuation">,</span><span class="string">&quot;cyb/LAVIS/lavis/projects/blip2/train/pretrain_stage1.yaml&quot;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="314日更增加指定gpu选择"><a class="markdownIt-Anchor" href="#314日更增加指定gpu选择"></a> 3.14日更–增加指定GPU选择</h2>
<p>.sh文件如下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.run --nproc_per_node=1 --master_port=2564 train.py --cfg-path lavis/projects/blip2/train/pretrain_stage1.yaml </span><br></pre></td></tr></table></figure>
<p>launch.json文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;version&quot;</span>: <span class="string">&quot;0.2.0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;configurations&quot;</span>: [</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Python: stage1&quot;</span>,</span><br><span class="line">            <span class="string">&quot;type&quot;</span>:<span class="string">&quot;debugpy&quot;</span>,</span><br><span class="line">            <span class="string">&quot;request&quot;</span>: <span class="string">&quot;launch&quot;</span>,</span><br><span class="line">            <span class="string">&quot;program&quot;</span>: <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/torch/distributed/run.py&quot;</span>,</span><br><span class="line">            //<span class="string">&quot;module&quot;</span>: <span class="string">&quot;torch.distributed.run&quot;</span>,</span><br><span class="line">            <span class="string">&quot;console&quot;</span>: <span class="string">&quot;integratedTerminal&quot;</span>,</span><br><span class="line">            <span class="string">&quot;env&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>: <span class="string">&quot;1&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;--nproc_per_node&quot;</span>,<span class="string">&quot;1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;--master_port&quot;</span>,<span class="string">&quot;2564&quot;</span>,</span><br><span class="line">                <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>,</span><br><span class="line">                <span class="string">&quot;--cfg-path&quot;</span>,<span class="string">&quot;cyb/LAVIS/lavis/projects/blip2/train/pretrain_stage1.yaml&quot;</span></span><br><span class="line">            ]</span><br><span class="line">           </span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        ,</span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Python: stage2&quot;</span>,</span><br><span class="line">            <span class="string">&quot;type&quot;</span>:<span class="string">&quot;debugpy&quot;</span>,</span><br><span class="line">            <span class="string">&quot;request&quot;</span>: <span class="string">&quot;launch&quot;</span>,</span><br><span class="line">            <span class="string">&quot;program&quot;</span>: <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/torch/distributed/run.py&quot;</span>,</span><br><span class="line">            //<span class="string">&quot;module&quot;</span>: <span class="string">&quot;torch.distributed.run&quot;</span>,</span><br><span class="line">            <span class="string">&quot;console&quot;</span>: <span class="string">&quot;integratedTerminal&quot;</span>,</span><br><span class="line">            <span class="string">&quot;env&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>: <span class="string">&quot;1&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;--nproc_per_node&quot;</span>,<span class="string">&quot;1&quot;</span>,</span><br><span class="line">                <span class="string">&quot;--master_port&quot;</span>,<span class="string">&quot;256&quot;</span>,</span><br><span class="line">                <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>,</span><br><span class="line">                <span class="string">&quot;--cfg-path&quot;</span>,<span class="string">&quot;/cyb/LAVIS/lavis/projects/blip2/train/pretrain_stage2.yaml&quot;</span></span><br><span class="line">            ]</span><br><span class="line">           </span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title>上游任务 and 下游任务</title>
    <url>/2023/12/18/%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1-and-%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="cv领域"><a class="markdownIt-Anchor" href="#cv领域"></a> CV领域</h1>
<h2 id="1前言"><a class="markdownIt-Anchor" href="#1前言"></a> 1.前言</h2>
<p>计算机视觉中有常见的四大任务：</p>
<ul>
<li>分类（解决&quot;what&quot;）</li>
<li>定位（解决&quot;where&quot;）</li>
<li>检测（解决&quot;what&quot;和&quot;where&quot;）</li>
<li>分割（实例分割、语义分割和场景分割等像素级别的处理）</li>
</ul>
<br>
<h2 id="2上游任务"><a class="markdownIt-Anchor" href="#2上游任务"></a> 2.上游任务</h2>
<p>预训练模型。一般就是利用上游数据进行预训练，以生成一个包含视觉表征能力的模型。</p>
<p>比如，我们想要的是一个能够提取图片特征能力的卷积神经网络或者Transformer，我们会用大量图片用图片分类这个下游任务或者其他比如自监督的方法（可以参考CLIP）去进行训练，得到一个权重合适的模型（能够很好地提取出图像的特征），那么最后我们把得到的这个模型最后一层的FC层（原本用于图片分类输出类别）去掉，这个模型就成为了一个很好的预训练模型，输入一张图，就能够提取出图像的特征，就可以用于我们的下游任务（在这个模型后面加一些诸如检测头之类的模块，处理我们想要的下游任务，或者修改下FC层，用于另外一堆类别的图像分类）。</p>
<p>上游任务一般称为backbone，主干网络。</p>
<br>
<h2 id="3下游任务"><a class="markdownIt-Anchor" href="#3下游任务"></a> 3.下游任务</h2>
<p>下游任务是计算机视觉应用程序，用于评估通过自监督学习学习到的特征的质量。当训练数据稀缺时，这些应用程序可以极大地受益于预训练模型。</p>
<p>下游任务更多的是评估任务，相当于项目落地，需要去做具体任务来评价模型好坏。如图像分类，目标检测、语义分割等具体任务。</p>
<p>下游上游的取名就在于下游任务往往是先用上游任务得到的模型（一般会称为backbone，主干网络）提取图像特征，然后再从这些特征中得到我们想要的结果。</p>
<br>
<hr />
<h2 id="gpt的理解"><a class="markdownIt-Anchor" href="#gpt的理解"></a> <code>GPT的理解</code></h2>
<p>在计算机视觉中，上游任务和下游任务是两种不同类型的任务，它们在数据处理和应用方面有所区别：</p>
<p><strong>上游任务（Upstream Tasks）</strong>：</p>
<ul>
<li>上游任务通常是更为基础的任务，它们关注于提取和理解图像数据的基本特征。</li>
<li>这类任务往往是更加通用的，例如图像分类、物体检测、特征提取等。</li>
<li>上游任务的结果通常用于为下游任务提供必要的信息和特征。</li>
<li>它们通常与深度学习中的特征学习阶段相关，如通过卷积神经网络（CNN）提取图像特征。</li>
</ul>
<p><strong>下游任务（Downstream Tasks）</strong>：</p>
<ul>
<li>下游任务是指那些利用上游任务提取的特征来完成具体应用的任务。</li>
<li>这些任务通常更加专门化，例如面部识别、情感分析、图像描述生成等。</li>
<li>它们依赖于上游任务提供的特征来实现更复杂的决策和预测。</li>
<li>下游任务通常更接近实际应用，例如在自动驾驶、医疗诊断、监控系统中的应用。</li>
</ul>
<p>总的来说，上游任务关注于从原始数据中提取有用的特征和信息，而下游任务则利用这些特征来执行更具体和高级的分析和应用。在很多计算机视觉系统中，上游和下游任务是紧密相连的，上游任务的输出直接影响着下游任务的效果和准确性。</p>
<hr />
<br>
<h1 id="nlp领域"><a class="markdownIt-Anchor" href="#nlp领域"></a> NLP领域</h1>
<h2 id="nlp中上游任务与下游任务的理解"><a class="markdownIt-Anchor" href="#nlp中上游任务与下游任务的理解"></a> NLP中上游任务与下游任务的理解</h2>
<p>上游任务指对数据做预处理，如：分词、过滤、生成词向量等，上游任务的结果作为下游任务的输入</p>
<p>下游任务是你在什么数据集上干的什么事，比如做分类任务，问答任务</p>
<br>
<h2 id="gpt的理解-2"><a class="markdownIt-Anchor" href="#gpt的理解-2"></a> <code>GPT的理解</code></h2>
<p>在自然语言处理（NLP）中，上游任务和下游任务的概念是理解数据处理和模型训练流程的关键。</p>
<p><strong>上游任务（Pre-training Tasks）</strong>：</p>
<ul>
<li><strong>定义</strong>：上游任务通常指的是在大规模无标签数据上进行的预训练。这些任务设计来帮助模型理解语言的基本结构和语义。</li>
<li><strong>目的</strong>：主要是为了让模型学习到广泛的语言表示，包括词汇、语法、句子结构等。</li>
<li><strong>示例</strong>：诸如掩码语言建模（在BERT中使用）、下一句预测、自回归语言建模（如GPT系列使用）等。</li>
<li><strong>特点</strong>：这些任务不针对特定的应用场景，而是提供一种通用的语言理解能力。</li>
</ul>
<p><strong>下游任务（Fine-tuning Tasks）</strong>：</p>
<ul>
<li><strong>定义</strong>：下游任务是指在特定标注数据集上进行的微调。这些任务通常是具体的NLP应用，例如情感分析、问答系统、文本分类等。</li>
<li><strong>目的</strong>：利用上游任务学到的语言表示，让模型能够在特定任务上表现良好。</li>
<li><strong>示例</strong>：命名实体识别、文本分类、机器翻译、问答等。</li>
<li><strong>特点</strong>：这些任务高度依赖于特定领域的数据，需要模型能够应对具体的问题和挑战。</li>
</ul>
<p>总结来说，上游任务是为了让模型建立起对语言的通用理解，而下游任务则是在此基础上针对具体问题进行优化和调整。上游任务提供了一种基础的语言能力，而下游任务则是这种能力的具体应用。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>CV</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>中介避坑指北</title>
    <url>/2023/07/23/%E4%B8%AD%E4%BB%8B%E9%81%BF%E5%9D%91%E6%8C%87%E5%8C%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="中介避坑指北"><a class="markdownIt-Anchor" href="#中介避坑指北"></a> 中介避坑指北🧭</h1>
<p>下面将列出几大中介的坑：</p>
<h2 id="1虚假承诺"><a class="markdownIt-Anchor" href="#1虚假承诺"></a> 1.虚假承诺</h2>
<p>为了和你签单，故意给你报高你的选校定位，然后在别人offer 都下的差不多了之后利用你的焦虑心理 pua 你，让你同意加申一所烂学校，保证你有学上。中介为什么这样呢？因为大部分中介在和你签合同的时候会写明帮你申请哪几所学校，全拒退全款。但是一般合同里也会有特殊条款（类似如果你拿了offer 就不算全拒），因而会出现上述行为。</p>
<p>避坑方法：</p>
<ul>
<li>多咨询几家中介，综合来看选校定位</li>
<li>根据自己的 bg 结合往届学长学姐的申请数据和万能的互联网，自行定<br />
位，然后和中介给的定位进行比较。</li>
<li>要有合适、正确的心理预期</li>
</ul>
<h2 id="2洗脑式推销付费实习-科研-论文此条群内有争论下述观点仅代表我个人"><a class="markdownIt-Anchor" href="#2洗脑式推销付费实习-科研-论文此条群内有争论下述观点仅代表我个人"></a> 2.洗脑式推销付费实习、科研、论文（此条群内有争论，下述观点仅代表我个人）</h2>
<p>我的观点是这些东西只对 1 的人有用（这 1 的人是指：分数够申请牛剑及同档次学校，但是软实力不够即无实习、科研，此时如果买一段可能会有用，但是注意你一定要切切实实的做了，否则在面试中被问到答不出来是大忌。但是吐槽一句，咱学校 bg 能够到牛剑的，一般身上不会缺实习科研吧），申请授课型硕士我认为这些东西的作用不高。 那么问题来了： 中介为什么这么做？赚钱嘛，不寒酸。</p>
<p>避坑方法：</p>
<ul>
<li>擦亮眼睛</li>
</ul>
<h2 id="3不给你网申邮箱这种中介快-run别犹豫-假如你已经签了该怎么办呢"><a class="markdownIt-Anchor" href="#3不给你网申邮箱这种中介快-run别犹豫-假如你已经签了该怎么办呢"></a> 3.不给你网申邮箱：这种中介快 RUN！别犹豫。假如你已经签了，该怎么办呢</h2>
<p>避坑方法：</p>
<ul>
<li>在申请季的时候问问中介有没有提交，他说提交了之后，你私下发邮件问问学校有没有收到你的申请</li>
</ul>
<p>PS：有的恶心的中介会有告诉你帮你加申了 xx 学校，收了你加申的钱，然后不帮你申</p>
<h2 id="4不让你直接和文书老师直接联系很有可能你的文书写出来变成九转大肠意思是文书写的很烂"><a class="markdownIt-Anchor" href="#4不让你直接和文书老师直接联系很有可能你的文书写出来变成九转大肠意思是文书写的很烂"></a> 4.不让你直接和文书老师直接联系：很有可能你的文书写出来变成九转大肠（意思是文书写的很烂）</h2>
<p>避坑方法：</p>
<ul>
<li>先做好心理准备，同时 如果有时间，自己再写一份文书以备后用，没时间的<br />
话就多催催中介，让他在文书写好的第一时间发过来，自己看看 ，有问题及<br />
时修改</li>
</ul>
<h2 id="5pua-搞心态-听说过被中介-pua-搞到心态爆炸的同学-例如好几天不回消息-回消息很敷衍-你买点他推销的-实习-科研等-对你好两天不买就不鸟你"><a class="markdownIt-Anchor" href="#5pua-搞心态-听说过被中介-pua-搞到心态爆炸的同学-例如好几天不回消息-回消息很敷衍-你买点他推销的-实习-科研等-对你好两天不买就不鸟你"></a> 5.pua ，搞心态。听说过被中介 pua 搞到心态爆炸的同学。例如好几天不回消息、回消息很敷衍、你买点他推销的 实习、科研等 ，对你好两天，不买就不鸟你。</h2>
<p>避坑指南：</p>
<ul>
<li>擦亮眼睛</li>
</ul>
<h2 id="6diy-的同学在套信息的之后如果被中介认出来是-diy-的有可能会被中介搞心态报个高学校让你有心理落差"><a class="markdownIt-Anchor" href="#6diy-的同学在套信息的之后如果被中介认出来是-diy-的有可能会被中介搞心态报个高学校让你有心理落差"></a> 6.Diy 的同学在套信息的之后，如果被中介认出来是 diy 的，有可能会被中介搞心态（报个高学校，让你有心理落差）</h2>
<p>避坑方法：</p>
<ul>
<li>心态放好，多问问</li>
<li>对自己有清晰的轻微</li>
</ul>
<h2 id="7如何分辨坑中介呢"><a class="markdownIt-Anchor" href="#7如何分辨坑中介呢"></a> 7.如何分辨坑中介呢？</h2>
<ul>
<li>多问问历届学长学姐的评价</li>
<li>多聊聊，看专业不专业</li>
<li>看收费，太便宜一定不正常</li>
</ul>
<h2 id="8中介的作用"><a class="markdownIt-Anchor" href="#8中介的作用"></a> 8.中介的作用</h2>
<p>随便写点：我和中介接触的这段时间，我的直观感受就是中介的作用就是帮你省时间精力（好中介会省时间，但是如果是坑中介可能浪费你时间） 提供情绪价值（在你焦虑、不安、学不下去、情绪崩溃等等的时候给你情绪价值）中介赚钱也是这两部分 ：帮你省时间精力和提供情绪价值。所以要不要找中介就看大家怎么决定了（虽然我在准备和一个团队合作，做新模式中介，但是我还是要说一句，能考上咱学校的同学完全有能力自己 diy ，只需要花费时间就够了</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>中介</tag>
      </tags>
  </entry>
  <entry>
    <title>github小技巧</title>
    <url>/2023/10/27/github%E5%B0%8F%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1高级搜索功能"><a class="markdownIt-Anchor" href="#1高级搜索功能"></a> 1.高级搜索功能</h2>
<p>直接点击这里：<a href="https://github.com/search/advanced">GitHub·Where software is built</a></p>
<p>另一种方法：点击左下角的<strong>Advanced search</strong>:</p>
<p><img src="https://pbs.twimg.com/media/F9bFrutXoAAUGxP?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<h2 id="2查找文件"><a class="markdownIt-Anchor" href="#2查找文件"></a> 2.查找文件</h2>
<p>进入github仓库界面，按住t进行查找文件<br />
<img src="https://pbs.twimg.com/media/F9bGNH9WkAAV_Iw?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>进入源代码后，按住l，跳到某一行：<br />
<img src="https://pbs.twimg.com/media/F9bGzlpWMAAvMaF?format=jpg&amp;name=medium" alt="" /></p>
<BR>
<p>点击行号，可以复制这行代码/也可生成永久链接<br />
<img src="https://pbs.twimg.com/media/F9bHHOQWoAAhZa4?format=jpg&amp;name=medium" alt="" /></p>
<Br>
<p>在源代码页面按住b查看更改记录：<br />
<img src="https://pbs.twimg.com/media/F9bHrUOXIAAF9nb?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="3阅读代码技巧"><a class="markdownIt-Anchor" href="#3阅读代码技巧"></a> 3.阅读代码技巧</h2>
<p>仓库的code页面，按住英文的<code>.</code>进行代码跳转</p>
<p>代码跳转：</p>
<ul>
<li>下载到本地</li>
<li>在线vscode</li>
</ul>
<br>
<h2 id="4在线运行项目"><a class="markdownIt-Anchor" href="#4在线运行项目"></a> 4.在线运行项目</h2>
<p>给项目地址前面加上<code>gitpod.io/#/</code>前缀</p>
<p>举例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://github.com/nginx/nginx </span><br><span class="line">=&gt; https://gitpod.io/#/github.com/nginx/nginx</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>中国大陆购买ChatGPT Plus教程</title>
    <url>/2024/04/15/%E4%B8%AD%E5%9B%BD%E5%A4%A7%E9%99%86%E8%B4%AD%E4%B9%B0ChatGPT-Plus%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1登录一个美区apple-id帐号打开app-store"><a class="markdownIt-Anchor" href="#1登录一个美区apple-id帐号打开app-store"></a> 1.登录一个美区Apple ID帐号，打开APP Store</h2>
<p><img src="https://pbs.twimg.com/media/GLMF2eOXQAEEr1U?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="2在app-store中下载chatgpt"><a class="markdownIt-Anchor" href="#2在app-store中下载chatgpt"></a> 2.在APP Store中下载ChatGPT</h2>
<p><img src="https://pbs.twimg.com/media/GLMF5lsWUAADzzS?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="3打开梯子不要用香港节点"><a class="markdownIt-Anchor" href="#3打开梯子不要用香港节点"></a> 3.打开梯子，不要用香港节点</h2>
<p><img src="https://pbs.twimg.com/media/GLMF7ULXUAA9_h3?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="4下载完chatgpt后登录帐号可以看到gpt4需要1999美元"><a class="markdownIt-Anchor" href="#4下载完chatgpt后登录帐号可以看到gpt4需要1999美元"></a> 4.下载完ChatGPT后登录帐号，可以看到GPT4需要19.99美元</h2>
<p><img src="https://pbs.twimg.com/media/GLMF80aW4AAjqoC?format=jpg&amp;name=medium" alt="" /></p>
<br>
<p>我们可以看到中美货币汇率如下，19.99美元需要144.70元：<br />
<img src="https://pbs.twimg.com/media/GLMHCaIXgAAI--D?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="5打开支付宝在左上角切换位置为旧金山"><a class="markdownIt-Anchor" href="#5打开支付宝在左上角切换位置为旧金山"></a> 5.打开支付宝，在左上角切换位置为旧金山</h2>
<p><img src="https://pbs.twimg.com/media/GLMHYf7XAAATo11?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="6在最下面点击出境然后点击折扣礼品卡"><a class="markdownIt-Anchor" href="#6在最下面点击出境然后点击折扣礼品卡"></a> 6.在最下面点击出境,然后点击折扣礼品卡</h2>
<p><img src="https://pbs.twimg.com/media/GLMHoMeXIAA_-lv?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="7点击app-store"><a class="markdownIt-Anchor" href="#7点击app-store"></a> 7.点击APP Store</h2>
<p><img src="https://pbs.twimg.com/media/GLMHxeeWUCAqvTI?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="8进去之后我们可以输入想要充值的金额"><a class="markdownIt-Anchor" href="#8进去之后我们可以输入想要充值的金额"></a> 8.进去之后，我们可以输入想要充值的金额</h2>
<p><img src="https://pbs.twimg.com/media/GLMIGIcXMAEA7z7?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="9首次充值需要注册帐号"><a class="markdownIt-Anchor" href="#9首次充值需要注册帐号"></a> 9.首次充值需要注册帐号</h2>
<p><img src="https://pbs.twimg.com/media/GLMIQnqWIAAj894?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="10充值成功后返回app-store点击兑换充值卡d代码"><a class="markdownIt-Anchor" href="#10充值成功后返回app-store点击兑换充值卡d代码"></a> 10.充值成功后返回APP Store，点击兑换充值卡/d代码</h2>
<p><img src="https://pbs.twimg.com/media/GLMIZ1nWsAEoMtl?format=jpg&amp;name=medium" alt="" /></p>
<h2 id="11将充值后的礼品卡兑换码输入即可充值成功然后购买gpt4即可"><a class="markdownIt-Anchor" href="#11将充值后的礼品卡兑换码输入即可充值成功然后购买gpt4即可"></a> 11.将充值后的礼品卡兑换码输入即可充值成功，然后购买GPT4即可</h2>
<p><img src="https://pbs.twimg.com/media/GLMIkn8XwAETw9q?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]互联网裁员</title>
    <url>/2024/06/16/%E4%BA%92%E8%81%94%E7%BD%91%E8%A3%81%E5%91%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p><strong>paopjian1</strong> (whoami)：<br />
不景气，互联网员工在网上声音大。</p>
<p><strong>LiYiShan</strong> (义山Li公子)：<br />
从2021年底到现在，裁员一波一波没有停过，只是有时候新闻大，有时候新闻小而已。</p>
<p><strong>wujixian666</strong> (无极限)：<br />
经济严重衰退，没办法。</p>
<p><strong>cutepeanut</strong> (Alpha)：<br />
没有新的风口了。</p>
<p><strong>buptpyl</strong>：<br />
其他行业可能更拉。</p>
<p><strong>zzh98</strong> (稻草人)：<br />
不需要这么多人才了，对外输送。</p>
<p><strong>ry620620</strong> (LovMe1on)：<br />
也不是最近吧，是一直。</p>
<p><strong>ym19940508</strong> (【意涵团】噗噗噗)：<br />
没有大规模的用户增长了，现在公司的业务基本都到顶，扩展的新业务大多都赔钱，前几年因为业务扩张的快招了太多人，导致现在很多团队就在瞎搞，直接干掉对现有业务一点影响都没有。</p>
<p><strong>kezhifeng</strong> (whateveryouwant)：<br />
看一些公众号推送，美国那边一股股的几千几千的释放技术人才，光美团一家近两年就持续不断的向市场投放人才，践行小步快跑的精髓。互联网还有各种资本爸爸，其他非信息这种虚拟产业的，可没这么好的命，实体行业是订单催动的，没有单子必然失业，沦为灵活就业人员。最近也在望京看到了更多的发传单的，摆散摊的，还看到了一只蛙，再看看这个环境，我也就扭头离去了。不去缓解日渐扩大的贫富分化，不去对资产课重税，指望我们继续负债买房消费，忽悠再生育和自救，那我等也只能自保了。</p>
<p><strong>soramaru</strong>：<br />
在线教育被重拳出击后，中概股腰斩。</p>
<p><strong>muli</strong>：<br />
上周哲库裁员，博导收到一被裁员同学的读博申请。</p>
<p><strong>qwe245347444</strong> (路言程)：<br />
我作为腾讯、美团、京东的股东，看着跌跌不休的股价，财报上不再增加的营收。既然营收已经不涨了，那就寄希望于利润上涨了。腾讯一季报同比裁员一万人，对应的利润增长了不少，反映出公司降本增效在股东的层面来看是合理的。对比腾讯，阿里的财报就更惨了，所以更大力度的降本增效，站在股东层面来看应该也是合理的。</p>
<p><strong>kevinqcl</strong> (AllenTsien)：<br />
本质是经济衰退，大通缩影响力生产经济，各行各业，当然你从具体某个行业找原因也能找到，更多是传导产生的具体表现而已。</p>
<p><strong>bltyy</strong>：<br />
一个工厂有500订单，需要100个人干活，现在500订单就剩250了，我作为老板，不降薪只能剩50个人干活了。</p>
<p><strong>Kami</strong> (Moonsheep)：<br />
因为前几年大家都疯狂扩招，什么业务都想掺一脚，这几年大形势不好，保住主营业务盈利就行，无关的直接裁员，降本增效。2023年现在发现可能维护一个业务也不需要那么多人，主营业务也开始裁员，可以参考Twitter。</p>
<p><strong>rancho</strong>：<br />
简单，因为互联网公司也是公司，而裁员是对当下所有公司而言的。</p>
<p><strong>zeyazhu</strong>：<br />
22年的关键词叫盈利，导致互联网大量裁掉实验探索类部门。23年关键词叫造血，不能造血的部门都要精简。经济大环境是对外出海困难，对内进入存量竞争，投资都不好投。经济下行的环境出现大量裁员显然是不可避免的。</p>
<p><strong>rain2018</strong>：<br />
想起21年底论坛神贴，“互联网大厦将倾，快润吧”。</p>
<p><strong>Aoi7</strong>：<br />
哪里都倾，润哪。</p>
<p><strong>Kassel</strong>：<br />
21年招人多嚣张，23年裁员就多疯狂。顺风疯狂梭哈，逆风快速斩仓。</p>
<p><strong>maccree</strong>：<br />
有些公司就是宁可裁员也要多招应届生抢夺人才，用一会儿不顺手了再裁掉，这也是一种策略。</p>
<p><strong>risentang</strong>：<br />
旱涝保收的国企体制内，盛世分房子，乱世保稳定，达成双赢（赢两次）。</p>
<p><strong>Suiyifan1998</strong>：<br />
似乎从17年开始，每年都能听到这样的声音，总有一年是能预测对的。</p>
<p><strong>zk2012</strong>：<br />
理性点分析的话，我觉得一方面是因为19年开始的后面两年里，大部分头部互联网公司人员扩充太快了，几乎人员翻倍了。</p>
<p><strong>carolwing</strong>：<br />
国企算稳的，但不是百分百稳，08年经济在危机，公务员在涨薪（国家希望促进消费），赢麻了，不知道这几年如何。</p>
<p><strong>Poet</strong>：<br />
资本有序收缩。</p>
<p><strong>qhj646</strong>：<br />
你去哪了？</p>
<p><strong>XJXJ</strong>：<br />
我们这里现在流行”单解“，就是没谈妥直接给你解除劳动合同，简直奇葩。</p>
<p><strong>Megamind</strong>：<br />
其实就是产业升级失败了。资本觉醒：原来不需要那么多高精尖、高学历、创新型人才，抄袭、代工厂、打螺丝才是归途。</p>
<p><strong>JOJO123</strong>：<br />
那研一的该如何择业呢？</p>
<p><strong>TZZS</strong>：<br />
汽车行业还好吧…起码我在的企业到现在还没有启动任何一轮裁员的计划，只是今年的减员降本目标是15%，到年中，貌似自然离职的就已经快完成这个目标了。</p>
<p><strong>kezhifeng</strong>：<br />
你去看看统计局的数据。IT业，金融业是最牛的，平均收入都比其他行业高得多，金融业方差太大了，IT业好一些，年轻就是资本，卷10年，期间做好计划就行了。还可以走另一条路，卷5年直接出国工作签，然后移民。</p>
<p><strong>Lin12333</strong>：<br />
看来互联网再难也是天花板，谢谢大佬指点迷津。</p>
<p><strong>pyxply</strong>：<br />
国内互联网渗透率到顶了，以往的高增长已经不存在，你能想到的业务形态基本上都有公司在做。市场就那么大，大公司小公司就是互相蚕食和卷。我所知道的叫得上的互联网公司，都是内部有非常多的创新团队，希望是给公司找第二增长曲线之类的，但是少见能成的（最近几年就是clubhouse，区块链，元宇宙，相亲，以及当下比较火的大模型），所以很多团队就是直接解散，人员流动比之前大太多，裁员也是。其次，现在做东西的成本已经非常高了，因为互联网渗透率太高，导致现在获客成本非常高，推广买量的钱很可怕（我们之前曾经每天大几百W的花）。导致的情况就是验证的很快，死的也很快。按照早些年，抢占市场，然后迅速砸钱扩大规模以达到规模化效应，然后不断融资，这条路已经很难了。之前这个行业吸收了很多很多的人，增长上不去了后，就是不断优化，也要精打细算过日子了。</p>
<p><strong>beta2</strong>：<br />
互联网卖货有什么可以产业升级的？GPT搞出来了吗？</p>
<p><strong>xiaominlong</strong>：<br />
感觉现在产业互联网应该还可以吧，可惜北邮没赶上吧。</p>
<p><strong>f824618325</strong>：<br />
凉凉，准备跑路。全tm裁了。</p>
<p><strong>SSN</strong>：<br />
看以后互联网企业的定位吧，毕竟现在的高薪来自股价在撑着。如果以后上面把互联网企业定位为基础设施的话，那二级市场的整个估值框架都会变，也支撑不起这么大的规模和高薪。</p>
<p><strong>Linus1991</strong>：<br />
今天我朋友锐评：开猿节流。</p>
<p><strong>twzzqb</strong>：<br />
就咱们国家这些互联网公司，一个个都想着做平台抽成，有几个算得上产业升级的？往外卖、网购、打车上升级吗？一开始就是靠砸钱打开的市场，还真以为凭技术呢，可别贴金了。</p>
<p><strong>mumubin</strong>：<br />
国外互联网裁的更猛。</p>
<p><strong>wu123</strong>：<br />
互联网裁员跟产业升级有关系？互联网吃的就是流量饭，流量见顶出海受阻，就不需要那么多人。至于代工厂、打螺丝更是搞笑，看看今年出口的数据啊，缺你这个打螺丝的吗？</p>
<p><strong>JackPaul163</strong>：<br />
裁一波年龄大的老员工，招点应届生消化校招，双赢。</p>
<p><strong>zhaofanghao</strong>：<br />
老哥在哪个车企啊？</p>
<p><strong>ym19940508</strong>：<br />
你不用外卖打车</p>
<p>网购平台？产品方便了你，回头还反说人家都想着做平台。别管是不是技术贴金，你觉得没技术，你能做出来么？</p>
<p><strong>JJoker</strong>：<br />
宁予股东高管，不予驴马。</p>
<p><strong>spy1993</strong>：<br />
bd。</p>
<p><strong>botman</strong>：<br />
国内市场卷到头了，出海前景被政治因素扼杀了。</p>
<p><strong>wj364952553</strong>：<br />
就喜欢看这种大佬们高谈阔论的帖子。</p>
<p><strong>leiky</strong>：<br />
今年北京市属高校普涨工资，补发了好几万！</p>
<p><strong>pythonic</strong>：<br />
re。</p>
<p><strong>EdwardLiu23</strong>：<br />
阁下有何高见？</p>
<p><strong>ning1187</strong>：<br />
有没有可能是在完成政府的就业指标？</p>
<p><strong>socrazyaaa</strong>：<br />
2016年，我国互联网行业向全球吸纳的投资总额为332亿美元；2017年，该数据为479亿美元；2018年，该数据为697亿美元。2019年，该数据为332亿美元；2020年，该数据为361亿美元；2021年，该数据为514亿美元。2022年，该数据为103亿美元，同比增幅-80.0%。</p>
<p><strong>zzxxx</strong>：<br />
互联网再狠，对失业率也只是个零头的。</p>
<p><strong>doug</strong>：<br />
反过来我问一下，为啥你觉得会不裁员？</p>
<p><strong>twzzqb</strong>：<br />
就是无序扩张结束了，经济形势不好不砸钱了，不盈利或者盈利少的项目、人员该裁就裁呗，即便是盈利的项目也不需要这么多的人来运转，这不难理解吧？</p>
<p><strong>B612</strong>：<br />
覆巢之下焉有完卵，这几年整体经济形势的下行绝大多数的行业都绷不住了。至于为什么大家会觉得互联网裁员严重，因为这个行业太透明了，任何信息都很容易在网上搜到，太容易传播。正如几年前行业好的时候全民吹一样，其实好的时候没有那么好，现在差的时候也没你想象的那么差。看看各大公司的财报，虽然失去了高速增长，但是整体盈利能力还是可观的。</p>
<p><strong>ym19940508</strong>：<br />
产业升级哪是几个公司就能搞定的事情，整个国家从学校教育开始，到国家科研人员以及资本市场都没有培养创新人才的环境。企业应该承担更多的产业升级的责任但是毕竟企业的第一要务是活下去盈利。阿里想颠覆传统银行的想法，就随便说几句后果怎样大家也都看见了。产业升级这个锅不应该由民营企业来背。国外99%的企业也是做打车外卖这种平台，没什么不同的。</p>
<p><strong>Archibald</strong>：<br />
美元加息周期里，资本回流，就没有那么多钱给码农们发工资了。</p>
<p><strong>D0T</strong>：<br />
整这马后炮没有，想想自己以后怎么办吧？</p>
<p><strong>woyebuzhidao</strong>：<br />
21年全球在放水吧，那一年GDP增速达到8%，所以22届秋招行情可以说特别好。</p>
<p><strong>Megamind</strong>：<br />
我是说整个国家的产业升级失败了，互联网不是孤立存在的。</p>
<p><strong>Warden</strong>：<br />
以前的互联网钱太好挣了，导致很多人都愿意去恰烂钱，这种情况下国家肯定会阻止，人才都去干高薪的容易工作了，谁来突破核心技术。大浪淘沙，慢慢互联网只会留下会社会有益的业务，那些无益社会的捞钱业务慢慢就会消失，随之从业人员也会减少。</p>
<p><strong>kezhifeng</strong>：<br />
这个产业升级指的是制造业，咱们的根底还是制造业大国，不是互联网，更不是互联网+。互联网最多就是集中+提效，相当于把5-8年的产业周期缩短到1-2年，你可以理解美林时钟越转越快了，不是什么好事情，特么债务周期可不是那么好掰的。</p>
<p><strong>qwe245347444</strong>：<br />
产业升级彻底失败了吗？那以下这几个新闻跟产业升级有关系吗？1、比亚迪新能源增长，中国取代日本成为全世界出口汽车最多的国家。2、镁光芯片已能完全国产替代，中国宣布制裁镁光，国内禁售。3、国产飞机C919已交付，准备投入实际运营。有没有这样一种可能性，由于中国开始了产业升级，并让美国感受到了威胁，于是美国开始制裁中国，贸易脱钩，逆全球化。中国逐渐失去最大的消费市场份额，公司发展受到科技封锁和国家风险，导致股价下跌，投资减少，从而产生裁员和部分高杠杆产业暴雷。</p>
<p><strong>byr118</strong>：<br />
你的结论没问题，但例子咋没一个互联网？</p>
<p><strong>d1042588361</strong>：<br />
多招便宜的应届生，把能卷的留下，不能卷的滚蛋，降本增效。</p>
<p><strong>KatyuMarisa</strong>：<br />
经济危机，现在全行业都不好过。某种程度上讲经济危机挺像是击鼓传花的，世纪末的雷靠着入世苟到了08年，08年的两轮炸雷硬是靠着放水苟到了16年，本该在16年炸的雷靠着运气苟到了20年，如果说20年底尚有回环余地修补过往错误的话，21年、22年的多轮离奇操作基本透支掉了未来十年的信心和凝聚力，以及过去十年攒下来的底气，现在别说成天被喊打喊杀的资本家选择收缩了，你随便抓个挤地铁的年轻人，但凡觉得靠着奋斗改变命运的都是乐观派中的乐观派了。</p>
<p><strong>rolander</strong>：<br />
90年代的国企工人，下岗前也是这么想的。</p>
<p><strong>luostar</strong>：<br />
降本增效，新人好于池中人。</p>
<p><strong>paper777</strong>：<br />
请问世纪末的雷是指什么啊？</p>
<p><strong>KatyuMarisa</strong>：<br />
1998。</p>
<p><strong>sinnus</strong>：<br />
美国失业率还是很低3.2%。</p>
<p><strong>mosu</strong>：<br />
ToC暂时看不到爆点，还是老老实实去ToB吧。</p>
<p><strong>KatyuMarisa</strong>：<br />
ToB感觉更地狱哇…小微企业这几年挂的太多了，万恶的资本家也收缩了（政治风险闹玩笑呢），有司为了提振信心都把福报老总请回来了＋公开宣告会灵活执法，投资都没上来…没投资没业务哪儿来的ToB…</p>
<p><strong>mumubin</strong>：<br />
别扩大范围,就是说互联网裁员,国外猛地很,我司小外企都20%了。</p>
<p><strong>zhaoxiyuan</strong>：<br />
信心很重要，不敢扩张了。</p>
<p><strong>risentang</strong>：<br />
温馨提示 90年代只下工人 不下干部。</p>
<p><strong>ghikld</strong>：<br />
其他的我不知道真不真实，但是飞机……你看看发动机和电控系统产自哪里吧。</p>
<p><strong>qwe245347444</strong>：<br />
C919的完全国产化是60%，不积跬步无以至千里。</p>
<p><strong>Aherine</strong>：<br />
本质还是美元加息资本回流，国内互联网一部分吃的就是融资这口饭，另一部分是国内制造业赚不到钱，互联网就更难赚到这部分金主爸爸的钱。</p>
<p><strong>feilongren</strong>：<br />
润土木，天天缺人。</p>
<p><strong>Aoi7</strong>：<br />
你人还怪好嘞。</p>
<p><strong>patarina</strong>：<br />
需求侧已经饱和了 等供给侧结构性改革。</p>
<p><strong>SORRY</strong>：<br />
你说的很片面，现在各行各业都在大裁员，不限于互联网或者IT。私企、外企、上市公司、国企都有裁员，不过总体说，还是事业编公务员最稳，垄断央企也成。别的就算了，身边很多应届生干一两年就被裁员了。</p>
<p><strong>beamhaha</strong>：<br />
5。</p>
<p><strong>huashenger</strong>：<br />
为啥把互联网跟实体对立，逻辑好奇怪。</p>
<p><strong>ASASASQCW</strong>：<br />
虽然我不是互联网的，但是我感觉我们国家大部分都是复制粘贴公司吧，没有几家搞技术的。</p>
<p><strong>shlysz</strong>：<br />
互联网就是服务业啊，他没有产生实体价值，像华为小米更多是制造业而不是互联网产业。</p>
<p><strong>while</strong>：<br />
快向北京的那些央企国企机关事业单位投简历吧，确实旱涝保收。</p>
<p><strong>B612</strong>：<br />
我感觉主要还是现在公司对于未来判断的不确定性，导致现在公司都不愿意扩张。可以看看几家大厂都在干什么，腾讯阿里都在不断地回购自己的股份，砍掉了大量冗余的业务。其实透露出来的一个信息就是不愿意扩张了，专注降本增效。公司不是不赚钱了，而是希望更加稳妥的运转，这个局面目前看还会继续持续下去。其实这个局面是非常可怕的，当这些巨头公司现金牛都不花钱了，一大群指着</p>
<p>这些巨头供血的公司都难以为继，整个行业一潭死水，不知道什么时候才能好转。</p>
<p><strong>fire</strong>：<br />
想知道你眼中的产业升级有哪些呢？外卖、网购、打车不入您法眼，什么业务算高级的呢？</p>
<p><strong>platu</strong>：<br />
因为宏观经济下行，说白了就是那两百万权力和资本重合的人不肯让渡利益，口喊好的比天响，实际的利益一个都不让。国内现在的矛盾某种程度上那两百万权力和资本重合的人与两亿中产之间的利益诉求的问题，然后裹挟底层。我们过去十几年不光花光了六个钱包以及未来三十年的钱，还倒欠了一屁股债，就这样还在各种盘剥。维持宏观系统和喊口号是需要巨大的系统运营成本的，如今这个运营成本不可持续了。当前的环境趋于计划向，增量思维变成了存量思维，可不得裁员了。而且互联网大企业每年都是要解决应届生就业的，这里面还有各种税收补贴，裁老人招新人是必须干的。</p>
<p><strong>platu</strong>：<br />
可别吹华为了，华为搞5G大跃进，把运营商和国家战略绑上战车像当年大炼钢铁一样的搞5G，用爱国情绪裹挟国家战略，现在运营商搞的半死不活的，还吹华为…华为到现在都没法上市，背后有多少隐形股东…</p>
<p><strong>platu</strong>：<br />
说国企稳的，想想98年我不下岗谁下岗。</p>
<p><strong>platu</strong>：<br />
金融行业已经废了，搞金融是要和美国搞好关系的，现在连金融圈的人自己都说，我国的金融就像是纵欲过度的，想要恢复这个周期是以十年计数的。</p>
<p><strong>ww43</strong>：<br />
外卖，网购，打车上最低级的产业业态了，全是挣的辛苦钱。微软靠卖系统每年赚多少钱，这才是真正的高端产业，拿的是全世界的钱，挣的是智力成果的钱。外卖平台挣的是什么钱，是压榨商家和骑手的钱。</p>
<p><strong>a299792458</strong>：<br />
马克思主义教导我们，市场调节具有自发性、盲目性和滞后性。国内外的区别无非是我们没经历过市场经济的低谷但老牌资本主义国家已经经历过很多轮。指望着去国外就能躲过经济周期就像美国人觉得美利坚永远是世界第一，永远不会垮台一样。</p>
<p><strong>lizzie1</strong>：<br />
一只蛙是啥意思啊？</p>
<p><strong>youngless</strong>：<br />
热评一 资金不在这里 没有新叙事 要看背后资金动向 肯定投AI了。</p>
<p><strong>iamwugong</strong>：<br />
业务没有扩张和增长前景了，公司不需要那么多人了。</p>
<p><strong>a2021210976</strong>：<br />
产业升级失败，用不了那么多人了。</p>
<p><strong>Wizmann</strong>：<br />
CRUD还能怎么升级？</p>
<p><strong>Wizmann</strong>：<br />
“高精尖、高学历、创新型”，90%的互联网公司都不占边，不管是2014年，还是2024年。</p>
<p><strong>lovechina</strong>：<br />
换个视觉，拼多多人少却能市值打败京东兄弟，可能导致大厂CEO也会学。</p>
<p><strong>fire</strong>：<br />
你知道你看不起的这几个产业，带来了多少就业机会吗？十几年前人们想打车只能路上拦出租，想吃饭只能自己做或者出门去饭馆，想买东西只能去实体店。外卖网购和打车平台卷生卷死把用户与“黑车司机”、外卖员和小餐馆、个体工商户连接起来，这些对你来说都不是价值是吗？如果没有这些平台，商家和骑手有被压榨的机会吗？微软做到了它所在行业的顶尖，在外卖、网购和打车业务做到顶尖，怎么就丢人了呢？就像不能说人没达到比尔盖茨的成就，就只配被说低端吧，也太社达了。</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
  </entry>
  <entry>
    <title>分布式训练</title>
    <url>/2024/05/05/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h3 id="1分布式训练"><a class="markdownIt-Anchor" href="#1分布式训练"></a> 1.分布式训练</h3>
<p>分类：</p>
<ul>
<li>Data Parrallel：每个GPU上复制一份完整模型，但每个GPU上的训练数据不同</li>
<li>Pipeline Parrallel：模型按层拆开</li>
<li>Tensor Parrallel：每层的权重拆开</li>
<li>3D并行：上面的合体</li>
</ul>
<h3 id="2data-parrallelnndataparallel"><a class="markdownIt-Anchor" href="#2data-parrallelnndataparallel"></a> 2.Data Parrallel(nn.DataParallel)</h3>
<p><strong>Data Parrallel</strong>：每个GPU上复制一份完整模型，但每个GPU上的训练数据不同;如果单卡无法运行完整流程则无法使用。</p>
<p>流程：</p>
<ul>
<li>GPU0 载入model和batch数据</li>
<li>batch数据从GPU0分发到各卡</li>
<li>model从GPU0复制到各卡</li>
<li>各卡同时前向传播</li>
<li>GPU0收集各卡的输出计算loss</li>
<li>loss分发至各卡反向传播计算梯度</li>
<li>GPU0收集各卡梯度，更新模型</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>分布式训练</tag>
      </tags>
  </entry>
  <entry>
    <title>内存与显存、CPU与GPU、GPU与CUDA</title>
    <url>/2023/12/21/%E5%86%85%E5%AD%98%E4%B8%8E%E6%98%BE%E5%AD%98%E3%80%81CPU%E4%B8%8EGPU%E3%80%81GPU%E4%B8%8ECUDA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li>内存与显存</li>
<li>CPU与GPU</li>
<li>GPU与CUDA</li>
</ul>
<br>
<h2 id="1内存与显存"><a class="markdownIt-Anchor" href="#1内存与显存"></a> 1.内存与显存</h2>
<h3 id="11-内存"><a class="markdownIt-Anchor" href="#11-内存"></a> 1.1 内存</h3>
<p>内存(Memory)也被称为内存储器，其作用是用于暂时存放CPU中的运算数据，以及与硬盘等外部存储器交换的数据。只要计算机在运行中，CPU就会把需要运算的数据调到内存中进行运算，当运算完成后CPU再将结果传送出来，内存的运行也决定了计算机的稳定运行。内存一般采用半导体存储单元，包括随机存储器，只读存储器，以及高速缓存。</p>
<br>
<p><strong>随机存储器（Random Access Memory，RAM）</strong>:</p>
<ul>
<li>既可以从中读取数据，也可以写入数据。当机器电源关闭时，存于其中的数据就会丢失。</li>
<li>通常购买或升级的内存条就是用作电脑的内存，内存条（SIMM）就是将RAM集成块集中在一起的一小块电路板，它插在计算机中的内存插槽上，以减少RAM集成块占用的空间。</li>
</ul>
<p><strong>只读存储器（Read Only Memory，ROM）</strong></p>
<ul>
<li>只读存储器在制造的时候，信息（数据或程序）就被存入并永久保存。这些信息只能读出，一般不能写入，即使机器停电，这些数据也不会丢失。</li>
<li>ROM一般用于存放计算机的基本程序和数据，如BIOS ROM。其物理外形一般是双列直插式（DIP）的集成块。</li>
</ul>
<p><strong>高速缓冲存储器（CACHE）</strong></p>
<ul>
<li>高速缓冲存储器位于CPU与内存之间，是一个读写速度比内存更快的存储器。</li>
<li>当CPU向内存中写入或读出数据时，这个数据也被存储进高速缓冲存储器中。当CPU再次需要这些数据时，CPU就从高速缓冲存储器读取数据，而不是访问较慢的内存，当然，如需要的数据在Cache中没有，CPU会再去读取内存中的数据。</li>
</ul>
<br>
<h2 id="12-显存"><a class="markdownIt-Anchor" href="#12-显存"></a> 1.2 显存</h2>
<p>显卡(Video card，Graphics card)全称显示接口卡，又称显示适配器。显卡接在电脑主板上，它将电脑的<strong>数字信号转换成模拟信号</strong>让显示器显示出来，同时显卡还是有<strong>图像处理能力</strong>，可协助CPU工作，提高整体的运行速度。</p>
<p><strong>集成显卡</strong>：</p>
<ul>
<li>集成显卡是将显示芯片、显存及其相关电路都做在主板上，与主板融为一体。</li>
<li>独立显存集成显卡：在主板上有独立的显存芯片，不需要系统内存，独立运作</li>
<li>内存划分集成显卡：从主机系统内存当中划分出来的一部分内存作为显存供集成显卡调用，具体的数量一般是系统根据需要自动动态调整的。</li>
</ul>
<p><strong>独立显卡</strong>：</p>
<ul>
<li>独立显卡是指将显示芯片、显存及其相关电路单独做在一块电路板上，自成一体而作为一块独立的板卡存在，它需占用主板的扩展插槽（ISA、PCI、AGP或PCI-E）。</li>
</ul>
<br>
<p>显存全称显示内存，即<strong>显卡的专用内存</strong>，作用是用来存储显卡芯片处理过或者即将提取的渲染数据，如同计算机的内存一样，显存是用来存储要处理的图形信息的部件。从早期的EDORAM、MDRAM、SDRAM、SGRAM、VRAM、WRAM等到今天广泛采用的DDR SDRAM显存经历了很多代的进步，市场中所采用的显存类型主要有SDRAM，DDR SDRAM，DDR SGRAM三种。</p>
<p><strong>SDRAM / 同步内存:</strong></p>
<ul>
<li>可以在一个时钟周期内进行数据的读写，从而节省了等待时间。由于低廉的价格和较佳的性能，目前SDRAM已成为中低档显卡和大多数主板普遍采用的内存。用作显存的SDRAM外形和内存条上的芯片无异，它最重要的特征是整个芯片采用两边扁平封装形式(只有两侧有针脚)。</li>
</ul>
<p><strong>SGRAM</strong>:</p>
<ul>
<li>SGRAM可以说是SDRAM的显卡专用版，速度比EDO DRAM快8倍，具有图形增强方面的特性，支持图形处理中两个最有用的操作：写掩码和块写(写掩码可以减少或消除对内存的读/写操作，块写则有利于前景或背景的填充)。</li>
</ul>
<p><strong>DDR/DDR2/DDR3 SDRAM/SGRAM:</strong></p>
<ul>
<li>这类是目前高、中端显卡最常见的显存种类，DDR(Double Data Rate)为双倍速率之意，它能在信号的上升沿和下降沿都传输数据，其数据传输带宽相当于SDRAM/SGRAM运行速度的两倍。</li>
</ul>
<p><strong>VRAM(Video DRAM) / 视频RAM:</strong></p>
<ul>
<li>是专门为图形应用优化的双端口存储器，常用于中高档显示卡。VRAM是为显示卡量身定作的，除了运用在显示卡上别无它用，但VRAM制造成本很高，故采用这种显存的显卡很少见。</li>
</ul>
<p><strong>WRAM(Window RAM):</strong></p>
<ul>
<li>WRAM是增强型的VRAM内存，它可以加速常用的视频功能，如位块传输和模式填充等。WRAM性能比VRAM高50%，但WRAM的成本也较高，所以应用上受到很大限制(MGA的Millenium Ⅱ就使用这种显存)。</li>
</ul>
<br>
<h2 id="2cpu与gpu"><a class="markdownIt-Anchor" href="#2cpu与gpu"></a> 2.CPU与GPU</h2>
<h2 id="21-cpu"><a class="markdownIt-Anchor" href="#21-cpu"></a> 2.1 CPU</h2>
<p>CPU（Central Processing Unit，中央处理器）的功能主要是<strong>解释计算机指令以及处理计算机软件中的数据</strong>。电脑中所有操作都由CPU负责读取指令，对指令译码并执行指令的核心部件。CPU包括运算逻辑部件、寄存器部件，运算器和控制部件等。</p>
<p><strong>组件</strong>：</p>
<ul>
<li><strong>运算逻辑部件</strong>：可以执行定点或浮点算术运算操作、移位操作以及逻辑操作，也可执行地址运算和转换。</li>
<li><strong>寄存器</strong>：
<ul>
<li><strong>通用寄存器</strong>：用来保存指令中的寄存器操作数和操作结果。通用寄存器的宽度决定计算机内部的数据通路宽度，其端口数目往往可影响内部操作的并行性。</li>
<li><strong>专用寄存器</strong>：为了执行一些特殊操作所需用的寄存器。</li>
<li><strong>控制寄存器</strong>：通常用来指示机器执行的状态</li>
</ul>
</li>
<li><strong>控制部件</strong>：主要负责对指令译码，并且发出为完成每条指令所要执行的各个操作的控制信号。</li>
</ul>
<br>
<h2 id="22-gpu"><a class="markdownIt-Anchor" href="#22-gpu"></a> 2.2 GPU</h2>
<p>GPU（Graphics Processing Unit，图形处理器）是显卡上的一块芯片，是一种<strong>专门进行图像运算工作的微处理器</strong>。</p>
<br>
<h2 id="23-cpu与gpu的关系"><a class="markdownIt-Anchor" href="#23-cpu与gpu的关系"></a> 2.3 CPU与GPU的关系</h2>
<p>CPU与GPU的设计逻辑不一样，用两种不同的思路实现了计算能力最大化：</p>
<ul>
<li>CPU秉承着低延时性：就是一台挖掘机（控制器），用它的爪子（缓存），一次就能够挖很多的资源（计算）；</li>
<li>GPU秉承高吞吐量：就是一个团的人（控制器），用他们的手（缓存），一次一个个的也能捧很多资源（计算）。</li>
</ul>
<p>基于不同的设计思路，两者的应用场景也是大不相同：CPU适合逻辑性强的事物处理和串行计算，而GPU适合执行高度线程化的并行处理任务（大规模计算任务）。对图像数据的应用就是一种并行计算场景，图像数据由很多像素点组成，各个像素相互独立，并行存在的。，因此GPU最早用于图像渲染等操作。而最近，利用深度学习的解决图像问题的场景也很适合用GPU计算。</p>
<br>
<h2 id="3gpu与cuda"><a class="markdownIt-Anchor" href="#3gpu与cuda"></a> 3.GPU与CUDA</h2>
<h2 id="31-gpu"><a class="markdownIt-Anchor" href="#31-gpu"></a> 3.1 GPU</h2>
<p>GPU这个概念是由Nvidia公司于1999年提出的，在这之后，经过了以下几个阶段的发展：</p>
<ul>
<li>仅用于图形渲染：此功能是GPU的初衷，这一点从它的名字就可以看出；</li>
<li>GPU这么一个强大的器件只用于图形处理太浪费了，它应该用来做更多的工作，例如浮点运算。怎么做呢？直接把浮点运算交给GPU是做不到的，因为当时它只能用于图形处理。最容易想到的，是把浮点运算做一些处理，包装成图形渲染任务，然后交给GPU来做，这就是GPGPU（General Purpose GPU）的概念。不过这样做有一个缺点，就是你必须有一定的图形学知识，否则你不知道如何包装。</li>
<li>为了让不懂图形学知识的人也能体验到GPU运算的强大，Nvidia公司又提出了CUDA的概念。</li>
</ul>
<br>
<h2 id="32-cuda"><a class="markdownIt-Anchor" href="#32-cuda"></a> 3.2 CUDA</h2>
<p>CUDA（Compute Unified Device Architecture，通用并行计算架构）是一种运算平台，它包含CUDA指令集架构以及GPU内部的并行计算引擎。只要使用一种类似于C语言的CUDA C语言，就可以开发CUDA程序，从而可以更加<strong>方便的利用GPU强大的计算能力</strong>，而不是像以前那样先将计算任务包装成图形渲染任务，再交由GPU处理。</p>
<p>CUDA的诞生就是为了<strong>让GPU能够有可用的编程环境，使得开发人员可以用程序控制GPU的硬件进行并行计算</strong>，但并不是所有GPU都支持CUDA。CUDA本质上是一个软件体系，该体系结构三部分组成：</p>
<p><img src="https://pbs.twimg.com/media/GB3IJZPWwAAt8sR?format=jpg&amp;name=medium" alt="" /></p>
<p><strong>CUDA驱动API</strong>:</p>
<ul>
<li>通过直接操纵硬件来实现GPU的使用，编程复杂，编程难度大，类似与汇编语言。（函数前缀为cu）</li>
</ul>
<p><strong>CUDA运行时API</strong>:</p>
<ul>
<li>对驱动API中的操作进行了一次封装，使用起来相对更友好，因此在编程过程中使用会比驱动API的频率要高。需要注意的是不可以和驱动API混合使用。（函数前缀为cuda）</li>
</ul>
<p><strong>CUDA函数库（官方和第三方）</strong>:</p>
<ul>
<li>为了实现更高级的功能，官方或者第三方开发者提供的针对于某个领域的高级函数库，使得普通开发人员能够快速上手实现定制化功能。比如CUDNN就是针对于卷积计算的CUDA函数库，使得深度学习开发者能够很容易的调用CUDA实现深度学习算法的构建。</li>
</ul>
<p>最后当开发人员利用C语言编写好CUDA应用程序后，还需要用特殊的编译器将C语言编译GPU能够识别的机器语言。如上图所示，CUDA的应用程序是以CPU作为宿主，然后达到操纵GPU的目的，所以最终真正运行时整个解决方案中既有运行在CPU上的代码，也会有运行在GPU上的代码。NVCC编译器就是专门针对这种情形开发出来的编译器。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>gpu</tag>
        <tag>显存</tag>
        <tag>内存</tag>
        <tag>cpu</tag>
      </tags>
  </entry>
  <entry>
    <title>在Pytorch中精细化利用显存</title>
    <url>/2024/01/11/%E5%9C%A8Pytorch%E4%B8%AD%E7%B2%BE%E7%BB%86%E5%8C%96%E5%88%A9%E7%94%A8%E6%98%BE%E5%AD%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="在pytorch中精细化利用显存"><a class="markdownIt-Anchor" href="#在pytorch中精细化利用显存"></a> 在Pytorch中精细化利用显存</h1>
<h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> <strong>前言</strong></h2>
<p>在上篇文章《计算模型以及中间变量的显存占用大小》中我们对如何计算各种变量所占显存大小进行了一些探索。而这篇文章我们着重讲解如何利用Pytorch深度学习框架的一些特性,去查看我们当前使用的变量所占用的显存大小,以及一些优化工作。以下代码所使用的平台框架为Pytorch。</p>
<br>
<h2 id="优化显存"><a class="markdownIt-Anchor" href="#优化显存"></a> <strong>优化显存</strong></h2>
<p>在Pytorch中优化显存是我们处理大量数据时必要的做法,因为我们并不可能拥有无限的显存。显存是有限的,而数据是无限的,我们只有优化显存的使用量才能够最大化地利用我们的数据,实现多种多样的算法。</p>
<Br>
<h2 id="估测模型所占的内存"><a class="markdownIt-Anchor" href="#估测模型所占的内存"></a> <strong>估测模型所占的内存</strong></h2>
<p>上篇文章中说过,一个模型所占的显存无非是这<strong>两种</strong>:</p>
<ul>
<li>
<p><strong>模型权重参数</strong></p>
</li>
<li>
<p><strong>模型所储存的中间变量</strong></p>
</li>
</ul>
<p>其实权重参数一般来说并不会占用很多的显存空间,<strong>主要占用显存空间的还是计算时产生的中间变量</strong>,当我们定义了一个model之后,我们可以通过以下代码简单计算出这个模型权重参数所占用的数据量:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># model是我们在pytorch定义的神经网络层</span></span><br><span class="line"><span class="comment"># model.parameters()取出这个model所有的权重参数</span></span><br><span class="line">para = <span class="built_in">sum</span>([np.prod(<span class="built_in">list</span>(p.size())) <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()])</span><br></pre></td></tr></table></figure>
<p>假设我们有这样一个model:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (conv_1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu_1): ReLU(inplace)</span><br><span class="line">  (conv_2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (relu_2): ReLU(inplace)</span><br><span class="line">  (pool_2): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (conv_3): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>然后我们得到的<code>para</code>是<code>112576</code>,但是我们计算出来的仅仅是权重参数的“数量”,单位是B,我们需要转化一下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下面的type_size是4,因为我们的参数是float32也就是4B,4个字节</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&#x27;Model &#123;&#125; : params: &#123;:4f&#125;M&#x27;</span>.<span class="built_in">format</span>(model._get_name(), para * type_size / <span class="number">1000</span> / <span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<p>这样就可以打印出:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Model Sequential : params: <span class="number">0.450304</span>M</span><br></pre></td></tr></table></figure>
<p>但是我们之前说过一个神经网络的模型,不仅仅有权重参数还要计算中间变量的大小。怎么去计算,我们可以假设一个<code>输入变量</code>,然后将这个输入变量投入这个模型中,然后我们主动提取这些计算出来的中间变量:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># model是我们加载的模型</span></span><br><span class="line"><span class="comment"># input是实际中投入的input(Tensor)变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用clone()去复制一个input,这样不会对input造成影响</span></span><br><span class="line">input_ = <span class="built_in">input</span>.clone()   </span><br><span class="line"><span class="comment"># 确保不需要计算梯度,因为我们的目的只是为了计算中间变量而已</span></span><br><span class="line">input_.requires_grad_(requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">mods = <span class="built_in">list</span>(model.modules())</span><br><span class="line">out_sizes = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(mods)):</span><br><span class="line">    m = mods[i]</span><br><span class="line">    <span class="comment"># 注意这里,如果relu激活函数是inplace则不用计算</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.ReLU):  </span><br><span class="line">        <span class="keyword">if</span> m.inplace:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    out = m(input_)</span><br><span class="line">    out_sizes.append(np.array(out.size()))</span><br><span class="line">    input_ = out</span><br><span class="line"></span><br><span class="line">total_nums = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(out_sizes)):</span><br><span class="line">    s = out_sizes[i]</span><br><span class="line">    nums = np.prod(np.array(s))</span><br><span class="line">    total_nums += nums</span><br></pre></td></tr></table></figure>
<p>上面得到的值是模型在运行时候产生所有的中间变量的“数量”,当然我们需要换算一下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 打印两种,只有 forward 和 foreward、backward的情况</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Model &#123;&#125; : intermedite variables: &#123;:3f&#125; M (without backward)&#x27;</span></span><br><span class="line">        .<span class="built_in">format</span>(model._get_name(), total_nums * type_size / <span class="number">1000</span> / <span class="number">1000</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Model &#123;&#125; : intermedite variables: &#123;:3f&#125; M (with backward)&#x27;</span></span><br><span class="line">        .<span class="built_in">format</span>(model._get_name(), total_nums * type_size*<span class="number">2</span> / <span class="number">1000</span> / <span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<p>因为在<code>backward</code>的时候所有的中间变量需要保存下来再来进行计算,所以我们在计算<code>backward</code>的时候,计算出来的中间变量需要乘个2。</p>
<p>然后我们得出,上面这个模型的中间变量需要的占用的显存,很显然,中间变量占用的值比模型本身的权重值多多了。如果进行一次backward那么需要的就更多。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Model Sequential : intermedite variables: <span class="number">336.089600</span> M (without backward)</span><br><span class="line">Model Sequential : intermedite variables: <span class="number">672.179200</span> M (<span class="keyword">with</span> backward)</span><br></pre></td></tr></table></figure>
<p>我们总结一下之前的代码:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 模型显存占用监测函数</span></span><br><span class="line"><span class="comment"># model:输入的模型</span></span><br><span class="line"><span class="comment"># input:实际中需要输入的Tensor变量</span></span><br><span class="line"><span class="comment"># type_size 默认为 4 默认类型为 float32 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modelsize</span>(<span class="params">model, <span class="built_in">input</span>, type_size=<span class="number">4</span></span>):</span><br><span class="line">    para = <span class="built_in">sum</span>([np.prod(<span class="built_in">list</span>(p.size())) <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Model &#123;&#125; : params: &#123;:4f&#125;M&#x27;</span>.<span class="built_in">format</span>(model._get_name(), para * type_size / <span class="number">1000</span> / <span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line">    input_ = <span class="built_in">input</span>.clone()</span><br><span class="line">    input_.requires_grad_(requires_grad=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    mods = <span class="built_in">list</span>(model.modules())</span><br><span class="line">    out_sizes = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(mods)):</span><br><span class="line">        m = mods[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.ReLU):</span><br><span class="line">            <span class="keyword">if</span> m.inplace:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        out = m(input_)</span><br><span class="line">        out_sizes.append(np.array(out.size()))</span><br><span class="line">        input_ = out</span><br><span class="line"></span><br><span class="line">    total_nums = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(out_sizes)):</span><br><span class="line">        s = out_sizes[i]</span><br><span class="line">        nums = np.prod(np.array(s))</span><br><span class="line">        total_nums += nums</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Model &#123;&#125; : intermedite variables: &#123;:3f&#125; M (without backward)&#x27;</span></span><br><span class="line">          .<span class="built_in">format</span>(model._get_name(), total_nums * type_size / <span class="number">1000</span> / <span class="number">1000</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Model &#123;&#125; : intermedite variables: &#123;:3f&#125; M (with backward)&#x27;</span></span><br><span class="line">          .<span class="built_in">format</span>(model._get_name(), total_nums * type_size*<span class="number">2</span> / <span class="number">1000</span> / <span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<p>当然我们计算出来的占用显存值仅仅是做参考作用,因为Pytorch在运行的时候需要额外的显存值开销,所以实际的显存会比我们计算的稍微大一些。</p>
<br>
<h2 id="关于inplacefalse"><a class="markdownIt-Anchor" href="#关于inplacefalse"></a> 关于inplace=False</h2>
<p>我们都知道激活函数Relu()有一个默认参数inplace,默认设置为False,当设置为True时,我们在通过relu()计算时的得到的新值不会占用新的空间而是直接覆盖原来的值,这也就是为什么当inplace参数设置为True时可以节省一部分内存的缘故。</p>
<p><img src="https://pbs.twimg.com/media/GDfu20gbMAEIF3C?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="牺牲计算速度减少显存使用量"><a class="markdownIt-Anchor" href="#牺牲计算速度减少显存使用量"></a> <strong>牺牲计算速度减少显存使用量</strong></h2>
<p>在Pytorch-0.4.0出来了一个新的功能,可以将一个计算过程分成两半,也就是如果一个模型需要占用的显存太大了,我们就可以先计算一半,保存后一半需要的中间结果,然后再计算后一半。</p>
<p>也就是说,新的checkpoint允许我们只存储反向传播所需要的部分内容。如果当中缺少一个输出(为了节省内存而导致的),checkpoint将会从最近的检查点重新计算中间输出,以便减少内存使用(当然计算时间增加了):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输入</span></span><br><span class="line"><span class="built_in">input</span> = torch.rand(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 假设我们有一个非常深的网络  </span></span><br><span class="line">layers = [nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)]</span><br><span class="line">model = nn.Sequential(*layers)</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>
<p>上面的模型需要占用很多的内存,因为计算中会产生很多的中间变量。为此checkpoint就可以帮助我们来节省内存的占用了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先设置输入的input=&gt;requires_grad=True</span></span><br><span class="line"><span class="comment"># 如果不设置可能会导致得到的gradient为0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.rand(<span class="number">1</span>, <span class="number">10</span>, requires_grad=<span class="literal">True</span>) </span><br><span class="line">layers = [nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义要计算的层函数,可以看到我们定义了两个</span></span><br><span class="line"><span class="comment"># 一个计算前500个层,另一个计算后500个层</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_first_half</span>(<span class="params">*args</span>):</span><br><span class="line">    x = args[<span class="number">0</span>]  </span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> layers[:<span class="number">500</span>]:</span><br><span class="line">        x = layer(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_second_half</span>(<span class="params">*args</span>):</span><br><span class="line">    x = args[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> layers[<span class="number">500</span>:-<span class="number">1</span>]:</span><br><span class="line">        x = layer(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们引入新加的checkpoint</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.checkpoint <span class="keyword">import</span> checkpoint</span><br><span class="line"></span><br><span class="line">x = checkpoint(run_first_half, <span class="built_in">input</span>)</span><br><span class="line">x = checkpoint(run_second_half, x)</span><br><span class="line"><span class="comment"># 最后一层单独调出来执行  </span></span><br><span class="line">x = layers[-<span class="number">1</span>](x)</span><br><span class="line">x.<span class="built_in">sum</span>.backward()  <span class="comment"># 这样就可以了</span></span><br></pre></td></tr></table></figure>
<p>对于Sequential-model来说,因为Sequential()中可以包含很多的block,所以官方提供了另一个功能包:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">input</span> = torch.rand(<span class="number">1</span>, <span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">layers = [nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)] </span><br><span class="line">model = nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.checkpoint <span class="keyword">import</span> checkpoint_sequential</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分成两个部分</span></span><br><span class="line">num_segments = <span class="number">2</span></span><br><span class="line">x = checkpoint_sequential(model, num_segments, <span class="built_in">input</span>)</span><br><span class="line">x.<span class="built_in">sum</span>().backward() <span class="comment"># 这样就可以了</span></span><br></pre></td></tr></table></figure>
<h2 id="跟踪显存使用情况"><a class="markdownIt-Anchor" href="#跟踪显存使用情况"></a> <strong>跟踪显存使用情况</strong></h2>
<p>显存的使用情况,在编写程序中我们可能无法精确计算,但是我们可以通过pynvml这个Nvidia的Python环境库和Python的垃圾回收工具,可以实时地打印我们使用的显存以及哪些Tensor使用了我们的显存。</p>
<p>类似于下面的报告:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 08-Jun-18-17:56:51-gpu_mem_prof</span><br><span class="line"></span><br><span class="line">At __main__ &lt;module&gt;: line 39                        Total Used Memory:399.4  Mb</span><br><span class="line">At __main__ &lt;module&gt;: line 40                        Total Used Memory:992.5  Mb</span><br><span class="line">+ __main__ &lt;module&gt;: line 40                         (1, 1, 682, 700)     1.82 M &lt;class &#x27;torch.Tensor&#x27;&gt;  </span><br><span class="line">+ __main__ &lt;module&gt;: line 40                         (1, 3, 682, 700)     5.46 M &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">At __main__ &lt;module&gt;: line 126                       Total Used Memory:1088.5 Mb  </span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (64, 64, 3, 3)       0.14 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (128, 64, 3, 3)      0.28 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (128, 128, 3, 3)     0.56 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;  </span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (64, 3, 3, 3)        0.00 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (256, 256, 3, 3)     2.25 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (512, 256, 3, 3)     4.5 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt; </span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (512, 512, 3, 3)     9.0 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (64,)                0.00 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (1, 3, 682, 700)     5.46 M &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (128,)               0.00 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (256,)               0.00 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt; </span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (512,)               0.00 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (3,)                 1.14 M &lt;class &#x27;torch.Tensor&#x27;&gt;</span><br><span class="line">+ __main__ &lt;module&gt;: line 126                        (256, 128, 3, 3)     1.12 M &lt;class &#x27;torch.nn.parameter.Parameter&#x27;&gt;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">None</span><br></pre></td></tr></table></figure>
<p>以下是相关的代码,目前代码依然有些地方需要修改,等修改完善好我会将完整代码以及使用说明放到github上:<a href="https://github.com/Oldpan/Pytorch-Memory-Utils">https://github.com/Oldpan/Pytorch-Memory-Utils</a><br />
请大家多多留意。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> linecache</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> pynvml</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print_tensor_sizes = <span class="literal">True</span></span><br><span class="line">last_tensor_sizes = <span class="built_in">set</span>()</span><br><span class="line">gpu_profile_fn = <span class="string">f&#x27;<span class="subst">&#123;datetime.datetime.now():%d-%b-%y-%H:%M:%S&#125;</span>-gpu_mem_prof.txt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if &#x27;GPU_DEBUG&#x27; in os.environ:</span></span><br><span class="line"><span class="comment">#     print(&#x27;profiling gpu usage to &#x27;, gpu_profile_fn)</span></span><br><span class="line"></span><br><span class="line">lineno = <span class="literal">None</span></span><br><span class="line">func_name = <span class="literal">None</span></span><br><span class="line">filename = <span class="literal">None</span></span><br><span class="line">module_name = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fram = inspect.currentframe()</span></span><br><span class="line"><span class="comment"># func_name = fram.f_code.co_name</span></span><br><span class="line"><span class="comment"># filename = fram.f_globals[&quot;__file__&quot;]</span></span><br><span class="line"><span class="comment"># ss = os.path.dirname(os.path.abspath(filename)) </span></span><br><span class="line"><span class="comment"># module_name = fram.f_globals[&quot;__name__&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gpu_profile</span>(<span class="params">frame, event</span>):</span><br><span class="line">    <span class="comment"># it is _about to_ execute (!)</span></span><br><span class="line">    <span class="keyword">global</span> last_tensor_sizes</span><br><span class="line">    <span class="keyword">global</span> lineno, func_name, filename, module_name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> event == <span class="string">&#x27;line&#x27;</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># about _previous_ line (!)</span></span><br><span class="line">            <span class="keyword">if</span> lineno <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                pynvml.nvmlInit()</span><br><span class="line">                <span class="comment"># handle = pynvml.nvmlDeviceGetHandleByIndex(int(os.environ[&#x27;GPU_DEBUG&#x27;]))</span></span><br><span class="line">                handle = pynvml.nvmlDeviceGetHandleByIndex(<span class="number">0</span>)</span><br><span class="line">                meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)</span><br><span class="line">                line = linecache.getline(filename, lineno)</span><br><span class="line">                where_str = module_name+<span class="string">&#x27; &#x27;</span>+func_name+<span class="string">&#x27;:&#x27;</span>+<span class="string">&#x27; line &#x27;</span>+<span class="built_in">str</span>(lineno)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(gpu_profile_fn, <span class="string">&#x27;a+&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(<span class="string">f&quot;At <span class="subst">&#123;where_str:&lt;<span class="number">50</span>&#125;</span>&quot;</span> </span><br><span class="line">                            <span class="string">f&quot;Total Used Memory:<span class="subst">&#123;meminfo.used/<span class="number">1024</span>**<span class="number">2</span>:&lt;<span class="number">7.1</span>f&#125;</span>Mb\n&quot;</span>)</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> print_tensor_sizes <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">                        <span class="keyword">for</span> tensor <span class="keyword">in</span> get_tensors():</span><br><span class="line">                            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(tensor, <span class="string">&#x27;dbg_alloc_where&#x27;</span>):</span><br><span class="line">                                tensor.dbg_alloc_where = where_str</span><br><span class="line">                        new_tensor_sizes = &#123;(<span class="built_in">type</span>(x), <span class="built_in">tuple</span>(x.size()), np.prod(np.array(x.size()))*<span class="number">4</span>/<span class="number">1024</span>**<span class="number">2</span>,  </span><br><span class="line">                                             x.dbg_alloc_where) <span class="keyword">for</span> x <span class="keyword">in</span> get_tensors()&#125;</span><br><span class="line">                        <span class="keyword">for</span> t, s, m, loc <span class="keyword">in</span> new_tensor_sizes - last_tensor_sizes:</span><br><span class="line">                            f.write(<span class="string">f&#x27;+ <span class="subst">&#123;loc:&lt;<span class="number">50</span>&#125;</span> <span class="subst">&#123;<span class="built_in">str</span>(s):&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;<span class="built_in">str</span>(m)[:<span class="number">4</span>]&#125;</span> M <span class="subst">&#123;<span class="built_in">str</span>(t):&lt;<span class="number">10</span>&#125;</span>\n&#x27;</span>)</span><br><span class="line">                        <span class="keyword">for</span> t, s, m, loc <span class="keyword">in</span> last_tensor_sizes - new_tensor_sizes:</span><br><span class="line">                            f.write(<span class="string">f&#x27;- <span class="subst">&#123;loc:&lt;<span class="number">50</span>&#125;</span> <span class="subst">&#123;<span class="built_in">str</span>(s):&lt;<span class="number">20</span>&#125;</span> <span class="subst">&#123;<span class="built_in">str</span>(m)[:<span class="number">4</span>]&#125;</span> M <span class="subst">&#123;<span class="built_in">str</span>(t):&lt;<span class="number">10</span>&#125;</span>\n&#x27;</span>)</span><br><span class="line">                        last_tensor_sizes = new_tensor_sizes</span><br><span class="line">                pynvml.nvmlShutdown()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># save details about line _to be_ executed</span></span><br><span class="line">            lineno = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            func_name = frame.f_code.co_name</span><br><span class="line">            filename = frame.f_globals[<span class="string">&quot;__file__&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> (filename.endswith(<span class="string">&quot;.pyc&quot;</span>) <span class="keyword">or</span>  </span><br><span class="line">                    filename.endswith(<span class="string">&quot;.pyo&quot;</span>)):</span><br><span class="line">                filename = filename[:-<span class="number">1</span>]</span><br><span class="line">            module_name = frame.f_globals[<span class="string">&quot;__name__&quot;</span>]</span><br><span class="line">            lineno = frame.f_lineno</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> gpu_profile</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;A exception occured: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(e))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> gpu_profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_tensors</span>():</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> gc.get_objects():</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> torch.is_tensor(obj):</span><br><span class="line">                tensor = obj</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> tensor.is_cuda:</span><br><span class="line">                <span class="keyword">yield</span> tensor</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;A exception occured: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(e))</span><br></pre></td></tr></table></figure>
<p>需要注意的是,linecache中的getlines只能读取缓冲过的文件,如果这个文件没有运行过则返回无效值。Python 的垃圾收集机制会在变量没有应引用的时候立马进行回收,但是为什么模型中计算的中间变量在执行结束后还会存在呢。既然都没有引用了为什么还会占用空间?</p>
<p>一种可能的情况是这些引用不在Python代码中,而是在神经网络层的运行中为了backward被保存为gradient,这些引用都在计算图中,我们在程序中是无法看到的:</p>
<br>
<h2 id="后记"><a class="markdownIt-Anchor" href="#后记"></a> 后记</h2>
<p>实际中我们会有些只使用一次的模型，为了节省显存，我们需要一边计算一遍清除中间变量，使用del进行操作。限于篇幅这里不进行讲解，下一篇会进行说明。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>memory</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>面试：关于Transformer的问题</title>
    <url>/2024/01/25/%E5%85%B3%E4%BA%8ETransformer%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://blog.csdn.net/m0_51879931/article/details/134142492">transformer模型— 20道面试题自我检测</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/496012402?utm_medium=social&amp;utm_oi=629375409599549440">Transformer常见问题与回答总结</a></li>
<li><a href="https://www.bilibili.com/video/BV1pu411o7BE/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">Transformer论文逐段精读【论文精读】</a></li>
<li><a href="https://www.zhihu.com/question/341222779">为什么Transformer 需要进行 Multi-head Attention？</a></li>
<li><a href="https://www.zhihu.com/question/319339652">transformer中为什么使用不同的K 和 Q， 为什么不能使用同一个值？</a></li>
<li><a href="https://github.com/huggingface/transformers/blob/aa6a29bc25b663e1311c5c4fb96b004cf8a6d2b6/src/transformers/modeling_bert.py#L720">Breadcrumbstransformers/src/transformers<br />
/modeling_bert.py</a></li>
</ul>
<p>位置编码：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/QxaZTVOUrzKfO7B78EM5Uw">一文读懂Transformer模型的位置编码</a></li>
<li><a href="https://mp.weixin.qq.com/s/vXYJKF9AViKnd0tbuhMWgQ">浅谈Transformer模型中的位置表示</a></li>
<li><a href="https://mp.weixin.qq.com/s/NPM3w7sIYVLuMYxQ_R6PrA">Transformer改进之相对位置编码(RPE)</a></li>
<li><a href="https://mp.weixin.qq.com/s/ENpXBYQ4hfdTLSXBIoF00Q">如何优雅地编码文本中的位置信息？三种positioanl encoding方法简述</a></li>
</ul>
<h2 id="面试十问"><a class="markdownIt-Anchor" href="#面试十问"></a> 面试十问</h2>
<h3 id="1-transformer为何使用多头注意力机制为什么不使用一个头"><a class="markdownIt-Anchor" href="#1-transformer为何使用多头注意力机制为什么不使用一个头"></a> 1. Transformer为何使用多头注意力机制？（为什么不使用一个头）</h3>
<p>多头保证了transformer可以注意到不同子空间的信息，捕捉到更加丰富的特征信息。可以<strong>类比CNN中同时使用多个卷积核</strong>的作用，直观上讲，多头的注意力<strong>有助于网络捕捉到更丰富的特征/信息</strong>。</p>
<p>捕捉多种依赖关系：不同的注意力头可以学习到序列中不同位置之间的不同依赖关系。一个头可能专注于捕捉语法依赖，另一个头可能专注于语义依赖，这样模型就能够更全面地理解输入数据。</p>
<p>提高模型容量：多头注意力机制增加了模型的容量，使得模型能够学习到更复杂的表示。</p>
<p>更好的泛化能力：由于多头注意力机制能够从多个角度分析输入数据，模型的泛化能力得到提升。</p>
<p>并行计算：多头注意力机制的计算可以并行进行，这提高了训练和推理的效率。</p>
<br>
<h3 id="2-transformer为什么q和k使用不同的权重矩阵生成为何不能使用同一个值进行自身的点乘-注意和第一个问题的区别"><a class="markdownIt-Anchor" href="#2-transformer为什么q和k使用不同的权重矩阵生成为何不能使用同一个值进行自身的点乘-注意和第一个问题的区别"></a> 2. Transformer为什么Q和K使用不同的权重矩阵生成，为何不能使用同一个值进行自身的点乘？ （注意和第一个问题的区别）</h3>
<p><strong>理解自注意力机制：Q、K、V的角色</strong></p>
<p>您可能好奇，为什么在‘K’和‘Q’很相似的情况下（主要区别在于权重W_k和W_Q），还要创建一个单独的‘Q’？使用‘K’自身进行点乘似乎就足够了，这样不仅省去了创建和更新‘Q’的麻烦，还节约了内存空间。</p>
<p><img src="https://pbs.twimg.com/media/GEr3GLAWoAAPrcT?format=png&amp;name=small" alt="自注意力公式" /><br />
<em>(上图是自注意力公式，涉及Q、K、V三个向量。)</em></p>
<p>为了解答这个问题，我们首先要理解为什么计算Q和K的点乘是关键的。</p>
<ol>
<li><strong>点乘的本质</strong>：从物理意义上讲，两个向量的点乘代表了这两个向量的相似度。</li>
<li><strong>Q、K、V的物理意义</strong>：Q、K、V在物理上都代表了由同一个句子中不同token组成的矩阵。这些矩阵中的每一行都是一个token的词嵌入向量。例如，在句子“Hello, how are you?”中，长度为6，<a href="https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/">嵌入维度</a>为300，那么Q、K、V都将形成一个(6, 300)的矩阵。</li>
</ol>
<p>简单来说，K和Q的点乘是为了计算句子中每个token相对于其他token的相似度，这种相似度可以理解为<strong>注意力得分</strong>。</p>
<p>例如，在处理“Hello, how are you?”这句话时，当前token为“Hello”，我们可以计算出“Hello”与句子中的“,”、“how”、“are”、“you”、“?”这些token的注意力得分。有了这个注意力得分，我们就能知道在处理“Hello”时，模型关注了句子中的哪些token。</p>
<p><img src="https://pic1.zhimg.com/50/v2-71c50aef27eedfe5ca0279efc21a1a4d_720w.jpg?source=1def8aca" alt="注意力得分矩阵" /><br />
这个注意力得分是一个(6, 6)的矩阵。每一行代表一个token相对于其他token的关注度。例如，上图中的第一行代表了“Hello”这个单词相对于本句中其他单词的关注度。添加softmax函数是为了对关注度进行归一化。</p>
<p>虽然我们通过各种计算得到了注意力得分矩阵，但它<strong>很难直接代表原始句子</strong>。然而，<strong>'V’仍然代表原始句子</strong>，因此我们将这个注意力得分矩阵与’V’相乘，得到的是一个加权后的结果。最初，'V’中的每个单词仅通过词嵌入来表示，彼此之间没有关联。但经过与注意力得分相乘后，'V’中每个token的向量（即每个单词的词嵌入向量）在每个维度（每一列）上都根据其他token的关注度进行了调整。这一步相当于提纯，使每个单词关注其应关注的部分。</p>
<p>现在，我们来解释为什么不使用相同的值来代表K和Q。从以上解释中，我们知道K和Q的点乘旨在产生一个注意力得分矩阵，用于提纯’V’。K和Q使用不同的W_k和W_Q进行计算，这可以理解为在<strong>不同的空间上进行投影</strong>。正是因为这种不同空间的投影，提高了表达能力，使得计算出的注意力得分矩阵具有更高的泛化能力。我的理解是，<strong>由于K和Q使用了不同的W_k和W_Q，所以它们形成了两个完全不同的矩阵，因此具有更强的表达能力</strong>。但如果不使用Q，而是直接使用K与K进行点乘，你会发现注意力得分矩阵是一个对称矩阵。这意味着它们都在相同的空间中进行了投影，因此泛化能力较差。这样的矩阵在提纯’V’时的效果也不会很好。</p>
<br>
<h3 id="3-transformer计算attention的时候为何选择点乘而不是加法两者计算复杂度和效果上有什么区别"><a class="markdownIt-Anchor" href="#3-transformer计算attention的时候为何选择点乘而不是加法两者计算复杂度和效果上有什么区别"></a> 3. Transformer计算attention的时候为何选择点乘而不是加法？两者计算复杂度和效果上有什么区别？</h3>
<table>
<thead>
<tr>
<th>特性 / 类型</th>
<th>点乘注意力（Dot-product Attention）</th>
<th>加法注意力（Additive Attention）</th>
</tr>
</thead>
<tbody>
<tr>
<td>公式</td>
<td><code>Attention(Q, K, V) = softmax((QK^T) / sqrt(d_k)) V</code></td>
<td><code>Attention(Q, K, V) = softmax(score(Q, K)) V</code></td>
</tr>
<tr>
<td>输入</td>
<td>查询（Q）、键（K）和值（V）</td>
<td>查询（Q）、键（K）和值（V）</td>
</tr>
<tr>
<td>计算特点</td>
<td>使用查询和键的点乘来计算相似度</td>
<td>使用自定义的分数函数来计算查询和键之间的相似度</td>
</tr>
<tr>
<td>优点</td>
<td>- 高效：点乘操作可以在硬件上<strong>高效并行化</strong><br>- 强大的建模能力：能够捕捉查询和键之间的细微<strong>相似度</strong></td>
<td>- 对长序列的性能可能优于点乘注意力<br>- 可能更适合处理复杂的分数函数</td>
</tr>
<tr>
<td>缺点</td>
<td>- 维度高时可能导致梯度消失问题<br>- 需要适当缩放以防止softmax输出极端值</td>
<td>- 计算复杂度高：需要为每对查询和键计算分数<br>- 计算速度可能较慢</td>
</tr>
<tr>
<td>计算复杂度</td>
<td>O(n^2 * d)，其中n是序列长度，d是维度</td>
<td>O(n^2 * d)，但常数因子可能更大</td>
</tr>
<tr>
<td>效果</td>
<td>- 在多数任务中表现良好<br>- 在硬件上更易于并行化，计算更快</td>
<td>- 在某些长序列任务中可能表现更好<br>- 适合复杂的相似度计算</td>
</tr>
</tbody>
</table>
<br>
<h3 id="4为什么在进行softmax之前需要对attention进行scaled为什么除以dk的平方根并使用公式推导进行讲解"><a class="markdownIt-Anchor" href="#4为什么在进行softmax之前需要对attention进行scaled为什么除以dk的平方根并使用公式推导进行讲解"></a> 4.为什么在进行softmax之前需要对attention进行scaled（为什么除以dk的平方根），并使用公式推导进行讲解</h3>
<p>self-attention的公式如下：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi><mspace linebreak="newline"></mspace></mrow><annotation encoding="application/x-tex">\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \\
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.468361em;vertical-align:-0.95003em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em;"><span style="top:-2.25278em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span><span class="mspace newline"></span></span></span></span></p>
<p>这里我们引用一下<a href="https://arxiv.org/pdf/1706.03762.pdf">Transformer论文</a>中的解释:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">While for small values of d_k, the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of d_k. We suspect that for large values of $d_k$, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients. To counteract this effect, we scale the dot products by 1/√dk.</span><br></pre></td></tr></table></figure>
<p>通过上面内容，可以将该思考题分为两部分进行描述：</p>
<ul>
<li>问题1: Transformer的计算Attention时为什么要除以一个数</li>
<li>问题2: 这个数为什么是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{d_k}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.383108em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.5864385em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622307142857143em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222307142857144em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17776928571428574em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ul>
<Br>
<h3 id="问题1-transformer的计算attention时为什么要除以一个数"><a class="markdownIt-Anchor" href="#问题1-transformer的计算attention时为什么要除以一个数"></a> <code>问题1: Transformer的计算Attention时为什么要除以一个数</code></h3>
<p>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 很大的时候,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 的结果里面会有很大,如果不进行scale，softmax将会作用于一些很大的值，那么根据softmax函数的分布，大多数值会堆积在分布的两端、也就是那些分布曲线平缓、梯度很小的地方，梯度很小就会导致梯度消失。</p>
<h3 id="问题2-这个数为什么是1dk"><a class="markdownIt-Anchor" href="#问题2-这个数为什么是1dk"></a> <code>问题2: 这个数为什么是1/√dk</code></h3>
<p>设文中提出的向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>n</mi><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">q_i \in R^{n \times 1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">Q \in R^{n \times d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>)和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">k_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>m</mi><mo>×</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">k_i \in R^{m \times 1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>m</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">K \in R^{m \times d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>)都是相互独立的、均值为0,方差为1的随机变量，那么根据独立变量性质有:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Var</mtext><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mtext>Var</mtext><mrow><mo fence="true">(</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>d</mi><mi>k</mi></msub></munderover><msub><mi>q</mi><mi>i</mi></msub><msubsup><mi>k</mi><mi>i</mi><mi>T</mi></msubsup><mo fence="true">)</mo></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>d</mi><mi>k</mi></msub></munderover><mtext>Var</mtext><mo stretchy="false">(</mo><msub><mi>q</mi><mi>i</mi></msub><msubsup><mi>k</mi><mi>i</mi><mi>T</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><msub><mi>d</mi><mi>k</mi></msub><mspace linebreak="newline"></mspace></mrow><annotation encoding="application/x-tex">\text{Var}(QK^T) = \text{Var}\left(\sum_{i=1}^{d_k} q_i k_i^T\right) = \sum_{i=1}^{d_k} \text{Var}(q_i k_i^T) = d_k \\
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Var</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.130642em;vertical-align:-1.277669em;"></span><span class="mord text"><span class="mord">Var</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8529730000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.316865em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.130642em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8529730000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.316865em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">Var</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span></span></span></span></p>
<p>因为有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Var</mtext><mo stretchy="false">(</mo><mi>a</mi><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>a</mi><mn>2</mn></msup><mtext>Var</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Var}(ax) = a^2 \text{Var}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Var</span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord text"><span class="mord">Var</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></p>
<p>所以在softmax之前除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span> 可以将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 的分布的方差缩小至1。</p>
<p>这样一来，大部分数值都会分布在softmax梯度适当的位置，也就避免了梯度消失的问题。</p>
<br>
<br>
<br>
<h3 id="实验验证"><a class="markdownIt-Anchor" href="#实验验证"></a> <code>实验验证</code></h3>
<p>以下是用于实验的Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> softmax  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_gradient</span>(<span class="params">dimension, time_steps=<span class="number">50</span>, scaling_factor=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    - dimension: 查询向量和键向量的维度。</span></span><br><span class="line"><span class="string">    - time_steps: 生成键向量的数量。</span></span><br><span class="line"><span class="string">    - scaling_factor: 应用于点积的缩放因子。</span></span><br><span class="line"><span class="string">    - return: 梯度矩阵中最大的绝对值分量。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成随机的查询向量和键向量，其组成部分从标准正态分布中抽取</span></span><br><span class="line">    query_vector = np.random.randn(dimension)</span><br><span class="line">    key_vectors = np.random.randn(time_steps, dimension)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算点积，应用缩放，然后计算softmax</span></span><br><span class="line">    dot_products = np.<span class="built_in">sum</span>(query_vector * key_vectors, axis=<span class="number">1</span>) / scaling_factor</span><br><span class="line">    softmax_output = softmax(dot_products)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算softmax输出的梯度</span></span><br><span class="line">    gradient_matrix = np.diag(softmax_output) - np.outer(softmax_output, softmax_output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回梯度矩阵中的最大绝对值</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">max</span>(np.<span class="built_in">abs</span>(gradient_matrix))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实验次数</span></span><br><span class="line">NUMBER_OF_EXPERIMENTS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行没有缩放的实验</span></span><br><span class="line">results_without_scaling_100 = [test_gradient(<span class="number">100</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(NUMBER_OF_EXPERIMENTS)]</span><br><span class="line">results_without_scaling_1000 = [test_gradient(<span class="number">1000</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(NUMBER_OF_EXPERIMENTS)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行有缩放的实验</span></span><br><span class="line">results_with_scaling_100 = [test_gradient(<span class="number">100</span>, scaling_factor=np.sqrt(<span class="number">100</span>)) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(NUMBER_OF_EXPERIMENTS)]</span><br><span class="line">results_with_scaling_1000 = [test_gradient(<span class="number">1000</span>, scaling_factor=np.sqrt(<span class="number">1000</span>)) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(NUMBER_OF_EXPERIMENTS)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;没有缩放的结果（维度=100）:&quot;</span>, results_without_scaling_100)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;没有缩放的结果（维度=1000）:&quot;</span>, results_without_scaling_1000)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;有缩放的结果（维度=100）:&quot;</span>, results_with_scaling_100)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;有缩放的结果（维度=1000）:&quot;</span>, results_with_scaling_1000)</span><br></pre></td></tr></table></figure>
<p><strong>实验结果</strong>：通过散点图展示，对比了不同实验条件下梯度最大绝对值分量的分布：<br />
<img src="https://pbs.twimg.com/media/GEMYvc6XsAAp9Vo?format=jpg&amp;name=medium" alt="" /></p>
<p><strong>实验结果对比分析：</strong></p>
<p><strong>不带scaling的结果（维度=1000）：</strong> 在没有缩放处理的情况下，维度为1000的实验组中，梯度的最大绝对值分量出现了极小的值，如<code>1.8829382497642655e-11</code>，这表明在高维空间中不进行缩放可能会导致梯度消失。这是因为在高维空间中，点积的结果通常会非常大，导致softmax函数饱和，从而在反向传播时梯度接近于零。</p>
<p><strong>不带scaling的结果（维度=100）：</strong> 在维度为100时，没有缩放处理的情况下，梯度的最大绝对值分量显得较大且变化范围宽，比如从<code>0.059398546712975064</code>到<code>0.2498360169388831</code>。这表明在较低维度的空间中，梯度消失的问题不像在高维空间那么显著。</p>
<p><strong>带scaling的结果（维度=1000和100）：</strong> 在应用了缩放处理后，无论是维度为1000还是100的情况下，梯度的最大绝对值分量都较为稳定，没有出现接近于零的情况。例如，维度为1000时的输出值在<code>0.08899382001739972</code>到<code>0.1312868174831885</code>之间。这表明通过缩放可以有效避免梯度消失，确保了梯度流的稳定性。</p>
<h3 id="5-在计算attention-score的时候如何对padding做mask操作"><a class="markdownIt-Anchor" href="#5-在计算attention-score的时候如何对padding做mask操作"></a> 5. 在计算attention score的时候如何对padding做mask操作？</h3>
<p>padding位置置为负无穷(一般来说-1000就可以)，再对attention score进行相加。</p>
<p>步骤：</p>
<ul>
<li>
<p><strong>创建一个掩码矩阵</strong>: 对于输入序列中的每个位置，如果该位置是填充词，则在掩码矩阵的对应位置放置一个非常大的负数（如-1e9），否则放置0。</p>
</li>
<li>
<p><strong>应用掩码矩阵</strong>: 将掩码矩阵加到注意力分数上。因为掩码矩阵中填充词的位置是非常大的负数，加上它们之后，这些位置的注意力分数也会变成非常大的负数。</p>
</li>
<li>
<p><strong>应用softmax函数</strong>: 在加了掩码的注意力分数上应用softmax函数。由于填充词位置的分数是非常大的负数，经过softmax函数后，这些位置的权重将接近于0，而其他位置的权重将保持不变（因为softmax是一个归一化函数）。</p>
</li>
<li>
<p><strong>计算加权和</strong>: 使用softmax的输出作为权重，计算值（Value）的加权和。</p>
</li>
</ul>
<Br>
<h3 id="6-为什么在进行多头注意力的时候需要对每个head进行降维可以参考上面一个问题"><a class="markdownIt-Anchor" href="#6-为什么在进行多头注意力的时候需要对每个head进行降维可以参考上面一个问题"></a> 6. 为什么在进行多头注意力的时候需要对每个head进行降维？（可以参考上面一个问题）</h3>
<p>将原有的高维空间转化为多个低维空间并再最后进行拼接，形成同样维度的输出，借此丰富特性信息</p>
<h3 id="7-大概讲一下transformer的encoder模块"><a class="markdownIt-Anchor" href="#7-大概讲一下transformer的encoder模块"></a> 7. 大概讲一下Transformer的Encoder模块？</h3>
<p>基本结构：</p>
<ul>
<li>Embedding + Position Embedding</li>
<li>Self-Attention</li>
<li>Add + LN</li>
<li>FN</li>
<li>Add + LN</li>
</ul>
<br>
<p>Transformer的Encoder模块是由一系列相同的层堆叠而成的，每一层都有两个主要的子模块：多头自注意力机制（Multi-Head Self-Attention）和前馈神经网络（Position-wise Feed-Forward Networks）。此外，每个子模块周围都有一个残差连接，并且每个子模块的输出都会经过层归一化（Layer Normalization）。下面是对这些组件的详细说明：</p>
<ul>
<li>
<p>1.<strong>多头自注意力机制（Multi-Head Self-Attention）</strong>:这个模块可以使网络在进行预测时考虑输入序列的不同位置，对不同位置的输入分配不同的注意力。多头注意力机制意味着模型有多组不同的注意力参数，每组都会输出一个注意力权重，这些注意力权重会被合并成最终的注意力输出。</p>
</li>
<li>
<p>2.<strong>残差连接（Residual Connection）</strong>: 残差连接帮助避免了深度神经网络中的梯度消失问题。在Transformer中，每个子模块的输出是 LayerNorm(x + SubLayer(x))，其中SubLayer(x)是子模块自身（比如多头自注意力或前馈神经网络）的输出。</p>
</li>
<li>
<p>3.<strong>层归一化（Layer Normalization）</strong>: 层归一化是在模型的训练过程中加速收敛的一种技术，它对层的输入进行归一化处理，使得其均值为0，方差为1。</p>
</li>
<li>
<p>4.<strong>前馈神经网络（Position-wise Feed-Forward Networks）</strong>: 这个模块由两个线性变换组成，中间夹有一个ReLU激活函数。它对每个位置的词向量独立地进行变换。</p>
</li>
<li>
<p>5.<strong>位置编码（Position Encoding）</strong>: 由于Transformer模型没有循环或卷积操作，为了让模型能够利用词的顺序信息，需要在输入嵌入层中加入位置编码。位置编码和词嵌入相加后输入到Encoder模块。</p>
</li>
</ul>
<p>整体来看，Transformer的Encoder模块将输入序列转换为一系列连续表示，这些表示在后续的Decoder模块中用于生成输出序列。每一层的Encoder都对输入序列的所有位置同时进行操作，而不是像RNN那样逐个位置处理，这是Transformer模型高效并行处理的关键。</p>
<Br>
<h3 id="8为何在获取输入词向量之后需要对矩阵乘以embedding-size的开方意义是什么"><a class="markdownIt-Anchor" href="#8为何在获取输入词向量之后需要对矩阵乘以embedding-size的开方意义是什么"></a> 8.为何在获取输入词向量之后需要对矩阵乘以embedding size的开方？意义是什么？</h3>
<p>embedding matrix的初始化方式是xavier init，这种方式的方差是1/embedding size，因此乘以embedding size的开方使得embedding matrix的方差是1，在这个scale下可能更有利于embedding matrix的收敛。</p>
<br>
<h3 id="9-简单介绍一下transformer的位置编码有什么意义和优缺点"><a class="markdownIt-Anchor" href="#9-简单介绍一下transformer的位置编码有什么意义和优缺点"></a> 9. 简单介绍一下Transformer的位置编码？有什么意义和优缺点？</h3>
<p>Transformer模型采用自注意力机制处理序列数据。与传统的循环神经网络（RNN）和长短时记忆网络（LSTM）不同，Transformer不依赖于序列的递归处理，因此无法直接捕捉到序列中的位置信息。为了解决这个问题，Transformer引入了位置编码（Positional Encoding）的概念，将位置信息添加到模型的输入中。</p>
<br>
<p>位置编码是一个与词嵌入维度相同的向量，它被加到词嵌入上，以提供关于单词在序列中位置的信息。位置编码的公式如下：</p>
<p>对于位置<code>pos</code>和维度<code>i</code>,位置编码的第<code>i</code>个元素被定义为:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">PE(pos, 2i) = \sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mop">sin</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.16289em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9471099999999999em;"><span style="top:-3.3485500000000004em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8371099999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><mi>d</mi></mfrac></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">PE(pos, 2i+1) = \cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mop">cos</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.16289em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9471099999999999em;"><span style="top:-3.3485500000000004em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8371099999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<p>其中,<code>d</code>是词嵌入的维度,<code>pos</code>是词在序列中的位置,<code>i</code>是维度的索引。</p>
<br>
<p>优点:</p>
<ul>
<li><strong>固定模式</strong>: 位置编码是根据绝对位置计算的，而且是固定的，这意味着模型在训练和测试时使用相同的位置编码，保持一致性。</li>
<li><strong>可推广性</strong>: 由于位置编码是基于三角函数计算的，它能够处理比训练时见过的序列更长的输入。</li>
<li><strong>并行计算</strong>: 与RNN和LSTM不同，Transformer模型能够利用位置编码一次性处理整个序列，这使得模型能够充分利用现代硬件的并行计算能力，显著提高训练和推断的速度。</li>
</ul>
<br>
<p>缺点:</p>
<ul>
<li><strong>固定长度</strong>: 尽管位置编码能够处理长序列，但是它们是根据固定长度计算的，这意味着如果序列太长，位置编码可能会失效。</li>
<li><strong>可能需要更多的训练数据</strong>: 由于位置信息是通过位置编码隐式提供的，模型需要从数据中学习如何最好地利用这些信息，这可能需要更多的训练数据。</li>
</ul>
<br>
<h3 id="10你还了解哪些关于位置编码的技术各自的优缺点是什么"><a class="markdownIt-Anchor" href="#10你还了解哪些关于位置编码的技术各自的优缺点是什么"></a> 10.你还了解哪些关于位置编码的技术，各自的优缺点是什么？</h3>
<table>
<thead>
<tr>
<th>位置编码技术</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>学习的位置编码</td>
<td>模型可以学习到最适合特定任务的位置编码，可能在某些任务上表现更好。</td>
<td>需要更多的参数和训练数据。<br>不能很好地泛化到训练时未见过的更长序列。</td>
</tr>
<tr>
<td>相对位置编码</td>
<td>能够更好地处理序列的局部结构，因为它关注的是元素之间的相对位置。</td>
<td>计算更复杂，可能增加训练和推理的时间。</td>
</tr>
<tr>
<td>固定但可学习的位置编码</td>
<td>能够在保持一定泛化能力的同时，适应特定任务的需求。</td>
<td>仍然需要更多的参数。</td>
</tr>
<tr>
<td>轴向位置编码</td>
<td>参数更少，更高效。</td>
<td>可能损失一些表达能力。</td>
</tr>
<tr>
<td>Transformer-XL中的位置编码</td>
<td>能够更好地处理长序列，并捕捉长范围的依赖关系。</td>
<td>结构更复杂，计算成本更高。</td>
</tr>
</tbody>
</table>
<br>
<h3 id="11简单讲一下transformer中的残差结构以及意义"><a class="markdownIt-Anchor" href="#11简单讲一下transformer中的残差结构以及意义"></a> 11.简单讲一下Transformer中的残差结构以及意义。</h3>
<p>在Transformer中的每个子层（如自注意力层和前馈神经网络层）后面，都会有一个残差连接，然后是一个层归一化（Layer Normalization）操作。具体来说，如果我们将子层的操作表示为(F(x))，那么残差连接的输出就是(x + F(x))。这里的(x)是子层的输入，(x + F(x))是残差连接的输出，也是下一层的输入。</p>
<p>残差结构的意义</p>
<ul>
<li><strong>缓解梯度消失: 残差连接允许梯度直接流过网络，这有助于缓解深层网络中常见的梯度消失问题，从而使得模型更容易训练。</strong></li>
<li>提升训练速度: 残差连接提供了一种直接的信息传播路径，可以加速训练过程。</li>
<li>增强网络能力: 通过允许信息直接传递，残差连接使网络能够学习到更复杂的表示，增强了模型的能力。</li>
<li>增加网络深度: 残差结构使得训练非常深的网络成为可能，而不用担心梯度消失或者训练难度的问题。</li>
<li>保持前向信息的完整性: 由于残差连接的加法操作，即使某个子层没有学到有用的信息（或者学到了错误的信息），输入信息x也仍然能够通过残差连接传到下一层，这有助于保持前向传播过程中信息的完整性。</li>
</ul>
<br>
<h3 id="12-为什么transformer块使用layernorm而不是batchnormlayernorm-在transformer的位置是哪里"><a class="markdownIt-Anchor" href="#12-为什么transformer块使用layernorm而不是batchnormlayernorm-在transformer的位置是哪里"></a> 12.  为什么transformer块使用LayerNorm而不是BatchNorm？LayerNorm 在Transformer的位置是哪里？</h3>
<p>这个我会单独写</p>
<br>
<h3 id="13-简单描述一下transformer中的前馈神经网络使用了什么激活函数相关优缺点"><a class="markdownIt-Anchor" href="#13-简单描述一下transformer中的前馈神经网络使用了什么激活函数相关优缺点"></a> 13.  简单描述一下Transformer中的前馈神经网络？使用了什么激活函数？相关优缺点？</h3>
<p>Transformer 中的前馈神经网络（Feed-Forward Neural Network, FFN）是模型每个注意力头后的一个重要组成部分。这个前馈神经网络对每个位置的词向量进行相同的操作，但它并不在不同位置间共享参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ReLU(x) = max(0, x)</span><br><span class="line">FFN(x) = max(0, xW_1 + b_1)W_2 + b_2</span><br></pre></td></tr></table></figure>
<p>其中，<code>W_1</code>, <code>W_2</code>, <code>b_1</code>, <code>b_2</code> 是网络参数，<code>x</code> 是输入的词向量，通常维度为 <code>d_model</code>。第一个线性层将输入从 <code>d_model</code> 维扩展到 <code>d_ff</code> 维，然后应用激活函数，再通过第二个线性层将维度从 <code>d_ff</code> 缩减回 <code>d_model</code>。</p>
<p>优点:</p>
<ul>
<li><strong>非线性</strong>：前馈神经网络引入了非线性变换，增加了模型的表达能力，使得 Transformer 能够学习到更复杂的函数映射。</li>
<li><strong>并行计算</strong>：由于前馈神经网络对每个位置的操作是独立的，所以可以高效地进行并行计算，提高训练和推理的速度。</li>
<li><strong>简单高效</strong>：前馈神经网络结构简单，计算效率高，易于优化。</li>
</ul>
<p>缺点:</p>
<ul>
<li><strong>局限性</strong>：前馈神经网络在处理序列数据时只能考虑单个位置的信息，无法捕捉序列中的上下文关系。这种局限性通过 Transformer 中的自注意力机制来解决。</li>
<li><strong>参数量大</strong>：尽管结构简单，但前馈神经网络中参数量较大，特别是当 <code>d_ff</code> 很大时，这可能导致过拟合和增加模型的计算负担。</li>
</ul>
<br>
<h3 id="14encoder端和decoder端是如何进行交互的在这里可以问一下关于seq2seq的attention知识"><a class="markdownIt-Anchor" href="#14encoder端和decoder端是如何进行交互的在这里可以问一下关于seq2seq的attention知识"></a> 14.Encoder端和Decoder端是如何进行交互的？（在这里可以问一下关于seq2seq的attention知识）</h3>
<p><img src="https://pbs.twimg.com/media/GEsRectWkAAtqpX?format=jpg&amp;name=medium" alt="" /></p>
<p>Encoder和Decoder之间的交互主要通过交叉注意力机制实现。具体来说：</p>
<p><strong>查询来自Decoder</strong>：在交叉注意力层中，查询（Query）来自于Decoder的上一层的输出。</p>
<p><strong>键和值来自Encoder</strong>：键（Key）和值（Value）来自于Encoder的输出。</p>
<p>通过计算查询与键的相似度，模型可以为每个Encoder输出分配一个权重，然后将这些权重应用于值，以产生一个加权和，该加权和将用作交叉注意力层的输出，并输入到下一层。</p>
<p>这种机制使Decoder能够关注输入序列的不同部分，特别是在生成每个新单词时。例如，在机器翻译任务中，当模型生成目标语言的一个单词时，它可以通过这种机制来聚焦于源语言句子中的相关部分。</p>
<h3 id="15decoder阶段的多头自注意力和encoder的多头自注意力有什么区别为什么需要decoder自注意力需要进行-sequence-mask"><a class="markdownIt-Anchor" href="#15decoder阶段的多头自注意力和encoder的多头自注意力有什么区别为什么需要decoder自注意力需要进行-sequence-mask"></a> 15.Decoder阶段的多头自注意力和encoder的多头自注意力有什么区别？（为什么需要decoder自注意力需要进行 sequence mask)</h3>
<p><strong>Encoder的多头自注意力</strong> :在Encoder的多头自注意力中，每个位置都可以自由地注意序列中的所有其他位置。这意味着计算注意力分数时，并没有位置上的限制。这种设置是因为在编码阶段，我们假定有完整的输入序列，并且每个词都可以依赖于上下文中的任何其他词来获得其表示。</p>
<p><strong>Decoder的多头自注意力（带掩码）</strong>:在Decoder的多头自注意力中，为了保持自回归属性（即生成当前词只依赖于前面的词），<strong>我们需要确保在计算注意力分数时，每个位置只能注意到它前面的位置</strong>。为了实现这一点，我们使用了序列掩码（sequence mask）的技术。</p>
<p>具体来说，序列掩码是在注意力分数计算之前，将当前位置之后所有位置的分数设置为一个非常大的负数（通常是负无穷）。这样，在接下来的softmax操作中，这些位置的注意力权重将变为0，确保模型不会注意到这些位置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">为什么需要Decoder自注意力进行序列掩码？</span><br><span class="line"></span><br><span class="line">在序列生成任务中，如机器翻译或文本生成，模型需要一次生成一个词，并且生成当前词时只能依赖于前面已经生成的词。</span><br><span class="line">如果我们不使用序列掩码，模型就能够“看到”后续的词，这与实际生成过程不符，并且会导致信息泄露，使模型学习到错误的依赖关系。</span><br></pre></td></tr></table></figure>
<h3 id="16transformer的并行化提现在哪个地方decoder端可以做并行化吗"><a class="markdownIt-Anchor" href="#16transformer的并行化提现在哪个地方decoder端可以做并行化吗"></a> 16.Transformer的并行化提现在哪个地方？Decoder端可以做并行化吗？</h3>
<p>Encoder侧：模块之间是串行的，一个模块计算的结果做为下一个模块的输入，互相之前有依赖关系。从每个模块的角度来说，注意力层和前馈神经层这两个子模块单独来看都是可以并行的，不同单词之间是没有依赖关系的。</p>
<p>Decode引入sequence mask就是为了并行化训练，Decoder推理过程没有并行，只能一个一个的解码，很类似于RNN，这个时刻的输入依赖于上一个时刻的输出。</p>
<h3 id="17-transformer训练的时候学习率是如何设定的dropout是如何设定的位置在哪里dropout-在测试的需要有什么需要注意的吗"><a class="markdownIt-Anchor" href="#17-transformer训练的时候学习率是如何设定的dropout是如何设定的位置在哪里dropout-在测试的需要有什么需要注意的吗"></a> 17.  Transformer训练的时候学习率是如何设定的？Dropout是如何设定的，位置在哪里？Dropout 在测试的需要有什么需要注意的吗？</h3>
<p>Transformer模型通常使用一种特殊的学习率调度策略,称为“Noam”学习率预热策略。具体来说,学习率随着训练的进行先增大后减小,计算公式为:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>l</mi><mi>r</mi><mo>=</mo><msubsup><mi>d</mi><mtext>model</mtext><mrow><mo>−</mo><mn>0.5</mn></mrow></msubsup><mo>⋅</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mtext>step_num</mtext><mrow><mo>−</mo><mn>0.5</mn></mrow></msup><mo separator="true">,</mo><mtext>step_num</mtext><mo>⋅</mo><msup><mtext>warmup_steps</mtext><mrow><mo>−</mo><mn>1.5</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">lr = d_{\text{model}}^{-0.5} \cdot \min(\text{step\_num}^{-0.5}, \text{step\_num} \cdot \text{warmup\_steps}^{-1.5})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1555469999999999em;vertical-align:-0.2914389999999999em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-2.408561em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2914389999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.174108em;vertical-align:-0.31em;"></span><span class="mop">min</span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord">step_num</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord">step_num</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.174108em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord text"><span class="mord">warmup_steps</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span><span class="mord mtight">.</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其中,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mtext>model</mtext></msub></mrow><annotation encoding="application/x-tex">d_{\text{model}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是模型的隐藏层大小, step_num是当前的训练步数,warmup_steps是预热的步数。这种学习率调度策略有助于模型在训练初期快速收敛,同时在训练后期通过减小学习率来稳定训练。</p>
<br>
<p>Dropout是一种正则化技术,用于防止神经网络过拟合。在Transformer模型中,Dropout被应用在以下几个地方:</p>
<ol>
<li>
<p>在注意力权重计算后,用于随机“丢弃”一些权重,以防止模型过分依赖某些特定的输入。</p>
</li>
<li>
<p>在每个子层(自注意力层,前馈神经网络层等)的输出后,用于防止过拟合。</p>
</li>
<li>
<p>在词嵌入层和位置编码的加和后。</p>
</li>
</ol>
<p>Dropout率(即随机丢弃的神经元比例)是一个超参数,需要根据具体任务进行调整。常见的取值范围在0.1到0.3之间。</p>
<p>在测试(或推理)阶段,通常会禁用Dropout,确保所有的神经元都参与到计算中,以获得最稳定的模型输出。这是因为Dropout在训练时引入了随机性,而在测试时我们希望模型的表现是确定的。在许多深度学习框架中,可以通过设置模型为评估模式来自动禁用Dropout。</p>
<br>
<h3 id="18-一个关于bert问题bert的mask为何不学习transformer在attention处进行屏蔽score的技巧"><a class="markdownIt-Anchor" href="#18-一个关于bert问题bert的mask为何不学习transformer在attention处进行屏蔽score的技巧"></a> 18.  一个关于bert问题，bert的mask为何不学习transformer在attention处进行屏蔽score的技巧？</h3>
<p>BERT和transformer的目标不一致，bert是语言的预训练模型，需要充分考虑上下文的关系，而transformer主要考虑句子中第i个元素与前i-1个元素的关系</p>
]]></content>
      <categories>
        <category>internship</category>
      </categories>
      <tags>
        <tag>transformer</tag>
        <tag>internship</tag>
      </tags>
  </entry>
  <entry>
    <title>paper:ResNet</title>
    <url>/2024/01/25/paper-ResNet/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
<li><a href="https://www.bilibili.com/video/BV1P3411y7nn/?share_source=copy_web&amp;vd_source=d8d8cd49f932177e1995e230d7816d44">ResNet论文逐段精读【论文精读】</a></li>
</ul>
<br>
<h2 id="1abstract"><a class="markdownIt-Anchor" href="#1abstract"></a> 1.abstract</h2>
<p>1.0 摘要，论文导读<br />
摘要主要内容：<br />
  <strong>深度神经网络很难训练，我们使用residual（残差结构）使得网络训练比之前容易很多</strong>在ImageNet上使用了152层的ResNet，比VGG多8倍，但是计算复杂度更低，最终赢下了ImageNet2015的分类任务第一名，并演示了如何在cifar-10上训练100-1000层的网络。（通常赢下ImageNet比赛且提出很不一样网络架构、方法的文章会被追捧。）<br />
  对很多任务来说，深度是非常重要的。我们仅仅是把之前的网络换成残差网络，在coco数据集上就得到了28%的改进。同样也赢下了ImageNet目标检测、coco目标检测和coco segmentation的第一名。</p>
<p><img src="https://pbs.twimg.com/media/GEn4BBUagAA0QL9?format=png&amp;name=small" alt="" /></p>
<p>上面这张图是没有使用残差结构的网络，更深的层训练误差比浅层更高，即深层网络其实是训练不动的。下面这张图，是是否使用resnet结构的网络效果对比图。可以看到右侧使用残差结构后，34层的网络训练和测试的误差都更低。</p>
<table>
<thead>
<tr>
<th>Layers\Model</th>
<th>Plain</th>
<th>ResNet</th>
</tr>
</thead>
<tbody>
<tr>
<td>18 layers</td>
<td>27.94</td>
<td>27.88</td>
</tr>
<tr>
<td>34 layers</td>
<td>28.54</td>
<td>25.03</td>
</tr>
</tbody>
</table>
<br>
<p><img src="https://pbs.twimg.com/media/GEn4Uxda4AM-QTF?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="2导论"><a class="markdownIt-Anchor" href="#2导论"></a> 2.导论</h2>
<h2 id="21-为什么提出残差结构"><a class="markdownIt-Anchor" href="#21-为什么提出残差结构"></a> 2.1 为什么提出残差结构</h2>
<p>深度卷积神经网络是非常有效的，因为可以堆叠很多层，不同层可以表示不同level的特征。但是学一个好的网络，就是简简单单的把所有网络堆在一起就行了吗？如果这样，网络做深就行了。</p>
<p>我们知道，网络很深的时候，<strong>容易出现梯度消失或者梯度爆炸</strong>，解决办法之一是一个好的<strong>网络权重初始化</strong>，使权重不能太大也不能太小；二是加入一些<strong>normalization</strong>，比如BN。这样可以校验每个词之间的输出，以及梯度的均值和方差，这样比较深的网络是可以训练的（可以收敛）。但同时有一个问题是，深层网络性能会变差，也就是精度会变差。</p>
<p>深层网络性能变差，不是因为网络层数多、模型变复杂而过拟合，因为训练误差也变高了。那为什么会这样呢？从理论上来说，往一个浅层网络中加入一些层，得到一个深一些的网络，后者的精度至少不应该变差。因为后者至少可以学成新加的层是identity mapping，而其它层直接从前者复制过来。但是实际上做不到，SGD优化器无法找到这个比较优的解。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">identity mapping可以理解成恒等映射吧，也就是网络输入x，输出也是x。网络权重简单学成输入特征的1/n。</span><br></pre></td></tr></table></figure>
<p>所以作者提出，显式地构造一个<code>identity mapping</code>，使得深层模型的精度至少不会变得更差。作者将其称为<code>deep residual learning framework</code>。</p>
<p>假设我们要学的是 <code>H(x)</code>，在原有层上添加一些新的层时，新的层不是直接学 <code>H(x)</code>，而是学习 <code>H(x) - x</code>，这部分用 <code>F(x)</code> 表示。（其中，<code>x</code> 是原有层的输出。）即，新加入的层不用全部重新学习，而是学习原来已经学习到的 <code>x</code> 和真实的 <code>H(x)</code> 之间的残差就行。最后模型的输出是 <code>F(x) + x</code>。这种新加入的层就是residual，结构如下图所示：</p>
<p><img src="https://pbs.twimg.com/media/GEq7GmpacAA88tw?format=jpg&amp;name=medium" alt="" /></p>
<p><code>F(x) + x</code> 在数学上就是直接相加，在神经网络中是通过<code>shortcut connections</code>实现（shortcut就是跳过一个或多个层，将输入直接加到这些跳过的层的输出上）。shortcut其实做的是一个identity mapping（恒等映射），而且这个操作不需要学习任何参数，不增加模型的复杂度。就多了一个加法，也不增加计算量，网络结构基本不变，可以正常训练。</p>
<br>
<h2 id="22-实验验证"><a class="markdownIt-Anchor" href="#22-实验验证"></a> 2.2 实验验证</h2>
<p>接下来作者在imagenet上做了一系列实验进行验证。结果表明，加了残差的网络容易优化，而且网络堆的更深之后，精度也会提高，所以赢下了比赛。在cifar-10上，作者尝试了训练超过1000层的网络。至此，论文的核心就讲完了，下面就是ResNet网络的设计。</p>
<br>
<h2 id="3相关工作"><a class="markdownIt-Anchor" href="#3相关工作"></a> 3.相关工作</h2>
<p><strong>ResNet并不是第一个提出residual的概念</strong>。 最早的线性模型的解法就是通过不断迭代residual来求解的。在机器学习中，GBDT通过残差residual不断学习，把弱分类器叠加起来，形成强分类器。不同之处在于，GBDT是在label上做残差，而ResNet是在特征上做残差。</p>
<p><strong>ResNet也不是第一个提出shortcut的</strong>。 比如在highway networks中就已经使用了shortcut，但其实现方式更为复杂，不仅仅是简单的加法。</p>
<p>一篇文章之所以成为经典，并不一定是因为它原创性地提出了许多新概念。有时，它的经典之处在于将多个已有概念巧妙地结合在一起，从而有效解决问题。甚至有时大家都可能忘记了之前有谁做过类似的工作。许多想法可能早已被前人提出并发表，但重要的是，这些想法可以被用来解决新的问题，使得旧技术在新的应用中展现出新的意义。</p>
<p>ResNet34比起VGG19，计算复杂度更低，只有前者的18%。其它是一些训练的细节，学习率优化器等等之类，就不细讲了。</p>
<Br>
<h2 id="4实验部分"><a class="markdownIt-Anchor" href="#4实验部分"></a> 4.实验部分</h2>
<h2 id="41-不同配置的resnet结构"><a class="markdownIt-Anchor" href="#41-不同配置的resnet结构"></a> 4.1 不同配置的ResNet结构</h2>
<p><img src="https://pbs.twimg.com/media/GEq8uMFagAEHSPW?format=png&amp;name=medium" alt="" /></p>
<ul>
<li>
<p>网络输入是ImageNet图像，短边在[256,480]中随机选取，然后resize到224×224尺寸，输入网络。</p>
</li>
<li>
<p>conv2_x：表示第二个卷积模块，x表示模块里有很多层。</p>
</li>
<li>
<p><code>[3 × 3, 64]</code><br />
<code>[3 × 3, 64]</code> × 3: []内的是一个残差块，其卷积核大小为3*3，channel=64。×3表示有两个这样的残差层。</p>
</li>
</ul>
<p>ResNet34结构图：（3+4+6+3）=16个残差模块，每个模块两层卷积层。再加上第一个7×7卷积层和最后一个全连接层，一共是34层。</p>
<br>
<h2 id="42-残差结构效果对比"><a class="markdownIt-Anchor" href="#42-残差结构效果对比"></a> 4.2 残差结构效果对比</h2>
<p>从下图可以看到有残差模块，网络收敛会更快，而且精度会更好:<br />
<img src="https://pbs.twimg.com/media/GEn4Uxda4AM-QTF?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="43-残差结构中输入输出维度不一致如何处理"><a class="markdownIt-Anchor" href="#43-残差结构中输入输出维度不一致如何处理"></a> 4.3 残差结构中，输入输出维度不一致如何处理</h2>
<ul>
<li>A. pad补0，使维度一致；</li>
<li>B. 维度不一致的时候，使其映射到统一维度，比如使用全连接或者是CNN中的1×1卷积（输出通道是输入的两倍）。</li>
<li>C. 不管输入输出维度是否一致，都进行投影映射。下面作者对这三种操作进行效果验证。从下面结果可以看到，B和C效果差不多，都比A好。但是做映射会增加很多复杂度，考虑到ResNet中大部分情况输入输出维度是一样的（也就是4个模块衔接时通道数会变），<strong>作者最后采用了方案B</strong>。</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GEq-MWgbwAAjJqY?format=png&amp;name=small" alt="" /></p>
<br>
<h2 id="44-深层resnet引入瓶颈结构bottleneck"><a class="markdownIt-Anchor" href="#44-深层resnet引入瓶颈结构bottleneck"></a> 4.4 深层ResNet引入瓶颈结构Bottleneck</h2>
<p><img src="https://pbs.twimg.com/media/GEq_BgdbwAAMsTe?format=jpg&amp;name=medium" alt="" /></p>
<p>在ResNet-50及以上的结构中，模型更深了，可以学习更多的参数，所以通道数也要变大。比如前面模型配置表中，ResNet-50/101/152的第一个残差模块输出都是256维，增加了4倍。</p>
<p>如果残差结构还是和之前一样，计算量就增加的太多了（增加16倍），划不来。所以重新设计了Bottleneck结构，将输入从256维降为64维，然后经过一个3×3卷积，再升维回256维。这样操作之后，复杂度和左侧图是差不多的。这也是为啥ResNet-50对比ResNet-34理论计算量变化不大的原因。（实际上1×1卷积计算效率不高，所以ResNet-50计算还是要贵一些）</p>
<p><img src="https://pbs.twimg.com/media/GEq_S0BaMAARJdJ?format=png&amp;name=small" alt="" /></p>
<br>
<h2 id="5代码实现"><a class="markdownIt-Anchor" href="#5代码实现"></a> 5.代码实现</h2>
<p>resnet中残差块有两种：（use_1x1conv=True/False）：</p>
<ul>
<li>步幅为2 ，高宽减半，通道数增加。所以shortcut连接部分会加一个1×1卷积层改变通道数</li>
<li>步幅为1，高宽不变</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GErAKOUboAAFcJ7?format=jpg&amp;name=medium" alt="" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):  <span class="comment">#@save</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, num_channels,</span></span><br><span class="line"><span class="params">                 use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides)</span><br><span class="line">        self.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_channels)<span class="comment">#每个bn都有自己的参数要学习，所以需要定义两个</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        Y = F.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        Y += X</span><br><span class="line">        <span class="keyword">return</span> F.relu(Y)</span><br></pre></td></tr></table></figure>
<Br>
<h2 id="6结论"><a class="markdownIt-Anchor" href="#6结论"></a> 6.结论</h2>
<p>ResNet就是在CNN主干上加了残差连接，这样如果新加的层训练效果不好的话，至少可以fallback变回简单模型，所以精度不会变差。<br />
  <br />
在现在来看，ResNet训练的比较快，是因为梯度保持的比较好。因为新加的层容易导致梯度消失（或者梯度爆炸），但是加了残差连接，梯度多了一部分，包含了之前层的梯度，这样不管加了多深，梯度会保持的比较大（主要是不会梯度消失，学不动），不会太快收敛，SGD跑得多就训练的比较好。（SGD的精髓就是，只要梯度比较大，就可以一直训练。反正有噪音，慢慢的总是会收敛，最后效果就会比较好）</p>
<p>为什么在cifar-10这样一个小的数据集上（32*32图片5w张）训练1202层的网络，过拟合也不是很厉害。为何transformer那些模型几千亿的参数不会过拟合，李沐认为是加了残差连接之后，模型内在复杂度大大降低了。（理论上模型加一些层，模型也至少可以将后面的层学成恒等映射，使精度不会变差。但实际上没有引导做不到这一点。所以本文才会显示的把残差结构加进去，使模型能够更容易的训练出来。比如后面层都是0，前面一些层才学到东西，也就是更容易训练出一个简单模型来拟合数据，所以加入残差连接等于是模型复杂度降低了）</p>
<h2 id="残差网络resnet"><a class="markdownIt-Anchor" href="#残差网络resnet"></a> 残差网络ResNet</h2>
<p>残差网络在设计之初，主要是服务于卷积神经网络(CNN)，在计算机视觉领域应用较多，但是随着CNN结构的发展，在很多文本处理，文本分类里面(n-gram)，也同样展现出来很好的效果。</p>
<h2 id="1网络深度为什么重要"><a class="markdownIt-Anchor" href="#1网络深度为什么重要"></a> 1.网络深度为什么重要？</h2>
<p>我们知道，在CNN网络中，我们输入的是图片的矩阵，也是最基本的特征，整个CNN网络就是一个信息提取的过程，从底层的特征逐渐抽取到高度抽象的特征，网络的层数越多也就意味这能够提取到的不同级别的抽象特征更加丰富，并且越深的网络提取的特征越抽象，就越具有语义信息。</p>
<br>
<h2 id="2为什么不能简单的增加网络层数"><a class="markdownIt-Anchor" href="#2为什么不能简单的增加网络层数"></a> 2.为什么不能简单的增加网络层数？</h2>
<p>对于传统的CNN网络，简单的增加网络的深度，容易导致<strong>梯度消失和爆炸</strong>。针对梯度消失和爆炸的解决方法一般是<strong>正则初始化(normalized initialization)和中间的正则化层(intermediate normalization layers)</strong>，但是这会导致另一个问题，<strong>退化问题</strong>，随着网络层数的增加，在训练集上的准确率却饱和甚至下降了。这个和过拟合不一样，因为过拟合在训练集上的表现会更加出色。</p>
<br>
<h2 id="3梯度消失和梯度下降"><a class="markdownIt-Anchor" href="#3梯度消失和梯度下降"></a> 3.梯度消失和梯度下降</h2>
<p>梯度爆炸和梯度消失问题都是因为网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。</p>
<p>梯度爆炸：很多大数相乘 梯度消失：很多小于1的数字相乘</p>
<br>
<h2 id="4正则化"><a class="markdownIt-Anchor" href="#4正则化"></a> 4.正则化</h2>
<p>在机器学习中，正则化是正则化系数的过程，即对系数进行惩罚，通过向模型添加额外参数来防止模型过度拟合，这有助于提高模型的可靠性、速度和准确性。可以这么说，正则化本质上是为了防止因网络参数过大导致模型过拟合的泛化技术</p>
<p><strong>正则化的作用和意义</strong>: 在于防止过度拟合。当发生过拟合时，模型几乎失去了泛化能力。这意味着该模型仅适用于训练它的数据集，而不能被用于其他数据集。</p>
<p><strong>正则化的原理</strong>：正则化通过向复杂模型添加带有残差平方和(RSS)的惩罚项来发挥作用</p>
<p><strong>正则化的类型</strong>：</p>
<ul>
<li><strong>dropout</strong>：在dropout中，激活的随机数会更有效地训练网络。激活是将输入乘以权重时得到的输出。如果在每一层都删除了激活的特定部分，则没有特定的激活会学习输入模型。这意味着输入模型不会出现任何过度拟合。</li>
<li><strong>批量归一化</strong>： 批量归一化通过减去批量均值并除以批量标准差来设法归一化前一个激活层的输出。它向每一层引入两个可训练参数，以便标准化输出乘以gamma和beta。gamma和beta的值将通过神经网络找到。通过弱化初始层参数和后面层参数之间的耦合来提高学习率，提高精度，解决协方差漂移问题。</li>
<li><strong>数据扩充</strong>：数据扩充涉及使用现有数据创建合成数据，从而增加可用数据的实际数量。通过生成模型在现实世界中可能遇到的数据变化，帮助深度学习模型变得更加精确。</li>
<li><strong>提前停止</strong>：使用训练集的一部分作为验证集，并根据该验证集衡量模型的性能。如果此验证集的性能变差，则立即停止对模型的训练。</li>
<li><strong>L1正则化</strong>：使用L1正则化技术的回归模型称为套索回归。Lasso回归模型即Least Absolute Shrinkage and Selection Operator，将系数的“绝对值”作为惩罚项添加到损失函数中。</li>
<li><strong>L2正则化</strong>：使用L2正则化的回归模型称为岭回归。岭回归模型即Ridge回归，在Ridge回归中系数的平方幅度作为惩罚项添加到损失函数中。</li>
</ul>
<br>
<h2 id="5退化问题"><a class="markdownIt-Anchor" href="#5退化问题"></a> 5.退化问题</h2>
<p>按照常理更深层的网络结构的解空间是包括浅层的网络结构的解空间的，也就是说深层的网络结构能够得到更优的解，性能会比浅层网络更佳。但是实际上并非如此，深层网络无论从训练误差或是测试误差来看，都有可能比浅层误差更差，这也证明了并非是由于过拟合的原因。<strong>导致这个原因可能是因为随机梯度下降的策略，往往解到的并不是全局最优解，而是局部最优解，由于深层网络的结构更加复杂，所以梯度下降算法得到局部最优解的可能性就会更大。</strong></p>
<br>
<h2 id="6如何解决退化问题"><a class="markdownIt-Anchor" href="#6如何解决退化问题"></a> 6.如何解决退化问题</h2>
<p>深度网络的退化问题至少说明深度网络不容易训练。但是我们考虑这样一个事实：现在你有一个浅层网络，你想通过向上堆积新层来建立深层网络，一个极端情况是这些增加的层什么也不学习，仅仅复制浅层网络的特征，即这样新层是<strong>恒等映射（Identity mapping</strong>）。在这种情况下，深层网络应该至少和浅层网络性能一样，也不应该出现退化现象。好吧，你不得不承认肯定是目前的训练方法有问题，才使得深层网络很难去找到一个好的参数。</p>
<p>对于一个堆积层结构（几层堆积而成）当输入为x时其学习特征标记为H(x),现在我们希望其可以学习到残差F(x)=H(x)-x,这样其实原始的学习特征是F(x)+x。<strong>之所以这样是因为残差学习相比原始特征直接学习更容易</strong>。当残差为0时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。</p>
<p><img src="https://pic1.zhimg.com/80/v2-2180e48afdee79382519d1f8a2a7dce8_1440w.webp" alt="" /></p>
<br>
<p>为什么残差学习相对更容易，从直观上看残差学习需要学习的内容少，因为残差一般会比较小，学习难度小点。不过我们可以从数学的角度来分析这个问题，首先<strong>残差单元</strong>可以表示为:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mi>h</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi>F</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y_1=h(x_1) + F(x_1,W_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_{l+1}=f(y_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>l</mi></msub><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_l,x_{l+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>: 第l个残差单元的输入和输出,每个残差单元包含多层结构</li>
<li>F: 残差函数，表示学习到的残差</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h(x_1)=x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>: 表示恒等映射</li>
<li>f: RELU激活函数</li>
</ul>
<br>
<p>根据上述，可以得到<strong>浅层l到深层L的学习特征</strong>为：<br />
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>L</mi></msub><mo>=</mo><msub><mi>x</mi><mi>l</mi></msub><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>l</mi></mrow><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mi>F</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x_L=x_l + \sum_{i=l}^{L-1}F(x_i,W_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<br>
<p>根据链式规则，可以求得<strong>反向过程梯度</strong>：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>l</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>L</mi></msub></mrow></mfrac><mo separator="true">⋅</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>L</mi></msub></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>l</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>L</mi></msub></mrow></mfrac><mo separator="true">⋅</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mi>l</mi></mrow><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mi>F</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mi>l</mi></msub></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial loss}{\partial x_l}=\frac{\partial loss}{\partial x_L}·\frac{\partial x_L}{\partial x_l}=\frac{\partial loss}{\partial x_L}·(1+\frac{\partial \sum_{i=l}^{L-1}F(x_i,W_i)}{\partial x_l})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.330968em;vertical-align:-0.4508599999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4508599999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.347273em;vertical-align:-0.4508599999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44530499999999995em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8964129999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.410305em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4508599999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.3254129999999997em;vertical-align:-0.44530499999999995em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.14329285714285717em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44530499999999995em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.629232em;vertical-align:-0.4508599999999999em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.178372em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5350070000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9190928571428572em;"><span style="top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.32143857142857146em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4508599999999999em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></p>
<br>
<h2 id="7resnet的tensorflow实现"><a class="markdownIt-Anchor" href="#7resnet的tensorflow实现"></a> 7.ResNet的tensorflow实现</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet50</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inputs, num_classes=<span class="number">1000</span>, is_training=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 scope=<span class="string">&quot;resnet50&quot;</span></span>):</span><br><span class="line">        self.inputs =inputs</span><br><span class="line">        self.is_training = is_training</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">            <span class="comment"># construct the model</span></span><br><span class="line">            net = conv2d(inputs, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>, scope=<span class="string">&quot;conv1&quot;</span>) <span class="comment"># -&gt; [batch, 112, 112, 64]</span></span><br><span class="line">            net = tf.nn.relu(batch_norm(net, is_training=self.is_training, scope=<span class="string">&quot;bn1&quot;</span>))</span><br><span class="line">            net = max_pool(net, <span class="number">3</span>, <span class="number">2</span>, scope=<span class="string">&quot;maxpool1&quot;</span>)  <span class="comment"># -&gt; [batch, 56, 56, 64]</span></span><br><span class="line">            net = self._block(net, <span class="number">256</span>, <span class="number">3</span>, init_stride=<span class="number">1</span>, is_training=self.is_training,</span><br><span class="line">                              scope=<span class="string">&quot;block2&quot;</span>)           <span class="comment"># -&gt; [batch, 56, 56, 256]</span></span><br><span class="line">            net = self._block(net, <span class="number">512</span>, <span class="number">4</span>, is_training=self.is_training, scope=<span class="string">&quot;block3&quot;</span>)</span><br><span class="line">                                                        <span class="comment"># -&gt; [batch, 28, 28, 512]</span></span><br><span class="line">            net = self._block(net, <span class="number">1024</span>, <span class="number">6</span>, is_training=self.is_training, scope=<span class="string">&quot;block4&quot;</span>)</span><br><span class="line">                                                        <span class="comment"># -&gt; [batch, 14, 14, 1024]</span></span><br><span class="line">            net = self._block(net, <span class="number">2048</span>, <span class="number">3</span>, is_training=self.is_training, scope=<span class="string">&quot;block5&quot;</span>)</span><br><span class="line">                                                        <span class="comment"># -&gt; [batch, 7, 7, 2048]</span></span><br><span class="line">            net = avg_pool(net, <span class="number">7</span>, scope=<span class="string">&quot;avgpool5&quot;</span>)    <span class="comment"># -&gt; [batch, 1, 1, 2048]</span></span><br><span class="line">            net = tf.squeeze(net, [<span class="number">1</span>, <span class="number">2</span>], name=<span class="string">&quot;SpatialSqueeze&quot;</span>) <span class="comment"># -&gt; [batch, 2048]</span></span><br><span class="line">            self.logits = fc(net, self.num_classes, <span class="string">&quot;fc6&quot;</span>)       <span class="comment"># -&gt; [batch, num_classes]</span></span><br><span class="line">            self.predictions = tf.nn.softmax(self.logits)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_block</span>(<span class="params">self, x, n_out, n, init_stride=<span class="number">2</span>, is_training=<span class="literal">True</span>, scope=<span class="string">&quot;block&quot;</span></span>):</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">            h_out = n_out // <span class="number">4</span></span><br><span class="line">            out = self._bottleneck(x, h_out, n_out, stride=init_stride,</span><br><span class="line">                                   is_training=is_training, scope=<span class="string">&quot;bottlencek1&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                out = self._bottleneck(out, h_out, n_out, is_training=is_training,</span><br><span class="line">                                       scope=(<span class="string">&quot;bottlencek%s&quot;</span> % (i + <span class="number">1</span>)))</span><br><span class="line">            <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_bottleneck</span>(<span class="params">self, x, h_out, n_out, stride=<span class="literal">None</span>, is_training=<span class="literal">True</span>, scope=<span class="string">&quot;bottleneck&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; A residual bottleneck unit&quot;&quot;&quot;</span></span><br><span class="line">        n_in = x.get_shape()[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> stride <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            stride = <span class="number">1</span> <span class="keyword">if</span> n_in == n_out <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(scope):</span><br><span class="line">            h = conv2d(x, h_out, <span class="number">1</span>, stride=stride, scope=<span class="string">&quot;conv_1&quot;</span>)</span><br><span class="line">            h = batch_norm(h, is_training=is_training, scope=<span class="string">&quot;bn_1&quot;</span>)</span><br><span class="line">            h = tf.nn.relu(h)</span><br><span class="line">            h = conv2d(h, h_out, <span class="number">3</span>, stride=<span class="number">1</span>, scope=<span class="string">&quot;conv_2&quot;</span>)</span><br><span class="line">            h = batch_norm(h, is_training=is_training, scope=<span class="string">&quot;bn_2&quot;</span>)</span><br><span class="line">            h = tf.nn.relu(h)</span><br><span class="line">            h = conv2d(h, n_out, <span class="number">1</span>, stride=<span class="number">1</span>, scope=<span class="string">&quot;conv_3&quot;</span>)</span><br><span class="line">            h = batch_norm(h, is_training=is_training, scope=<span class="string">&quot;bn_3&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> n_in != n_out:</span><br><span class="line">                shortcut = conv2d(x, n_out, <span class="number">1</span>, stride=stride, scope=<span class="string">&quot;conv_4&quot;</span>)</span><br><span class="line">                shortcut = batch_norm(shortcut, is_training=is_training, scope=<span class="string">&quot;bn_4&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                shortcut = x</span><br><span class="line">            <span class="keyword">return</span> tf.nn.relu(shortcut + h)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>ResNet</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]人生该何去何从</title>
    <url>/2024/06/16/%E4%BA%BA%E7%94%9F%E8%AF%A5%E4%BD%95%E5%8E%BB%E4%BD%95%E4%BB%8E/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="背景部分"><a class="markdownIt-Anchor" href="#背景部分"></a> 背景部分</h2>
<h3 id="第一部分楼主的性格与决定"><a class="markdownIt-Anchor" href="#第一部分楼主的性格与决定"></a> 第一部分：楼主的性格与决定</h3>
<p>楼主想清楚了，楼主的性格是那种偏向岁月静好，亲朋好友在身旁，性格懒散，靠责任心驱动的人，不想内卷的佛系性格，喜欢山山水水。</p>
<p>楼主决定推掉互联网面试，专心看看老家国企、浙江国企，进国企之后，如果有必要再考老家公务员（因为这边有关系）。楼主前两年工作攒了些钱，如果去省会国企，再工作一段时间，自己买房买车不是问题。</p>
<p>楼主还是希望过平凡的幸福人生，不是那种拼搏人，体力精力也跟不上。认清自己很重要，调整好自己的心态，不硬逼自己去做自己不喜欢的事情了。</p>
<p>这个帖子会保留，希望一样迷茫的同学能找到自己内心的答案。祝大家都无悔自己的选择，过上幸福人生。</p>
<h3 id="第二部分楼主的背景与职业经历"><a class="markdownIt-Anchor" href="#第二部分楼主的背景与职业经历"></a> 第二部分：楼主的背景与职业经历</h3>
<p>楼主北邮本硕，21届女生，目前26，马上快27了，都是计算机专业，感觉不是很喜欢写代码，上大学之后就挺迷茫的，就是按部就班学习然后莫名其妙地拿到了保研资格，当时没想好要干嘛就读研了，想着有个研究生学历以后选择多一些。但是硕士期间太emo了，导致一门必修课挂科，所以秋招没敢投国企，怕要成绩单。方向是前端开发，研究生暑期实习运气好进了阿里实习（真的是靠运气，部门新成立，hc超多），顺利转正了，也争取了个小sp。</p>
<p>入职之后发现都不太会，基础不好（因为是暑期实习前几个月才决定找前端工作，所以速成学习了两三个月，加上实验室做了前端项目，当时是直接就很容易上手了，边做不会的去查的，没有系统学过，因为不想oncall太累所以没找服务端），也没有mentor带，很痛苦挣扎。写代码上手很快，就模仿理解别人写，但是基本上也是不喜欢深入思考，就是那种干完了事的感觉，感觉那种写一写页面的、自己独立负责一个模块的就很适合我，不太喜欢被打乱计划天天被各种bug丢过来做琐碎的活。</p>
<p>因为实习期间自己负责独立的一块底层项目，表现的也不错，但是期间做不出来的时候内心也非常焦虑内耗，中途一度找老板崩溃地说不想做这块了，但是最后结果还是弄出来了，内心的煎熬自己才知道，但是出成果的那一刻还是开心的，简而言之就是适合自己做自己的事情。下班也根本不想学习，学习起来很痛苦，可能是前二十几年都是以找个好工作为目标，找到了就松懈了，就想玩，对技术不感兴趣（这点也存疑，其实做东西出来的成就感我也挺喜欢的，所以选的前端方向）。</p>
<p>性格内向、佛系，但表现出来挺外向的，至少同事没看出我内向，还有点幽默，不喜欢高竞争的环境，入职2年看同事各种技术分享表演，而我只想做好自己的事情，根本不想卷，当然也没有出彩的活，以及看出来不能晋升，所以积极性不高。理所当然的绩效就是普普通通，更加不能晋升。由于本人对自己要求还很高，看到周围同学或者比自己大一届的同事都顺利跳槽晋升，很痛苦。但是自己的技术水平感觉真的有限，也不爱学习。述职的时候被老板说自己就是懒，没有内驱力，希望我找到自己真正热爱的事情。自己开发的时候debug不出来也很难受，但是后面技术提升之后好了很多，但是代码调试不出来就很痛苦。本人又是要强的性格，不想轻易求助别人，主要是组里也都是男同事，频繁求助的话人家也忙，也怕被说女生技术差什么的，上学的时候也都是自己搞定的项目。</p>
<p>因为待着太内耗了，也有之前研究生就有的emo，去年体检查出来多了一个甲状腺结节，几个乳腺结节，可能因为心情持续低落导致免疫力下降，天天戴口罩的我还是二阳了。组里氛围比较差，我入职之后带我的师兄离职了，然后我的小组陆续走了快10个人，项目要处于维护阶段了，没人带，天天做些边角料活。每天因为内耗，有一段时间上班如上坟，坐在工位上都能哭出来，二阳之后体检去医院查出来有轻度抑郁和焦虑。怕再待下去影响身体，就裸辞了，因为其实很早就想着要跳槽的事情了，期间也经历了换老板的事情，可能被当作了前老板的嫡系以及做了一些得罪现在的老板的事情，所以就很内耗。在入职半年的时候就想走，入职一年的时候离职的心情达到了巅峰。但是那会儿又提不起劲复习，可能是抑郁情绪导致的，中间经历了异地分手、亲人去世，想着待满2年可能更好一些。但是结果就是第一年的时候还没有甲状腺结节，第二年体检多了甲状腺结节。</p>
<h3 id="第三部分裸辞后的生活与思考"><a class="markdownIt-Anchor" href="#第三部分裸辞后的生活与思考"></a> 第三部分：裸辞后的生活与思考</h3>
<p>裸辞之后躺平到现在9个月了，前半年偶尔想到之前工作上的事情还是会哭，但是基本上还是松弛的。本来是打算金三银四找工作，但是高估了自己的自律，过年之后房子到期搬回老家，但是回老家之后，爸妈不理解为什么我要辞掉那么好的工作，家里气氛不太好，爸妈很忧愁，我又内耗了2个月。之后被爸妈催着开始找工作，直到上个月中才开始刷leetcode，这个月开始看八股，但是真的很痛苦，感觉看不进去。一想到之后还要继续到那样高竞争的环境，可能还要遭受pua，就很害怕，可能是上份工作带给我的阴影。但是其实上份工作里老板有提到过我其实干的挺好的。</p>
<p>本人性格是敏感，对自己的技术不自信，表达能力包装能力也不好，还不会和老板拉关系舔老板（尤其男老板）。这期间复习的时候疯狂看出路，比如run、外企、国企、事业单位、人才引进、公务员，离职的时候前高p同事，问我考不考虑自己开公司、做独立开发者，也有同事说考不考虑数字游民，这些我都有考虑过，前几天还查了数字游民的招聘，我个人觉得我也更适合居家办公，会更专注。爸妈现在也随便我干嘛了，自己想好就行。本人家庭条件普通，父母不能提供什么帮助。但是自己之前在大厂工作两年，有一笔存款。之前没毕业楼主心比天高，想着要靠自己买房。现在好像看开了，自己的积蓄足够在十八线老家买套三室，但是买完应该也不剩多少钱了，想躺平的话又看到网上说年轻人该多挣钱，老了花钱的地方多。不过我是非独生子女，养老压力应该没那么大。裸辞之前也有看过论坛里各种裸辞的帖子，都说不建议裸辞，但是实在是太难受了。就算是天天下班回出租屋，也提不起劲复习，应该是emo导致的。自己一个人在杭州没朋友，也没对象，周末都是宅在家。现在倒是知道了社交的重要性。</p>
<h3 id="第四部分家庭与内心的挣扎"><a class="markdownIt-Anchor" href="#第四部分家庭与内心的挣扎"></a> 第四部分：家庭与内心的挣扎</h3>
<p>因为本人学历在老家亲戚算是独一份，以及毕业就进入大厂工作，所以亲戚们都觉得很厉害，会对我们家高看一眼。只有我自己知道自从上大学之后自己过得并不开心，其实本人可能更适合从事艺术类文学类的工作，天生感性，语言天赋音乐天赋很厉害，奈何高中分到了理科重点班，成绩也不错，想着理科更好找工作，就读了理科。报志愿的时候阴差阳错来了北邮，学了自己可能最不想学的计算机。（当时打字都不会，除了小时候上机课没接触过电脑）来北邮之后，学校气氛和我想的完全不同，我可能更喜欢那种人文气氛浓厚的。其实高中的时候有想过当英语老师，因为擅长，但是万万没想到学了最不喜欢的计算机，所以心里一直很虚很不自信。现在失业之后，也不敢告诉亲戚，害怕亲戚的闲言碎语，比如这么好的背景怎么最后这样，感觉自己起点太高被架上去了。过年的时候有和亲戚说过之后想去公务员躺平，亲戚说公务员工资低，国企会高一些。</p>
<p>自己的抗压能力比较差，还有点玻璃心，很容易因为一些事情哭出来。可能老板也看出来了。这段时间也想到了实习快结束的时候老板问我想不想转正，说国企其实也不错，以及p9说过女生去外企好一些。我的小老板也说要是不想卷的话，就把这里当作国企。我现在也会想，是不是我这种内向不会社交，不会来事儿的性格，在互联网是干不下去的。而且一想到每次跳槽都要各种准备就很难受。中间也考虑过去国企，然后自己干干副业的出路。</p>
<h3 id="第五部分未来的选择与担忧"><a class="markdownIt-Anchor" href="#第五部分未来的选择与担忧"></a> 第五部分：未来的选择与担忧</h3>
<p>现状，工作经验2年2个月，空窗目前第9个月。</p>
<p>目前大概梳理了下几种选择：</p>
<ol>
<li>继续找个互联网的公司，换个环境看看。（但是目前的现状没咋准备好，空窗太久项目细节忘差不多了，很难想起有什么难点亮点，因为当时做的项目也没那么有深度，我对面试通过和试用期没什么信心）然后再准备考公考编或者国企。</li>
<li>直接找国企，这个有个问题就是目前空窗9个月，国企流程很长，万一弄不上很尴尬。以及不知道找杭州的还是江西的国企。我看网上说国企也会在意空窗期。</li>
<li>考公考编，大专老师。嗯，这个也需要第二年三四月考，相当于是直接空窗奋力一搏。万一考不上只能继续，因为空窗已经时间很长。</li>
</ol>
<p>因为2、3好像都需要准备考试的，比如行测申论。</p>
<h3 id="第六部分具体选择的疑惑"><a class="markdownIt-Anchor" href="#第六部分具体选择的疑惑"></a> 第六部分：具体选择的疑惑</h3>
<p>假设有2个选择，</p>
<ol>
<li>北京上海央企，年包30w，三餐免费；（月到手1w2的样子吧，可能节约点一个月攒个比5k多点的）</li>
<li>江西老家国企，年包17，20w不到，月到手5k，年节福利。（我爸妈说太低了月工资）</li>
</ol>
<p>这种一般哪个更好呢？</p>
<h3 id="第七部分面试与心理压力"><a class="markdownIt-Anchor" href="#第七部分面试与心理压力"></a> 第七部分：面试与心理压力</h3>
<p>有没有过来人说一下，我下周约了好几个大厂面试，但是个人客观评价就是没准备好，需要时间。想问一下如果取消面试话术怎么说？后面再约面试还有戏吗？目前冷静下来了可以全力复习了。<br />
有两个厂已经是延迟了面试时间了。</p>
<h3 id="第八部分心理压力与家庭背景"><a class="markdownIt-Anchor" href="#第八部分心理压力与家庭背景"></a> 第八部分：心理压力与家庭背景</h3>
<p>再补充个信息，为什么楼主心理压力这么大，只想着靠自己，之前研究生时候就开始内耗呢，是因为自己有个小10岁的弟弟。而且ip在江西，楼主觉得自己可能buff叠满，但是实际上我家彩礼并不高，10出头，并且我爸妈说可以商量的，而且会给我带走一部分。但是我因为这些觉得很自卑，不敢找对象，因为外界一听江西人还有弟弟，就会说伏地魔，我真的蛮痛苦的。其实我们家家庭氛围还可以，爸妈是差不多对我们，但是因为家里条件是普通，弟弟还在读书，所以不能帮我多少，我只能靠自己。这就是我之前那么emo的原因之一，感觉生存压力很大，不知道是不是我自己想多了。</p>
<p>所以想问下大家，这种情况，我是不是还是去挣钱比较好？</p>
<h3 id="第九部分面试恐惧与项目经验"><a class="markdownIt-Anchor" href="#第九部分面试恐惧与项目经验"></a> 第九部分：面试恐惧与项目经验</h3>
<p>楼主害怕面试还有一个主要原因是，当时辞职实在是太难受太恶心了，根本不想或者来不及梳理项目，现在社招面试问项目细节都问的很细，楼主已经忘得差不多了。现在回想起来很困难，担心问细节问到我答不上来。而且两年都被边缘化拧螺丝，感觉根本没什么拿得出手的复杂有深度的项目可以说，说不出什么难点亮点，太难受了。</p>
<h2 id="对话部分"><a class="markdownIt-Anchor" href="#对话部分"></a> 对话部分</h2>
<h3 id="对话整理"><a class="markdownIt-Anchor" href="#对话整理"></a> 对话整理</h3>
<p><strong>royma520:</strong><br />
甚至有想过去pdd这种，只干活不汇报不内卷的公司，只要不要干什么其他幺蛾子，卷汇报卷技术分享卷表演，我觉得我还是可以干开发的。只要不精神内耗，而且希望组里的氛围好一些，因为本人性格敏感，但是之前对办公室政治挺迟钝的，后面经过一个男同事给我疯狂点拨，我才拨云见雾察觉出这里面的风起云涌。感受到大家在勾心斗角，我这个佛系人在里面真的很难受。</p>
<hr />
<p><strong>Cjp20030116:</strong><br />
那不是纯粹是环境的原因吗？换一个环境肯定会好吧！</p>
<hr />
<p><strong>Cjp20030116:</strong><br />
Pdd也太哈人了。</p>
<hr />
<p><strong>royma520:</strong><br />
怎么说？我也听说过里面强度，有个认识的人在里面，他说他们组10 10 6。</p>
<hr />
<p><strong>Cjp20030116:</strong><br />
006其实还好，主要是竞业协议吧，可以搜搜看。</p>
<hr />
<p><strong>royma520:</strong><br />
嗯嗯，可能觉得下一份工作如果是互联网可能就是职场终点了。所以也没有太介意，但是好像pdd也卡30%涨幅，那个强度就不知道合不合适了，而且我空窗，都说空窗会压价。</p>
<hr />
<p><strong>royma520:</strong><br />
害怕面试怎么办，呜呜，感觉没准备好，就很怂很心虚。所以暑期实习转正之后，秋招就直接all in了，没找其他的。</p>
<hr />
<p><strong>Cjp20030116:</strong><br />
找猎头问问？或者组内师兄跳槽的问问。</p>
<hr />
<p><strong>royma520:</strong><br />
问什么呀？就是她们去哪了，然后找她们内推吗？我担心我没准备好，找他们内推，挂了更尴尬了。</p>
<hr />
<p><strong>soBored:</strong><br />
看着都有点害怕，学姐加油emc22。</p>
<hr />
<p><strong>royma520:</strong><br />
现在还有一个问题就是，如果要继续找互联网工作，我简历的项目细节都有点记不太清楚了。担心社招问项目答不上来，被质疑。没准备好就去面试，感觉也浪费了面试机会。但是再准备准备也不知道什么时候能准备好，空窗期也越来越长。</p>
<hr />
<p><strong>smallhaes:</strong><br />
加油。</p>
<hr />
<p><strong>ym19940508:</strong><br />
既然这么不喜欢这工作，要不然就算了吧。为自己活一次吧。</p>
<hr />
<p><strong>cccoco:</strong><br />
“之前对办公室政治挺迟钝的，后面经过一个男同事给我疯狂点拨，我才拨云见雾察觉出这里面的风起云涌。”<br />
钝感力其实就是种能力，这个点拨真的不要也罢。你在旋涡边上看旋涡，其实就是一个小酒窝，当风景就好，底下的暗涌又与你何干呢？如果是我，我可能会在以后的工作中避免接受这种“点拨”。<br />
不受力就是最大的助力！楼主加油。</p>
<hr />
<p><strong>royma520:</strong><br />
但是也有生存压力的，不可能不为父母考虑，她们就希望我有个工作。</p>
<hr />
<p><strong>royma520:</strong><br />
嗯嗯，是的。知道了之后更痛苦了。</p>
<hr />
<p><strong>ym19940508:</strong><br />
可以有个工作，但不一定非得是程序员吧。</p>
<hr />
<p><strong>royma520:</strong><br />
但是转行也没思路，不知道可以干什么。</p>
<hr />
<p><strong>shd110110:</strong><br />
心疼楼主，想开点，人就活这一次，怎么活都没有对错。多问问自己想干什么，少在乎一些别人的眼光。</p>
<hr />
<p><strong>royma520:</strong><br />
我也没有信心能通过互联网公司的面试，感觉现在的面试水平还不如实习的时候速成的。</p>
<hr />
<p><strong>royma520:</strong><br />
有没有社招去国企的朋友说说2年2个月经验去容易吗？国企介意空窗期吗？以及国企需要提供成绩单吗？</p>
<hr />
<p><strong>buptchy:</strong><br />
国企校招的时候一般网申投简历会让上传成绩单。</p>
<hr />
<p><strong>suping:</strong><br />
通篇看下来，智商高、情商低、性格一般、身体素质不行。<br />
大部分人每天的状态：由里到外和工作息息相关，我不觉得私企会是你的终点。</p>
<p>个人建议：<br />
1.考公，智商高的考公会占优势，答题速度比较重要，考的就是脑子。<br />
2.打开目标省国资委找国企列表进一步看计算机信息类岗位，疯狂投简历，国企还是看重学校一点。</p>
<hr />
<p><strong>buptchy:</strong><br />
感觉楼主工作能力没有问题，更多的需要调整自己的心态吧，适应环境，我在国企感觉其实也是一样的演戏氛围，感觉跟着演就好了，别太认真了，现在感觉上班就是角色扮演，大家都是NPC，下班了就别去想工作。</p>
<hr />
<p><strong>intmain:</strong><br />
还好个锤子。</p>
<hr />
<p><strong>LNZthezero:</strong><br />
国企现在有编制也是编制在岗位而不在人，人是合同制的，我个人感觉似乎有点淡马锡模式的意思，只留个有官方身份的用来控制的总部，剩下的干活的都是市场化运营。<br />
想找编制就进体制当有编制的政府雇员吧，基本没可能一次考上因此大概需要报很多名，考很多试，我有几个同学当年沿海巡考考了好久。<br />
互联网公司的话，如果是厌倦和天天和绩效交期与项目经理打交道那就不要去了，哪的私企都是这个状态，项目经理天天催，厌恶这种状态的人去了只会更加抑郁。</p>
<hr />
<p><strong>LNZthezero:</strong><br />
还想找工作的话围绕着你自己的比较熟练的技术计划就行了，把自己的核心技术弄成个足够完整和足以自持的，然后就照着这个方向投简历。</p>
<hr />
<p><strong>royma520:</strong><br />
枯了，社招估计也会看？这条路堵死了。</p>
<hr />
<p><strong>royma520:</strong><br />
但我担心会看成绩单，研究生挂科了。</p>
<hr />
<p><strong>royma520:</strong><br />
我小老板也说过，上班就是表演，还让我像表演的好的同事学习。</p>
<hr />
<p><strong>royma520:</strong><br />
不是说不喜欢和老板打交道，是讨厌同事老说我这怎么都不会，如果老板比较好（我之前的女老板就比较好），不阴阳怪气，我觉得还行。就正常上班。</p>
<hr />
<p><strong>royma520:</strong><br />
嗯嗯，谢谢你的建议。</p>
<hr />
<p><strong>Cjp20030116:</strong><br />
接受情况不同，不予置评。上5天班加上周末oncall和006差不多。</p>
<hr />
<p><strong>buptchy:</strong><br />
试试吧，不试怎么知道，也不是所有都要求。</p>
<hr />
<p><strong>LNZthezero:</strong><br />
阴阳怪气是工作的一部分（bushi）。<br />
可以换个环境，只是未必新环境能有多好，不过大不了一方面觉得呆不下去跑路就是了，另一方面可以逐渐把自己的技术搓成个能独当一面的东西，工作上的压力会小不少。<br />
如果还想继续在私企/市场里靠技术搏一口饭吃的话，那就慢慢来呗，一边干一边打磨自己的技术。<br />
不想在市场里朝不保夕地搏命那就考有编制的体制内去，体制内安心当个办事人员/技术官僚不往风暴眼里走的话还是很稳定的，你的编制是组织部定的，用人单位基本只有正职领导才有通过组织部的流程启动开除的能力。</p>
<hr />
<p><strong>royma520:</strong><br />
嗯嗯，也是。</p>
<hr />
<p><strong>royma520:</strong><br />
好的，学习了。</p>
<hr />
<p><strong>shuizai:</strong><br />
楼主想得太多而做得太少，与其内耗不如多尝试。<br />
生活哪有什么捷径，每个人都在日复一日坚持。</p>
<hr />
<p><strong>lsx0871:</strong><br />
承受能力，抗压能力弱，就去真国企，或者考公务员，去有编制的事业单位，没有这么多压力，大厂，假国企大多是这种逼着大家内卷的氛围，你会更内耗。</p>
<hr />
<p><strong>royma520:</strong><br />
社招也能去真国企吗？主要是信息渠道有限，这段时间网上看国企信息，感觉信息壁垒很高，不知道待遇也不知道能报什么，感觉很多，筛选起来很复杂，需要一段时间。</p>
<hr />
<p><strong>lsx0871:</strong><br />
可以，一年只有一次，不是各种app上经常招人的那种。</p>
<hr />
<p><strong>royma520:</strong><br />
嗯嗯，有考虑过职业发展，当时想的是32左右考公务员或者去国企事业单位的来着。</p>
<hr />
<p><strong>royma520:</strong><br />
这种要去哪里看呢？之前在论坛里搜国企，感觉</p>
<p>信息量特别多，像国资委之类的，感觉就像个无头苍蝇没有方向。</p>
<hr />
<p><strong>dyjs:</strong><br />
看到了一些自己的影子，建议测测mbti，结合自己的兴趣和专长做自己喜欢的，没那么多包袱负担的。</p>
<hr />
<p><strong>tylovehhx:</strong><br />
感觉楼主现在的状态确实不太适合去大厂了吧，通篇看下来好像内耗比较严重、对面试没有信心、对面试成功以后进入工作岗位也有恐惧感？可能适合一个压力小一点，甚至与写代码完全没关系的工作。</p>
<hr />
<p><strong>royma520:</strong><br />
mbti大学的时候是istj（i的程度98%），快离职的时候是isfj（i 99%）。</p>
<hr />
<p><strong>royma520:</strong><br />
嗯嗯 但是目前无头苍蝇 也不知道到底去国企还是事业单位大专老师啥的 很迷茫 信息很多。</p>
<hr />
<p><strong>suping:</strong><br />
我今年入职的国企，当然是不是真国企另论：国资委控股50%，国资委官网里面能看到单位。<br />
社招我官方招聘投的简历，全程到最后，以及目前入职1个月，成绩单没有看过，我本科挂过科。<br />
权当参考吧。</p>
<p><strong>royma520:</strong></p>
<p>国企是不是面试流程什么的特别长呀？请问有几年工作经验呀？<br />
【 在 suping 的大作中提到: 】<br />
我今年入职的国企，当然是不是真国企另论：国资委控股50%，国资委官网里面能看到单位<br />
社招我官方招聘投的简历，全程到最后，以及目前入职1个月，成绩单没有看过，我本科挂过科<br />
权当参考吧</p>
<p>–</p>
<p><strong>royma520:</strong><br />
您是硕士吗？听说一般是看最高学历的成绩单。好后悔挂科了，不然当时就可以看看烟草、电网、三桶油之类的国企了，但是其实我也有个疑惑就是家里条件普通没什么帮助，女生去这些企业的话生活过的会舒服吗？<br />
【 在 suping 的大作中提到: 】<br />
我今年入职的国企，当然是不是真国企另论：国资委控股50%，国资委官网里面能看到单位<br />
社招我官方招聘投的简历，全程到最后，以及目前入职1个月，成绩单没有看过，我本科挂过科<br />
权当参考吧</p>
<p>–</p>
<p><strong>bv:</strong><br />
高校信息化专技岗位，缺点是收入比互联网低不少，LZ需要说服自己知道鱼和熊掌不可兼得，不少想法其实是不太实际的，可以多跟朋友交流下，调整下状态最重要</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，是大专吗？其实还有个疑惑就是去哪里发展，户口在杭州，老家在江西，江西的经济环境说实话不太好。<br />
【 在 bv 的大作中提到: 】<br />
高校信息化专技岗位，缺点是收入比互联网低不少，LZ需要说服自己知道鱼和熊掌不可兼得，不少想法其实是不太实际的，可以多跟朋友交流下，调整下状态最重要</p>
<p>–</p>
<p><strong>suping:</strong><br />
我对国企也不熟，只能从此次我的经验来说了<br />
流程是不短，一旦确定入职，入职时间也都可以谈好久；我不是硕士，本6，对你说的这些国企的社招面试流程不了解。工资不清楚，可能国企也参差不齐吧，我这个很低，房贷现在都cover不住…自己低保生活用的还是之前攒的小钱<br />
【 在 royma520 的大作中提到: 】<br />
您是硕士吗？听说一般是看最高学历的成绩单。好后悔挂科了，不然当时就可以看看烟草、电网、三桶油之类的国企了，但是其实我也有个疑惑就是家里条件普通没什么帮助，女生去这些企业的话生活过的会舒服吗？</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，所以感觉去国企也是得有了一定积蓄，如果不用自己买房，只养活自己的话感觉是够了。<br />
【 在 suping 的大作中提到: 】<br />
我对国企也不熟，只能从此次我的经验来说了<br />
流程是不短，一旦确定入职，入职时间也都可以谈好久；我不是硕士，本6，对你说的这些国企的社招面试流程不了解。工资不清楚，可能国企也参差不齐吧，我这个很低，房贷现在都cover不住…自己低保生活用的还是之前攒的小钱</p>
<p>–</p>
<p><strong>bv:</strong><br />
大专院校可以当任课老师了，也是不错的选择。信息化专技岗可以去本科院校找。找给事业编制的，一般春节后职位放出的比较多，其他时间零星的会放出岗位。南昌、上海、杭州、江西周边的省市都可以看一下。举例： <a href="https://www.gaoxiaojob.com/column/25.html">https://www.gaoxiaojob.com/column/25.html</a></p>
<p>–</p>
<p><strong>royma520:</strong><br />
好的，十分感谢！<br />
【 在 bv 的大作中提到: 】<br />
大专院校可以当任课老师了，也是不错的选择。信息化专技岗可以去本科院校找。找给事业编制的，一般春节后职位放出的比较多，其他时间零星的会放出岗位。南昌、上海、杭州、江西周边的省市都可以看一下。举例：<a href="https://www.gaoxiaojob.com/column/25.html">https://www.gaoxiaojob.com/column/25.html</a></p>
<p>–</p>
<p><strong>royma520:</strong><br />
是的，老板还和我说多劳多得，干那些比较小的活没有太大用处，可能别人的功能的复杂度比我的高。以及告诉我会哭的孩子有奶吃，让我去多和我现在的直属老板沟通。真的很心累，中间发生了很多事情，三言两语讲不清，总之就是让人心累，这复杂多变、瞬息万变的关系。<br />
【 在 lsx0871 的大作中提到: 】<br />
末尾淘汰的公司不可能不内卷，就比如，组内10人，奖金只有7个人的预算，10个人都想拿满，必然会内斗，内卷，出现你说的办公室政治，得利的并不是你们这10个人，你们只是棋子，得利的是游戏规则的制定者<br />
。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
你是回老家国企了吗？还是说在工作所在地的国企呀？<br />
【 在 suping 的大作中提到: 】<br />
我对国企也不熟，只能从此次我的经验来说了<br />
流程是不短，一旦确定入职，入职时间也都可以谈好久；我不是硕士，本6，对你说的这些国企的社招面试流程不了解。工资不清楚，可能国企也参差不齐吧，我这个很低，房贷现在都cover不住…自己低保生活用的还是之前攒的小钱</p>
<p>–</p>
<p><strong>l6030:</strong><br />
直接找国企，我找了那么多国企，感觉没几个看成绩单的，虽然我没有挂科。你这种状态早点从互联网逃离吧，要不然30多岁还要纠结。考公或者事业单位，现在就可以行动起来吧，为啥非要等到32岁，你能保证一两年就能顺利上岸？另外，好多国企，尤其是金融国企，年龄已经要求33岁以下了。挂了一科，校招也可以去试试央企或者国企啊，机会都是尝试出来的，自己主动放弃了那就一点机会都没有了。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，那现在是空窗，直接就国企找起来么？也犹豫找哪里的，目前户口在杭州，老家江西。<br />
【 在 l6030 的大作中提到: 】<br />
直接找国企，我找了那么多国企，感觉没几个看成绩单的，虽然我没有挂科。你这种状态早点从互联网逃离吧，要不然30多岁还要纠结。考公或者事业单位，现在就可以行动起来吧，为啥非要等到32岁，你能保证一两年就能顺利上岸？另外，好多国企，尤其是金融国企，年龄已经要求33岁以下了。挂了一科，校招也可以去试试央企或者国企啊，机会都是尝试出来的，自己主动放弃了那就一点机会都没有了。</p>
<p>–</p>
<p><strong>b5702906:</strong><br />
我觉得：<br />
1.楼主首先调整心态，不要既要又要，想好自己到底想要什么。<br />
2.工作和生活分开来，工作就是工作，下了班就好好放松，不要胡思乱想，如果找到工作以后。<br />
3.我很理解你只想开发的想法，但是现在大公司基本都卷认知，老板各种奇思妙想，最后活肯定是底层干，所以强迫自己适应吧。<br />
4.其实你再干几年互联网就会发现这些压力渐渐就不是啥事了，不要把工作放的太重。<br />
5.你找工作压力不大的，建议先从不想去的小厂练练手，多练练手再去面想去的。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，现在的尴尬之处就在于滴滴、美团、小红书、京东、百度、字节全都在这两周，个人觉得没准备好，可以拒绝面试机会么？感觉去面了可能就是一个挂。但是拖久了假如到下个月空窗期就是第10个月。<br />
【 在 b5702906 的大作中提到: 】<br />
我觉得：<br />
1.楼主首先调整心态，不要既要又要，想好自己到底想要什么。<br />
2.工作和生活分开来，工作就是工作，下了班就好好放松，不要胡思乱想，如果找到工作以后。<br />
3.我很理解你只想开发的想法，但是现在大公司基本都卷认知，老板各种奇思妙想</p>
<p>，最后活肯定是底层干，所以强迫自己适应吧。<br />
4.其实你再干几年互联网就会发现这些压力渐渐就不是啥事了，不要把工作放的太重。<br />
5.你找工作压力不大的，建议先从不想去的小厂练练手，多练练手再去面想去的。</p>
<p>–</p>
<p><strong>b5702906:</strong><br />
你可以和hr商量下，延长一下面试时间，拖个两三周没啥问题，期间找找小厂试试手。<br />
【 在 royma520 的大作中提到: 】<br />
嗯嗯，现在的尴尬之处就在于滴滴、美团、小红书、京东、百度、字节全都在这两周，个人觉得没准备好，可以拒绝面试机会么？感觉去面了可能就是一个挂。但是拖久了假如到下个月空窗期就是第10个月。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
那些hr都各个急得不得了，恨不得本周就面试，感觉延长时间的话也有风险，说不定hc就没了（我同学说）有个hr也说尽快。<br />
【 在 b5702906 的大作中提到: 】<br />
你可以和hr商量下，延长一下面试时间，拖个两三周没啥问题，期间找找小厂试试手。</p>
<p>–</p>
<p><strong>juda:</strong><br />
小姑娘是典型的左右脑打架的人，北邮不少你这样的女孩子，慵懒而又极聪明还要强，学啥都是一学就会。你这种人确实不适合一直做写代码这种没啥挑战的事情，写代码对你来讲太简单了，考个公务员做点有挑战的事情吧。<br />
【 在 royma520 的大作中提到: 】<br />
楼主北邮本硕，21届女生，目前26，马上快27了，都是计算机专业，感觉不是很喜欢写代码，上大学之后就挺迷茫的，就是按部就班学习然后莫名其妙的拿到了保研资格，当时没想好要干嘛就读研了，想着有个研究生学历以后选择多一些。但是硕士太emo了，导致一门必修课挂科，所以秋招没敢投国企，怕要成绩单。方向是前端开发，研究生暑期实习运气好进了阿里实习，顺利转正了，也争取了个小sp。<br />
入职之后发现都不太会，基础不好（因为是暑期实习前几个月才决定找前端工作，所以速成学习了两三个月，加上实验室做了前端项目，当时是直接就很容易上手了，边做不会的去查的，没有系统学过，因为不想oncall太累所以没找服务端），也没有metor带，很痛苦挣扎。写代码上手很快，但是基本上也是不喜欢深入思考，就是那种干完了事的感觉，感觉那种写一写页面的、自己独立负责一个模块的就很适合我，不太喜欢被打乱计划天天被各种bug丢过来做琐碎的活。因为实习期间自己负责独立的一块底层项目，表现的也不错，简而言之就是适合自己做自己的事情。下班也根本不想学习，学习起来很痛苦，可能是前二十几年都是以找个好工作为目标，找到了就松懈了，就想玩，对技术不感兴趣（这点也存疑，就是其实做东西出来的成就感我也挺喜欢的，所以选的前端方向）。性格内向、佛系，但是其实表现出来挺外向的，至少同事没看出我内向，还有点幽默，不喜欢高竞争的环境，入职2年看同事各种技术分享表演，而我只想做好自己的事情，根本不想卷，当然也有没有出彩的活，以及看出来不能晋升，所以积极性不高。理所当然的绩效就是普普通通，更加不能晋升。由于本人对自己要求还很高，看到周围同学或者比自己大一届的同事，都顺利跳槽晋升，很痛苦。但是自己的技术水平感觉真的有限，也不爱学习。述职的时候被老板说自己就是懒，没有内驱力，希望我找到自己真正热爱的事情。自己开发的时候debug不出来也很难受，但是后面技术提升之后好了很多，但是代码调试不出来就很痛苦。本人又是要强的性格，不想轻易求助别人，主要是组里也都是男同事，频繁求助的话人家也忙，也怕被说女生技术差什么的，上学的时候也都是自己搞定的项目。<br />
因为待着太内耗了，也有之前研究生就有的emo，去年体检查出来多了一个甲状腺结节，几个乳腺结节，可能因为心情持续低落导致免疫力下降，天天戴口罩的我还是二阳了。组里氛围比较差，我入职之后带我的师兄离职了，然后我的小组陆续走了快10个人，项目要处于维护阶段了，没人带，天天做些边角料活。每天因为内耗，有一段时间上班如上坟，坐在工位上都能哭出来，二阳之后体检去医院查出来有轻度抑郁和焦虑。怕再待下去影响身体，就裸辞了，因为其实很早就想着要跳槽的事情了，期间也经历了换老板的事情，可能被当作了前老板的嫡系以及做了一些得罪现在的老板的事情，所以就很内耗。在入职半年的时候就想走，入职一年的时候离职的心情达到了巅峰。但是那会儿又提不起劲复习，可能是抑郁情绪导致的，中间经历了异地分手、亲人去世，想着待满2年可能更好一些。但是结果就是第一年的时候还没有甲状腺结节，第二年体检多了甲状腺结节。</p>
<p>–</p>
<p><strong>l6030:</strong><br />
其实看你描述的性格，你真的不太适合在互联网，你现在年轻，可能还看不太出来，等你30多岁的时候，一方面老板经常更换，你需要频繁去适应组织架构调整，另一方面，年龄大升不上去，处境也会很尴尬。30多岁面临生育，你卷不过那些年轻的。我见过，有那年轻的时候，比你更能卷，升的也更快，但到了30多岁，一样会面临转型问题，但30多岁再转，时间和机会成本就比较高了。现阶段你可以先选择一家互联网，然后准备国企的面试，进了国企再准备考公，一线城市的国企机会多一些，可以考虑，如果想回家，可以准备家乡的公务员考试。另外，互联网的面试，你可以先准备准备，再约面试，隔一两周约一两家，总结经验，起步可以先约一些小厂。就算是一家面挂了，也可以换个部门继续面。互联网的机会还是很多的，只要你掌握了面试技巧，拿offer是迟早的事。在互联网公司，你肯定会有压力大的时候，也会有相对舒服的时候，舒服的时候，要多想想自己的退路，因为可能半年以后，你的老板离职或者组织架构变动，你在这家互联网公司的好日子也到头了。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，您说的很对，我就是入职半年换了老板，就开始很难受很内耗了。所以现在的思路是互联网面试按部就班，然后找到工作了，在工作里准备国企的面试和信息搜集（确定目标范围有哪些，待遇情况什么的），到了国企之后再准备公务员上岸。这个思路很合适。此外我也有些疑惑，就是如果没有一线城市的户口的话，同时家境没什么支持，留在一线城市的国企的出路是什么呢？找个一起在一线城市奋斗的对象吗？（之前自己是有想过32攒够七位数存款，然后可以fire，过低物欲生活的，这种没考虑对象的情况，因为目前单身）<br />
【 在 l6030 的大作中提到: 】<br />
其实看你描述的性格，你真的不太适合在互联网，你现在年轻，可能还看不太出来，等你30多岁的时候，一方面老板经常更换，你需要频繁去适应组织架构调整，另一方面，年龄大升不上去，处境也会很尴尬。30多岁面临生育，你卷不过那些年轻的。我见过，有那年轻的时候，比你更能卷，升的也更快，但到了30多岁，一样会面临转型问题，但30多岁再转，时间和机会成本就比较高了。现阶段你可以先选择一家互联网，然后准备国企的面试，进了国企再准备</p>
<p>考公，一线城市的国企机会多一些，可以考虑，如果想回家，可以准备家乡的公务员考试。另外，互联网的面试，你可以先准备准备，再约面试，隔一两周约一两家，总结经验，起步可以先约一些小厂。就算是一家面挂了，也可以换个部门继续面。互联网的机会还是很多的，只要你掌握了面试技巧，拿offer是迟早的事。在互联网公司，你肯定会有压力大的时候，也会有相对舒服的时候，舒服的时候，要多想想自己的退路，因为可能半年以后，你的老板离职或者组织架构变动，你在这家互联网公司的好日子也到头了。</p>
<p>–</p>
<p><strong>juda:</strong><br />
你这个建议不靠谱，耽误小姑娘了，早点考公上岸还有职业发展，没必要在互联网浪费时间。<br />
【 在 l6030 的大作中提到: 】<br />
其实看你描述的性格，你真的不太适合在互联网，你现在年轻，可能还看不太出来，等你30多岁的时候，一方面老板经常更换，你需要频繁去适应组织架构调整，另一方面，年龄大升不上去，处境也会很尴尬。30多岁面临生育，你卷不过那些年轻的。我见过，有那年轻的时候，比你更能卷，升的也更快，但到了30多岁，一样会面临转型问题，但30多岁再转，时间和机会成本就比较高了。现阶段你可以先选择一家互联网，然后准备国企的面试，进了国企再准备考公，一线城市的国企机会多一些，可以考虑，如果想回家，可以准备家乡的公务员考试。另外，互联网的面试，你可以先准备准备，再约面试，隔一两周约一两家，总结经验，起步可以先约一些小厂。就算是一家面挂了，也可以换个部门继续面。互联网的机会还是很多的，只要你掌握了面试技巧，拿offer是迟早的事。在互联网公司，你肯定会有压力大的时候，也会有相对舒服的时候，舒服的时候，要多想想自己的退路，因为可能半年以后，你的老板离职或者组织架构变动，你在这家互联网公司的好日子也到头了。</p>
<p>–</p>
<p><strong>juda:</strong><br />
这个思路不对，浪费时间，一步到位直接考公上岸，相信我，确实香。<br />
【 在 royma520 的大作中提到: 】<br />
嗯嗯，您说的很对，我就是入职半年换了老板，就开始很难受很内耗了。所以现在的思路是互联网面试按部就班，然后找到工作了，在工作里准备国企的面试和信息搜集（确定目标范围有哪些，待遇情况什么的），到了国企之后再准备公务员上岸。这个思路很合适。此外我也有些疑惑，就是如果没有一线城市的户口的话，同时家境没什么支持，留在一线城市的国企的出路是什么呢？找个一起在一线城市奋斗的对象吗？（之前自己是有想过32攒够七位数存款，然后可以fire，过低物欲生活的，这种没考虑对象的情况，因为目前单身）</p>
<p>–</p>
<p><strong>royma520:</strong><br />
考老家的吗，老家的我打听了一下，一年10w不到。<br />
【 在 juda 的大作中提到: 】<br />
这个思路不对，浪费时间，一步到位直接考公上岸，相信我，确实香。</p>
<p>–</p>
<p><strong>juda:</strong><br />
都可以，非常香，核心是阶级跨越，互联网太low,盯着钱就局限了。<br />
【 在 royma520 的大作中提到: 】<br />
考老家的吗，老家的我打听了一下，一年10w不到。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
跨越啥阶层呀？好奇，因为我两个堂哥都是公务员，做的还算不错。貌似社会地位是挺高的，但是一个堂哥也和我说这就是体面一点，孩子上学能方便点，钱的话没有多少。我也不知道是不是真的。<br />
【 在 juda 的大作中提到: 】<br />
都可以，非常香，核心是阶级跨越，互联网太low,盯着钱就局限了。</p>
<p>–</p>
<p><strong>juda:</strong><br />
傻孩子，人家那是谦虚，钱也不少的，越往后越多。<br />
【 在 royma520 的大作中提到: 】<br />
跨越啥阶层呀？好奇，因为我两个堂哥都是公务员，做的还算不错。貌似社会地位是挺高的，但是一个堂哥也和我说这就是体面一点，孩子上学能方便点，钱的话没有多少。我也不知道是不是真的。</p>
<p>–</p>
<p><strong>anying:</strong><br />
em33</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯 我也觉得是谦虚，毕竟都混得不错。<br />
【 在 juda 的大作中提到: 】<br />
傻孩子，人家那是谦虚，钱也不少的，越往后越多。</p>
<p>–</p>
<p><strong>zxzc1998:</strong><br />
阶级跨越比挣钱更不靠谱。</p>
<p>–</p>
<p><strong>SENDOHAKIRA:</strong><br />
加油。</p>
<p>–</p>
<p><strong>writer002:</strong><br />
我也江西人，我也菜于是不打算做程序员。做产品和项目类似的。关键我本科和研究生都挂科，我吐了，那完了，我也去不了国企了，但是我肯定都试一下那个要我去哪个，考公也会考。</p>
<p>–</p>
<p><strong>gwcbold:</strong><br />
bd。</p>
<p>–</p>
<p><strong>ws1025336322:</strong><br />
优柔寡断，还敏感。你为什么“担心会要成绩单，就不投了”呢？投了能咋滴？就算被拒绝了，能咋滴？能怎么样！你这跟担心被拒绝就不表白很像啊。你自己也知道行动力不行，又没有自驱力，为啥不尝试做出改变呢？择其善者而从之，其不善者而改之。总不能是拖延症把“要改掉拖延症”的行动给拖延了吧。工作的方向，我给不了啥建议，如果是我的话，我应该会调整心态投一波国企，没戏就继续互联网，工作期间挤时间准备考公的东西。你的结节很可能跟你脆弱敏感的心态有很大关系喔。至于一个二阳破防，二阳就二阳，三阳四阳一百阳，又怎么样？不就是一场感冒，几天发烧。你不调整心态，结节也要发展成瘤，成癌。职场暗流涌动，自己看不到，那不是很好吗？做个阳光开朗大女孩又有什么不好呢？你没执行力，没自驱力，还谈个屁的事业心啊，躺平与自己和解完事。他卷任他卷，我到点下班。你自己也说，能专心做你的工作就是让你很喜欢的事，那还不简单？可能是我没在你的环境里体验过，我很难理解一个人想要躺平怎么还能躺不平。裸辞都行，怎么能躺不平呢？难道到点下班还能倒扣工资？我觉得你可以行动起来，准备找工作的东西，无论你是决定要往哪个方向。找个兴趣爱好，最好是体育运动，跑跑步之类的，能够舒缓压力，适量运动也能让体格更健壮，身体更健康。更重要的是能帮助调整心态。你真的想躺平的话，同学朋友升职加薪有什么好羡慕的呢？“不想当将军的士兵不是好士兵”，那不是就不是，工资到位，不是又怎么样呢？盖将自其变者而观之，则天地曾不能以一瞬；自其不变者而观之，则物与我皆无尽也，而又何羡乎！不敢振翅，怎么翱翔？不敢亮剑，怎么杀敌？我真的不懂，md有什么难的，撸起袖子就是干！另外，我建议你不要一坐几个小时。最好是半小时去接杯水，半小时去趟厕所，路上活动活动手脚。你才刚刚腰肌劳损，再不改正习惯，痔疮、腰椎间盘突出、颈椎病、腱鞘炎、飞蚊症什么的全来你身上开会。不摆了，还有四五个小时又要上班了，加油！</p>
<p>–</p>
<p><strong>royma520:</strong><br />
先国企再互联网的话，国企流程长，那会儿再互联网空窗期应该10个多月甚至更长，可能就只能去od了。<br />
【 在 ws1025336322 的大作中提到: 】<br />
优柔寡断，还敏感。你为什么“担心会要成绩单，就不投了”呢？投了能咋滴？就算被拒</p>
<p>绝了，能咋滴？能怎么样！你这跟担心被拒绝就不表白很像啊。你自己也知道行动力不行，又没有自驱力，为啥不尝试做出改变呢？择其善者而从之，其不善者而改之。总不能是拖延症把“要改掉拖延症”的行动给拖延了吧。工作的方向，我给不了啥建议，如果是我的话，我应该会调整心态投一波国企，没戏就继续互联网，工作期间挤时间准备考公的东西。你的结节很可能跟你脆弱敏感的心态有很大关系喔。至于一个二阳破防，二阳就二阳，三阳四阳一百阳，又怎么样？不就是一场感冒，几天发烧。你不调整心态，结节也要发展成瘤，成癌。职场暗流涌动，自己看不到，那不是很好吗？做个阳光开朗大女孩又有什么不好呢？你没执行力，没自驱力，还谈个屁的事业心啊，躺平与自己和解完事。他卷任他卷，我到点下班。你自己也说，能专心做你的工作就是让你很喜欢的事，那还不简单？可能是我没在你的环境里体验过，我很难理解一个人想要躺平怎么还能躺不平。裸辞都行，怎么能躺不平呢？难道到点下班还能倒扣工资？我觉得你可以行动起来，准备找工作的东西，无论你是决定要往哪个方向。找个兴趣爱好，最好是体育运动，跑跑步之类的，能够舒缓压力，适量运动也能让体格更健壮，身体更健康。更重要的是能帮助调整心态。你真的想躺平的话，同学朋友升职加薪有什么好羡慕的呢？“不想当将军的士兵不是好士兵”，那不是就不是，工资到位，不是又怎么样呢？盖将自其变者而观之，则天地曾不能以一瞬；自其不变者而观之，则物与我皆无尽也，而又何羡乎！不敢振翅，怎么翱翔？不敢亮剑，怎么杀敌？我真的不懂，md有什么难的，撸起袖子就是干！另外，我建议你不要一坐几个小时。最好是半小时去接杯水，半小时去趟厕所，路上活动活动手脚。你才刚刚腰肌劳损，再不改正习惯，痔疮、腰椎间盘突出、颈椎病、腱鞘炎、飞蚊症什么的全来你身上开会。不摆了，还有四五个小时又要上班了，加油！</p>
<p>–</p>
<p><strong>royma520:</strong><br />
那你是考老家的公务员吗？<br />
【 在 writer002 的大作中提到: 】<br />
我也江西人，我也菜于是不打算做程序员。做产品和项目类似的。关键我本科和研究生都挂科，我吐了，那完了，我也去不了国企了，但是我肯定都试一下那个要我去哪个，考公也会考。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
直接空窗考公吗？<br />
【 在 suping 的大作中提到: 】<br />
通篇看下来，智商高、情商低、性格一般、身体素质不行。大部分人每天的状态：由里到外和工作息息相关，我不觉得私企会是你的终点。</p>
<p>–</p>
<p><strong>leozhao:</strong><br />
突然想认识你，思想有深度，对自己认识深刻，喜欢和这种交朋友。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
还有一个问题就是，如果决心去国企，那互联网公司那些面试都拒绝掉吗？</p>
<p>–</p>
<p><strong>juda:</strong><br />
考公对咱学校学生不算难，问题不大。<br />
【 在 zxzc1998 的大作中提到: 】<br />
阶级跨越比挣钱更不靠谱。</p>
<p>–</p>
<p><strong>juda:</strong><br />
不要去国企，你的性格不合适，比互联网还恶心。<br />
【 在 royma520 的大作中提到: 】<br />
还有一个问题就是，如果决心去国企，那互联网公司那些面试都拒绝掉吗？</p>
<p>–</p>
<p><strong>royma520:</strong><br />
倒也不是钝感力，就是没看出来老板之间的关系，但是也感觉组织变动很频繁，也会让人很焦虑。<br />
【 在 cccoco 的大作中提到: 】<br />
“之前对办公室政治挺迟钝的，后面经过一个男同事给我疯狂点拨，我才拨云见雾察觉出这里面的风起云涌”<br />
钝感力其实就是种能力，这个点拨真的不要也罢。你在旋涡边上看旋涡，其实就是一个小酒窝，当风景就好，底下的暗涌又与你何干呢？如果是我，我可能会在以后的工作中避免接受这种“点拨”。<br />
不受力就是最大的助力！楼主加油</p>
<p>–</p>
<p><strong>royma520:</strong><br />
问题是考哪里的公务员呢？初中同学都在老家干教师有事业编，她们的本科也一般，二本。但是感觉现在过的很滋润。我可能还是会在意外人的看法，所以说学历高一些，选择多有时候也会很迷茫。和学历不如自己的同学一样都在老家，感觉还是要调整自己的心态吧。<br />
【 在 juda 的大作中提到: 】<br />
考公对咱学校学生不算难，问题不大。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
直接空窗找么？担心没找到空窗更长了，到时候更是两头讨不着。<br />
【 在 l6030 的大作中提到: 】<br />
直接找国企，我找了那么多国企，感觉没几个看成绩单的，虽然我没有挂科。你这种状态早点从互联网逃离吧，要不然30多岁还要纠结。考公或者事业单位，现在就可以行动起来吧，为啥非要等到32岁，你能保证一两年就能顺利上岸？另外，好多国企，尤其是金融国企，年龄已经要求33岁以下了。挂了一科，校招也可以去试试央企或者国企啊，机会都是尝试出来的，自己主动放弃了那就一点机会都没有了。</p>
<p>–</p>
<p><strong>huashenger:</strong><br />
说句难听的，楼主就是典型的，不愿付出努力，而又想着天上掉馅饼。有挂科算个屁啊，你不试怎么知道人家要不要，好多社招根本不看的好吧，你得去朝着你想要的方向去努力去试啊。</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，骂得很对。本人是那种害怕的，目标不清晰的人，还懒惰。呜呜。<br />
【 在 huashenger 的大作中提到: 】<br />
说句难听的，楼主就是典型的，不愿付出努力，而又想着天上掉馅饼。有挂科算个屁啊，你不试怎么知道人家要不要，好多社招根本不看的好吧，你得去朝着你想要的方向去努力去试啊。</p>
<p>–</p>
<p><strong>bekbek:</strong><br />
余杭阿里和北京阿里氛围哪里不一样呀？</p>
<p>–</p>
<p><strong>suping:</strong><br />
回老家国企了，从北京离开的。<br />
【 在 royma520 的大作中提到: 】<br />
你是回老家国企了吗？还是说在工作所在地的国企<br />
呀？</p>
<p>–</p>
<p><strong>royma520:</strong><br />
可能因为我在一个小破园区，我觉得不好，环境啥的都不太行。<br />
【 在 bekbek 的大作中提到: 】<br />
余杭阿里和北京阿里氛围哪里不一样呀？</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，是攒够积蓄才离开的吗？<br />
【 在 suping 的大作中提到: 】<br />
回老家国企了，从北京离开的。</p>
<p>–</p>
<p><strong>suping:</strong><br />
我身边考上的，基本都是灵活就业中，全力备考的，有几个边上班边备，只能说不理想。<br />
【 在 royma520 的大作中提到: 】<br />
直接空窗考公吗？</p>
<p>–</p>
<p><strong>royma520:</strong><br />
嗯嗯，好像也看是考哪里的吧？杭州的就特别卷，可能还要和清北的竞争，但是老家的可能稍微好点，就是待遇没那么好。<br />
【 在 suping 的大作中提到: 】<br />
我身边考上的，基本都是灵活就业中，全力备考的，有几个边上班边备，只能说不理想。</p>
<p>–</p>
<p><strong>chenyi17:</strong></p>
<p>楼主抗压能力差，性格敏感的内耗型人格，也不会职场行为艺术，互联网是很难混的，曾经的我光是不擅长行为艺术表演这一点，我就呆的难受，后来离开互联网了，所以建议直接找国企，薪资要求低点，工作压力小，丰富个人生活，身心愉悦的上下班就挺好</p>
<hr />
<p><strong>binghai:</strong></p>
<p>看第二段简直世另我，也是干好自己的工作部分，一点儿不想学技术，最后想清楚去国企了，躺平然后才能天天开心，楼主加油。</p>
<hr />
<p><strong>suping:</strong></p>
<p>算不算攒够积蓄也不好说 em9 只能说未来还有很大的不可控，未来达不到靠积蓄过日子的地步，只是这2年想先好好休息，把身体养养</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯，是攒够积蓄才离开的吗？</dd>
</dl>
<hr />
<p><strong>buptstudent:</strong></p>
<p>学姐世另我了。不过学姐可以别那么紧绷，放松点，我也快26了，才刚工作马上快一年而已，还在继续牛马 ema1，而学姐你都工作两年，休息一年，已经速度很快了，也没有说落后什么的。可以各种工作都试试，最差的后果不就是没面上嘛，其实也没那么要紧，投多了自然中的机会就高了。可以考虑老家国企，大专老师，医院信息中心，老师（在家还可以考个教资啥的），银行，外企，感觉还是有很多机会的，多试试吧，然后趁着这段时间也可以好好休息呀，人生太难得有这么大短时间放假了，等找到工作就又要牛马了，所以在漫长的生活中，休息一下没什么的。看到学姐你晚上会半夜就醒了，就是太焦虑了，放松点，没什么事情是那么要紧的，裸辞在家休息也不是什么天塌下来的事，这学历经历找份工作是迟早的事，别太担心啦。学姐加油，放轻松～</p>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯，是的，不会人情世故，所以很难受，看到身边都各种舔老板。老板第一年谈绩效的时候也语重心长的和我说，这样以后会很累。我快离职的时候，女老板和我说我学生思维。我就很难受</p>
<dl>
<dt>【 在 chenyi17 的大作中提到: 】</dt>
<dd>楼主抗压能力差，性格敏感的内耗型人格，也不会职场行为艺术，互联网是很难混的，曾经的我光是不擅长行为艺术表演这一点，我就呆的难受，后来离开互联网了，所以建议直接找国企，薪资要求低点，工作压力小，丰富个人生活，身心愉悦的上下班就挺好</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！我也差不多明白了，我就是没有技术热情，根本不想去钻研什么架构什么的，分给我什么活我就做</p>
<dl>
<dt>【 在 binghai 的大作中提到: 】</dt>
<dd>看第二段简直世另我，也是干好自己的工作部分，一点儿不想学技术，最后想清楚去国企了，躺平然后才能天天开心，楼主加油。</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯，其实我开始一点都不焦虑。回老家之后我爸妈很焦虑，隔三差五说我为什么辞掉，怎么还没找工作。说的我开始非常焦虑了，她们比我更焦虑，因为我们家条件普通，可能我爸妈也担心我未来的路吧</p>
<dl>
<dt>【 在 buptstudent 的大作中提到: 】</dt>
<dd>学姐世另我了。不过学姐可以别那么紧绷，放松点，我也快26了，才刚工作马上快一年而已，还在继续牛马，而学姐你都工作两年，休息一年，已经速度很快了，也没有说落后什么的。可以各种工作都试试，最差的后果不就是没面上嘛，其实也没那么要紧，投多了自然中的机会就高了。可以考虑老家国企，大专老师，医院信息中心，老师（在家还可以考个教资啥的），银行，外企，感觉还是有很多机会的，多试试吧，然后趁着这段时间也可以好好休息呀，人生太难得有这么大短时间放假了，等找到工作就又要牛马了，所以在漫长的生活中，休息一下没什么的。</dd>
</dl>
<hr />
<p><strong>clear905:</strong></p>
<p>迷茫的时候就考公考编吧</p>
<hr />
<p><strong>writer002:</strong></p>
<p>不是，我研二，之后秋招打算都投一遍，哪里要我我去哪。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>直接空窗考公吗？</dd>
</dl>
<hr />
<p><strong>suping:</strong></p>
<p>是这样子的，看考哪里。老家肯定好考，我对老家和省会都还算熟悉，在考公这块，在的省会，据我所看，考上的大部分就是学历好的。当然，这玩意运气也有，但个人能力仍然重要也是真的</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯，好像也看是考哪里的吧？杭州的就特别卷，可能还要和清北的竞争，但是老家的可能稍微好点，就是待遇没那么好。</dd>
</dl>
<hr />
<p><strong>buptstudent:</strong></p>
<p>是的，住在家里父母确实挺让人有压力的，可以和他们说说自己的压力焦虑，让他们少说一下。然后也给他们说一下找工作的进展，让他们放宽心。ema3</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯，其实我开始一点都不焦虑。回老家之后我爸妈很焦虑，隔三差五说我为什么辞掉，怎么还没找工作。说的我开始非常焦虑了，她们比我更焦虑，因为我们家条件普通，可能我爸妈也担心我未来的路吧</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯，她们现在不说了，说没找到就没找到，因为我自己本身已经很焦虑了，她们反而让我不要焦虑，看开一点。但是我总是精神紧绷，半夜醒，害，所以我是易焦虑型</p>
<dl>
<dt>【 在 buptstudent 的大作中提到: 】</dt>
<dd>是的，住在家里父母确实挺让人有压力的，可以和他们说说自己的压力焦虑，让他们少说一下。然后也给他们说一下找工作的进展，让他们放宽心。</dd>
</dl>
<hr />
<p><strong>MaoFeng:</strong></p>
<p>想的太多，做的太少，我毕业后进大厂当码农和你完全一样的想法，工作了1年9个月后跳到央企了，以后不写代码了，大部分时间写写材料，写写公文，没有生产压力。如果怕技术荒废的话，可以自己学习学习，搞点项目做做，有底子知道流程啥样的，技术能捡起来的。</p>
<hr />
<p><strong>juda:</strong></p>
<p>这个太简单了，优先老家的要计算机相关专业的岗位撸一遍，没有的话就找几个喜欢的省份也用同样的选法看看，其实都差不多，都很香</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>问题是考哪里的公务员呢？初中同学都在老家干教师有事业编，她们的本科也一般，二本。但是感觉现在过的很滋润。我可能还是会在意外人的看法，所以说学历高一些，选择多有时候也会很迷茫。和学历不如自己的同学一样都在老家，感觉还是要调整自己的心态吧</dd>
</dl>
<hr />
<p><strong>vbbnnnm:</strong></p>
<p>其实也不用后悔，就算当时投了这些也很大概率拿不到offer。（我就是没拿到其中之一</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>您是硕士吗？听说一般是看最高学历的成绩单。好后悔挂科了，不然当时就可以看看烟草、电网、三桶油之类的国企了，但是其实我也有个疑惑就是家里条件普通没什么帮助，女生去这些企业的话生活过的会舒服吗？</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>北京央企吗？</p>
<dl>
<dt>【 在 MaoFeng 的大作中提到: 】</dt>
<dd>想的太多，做的太少，我毕业后进大厂当码农和你完全一样的想法，工作了1年9个月后跳到央企了，以后不写代码了，大部分时间写写材料，写写公文，没有生产压力。如果怕技术荒废的话，可以自己学习学习，搞点项目做做，有底子知道流程啥样的，技术能捡</dd>
</dl>
<p>起来的。</p>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯，哈哈哈</p>
<dl>
<dt>【 在 vbbnnnm 的大作中提到: 】</dt>
<dd>其实也不用后悔，就算当时投了这些也很大概率拿不到offer。（我就是没拿到其中之一</dd>
</dl>
<hr />
<p><strong>MaoFeng:</strong></p>
<p>对的</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>北京央企吗？</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>那这种考虑定居的么？北京央企待遇怎么样呀？不考虑买房，能舒服活着并且攒点钱么？央企是在哪里看的招聘信息呀</p>
<dl>
<dt>【 在 MaoFeng 的大作中提到: 】</dt>
<dd>对的</dd>
</dl>
<hr />
<p><strong>l6030:</strong></p>
<p>考公又不是一蹴而就的，有可能第一年不中，第二年才上岸的，没必要拉这么长的空窗期</p>
<p>先进个互联网公司，熬过最开始的适应期，后面一边挣着钱，一边考虑上岸的事情，这样心里压力也能小一点</p>
<p>互联网公司混日子的多了，大不了混几个月拿点赔偿走人呗，先上岸个国企，就有时间准备考公了</p>
<hr />
<p><strong>juda:</strong></p>
<p>那里那么容易，别人都全力以赴，虽然咱们学校的孩子学习能力很好，没好到那种兼职学学就行的</p>
<dl>
<dt>【 在 l6030 的大作中提到: 】</dt>
<dd>考公又不是一蹴而就的，有可能第一年不中，第二年才上岸的，没必要拉这么长的空窗期</dd>
<dd>先进个互联网公司，熬过最开始的适应期，后面一边挣着钱，一边考虑上岸的事情，这样心里压力也能小一点</dd>
</dl>
<hr />
<p><strong>abert:</strong></p>
<p>先练练阅读理解吧。高高在上起了个头，后给三岁小孩能搜出的烂大街回答。</p>
<dl>
<dt>【 在 suping 的大作中提到: 】</dt>
<dd>通篇看下来，智商高、情商低、性格一般、身体素质不行</dd>
<dd>大部分人每天的状态：由里到外和工作息息相关，我不觉得私企会是你的终点</dd>
</dl>
<hr />
<p><strong>l6030:</strong></p>
<p>嗯嗯，您说的很对，我就是入职半年换了老板，就开始很难受很内耗了。所以现在的思路是互联网面试按部就班，然后找到工作了，在工作里准备国企的面试和信息搜集（确定目标范围有哪些，待遇情况什么的），到了国企之后再准备公务员上岸。这个思路很合适。</p>
<p>此外我也有些疑惑，就是如果没有一线城市的户口的话，同时家境没什么支持，留在一线城市的国企的出路是什么呢？找个一起在一线城市奋斗的对象吗？（之前自己是有想过32攒够七位数存款，然后可以fire，过低物欲生活的，这种没考虑对象的情况，因为目前单身）</p>
<p>其实你得想想，你最终的目标是什么？如果是回家乡考公务员的话，那无论是国企还是互联网，都只是你考公的跳板而已，如果你能顺利考公回家，那就不需要考虑一线国企的出路问题。你想想，你考公面试的时候，空窗期太长，你不得解释解释，另外，考公期间自己能挣钱养活自己，压力不也小一点吗。如果你考公不顺利，没办法回家，那互联网也不会是你的归宿，相信我，30多岁的时候，你只会更加想逃离互联网。一线城市现在的房价也没那么高了，两个人奋斗几年，两边家里支持一下，凑个首付没那么难，当然户口就比较难办了，但也只是影响孩子高考吧。当然，最好的还是找个二线城市或者家乡的国企，不过机会就比较少了。国企的机会，有的时候运气的成分比较大，可能碰巧开了招聘，只为适合你，领导对你又有眼缘，就进去了，你自己要多留心，论坛或者招聘网站的招聘信息，多跟师兄师姐或者朋友打听打听，不要错误机会。</p>
<hr />
<p><strong>wywwt:</strong></p>
<p>“楼主研究生当时的职业规划大概是互联网大厂，然后互联网大厂/外企，最后是32岁左右国企/事业单位/公务员上岸躺平（因为怕一次考不上，留一点余地）”感觉这是去互联网人大多数的规划和归宿？大家都是一样的，都一样会因为没有晋升迷茫焦虑</p>
<hr />
<p><strong>royma520:</strong></p>
<p>最终的目标是找个地方躺平，那种房价不高适合养老的地方，山清水秀慢节奏的，可以是家乡</p>
<dl>
<dt>【 在 l6030 的大作中提到: 】</dt>
<dd>其实你得想想，你最终的目标是什么？如果是回家乡考公务员的话，那无论是国企还是互联网，都只是你考公的跳板而已，如果你能顺利考公回家，那就不需要考虑一线国企的出路问题。你想想，你考公面试的时候，空窗期太长，你不得解释解释，另外，考公期间自己能挣钱养活自己，压力不也小一点吗。如果你考公不顺利，没办法回家，那互联网也不会是你的归宿，相信我，30多岁的时候，你只会更加想逃离互联网。一线城市现在的房价也没那么高了，两个人奋斗几年，两边家里支持一下，凑个首付没那么难，当然户口就比较难办了，但也只是影响孩子高考吧。当然，最好的还是找个二线城市或者家乡的国企，不过机会就比较少了。国企的机会，有的时候运气的成分比较大，可能碰巧开了招聘，只为适合你，领导对你又有眼缘，就进去了，你自己要多留心，论坛或者招聘网站的招聘信息，多跟师兄师姐或者朋友打听打听，不要错误机会。</dd>
</dl>
<hr />
<p><strong>bekbek:</strong></p>
<p>楼主还能有个规划，我现在对自己未来完全没规划，走一步看一步，一直在摇摆不定</p>
<p>【 在 l6030 的大作中提到: 】</p>
<hr />
<p><strong>xuhaobupt:</strong></p>
<p>积极寻求建议是好的，但是哪有什么最优解，最重要的还是转变心态吧，楼主老是纠结于挂科，空窗，是按部就班上学的完美主义情结，这都毕业多久，哪还会有人拿着放大镜纠结你成绩单啊，不学着接受国企未必比互联网环境好，扯皮甩锅的事也很多，放低预期+厚脸皮</p>
<hr />
<p><strong>halfimmortal:</strong></p>
<p>出国读个水硕</p>
<hr />
<p><strong>b5702906:</strong></p>
<p>那些都是话术 没有那么急的</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>那些 hr 都各个急得不得了，恨不得本周就面试，感觉延长时间的话也有风险，说不定 hc 就没了（我同学说）有个 hr 也说尽快</dd>
</dl>
<hr />
<p><strong>rasp6erry:</strong></p>
<p>我研究生也被亲师姐挂了一门 完全不影响找工作的 国企有的其实不会细看你的研究生成绩 你就尽管投就行了 多试试总有机会的</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>但我担心会看成绩单，研究生挂科了</dd>
</dl>
<hr />
<p><strong>starever99:</strong></p>
<p>楼主这两年在杭州的生活是啥样的，我也是马上毕业去杭州阿里，那边也没什么朋友 em13</p>
<hr />
<p><strong>suping:</strong></p>
<p>好的，谢谢指导</p>
<dl>
<dt>【 在 abert 的大作中提到: 】</dt>
<dd>先练练阅读理解吧。高高在上起了个头，后给三岁小孩能搜出的烂大街回答。</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>就每天睁开眼就是上班，下班之后玩手机，睡觉，周末宅家里。日复一日，看不到尽头</p>
<dl>
<dt>【 在 starever99 的大作中提到: 】</dt>
<dd>楼主这两年在杭州的生活是啥样的，我也是马上毕业去杭州阿里，那边也没什么朋友</dd>
</dl>
<hr />
<p><strong>naginoa:</strong></p>
<p>学姐怎么 21 届本硕北邮 现在才 26 啊！ 我 22 届 现在 27  97 年</p>
<hr />
<p><strong>royma520:</strong></p>
<p>我也 97 年，没过生日，就没到 27，但是快了</p>
<dl>
<dt>【 在 naginoa 的大作中提到: 】</dt>
<dd>学姐怎么 21 届本硕北邮 现在才 26 啊！ 我 22 届 现在 27  97 年</dd>
</dl>
<hr />
<p><strong>naginoa:</strong></p>
<p>早上学一年！</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>我也 97 年，没过生日，就没到 27，但是快</dd>
</dl>
<p>了</p>
<hr />
<p><strong>duka:</strong></p>
<p>和我一样 担心这担心那 ema1</p>
<hr />
<p><strong>ww43:</strong></p>
<p>哥们不了解就别乱说，考公面试解释啥空窗期，考公面试是双盲结构化</p>
<p>【 在 l6030 的大作中提到: 】</p>
<hr />
<p><strong>ww43:</strong></p>
<p>只从考公的角度说，楼主如果走这条路，其实不用担心一年考不上得第二年，因为看楼主描述似乎不必须在江西，所以一年考公考编的机会少说有 20 次，而且不限应届的人才引进也有挺多的</p>
<hr />
<p><strong>szmrz123:</strong></p>
<p>一摸一样的生活 ema1</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>就每天睁开眼就是上班，下班之后玩手机，睡觉，周末宅家里。日复一日，看不到尽头</dd>
</dl>
<hr />
<p><strong>qwe245347444:</strong></p>
<p>国企不合适，1、非应届生身份，进的国企可能是坑。2、性格不合适，情商不够，不会跪舔领导。3、不在北京，地方上的国企少外加关系网更复杂。</p>
<p>互联网不合适，1、已经试过了，身心饱受摧残。2、gap 时间快赶上工作年限了，公司会比较介意。3、互联网行业整体发展也到了一个饱和期了，硬挤上车没必要。</p>
<p>体制内可以，1、智商高，方便刷题过笔试。2、可以表现短期的社交属性，适合短期强化通过面试。3、体制内下限高，各管一摊，不求进步，完成工作，没人能 pua 你。</p>
<p>个人建议全身心准备体制内的求职。1、国考考苏杭。2、江苏省考考苏州、浙江省考考杭州、江西省考考老家，如果时间冲突择一选择。3、江苏浙江江西事业编考试。4、江西专科或中学老师、苏杭中学老师，中学信息技术课老师有编清闲。5、医院信息科。以上考试基本集中于 11 月-5 月，然后面试集中于 6 月-10 月，一年都有事干。</p>
<hr />
<p><strong>zmaomao:</strong></p>
<p>过两个月会发现，现在纠结的都不是问题，加油</p>
<hr />
<p><strong>wqsnlzxq:</strong></p>
<p>看的人着急。1.我的建议直接江西公务员，你户口在杭州有啥用，你亲戚朋友在杭州吗?不在的话你考上了不还是自己一个人孤独?去江西考上了下班亲戚朋友一堆不好吗，刚好治愈你 i 性格。2.成绩单挂科。你该投就投，挂科就挂科，挂科了难道 hr 还打电话通知你说你因为挂科了不能来我们公司然后顺便羞辱你一番?如果不是那有什么关系，你收到笔试面试了，就证明你这家公司不看重你的挂科了。3.反复提空窗期，说实话九个月空窗期和十个月有啥区别，你自己反复在意的空窗期，多少一个月在 hr 眼里很重要?4.不能卷没有内驱力就建议一步到位直接躺平，别想什么杭州和钱的事，先直接老家公务员干三五年，把你身体养好，把结婚生孩子这些事该办都办了，五年后十年后看看经济好不好，好了再辞职出来干。说实话公务员钱再低难道养活不了你吗?5.最核心得一点，别想着既要还要，钱，工作地， wlb，发展，别人的眼光 balabala，你能兼顾两个已经是十分难得的了，那么老家公务员兼顾和 wlb 和亲戚朋友近，可以满足心里需求，不回去等啥呢?(别惦记你那 b 杭州户口了，p 用没有，你能拿一次，等你休养生息几年回来也能再拿)</p>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！思路太清晰啦，非常感谢！想问下，如果去北京上海的国企央企是否可行呢？</p>
<dl>
<dt>【 在 qwe245347444 的大作中提到: 】</dt>
<dd>国企不合适，1、非应届生身份，进的国企可能是坑。2、性格不合适，情商不够，不会跪舔领导。3、不在北京，地方上的国企少外加关系网更复杂。</dd>
<dd>互联网不合适，1、已经试过了，身心饱受摧残。2、gap 时间快赶上工作年限了，公司会比较介意。3、互联网行业整体发展也到了一个饱和期了，硬挤上车没必要。</dd>
<dd>体制内可以，1、智商高，方便刷题过笔试。2、可以表现短期的社交属性，适合短期强化通过面试。3、体制内下限高，各管一摊，不求进步，完成工作，没人能 pua 你。</dd>
<dd>个人建议全身心准备体制内的求职。1、国考考苏杭。2、江苏省考考苏州、浙江省考考杭州、江西省考考老家，如果时间冲突择一选择。3、江苏浙江江西事业编考试。4、江西专科或中学老师、苏杭中学老师，中学信息技术课老师有编清闲。5、医院信息科。以上考试基本集中于 11 月-5 月，然后面试集中于 6 月-10 月，一年都有事干。</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>是的，不必在江西。人才引进具体是干什么呢？其实我就知道这个概念，但是引进之后具体是干啥也是一头雾水</p>
<dl>
<dt>【 在 ww43 的大作中提到: 】</dt>
<dd>只从考公的角度说，楼主如果走这条路，其实不用担心一年考不上得第二年，因为看楼主描述似乎不必须在江西，所以一年考公考编的机会少说有 20 次，而且不限应届的人才引进也有挺多的</dd>
</dl>
<hr />
<p><strong>Jeanrry:</strong></p>
<p>同感，只要足够没有眼力见，所谓的这些“潜规则”就不能伤你分毫 emb10emb10</p>
<dl>
<dt>【 在 cccoco (哎呀我去) 的大作中提到: 】</dt>
<dd>“之前对办公室政治挺迟钝的，后面经过一个男同事给我疯狂点拨，我才拨云见雾察觉出这里面的风起云涌”</dd>
<dd>钝感力其实就是种能力，这个点拨真的不要也罢。你在旋涡边上看旋涡，其实就是一个小酒窝，当风景就好，底下的暗涌又与你何干呢？如果是我，我可能会在以后的工作中避免接受这种“点拨”。</dd>
<dd>不受力就是最大的助力！楼主加油</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！谢谢你的建议！我 i 人真的很需要有人陪，一个人很孤独，希望能有熟人多的地方。北京的话同学多，老家的话可以有亲人在。那其实思路很清晰，我不想去互联网卷，是否应该推掉互联网的面试呢？因为现在实在是没什么心思准备</p>
<dl>
<dt>【 在 wqsnlzxq 的大作中提到: 】</dt>
<dd>看的人着急。1.我的建议直接江西公务员，你户口在杭州有啥用，你亲戚朋友在杭州吗?不在的话你考上了不还是自己一个人孤独?去江西考上了下班亲戚朋友一堆不好吗，刚好治愈你 i 性格。2.成绩单挂科。你该投就投，挂科就挂科，挂科了难道 hr 还打电话通知你说你因为挂科了不能来我们公司然后顺便羞辱你一番?如果不是那有什么关系，你收到笔试面试了，就证明你这家公司不看重你的挂科了。3.反复提空窗期，说实话九个月空窗期和十个月有啥区别，你自己反复在意的空窗期，多少一个月在 hr 眼里很重要?4.不能卷没有内驱力就建议一步到位直接躺平，别想什么杭州和钱的事，先直接老家公务员干三五年，把你身体养好，把结婚生孩子这些事该办都办了，五年后十年后看看经济好不好，好了再辞职出来干。说实话公务员钱再低难道养活不了你吗?5.最核心得一点，别想着既要还要，钱，工作地， wlb，发展，别人的眼光 balabala，你能兼顾两个已经是十分难得的了，那么老家公务</dd>
</dl>
<p>员兼顾和 wlb 和亲戚朋友近，可以满足心里需求，不回去等啥呢?(别惦记你那 b 杭州户口了，p 用没有，你能拿一次，等你休养生息几年回来也能再拿)</p>
<hr />
<p><strong>wqsnlzxq:</strong></p>
<p>让你焦虑内耗的事情，该拒就拒了吧。实在不甘心可以留下一两家试试，要是面的一塌糊涂就更证明你不适合这行了，也能彻底断了你的念想，安心准备考公</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯！谢谢你的建议！我 i 人真的很需要有人陪，一个人很孤独，希望能有熟人多的地方。北京的话同学多，老家的话可以有亲人在。那其实思路很清晰，我不想去互联网卷，是否应该推掉互联网的面试呢？因为现在实在是没什么心思准备</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！很有道理</p>
<dl>
<dt>【 在 wqsnlzxq 的大作中提到: 】</dt>
<dd>让你焦虑内耗的事情，该拒就拒了吧。实在不甘心可以留下一两家试试，要是面的一塌糊涂就更证明你不适合这行了，也能彻底断了你的念想，安心准备考公</dd>
</dl>
<hr />
<p><strong>landeng:</strong></p>
<p>考公国企</p>
<hr />
<p><strong>leiky:</strong></p>
<p>你适合考博，博士毕业去老家的高校！</p>
<hr />
<p><strong>qwe245347444:</strong></p>
<p>不建议，因为对比体制内，北京上海的国企对于你来说是次选方案<br />
进入体制内方便你买房结婚生娃<br />
再去一线城市奋斗有点晚了，即使能找到好坑，也要面对高房价高生育成本的问题</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯！思路太清晰啦，非常感谢！想问下，如果去北京上海的国企央企是否可行呢？</dd>
</dl>
<hr />
<p><strong>wojiushiID:</strong></p>
<p>同 21，第一段话以为在说我自己，没有勇气裸辞，还在挣扎 ema1</p>
<hr />
<p><strong>royma520:</strong></p>
<p>后悔当时没直博了，哭，当时我亲戚也说我读个博士，然后去老家的大专院校，很舒服，有关系。现在时间成本年龄成本在这里了</p>
<dl>
<dt>【 在 leiky 的大作中提到: 】</dt>
<dd>你适合考博，博士毕业去老家的高校！</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>体制内一定是老家体制内吗？我妈的意思是我先找个班上，想考公上班的时候考</p>
<dl>
<dt>【 在 qwe245347444 的大作中提到: 】</dt>
<dd>不建议，因为对比体制内，北京上海的国企对于你来说是次选方案</dd>
<dd>进入体制内方便你买房结婚生娃</dd>
<dd>再去一线城市奋斗有点晚了，即使能找到好坑，也要面对高房价高生育成本的问题</dd>
</dl>
<hr />
<p><strong>qwe245347444:</strong></p>
<p>注意审题，我已经说了江苏浙江江西的体制内，至于没有说北京上海的体质内，一是钱少，二是房价高<br />
先找个班上的目的在于有养活自己的能力，但是你之前互联网工作有积蓄。如果找个很一般的工作，浪费了白天复习的时间，如果找个还不错的工作，既需要付出较大的精力准备，还需要在工作中付出较多时间。<br />
在家备考一年的好处在于精力集中，即使一年下来十几个机会都没上岸，也基本熟悉了相关流程和内容，这个时候再找个一般的工作，在职备考比较好</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>体制内一定是老家体制内吗？我妈的意思是我先找个班上，想考公上班的时候考</dd>
</dl>
<hr />
<p><strong>juda:</strong></p>
<p>那是我们那时候可以，你们现在也不好留了，除非跟的老师是大牛，你的性格估计也不讨喜，挺难的。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>后悔当时没直博了，哭，当时我亲戚也说我读个博士，然后去老家的大专院校，很舒服，有关系。现在时间成本年龄成本在这里了</dd>
</dl>
<hr />
<p><strong>leiky:</strong></p>
<p>可以读个韩国 泰国这种，成本小，容易毕业！</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>后悔当时没直博了，哭，当时我亲戚也说我读个博士，然后去老家的大专院校，很舒服，有关系。现在时间成本年龄成本在这里了</dd>
</dl>
<hr />
<p><strong>Hulkchan:</strong></p>
<p>。。莫名其妙就保研了，看来你的智商确实高，啥都不喜欢，但是啥都能干好 😂🌚，加油，感觉以你的水平找个国企不是难事</p>
<hr />
<p><strong>liangkeng:</strong></p>
<p>别给自己太大压力，人生不是只有持续往前一条路。你调整了这么久，还是这么抗拒这些工作，不如换思路转行。养活自己即可。当然不想转行，可以试试其他公司，你这个背景找份工作还是简单的。面试通过其实跟你的能力没啥关系不大，社招进去正常能干活就可以了，找太厉害了…领导也怕对原有组织架构冲击太大…每个人都有属于自己的位置，认清即可</p>
<hr />
<hr />
<p><strong>royma520:</strong></p>
<p>其他公司我看面试也要3轮技术面试+刷题，我啥都没太弄好，是不是就g了。</p>
<dl>
<dt>【 在 liangkeng 的大作中提到: 】</dt>
<dd>别给自己太大压力，人生不是只有持续往前一条路。你调整了这么久，还是这么抗拒这些工作，不如换思路转行。养活自己即可。当然不想转行，可以试试其他公司，你这个背景找份工作还是简单的。面试通过其实跟你的能力没啥关系不大，社招进去正常能干活就可以了，找太厉害了…领导也怕对原有组织架构冲击太大…每个人都有属于自己的位置，认清即可</dd>
</dl>
<hr />
<p><strong>whywhywhy7:</strong></p>
<p>21年毕业工作三年才26。。我今年硕士毕业也26ema1</p>
<hr />
<p><strong>royma520:</strong></p>
<p>读书读的早一年而已，现在不也gap了么，相当于也停滞了</p>
<dl>
<dt>【 在 whywhywhy7 的大作中提到: 】</dt>
<dd>21年毕业工作三年才26。。我今年硕士毕业也26</dd>
</dl>
<hr />
<p><strong>AXXE:</strong></p>
<p>我也女生，跟你性格有些像，但是技术没你强。今年毕业，选择回家乡找个轻松点的工作。在北邮这么多年，我也看明白自己对技术是既没热情也没天赋，不想死磕到底了，索性换条路。</p>
<hr />
<p><strong>royma520:</strong></p>
<p>回家乡么？不考虑北京国企央企么？</p>
<dl>
<dt>【 在 AXXE 的大作中提到: 】</dt>
<dd>我也女生，跟你性格有些像，但是技术没你强。今年毕业，选择回家乡找个轻松点的工作。在北邮这么多年，我也看明白自己对技术是既没热情也没天赋，不想死磕到底了，索性换条路。</dd>
</dl>
<hr />
<p><strong>ww43:</strong></p>
<p>人才引进其实就是事业编，不过是针对双一流的，容易考，很多都是没有笔试，只有面试，至于考上之后工作都是一样的，就是正常事业单位</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>是的，不必在江西。人才引进具体是干什么呢？其实我就知道这个概念，但是引进之后具体是干啥也是一头雾水</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>哦哦，好的！谢谢解答！</p>
<dl>
<dt>【 在 ww43 的大作中提到: 】</dt>
<dd>人才引进其实就是事业编，不过是针对双一流的，容易考，很多都是没有笔试，只有面试，至于考上之后工作都是一样的，就是正常事业单位</dd>
</dl>
<hr />
<p><strong>lorder:</strong></p>
<p>老哥你有飞蚊症吗？</p>
<dl>
<dt>【 在 ws1025336322 的大作中提到: 】</dt>
<dd>
<p>优柔寡断，还敏感。你为什么“担心会要成绩单，就不投了”呢？投了能咋滴？就算被拒绝了，能咋滴？能怎么样！你这跟担心被拒绝就不表白很像啊emb13 你自己也知道行动力不行，又没有自驱力，为啥不尝试做出改变呢？择其善者而从之，其不善者而改之。总不能是拖延症把“要改掉拖延症”的行动给拖延了吧emb23</p>
</dd>
<dd>
<p>工作的方向，我给不了啥建议，如果是我的话，我应该会调整心态投一波国企，没戏就继续互联网，工作期间挤时间准备考公的东西。</p>
</dd>
</dl>
<hr />
<p><strong>AXXE:</strong></p>
<p>不考虑。在北京不知道漂到哪年才能定居，压力太大了，受不了这种生活。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>回家乡么？不考虑北京国企央企么？</dd>
</dl>
<hr />
<p><strong>yvonne1997:</strong></p>
<p>姐妹，我老家也江西。我没你那么优秀，我研究生才考来北邮的。我们同龄，但我晚你一届。</p>
<p>我看你的帖子我发现人和人真的非常不一样，比如我对去国企之类的公司不咋感兴趣，却非常佩服去大厂的同学，觉得他们技术能力很强，而我也希望自己是个技术能力很强的人。</p>
<p>毕业后我去了外企。说实话老板很好，工作很轻松，工资也还不错，但我还是无可避免地陷入了深不见底的内耗。我想不明白自己要什么，感觉做什么都没有意义，很难快乐起来。</p>
<p>这两年来我一直在尝试自救，没有什么工作或者一些隶属社会价值体系的进步。但其实我自己知道，我真的比以前快乐多了。我的依恋类型，从高焦虑，变成低回避，再变成安全型。我花费了很多努力，做了很多尝试，现在也在不断地学习和练习。</p>
<p>所以姐妹，我想说的是，我觉得你的问题其实在于，不应该认为一份工作或是一份感情就足以拯救当下的自己。不是的，真正能救自己的只有自己。</p>
<p>只有真正接纳自己，才能知道什么是自己需要的，才能获得它们。我花了很多时间去理解和践行这句话。</p>
<p>人生其实不会有什么比快乐重要，而有些事情，只是你以为能给你提供快乐罢了。记得好好休息，推荐《当下的力量》，这本书给了我很大的帮助。祝好。</p>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！我也觉得“工资也还不错，但我还是无可避免地陷入了深不见底的内耗。我想不明白自己要什么，感觉做什么都没有意义，很难快乐起来。”这个就是我当时的心态，觉得很虚无，生活日复一日，不知道自己想要什么。所以其实不是工作的问题吗？</p>
<dl>
<dt>【 在 yvonne1997 的大作中提到: 】</dt>
<dd>
<p>姐妹，我老家也江西。我没你那么优秀，我研究生才考来北邮的。我们同龄，但我晚你一届。</p>
</dd>
<dd>
<p>我看你的帖子我发现人和人真的非常不一样，比如我对去国企之类的公司不咋感兴趣，却非常佩服去大厂的同学，觉得他们技术能力很强，而我也希望自己是个技术能力很强的人。</p>
</dd>
<dd>
<p>毕业后我去了外企。说实话老板很好，工作很轻松，工资也还不错，但我还是无可避免地陷入了深不见底的内耗。我想不明白自己要什么，感觉做什么都没有意义，很难快乐起来。</p>
</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>哦哦！也是哦，有种漂泊感</p>
<dl>
<dt>【 在 AXXE 的大作中提到: 】</dt>
<dd>不考虑。在北京不知道漂到哪年才能定居，压力太大了，受不了这种生活。</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>我没毕业前很佩服去大厂的同学，但是我经历过了之后，觉得周围的人都很厉害，对技术很有热情，我好像很菜，而且也不是那么有驱动力去学习，就还挺痛苦</p>
<dl>
<dt>【 在 yvonne1997 的大作中提到: 】</dt>
<dd>
<p>姐妹，我老家也江西。我没你那么优秀，我研究生才考来北邮的。我们同龄，但我晚你一届。</p>
</dd>
<dd>
<p>我看你的帖子我发现人和人真的非常不一样，比如我对去国企之类的公司不咋感兴趣，却非常佩服去大厂的同学，觉得他们技术能力很强，而我也希望自己是个技术能力很强的人。</p>
</dd>
<dd>
<p>毕业后我去了外企。说实话老板很好，工作很轻松，工资也还不错，但我还是无可避免地陷入了深不见底的内耗。我想不明白自己要什么，感觉做什么都没有意义，很难快乐起来。</p>
</dd>
</dl>
<hr />
<p><strong>Biden2028:</strong></p>
<p>别的先不说我是第一次听说有人因为研究生挂科担心影响找工作了，HR肯定知道理工科研究生的课就是凑个学分的，</p>
<p>我觉得你是担心的太多了，不过这都过去了，对你现在来说的话北邮本硕+大厂经历工作肯定好找，多点自信肯定没问题</p>
<hr />
<p><strong>buptchy:</strong></p>
<p>外企就是我羡慕的生活 有啥内耗的</p>
<dl>
<dt>【 在 yvonne1997 的大作中提到: 】</dt>
<dd>
<p>姐妹，我老家也江西。我没你那么优秀，我研究生才考来北邮的。我们同龄，但我晚你一届。</p>
</dd>
<dd>
<p>我看你的帖子我发现人和人真的非常不一样，比如我对去国企之类的公司不咋感兴趣，却非常佩服去大厂的同学，觉得他们技术能力很强，而我也希望自己是个技术能力很强的人。</p>
</dd>
<dd>
<p>毕业后我去了外企。说实话老板很好，工作很轻松，工资也还不错，但我还是无可避免地陷入了深不见底的内耗。我想不明白自己要什么，感觉做什么都没有意义，很难快乐起来。</p>
</dd>
</dl>
<hr />
<p>**q1932363919</p>
<p>😗*</p>
<p>我自己的规划还是干到30上岸公务员或者北京央企国企 这么说我没有你这么i</p>
<hr />
<p><strong>jellyfish:</strong></p>
<p>楼主写的很谦虚，但感觉能力应该很强，不喜欢也能做到计院保研+大厂暑期大厂工作</p>
<hr />
<p><strong>dandelion5:</strong></p>
<p>按楼主的个性和心态，进了体制内估计也要难受</p>
<hr />
<p><strong>royma520:</strong></p>
<p>呜呜，就是担心这样</p>
<dl>
<dt>【 在 dandelion5 的大作中提到: 】</dt>
<dd>按楼主的个性和心态，进了体制内估计也要难受</dd>
</dl>
<hr />
<p><strong>axing:</strong></p>
<p>首先排除互联网，你一个女生，挣那么多钱干啥呢。说难听点，我是你，不如多去扩大自己的社交圈子，结识新朋友，如果有男朋友，你就轻松一些（没有把男同胞们当成提款机的意思），如果你一个人生活，那够自己吃喝玩乐就行了，这么逼自己干啥呢</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>
<p>楼主北邮本硕，21届女生，目前26，马上快27了，都是计算机专业，感觉不是很喜欢写代码，上大学之后就挺迷茫的，就是按部就班学习然后莫名其妙的拿到了保研资格，当时…</p>
</dd>
<dd>
<pre><code>   入职之后发现都不太会，基础不好（因为是暑期实习前几个月才决定找前端工作，所以速成学习了两三个月，加上实验室做了前端项目，当时是直接就很容易上手了，...
</code></pre>
</dd>
</dl>
<hr />
<p><strong>sapling:</strong></p>
<p>bd</p>
<hr />
<p><strong>fancyli:</strong></p>
<p>咋感觉应该先找对象呢</p>
<hr />
<p><strong>ynlyxy:</strong></p>
<p>学姐你已经很优秀了！不要纠结，不要焦虑，你自己开心就行了啊！你的学习能力那么强，只要定好了目标，努力肯定可以实现。工作不分好坏，自己喜欢就是最好的。至于亲戚朋友闲言碎语都无所谓，日子是自己的，身体也是自己的。加油！！</p>
<hr />
<p><strong>royma520:</strong></p>
<p>说的也是，哭哭，因为之前老觉得要靠自己，自己婚前买房啥的</p>
<dl>
<dt>【 在 axing 的大作中提到: 】</dt>
<dd>首先排除互联网，你一个女生，挣那么多钱干啥呢。说难听点，我是你，不如多去扩大自己的社交圈子，结识新朋友，如果有男朋友，你就轻松一些（没有把男同胞们当成提款机的意思），如果你一个人生活，那够自己吃喝玩乐就行了，这么逼自己干啥呢</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！我妈也说我自己过得好就行了，不要管别人怎么说</p>
<dl>
<dt>【 在 ynlyxy 的大作中提到: 】</dt>
<dd>学姐你已经很优秀了！不要纠结，不要焦虑，你自己开心就行了啊！你的学习能力那么强，只要定好了目标，努力肯定可以实现。工作不分好坏，自己喜欢就是最好的。至于亲戚朋友闲言碎语都无所谓，日子是自己的，身体也是自己的。加油！！</dd>
</dl>
<hr />
<p><strong>kezhifeng:</strong></p>
<p>看完了，说下感受和建议</p>
<p>你和我是一大类人，外表看起来也不那么内向，特定场合甚至可以很外向，实际上是慢热的，相处久了才能做朋友，才会关系顺畅</p>
<p>我们对自己要求相对较高，会给自己设立能力匹配值，不达到某个水平似乎就不够称职，其实就是自己卷自己</p>
<p>这样的我们，对于社会是典型的牛马，还会错失很多机会，机会不是留给有准备的人，而是留给敢于拼和闯的人，你准备好了，机会要么溜走了，要么形势已经变了，这不是说准备不重要，而是在强调不要顾虑那么多，试了再说，拿到一手的反馈，有目的地准备和调整。</p>
<p>为什么你觉得自己表现一般，boss却说不错，因为你没他看的全面，其实你已经很卷了。</p>
<p>你在迷茫要往何处去，其实不止一个人，大家都是在边走边看。你还年轻，底子也好，你觉得哪个有戏就去尝试，也不要怕空窗期，国企并没有那么看重，尤其是在现在这种环境</p>
<p>按照性格来说，专注在做事而非做人的企业好过一点，建议去稍微市场化一些国企吧</p>
<p>事业单位也行，只是产出可能没人在意</p>
<p>有时候脸皮厚一点，别那么卷自己了，卷下自己的健康吧</p>
<hr />
<p><strong>royma520:</strong></p>
<p>是的，就是我老板也说过两次，说我对自己要求太高了</p>
<dl>
<dt>【 在 kezhifeng 的大作中提到: 】</dt>
<dd>
<p>看完了，说下感受和建议</p>
</dd>
<dd>
<p>你和我是一大类人，外表看起来也不那么内向，特定场合甚至可以很外向，实际上是慢热的，相处久了才能做朋友，才会关系顺畅</p>
</dd>
<dd>
<p>我们对自己要求相对较高，会给自己设立能力匹配值，不达到某个水平似乎就不够称职，其实就是自己卷自己</p>
</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>您说的很对，我的性格确实就是这样，很慢热，朋友很少</p>
<dl>
<dt>【 在 kezhifeng 的大作中提到: 】</dt>
<dd>
<p>看完了，说下感受和建议</p>
</dd>
<dd>
<p>你和我是一大类人，外表看起来也不那么内向，特定场合甚至可以很外向，实际上是慢热的，相处久了才能做朋友，才会关系顺畅</p>
</dd>
<dd>
<p>我们对自己要求相对较高，会给自己设立能力匹配值，不达到某个水平似乎就不够称职，其实就是自己卷自己</p>
</dd>
</dl>
<hr />
<p><strong>Forsun:</strong></p>
<p>有人的地方就有江湖啊，去哪里工作都一样，人心叵测，不仅仅是体制内，涉及利益就涉及勾心斗角。我感觉楼主把社会太理想化了，好好干活就行了</p>
<hr />
<p><strong>Forsun:</strong></p>
<p>有大厂经历，建议找银行IT岗</p>
<hr />
<p><strong>royma520:</strong></p>
<p>哪里的银行 IT 岗呀？这种是在指定银行公众号上看吗</p>
<dl>
<dt>【 在 Forsun 的大作中提到: 】</dt>
<dd>有大厂经历，建议找银行IT岗</dd>
</dl>
<hr />
<p><strong>Forsun:</strong></p>
<p>宁波银行、南京银行、兴业总行（江西人可以考虑来福州？）等等的科技岗位有招前端的，可以去银行官网去看看哈，我感觉很适合楼主的，既然学习能力有，就当一份谋生的技能就好，工资虽然比大厂差点，但胜在稳定</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>哪里的银行 IT 岗呀？这种是在指定银行公众号上看吗</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯，我喜欢偏安一隅，不喜欢斗争</p>
<dl>
<dt>【 在 Forsun 的大作中提到: 】</dt>
<dd>有人的地方就有江湖啊，去哪里工作都一样，人心叵测，不仅仅是体制内，涉及利益就涉及勾心斗角。我感觉楼主把社会太理想化了，好好干活就行了</dd>
</dl>
<hr />
<p><strong>kezhifeng:</strong></p>
<p>其实也没什么，首先得接受这样的自己，其次如果有很强的意愿，也是可以改变自己</p>
<p>我的朋友圈都关了好多年了，我不发也不看，过年的时候逐个聊聊近况</p>
<p>我反正没有太强烈的物质欲望，属于被社会洪流卷着走，太穷了就没法正常生活，不能太穷，仅此而已</p>
<p>这一点上，也没必要与同龄人分高下</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>您说的很对，我的性格确实就是这样，很慢热，朋友很少</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>我也是关了朋友圈</p>
<dl>
<dt>【 在 kezhifeng 的大作中提到: 】</dt>
<dd>
<p>其实也没什么，首先得接受这样的自己，其次如果有很强的意愿，也是可以改变自己</p>
</dd>
<dd>
<p>我的朋友圈都关了好多年了，我不发也不看，过年的时候逐个聊聊近况</p>
</dd>
<dd>
<p>我反正没有太强烈的物质欲望，属于被社会洪流卷着走，太穷了就没法正常生活，不能太穷，仅此而已</p>
</dd>
</dl>
<hr />
<p><strong>hxhlf:</strong></p>
<p>借楼问一下，小东西和lz性格、家庭都差不多，不过是本科生，感觉以后自己去了互联网或国企也会常常内耗，也在思考未来是考公还是考研还是去离家近的运营商，学长学姐们有什么建议吗</p>
<hr />
<p><strong>WatchingU:</strong></p>
<p>我觉得都可以尝试，在尝试的过程中可能路就清晰了</p>
<dl>
<dt>【 在 hxhlf 的大作中提到: 】</dt>
<dd>借</dd>
</dl>
<p>楼问一下，小东西和lz性格、家庭都差不多，不过是本科生，感觉以后自己去了互联网或国企也会常常内耗，也在思考未来是考公还是考研还是去离家近的运营商，学长学姐们有什么建议吗</p>
<hr />
<p><strong>royma520:</strong></p>
<p>这种也算是国企么？干一辈子？</p>
<dl>
<dt>【 在 Forsun 的大作中提到: 】</dt>
<dd>宁波银行、南京银行、兴业总行（江西人可以考虑来福州？）等等的科技岗位有招前端的，可以去银行官网去看看哈，我感觉很适合楼主的，既然学习能力有，就当一份谋生的技能就好，工资虽然比大厂差点，但胜在稳定</dd>
</dl>
<hr />
<p><strong>tar:</strong></p>
<p>江西老家国企，年包17，20w不到，年节福利。</p>
<hr />
<p><strong>tar:</strong></p>
<p>如果高敏，且抗压能力差。 选老家吧，人生苦短，找适合自己的工作</p>
<hr />
<p><strong>tar:</strong></p>
<p>坚决拒掉互联网及狼性文化的公司。</p>
<hr />
<p><strong>lorder:</strong></p>
<p>6</p>
<hr />
<p><strong>whiisper:</strong></p>
<p>挂科和进国企关系不大吧？感觉楼主的性格更适合国企躺</p>
<hr />
<p><strong>chuben:</strong></p>
<p>小妹妹是典型的【问题多】的好女孩。其实可以把自己担心的问题写在一张纸上，把自己放空一下，理性务实地思考。其实很多都是自己和自己过不去，人要学会自己放过自己，自己才会放过别人，放过社会。   人际关系的本质是自己和自己的关系。</p>
<hr />
<p><strong>getIt:</strong></p>
<p>考公去吧，你不适合互联网！体制内完美匹配啊！</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>楼主北邮本硕，21届女生，目前26，马上快27了，都是计算机专业，感觉不是很喜欢写代码，上大学之后就挺迷茫的，就是按部就班学习然后莫名其妙的拿到了保研资格，当时没想好要干嘛就读研了，想着有个研究生学历以后选择多一些。但是硕士太emo了，导致一门必修课挂科，所以秋招没敢投国企，怕要成绩单。方向是前端开发，研究生暑期实习运气好进了阿里实习，顺利转正了，也争取了个小sp。</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯！谢谢您的建议</p>
<dl>
<dt>【 在 chuben 的大作中提到: 】</dt>
<dd>小妹妹是典型的【问题多】的好女孩。其实可以把自己担心的问题写在一张纸上，把自己放空一下，理性务实地思考。其实很多都是自己和自己过不去，人要学会自己放过自己，自己才会放过别人，放过社会。   人际关系的本质是自己和自己的关系。</dd>
</dl>
<hr />
<p><strong>biger:</strong></p>
<p>考公</p>
<p>多读书，把自己的心理调整过来</p>
<hr />
<p><strong>poiu1234:</strong></p>
<p>感觉楼主的性格挺适合微软的.</p>
<p>我现在所在的组感觉领导就挺nice的，而且完全没有pua，而且同事之间也没啥内卷</p>
<p>如果需要我可以帮忙内推一波</p>
<hr />
<p><strong>royma520:</strong></p>
<p>但是我听说微软要刷好多leetcode，微软歧视空窗期吗？想问下是不是还要准备系统设计和英语呀？方便私信加个v聊下不</p>
<dl>
<dt>【 在 poiu1234 的大作中提到: 】</dt>
<dd>
<p>感觉楼主的性格挺适合微软的.</p>
</dd>
<dd>
<p>我现在所在的组感觉领导就挺nice的，而且完全没有pua，而且同事之间也没啥内卷</p>
</dd>
<dd>
<p>如果需要我可以帮忙内推一波</p>
</dd>
</dl>
<hr />
<p><strong>yaoyuhao666:</strong></p>
<p>互联网不适合楼主</p>
<dl>
<dt>【 在 juda 的大作中提到: 】</dt>
<dd>你这个建议不靠谱，耽误小姑娘了，早点考公上岸还有职业发展，没必要在互联网浪费时间。</dd>
</dl>
<hr />
<p><strong>pqptsl123:</strong></p>
<p>世界就是个草台班子，感觉lz不用去想很多没发生的问题</p>
<hr />
<p><strong>poiu1234:</strong></p>
<p>嗯，可以的，17801202066</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>但是我听说微软要刷好多leetcode，微软歧视空窗期吗？想问下是不是还要准备系统设计和英语呀？方便私信加个v聊下不</dd>
</dl>
<hr />
<p><strong>SAKING:</strong></p>
<p>人生的容错率很高的 宝宝</p>
<hr />
<p><strong>royma520:</strong></p>
<p>谢谢安慰</p>
<dl>
<dt>【 在 SAKING 的大作中提到: 】</dt>
<dd>人生的容错率很高的 宝宝</dd>
</dl>
<hr />
<p><strong>zgyfjch:</strong></p>
<p>98年的比你小一岁但是今年刚毕业，性格跟你类似，毕竟是男生所以研究生期间脸皮磨的也厚一点了，职业安排是干两年互联网，可已的话就继续干，不行就全职考公，相信我，以你的能力，为了一个短期的目标(考公上岸)可以迸发出强大的能力的</p>
<dl>
<dt>【 在 kezhifeng 的大作中提到: 】</dt>
<dd>
<p>看完了，说下感受和建议</p>
</dd>
<dd>
<p>你和我是一大类人，外表看起来也不那么内向，特定场合甚至可以很外向，实际上是慢热的，相处久了才能做朋友，才会关系顺畅</p>
</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>那你家里应该可以支持吧？我家境普通，感觉还是要靠自己，不过如果面试不顺利，这也是最后的退路了</p>
<dl>
<dt>【 在 zgyfjch 的大作中提到: 】</dt>
<dd>98年的比你小一岁但是今年刚毕业，性格跟你类似，毕竟是男生所以研究生期间脸皮磨的也厚一点了，职业安排是干两年互联网，可已的话就继续干，不行就全职考公，相信我，以你的能力，为了一个短期的目标(考公上岸)可以迸发出强大的能力的</dd>
</dl>
<hr />
<p><strong>zgyfjch:</strong></p>
<p>是的，家里可以在生活全款买房(150w左右)，可是买房是两个人的事情啊姐姐！你到时候找个男朋友，你们俩都有收入，江西房价不高吧？你们俩人买套一百平的房子肯定没压力的，千万别为了房子焦虑了</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>那你家里应该可以支持吧？我家境普通，感觉还是要靠自己，不过如果面试不顺利，这也是最后的退路了</dd>
</dl>
<hr />
<p><strong>royma520:</strong></p>
<p>嗯嗯，其实我妈的意思是让我去户口所在地杭州找，说这边本地不好找</p>
<dl>
<dt>【 在 zgyfjch 的大作中提到: 】</dt>
<dd>是的，家里可以在生活全款买房(150w左右)，可是买房是两个人的事情啊姐姐！你到时候找个男朋友，你们俩都有收入，江西房价不高吧？你们俩人买套一百平的房子肯定没压力的，千万别为了房子焦虑了</dd>
</dl>
<hr />
<p><strong>xxx666:</strong></p>
<p>打眼一溜，可以心态上积极一点。</p>
<p>干啥都得现学啊，工作也要学习啊。</p>
<hr />
<p><strong>wcxdell:</strong></p>
<p>在以前我会鄙视楼主，不努力家里没条件又想钱多事少离家近。现在不会了，人各有志，去个老家没事业编的大专应该比较适合。</p>
<hr />
<p>x18436370083</p>
<p>太长了 姐姐 写简短点吧ema13</p>
<dl>
<dt>【 在 l6030 的大作中提到: 】</dt>
<dd>
<p>直接找国企，我找了那么多国企，感觉没几个看成绩单的，虽然我没有挂科</p>
</dd>
<dd>
<p>你这种状态早点从互联网逃离吧，要不然30多岁还要纠结</p>
</dd>
</dl>
<hr />
<p>dazhen</p>
<p>你本硕北邮的，学习能力应该很强的，自信点就是。你的成绩单应该不显示挂科，你投国企就是了，记得几乎没有看成绩的。国企挺喜欢本硕重点学校的。有人的地方就有江湖，自己内心强大就好。外界是外界，干嘛老在乎外界呢？</p>
<hr />
<p>royma520</p>
<p>研究生成绩单会显示重修。这个我们那届改革了。如果我还想再试试互联网呢，害，人已经平静下来了，就面试试试得了，这几天准备通宵搞</p>
<dl>
<dt>【 在 dazhen 的大作中提到: 】</dt>
<dd>你本硕北邮的，学习能力应该很强的，自信点就是。你的成绩单应该不显示挂科，你投国企就是了，记得几乎没有看成绩的。国企挺喜欢本硕重点学校的。有人的地方就有江湖，自己内心强大就好。外界是外界，干嘛老在乎外界呢？</dd>
</dl>
<hr />
<p>Qme</p>
<p>太长没看完，但是lz身体没啥问题，要知道我大四就有甲状腺结节和乳腺结节了。。。这个不影响激素水平就没事的。</p>
<hr />
<p>royma520</p>
<p>昂 主要就是精神内耗 在家的时候偶尔想到工作的一些烦心事儿容易哭出来</p>
<dl>
<dt>【 在 Qme 的大作中提到: 】</dt>
<dd>太长没看完，但是lz身体没啥问题，要知道我大四就有甲状腺结节和乳腺结节了。。。这个不影响激素水平就没事的。</dd>
</dl>
<hr />
<p>Dijkstraaaaa</p>
<p>其实不知道lz有没有意识到，你现在的情绪困境很多并不是工作造成的，工作只是一个引子，你的核心困扰来源于，你对自我价值的评估，几乎都是建立于周围人对你的评价，比如亲朋好友对你职业发展的闲言碎语，比如领导对你工作质量的碎碎念，而你又不是一个情绪外放的人，喜欢自己消化外界的声音，但其实你并不知道这些声音到底是有道理还是没道理，就会在反复的自省中消耗自己，越来越心累。</p>
<p>这种情况常常出现在，你的原生家庭圈层和你现在的圈层差距比较大的时候，他们无法共情你的情绪困境，也无法对你未来的道路提供必要的帮助，甚至会用不匹配的认知，给你带来额外的噪声。没有过来人告诉你什么是好的，什么是不好的，什么是值得的，什么是可以放弃的，你就会越来越迷茫。</p>
<p>你现在应该先想明白，你工作预期的终点是什么，什么样的事情能让你感到发自内心的开心。比如，写代码实现一个牛逼的功能，你会感到快乐吗？你的目的是快速攒一笔钱，然后辞掉工作，专心干自己喜欢的事情，还是想要找到一个work life balance的工作？是享受持有工作给你带来的稳定感，还是想有更大的自由度去挑战未知的可能，这些诉求对应的职业路径都不一样。</p>
<p>想明白自己想要什么之后，你需要找一个对应职业路径上，level比你更高的人，给你一些执行路径上的建议，然后再顺着这条路摸索出自己的心得，最终找到自己的价值，自得其乐。那个时候你就有足够的能量，去面临外界的诸多质疑了，甚至能进一步影响周围的人。如果没想清楚这些，互联网也好、国企也好、公务员也好，工作中都会面临外界对你的施压，如果这些很容易给你带来情绪上的困扰的话，你不管选哪条路都不会开心。</p>
<p>最后补充一下，其实你在互联网的经历很典型，你并不能根据一段不到一年的，在互联网颠沛流离的工作体验，来否定你的职业兴趣。其实你的痛苦很可能是压根没有人领你“上道”，所以无法真正体会到这份工作的乐趣和挑战。你需要找机会加入一个有生命力的业务，挑到一个技术扎实&amp;双商正常的mentor或leader，帮助你完成第一个有价值的工作，然后你慢慢长成独当一面的心境和能力，做出被大家看得到的成果，最后争取到正向回报。完成这一轮的经历，你才能摸清互联网生存的基本规则，那时候你的体感可能又完全不一样。我觉得，你只有拥有入门过的经历，才能够下结论，你到底适不适合或喜不喜欢某个职业。</p>
<p>要对自己多份信心，多份憧憬，路会越走越清晰的。</p>
<hr />
<p>royma520</p>
<p>嗯嗯嗯 是的 自身没建立一个评价体系，依赖外部评价，也不知道别人说的是对的还是错的。就很内耗，自己的社会化程度不高，还会被上个老板说幼稚</p>
<dl>
<dt>【 在 Dijkstraaaaa 的大作中提到: 】</dt>
<dd>
<p>毕业多年的老北邮人，很久没在论坛打字了。点开帖子，很能共情lz的状态，谈谈我的感受。</p>
</dd>
<dd>
<p>其实不知道lz有没有意识到，你现在的情绪困境其实并不是工作造成的，工作只是一个引子，你的核心困扰都来源于你的自我价值几乎都建立于周围人对你的评判，亲朋好友对你境遇的闲言碎语，领导对你工作质量的点评等等，而你又不是一个情绪外放的人，喜欢自己消化外界的声音，而你甚至不知道这些声音到底是有道理还是没道理。</p>
</dd>
</dl>
<hr />
<p>royma520</p>
<p>被同事说我还是个孩子……</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯嗯 是的 自身没建立一个评价体系，依赖外部评价，也不知道别人说的是对的还是错的。就很内耗，自己的社会化程度不高，还会被上个老板说幼稚</dd>
</dl>
<hr />
<p>hsyh1998</p>
<p>放下过去，着眼于未来，不要给自己太多负担，该接受心理辅导和治疗就去接受，多做冥想多运动，时刻记住，一切都还不算太晚，正是这种挫折激发了你自我保护机制，退一万步讲，生不带来，死不带去，别想太多</p>
<hr />
<p>Dijkstraaaaa</p>
<p>回复的好快，刚才码字还没码完，hh</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯嗯 是的 自身没建立一个评价体系，依赖外部评价，也不知道别人说的是对的还是错的。就很内耗，自己的社会化程度不高，还会被上个老板说幼稚</dd>
</dl>
<hr />
<p>dazhen</p>
<p>即使显示重修，也没说招聘一定不要啊？为啥不试试呢？</p>
<dl>
<dt>【 在 royma520 (fly) 的大作中提到: 】</dt>
<dd>研究生成绩单会显示重修。这个我们那届改革了。如果我还想再试试互联网呢，害，人已经平静下来了，就面试试试得了，这几天准备通宵搞</dd>
</dl>
<hr />
<p>royma520</p>
<p>哈哈 又回去看了一下剩下的</p>
<dl>
<dt>【 在 Dijkstraaaaa 的大作中提到: 】</dt>
<dd>回复的好快，刚才码字还没码完，hh</dd>
</dl>
<hr />
<p>royma520</p>
<p>嗯嗯 会试试的</p>
<dl>
<dt>【 在 dazhen 的大作中提到: 】</dt>
<dd>即使显示重修，也没说招聘一定不要啊？为啥不试试呢？</dd>
</dl>
<hr />
<p>iamwugong</p>
<p>你太焦虑了，换个互联网公司试试就好，觉得不爽了就再换。其他的都可以慢慢去纾解。</p>
<hr />
<p>fengliquan</p>
<p>看到了曾经的影子</p>
<hr />
<p>yondchang</p>
<p>属于是北邮张雪峰了</p>
<hr />
<p>mutex</p>
<p>同江西，互联网一年了，上个月裁了一大波</p>
<hr />
<p>lorder</p>
<p>学姐可以看看叔本华的书缓解痛苦</p>
<dl>
<dt>【 在 kezhifeng 的大作中提到: 】</dt>
<dd>
<p>看完了，说下感受和建议</p>
</dd>
<dd>
<p>你和我是一大类人，外表看起来也不那么内向，特定场合甚至可以很外向，实际上是慢热的，相处久了才能做朋友，才会关系顺畅</p>
</dd>
</dl>
<hr />
<p>ASASASQCW</p>
<p>长文啊，我得收藏慢慢读，一次性读不完</p>
<hr />
<p>royma520</p>
<p>嗯嗯 我觉得互联网这种还挺焦虑的，不想准备面试，面试通过还得卷试用期。有时候代码</p>
<p>不会写还挺无助的，内心总是很颤颤巍巍，还担心裁员和晋升压力。绞尽脑汁想okr</p>
<dl>
<dt>【 在 mutex 的大作中提到: 】</dt>
<dd>同江西，互联网一年了，上个月裁了一大波</dd>
</dl>
<hr />
<p>royma520</p>
<p>有时候也纠结，现在快27，可能去互联网，最多干到32，然后就得准备上岸之类的。因为自己也没信心能做到像之前女老板那样那么卷，她做到了大厂高p，我觉得职场里技术女高层还是很少的</p>
<hr />
<p>royma520</p>
<p>有时候也怀疑，自己在团队里感觉很难融入，就自己一个女生，那些男同事也都基本上是结婚或者快结婚，自己很难和他们打成一片，还挺孤独的。这种情况去了国企会好点吗</p>
<hr />
<p>royma520</p>
<p>这些天也无数次内心反复拷问自己，想到之前同事说的他的一个女生同学也是可以干这行但是不喜欢结果去了银行，然后又说我可以找个测试岗位干。我想人在自己不擅长的领域真的很痛苦，看到代码架构，看不懂，然后硬看，其实也没有天赋，想到本科的作业也是不求甚解，有时候也不会深入思考为啥要这么干。就很难过，可能是真不喜欢这行吧。想到之前同事们大部分都是说因为喜欢干这行喜欢写代码，才干的。有时候碰到复杂的代码自己还不敢直接上手改，畏难情绪也在。感觉可能一直都是害怕的，在勉强自己。</p>
<p>虽然我保研了，但其实只是学习上的。动手能力还是没有那么强，其实大三也做过服务端的实习go语言方面的，那会儿也是很头疼。想到p6的要求是独当一面，自己能出方案负责一个模块，自己也很没有信心。</p>
<p>思来想去，可能国企事业单位公务员才是合适的，脱离了代码，可能会也忙也累，但是不会有那种死活不知道bug出在哪里的痛苦。这只是我现在的看法，有没有了解的同学说一下国企的卷是在哪里呢？因为我有问过国企公务员的学长学姐，他们说国企公务员也卷，卷亮点之类的。有同学知道吗？还有的同学说国企也累，可能还不如互联网。</p>
<hr />
<p>kezhifeng</p>
<p>你得回复楼主，我是毕业多年的老咸鱼了</p>
<dl>
<dt>【 在 zgyfjch 的大作中提到: 】</dt>
<dd>98年的比你小一岁但是今年刚毕业，性格跟你类似，毕竟是男生所以研究生期间脸皮磨的也厚一点了，职业安排是干两年互联网，可已的话就继续干，不行就全职考公，相信我，以你的能力，为了一个短期的目标(考公上岸)可以迸发出强大的能力的</dd>
</dl>
<hr />
<p>kezhifeng</p>
<p>呃，师兄我并没有觉得痛苦，只是看清楚了，在社会中，我们这种人的弱势一面</p>
<p>想清楚是接受自己，还是改变自己，都是可以的，最忌讳就是摇摆不定，和否定自己</p>
<p>看到楼主这么焦虑，出来说两句感受</p>
<p>感谢你的建议，近十年都没怎么看人文的书了，也静不下来</p>
<dl>
<dt>【 在 lorder 的大作中提到: 】</dt>
<dd>学姐可以看看叔本华的书缓解痛苦</dd>
</dl>
<hr />
<p>vagina</p>
<p>要不投个运维岗位吧</p>
<hr />
<p>dazhen</p>
<p>现在就业环境很透明，在学校觉得互联网不适合自己，找工作的时候就不建议投。无论哪个工作那个企业，只要岗位符合自己，就海投就完事了。每年好多地方也有计算机类的事业单位招聘，也可以考考试试。老内耗，不行动，啥也百搭</p>
<dl>
<dt>【 在 royma520 (fly) 的大作中提到: 】</dt>
<dd>嗯嗯 会试试的</dd>
</dl>
<hr />
<p>r29</p>
<p>学姐，看了你的帖子，感觉我性格跟你很像，直白地说就是不爱竞争，又怕落后，目前还在读书也没办法给什么好的建议，人生本来就是不断试错的过程，走一步看一步也没什么不好，祝学姐早日找到适合自己的路！</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>楼主北邮本硕，21届女生，目前26，马上快27了，都是计算机专业，感觉不是很喜欢写代码，上大学之后就挺迷茫的，就是按部就班学习然后莫名其妙的拿到了保研资格，当时没想好要干嘛就读研了，想着有个研究生学历以后选择多一些。但是硕士太emo了，导致一门必修课挂科，所以秋招没敢投国企，怕要成绩单。方向是前端开发，研究生暑期实习运气好进了阿里实习，顺利转正了，也争取了个小sp。</dd>
</dl>
<hr />
<p>myroy</p>
<p>跟你一样对写代码提升技术没兴趣，现在32了天天看马斯洛和阿德勒的心理学自我疗愈ema9</p>
<hr />
<p>Tayee</p>
<p>楼主应该是做题比较厉害那种，楼主自己也说了“按部就班”学习就能取得不错的成绩。在任务已经被规划好了，只需要自己“按部就班”去做，楼主很擅长这个。这种其实就是典型的学生时代线性系统。但工作是非线性的是复杂多样的，环境更是动态变化的。很多时候需要自己去规划，去思考自己喜欢做什么，这个也没有固定答案。很明显，楼主在这方面能力还很差。读书，保研，找工作，更多像是随大流被推着走，没有自己主动去思考自己喜欢什么，什么道路才是适合自己的。所以在复杂多变的环境中容易产生倦怠，疲于应付。自己喜欢什么，自己才是最清楚的。论坛上询问别人，这种有点像是隔靴搔痒，治标不治本。当然询问别人有一点好处是，可以弥补自己一些认知上的差距，可以少走一点弯路而已。建议楼主多向内发展，提升一下自己的思想水平，做一个有主意的人！</p>
<hr />
<p>royma520</p>
<p>嗯嗯！是的，视野比较局限，就是随大流。感觉还是要自己选择，路是自己走出来的</p>
<dl>
<dt>【 在 Tayee 的大作中提到: 】</dt>
<dd>楼主应该是做题比较厉害那种，楼主自己也说了“按部就班”学习就能取得不错的成绩。在任务已经被规划好了，只需要自己“按部就班”去做，楼主很擅长这个。这种其实就是典型的学生时代线性系统。但工作是非线性的是复杂多样的，环境更是动态变化的。很多时候需要自己去规划，去思考自己喜欢做什么，这个也没有固定答案。很明显，楼主在这方面能力还很差。读书，保研，找工作，更多像是随大流被推着走，没有自己主动去思考自己喜欢什么，什么道路才是适合自己的。所以在复杂多变的环境中容易产生倦怠，疲于应付。自己喜欢什么，自己才是最清楚的。论坛上询问别人，这种有点像是隔靴搔痒，治标不治本。当然询问别人有一点好处是，可以弥补自己一些认知上的差距，可以少走一点弯路而已。建议楼主多向内发展，提升一下自己的思想水平，做一个有主意的人！</dd>
</dl>
<hr />
<p>luXiaoFeng12</p>
<p>同样，经常看同事间讨论各种“嫡系，站队”，勾心斗角，想好好干事的人，挺心累的</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>甚至有想过去pdd这种，只干活不汇报不内卷的公司，只要不要干什么其他幺蛾子，卷汇报卷技术分享卷表演，我觉得我还是可以干开发的。只要不精神内耗，而且希望组里的氛围好一些，因为本人性格敏感，但是之前对办公室政治挺迟钝的，后面经过一个男同事给我疯狂点拨，我才拨云见雾察觉出这里面的风起云涌。感受到大家在勾心斗角，我这个佛系人在里面真的很难受</dd>
</dl>
<hr />
<p>landeng</p>
<p>我感觉可以试试那些&quot;真国企&quot;，或者好点的不太卷的金融软开，这种学历更重要，进去了管外包，但是肯定更多是需要跟人打交道，也有更多不公平啥的，有利有弊吧！找工作确实很焦虑，希望楼主早日找到自己的正轨emb0</p>
<hr />
<p>royma520</p>
<p>真国企要怎么知道是不是真国企呢？去论坛搜信息吗？</p>
<dl>
<dt>【 在 landeng 的大作中提到: 】</dt>
<dd>我感觉可以试试那些&quot;真国企&quot;，或者好点的不太卷的金融软开，这种学历更重要，进去了管外包，但是肯定更多是需要跟人打交道，也有更多不公平啥的，有利有弊吧！找工作确实很焦虑，希望楼主早日找到自己的正轨emb0</dd>
</dl>
<hr />
<p>mumubin</p>
<p>行文中每一个关键选择都说是逐利的选择,却每一步都在后悔没去追随内心,其实你所谓的内心的喜好也不过是叶公好龙而已.</p>
<hr />
<p>landeng</p>
<p>这渠道很多，论坛脉脉等，问校友等等，不过我感觉先调整好自己心态吧</p>
<dl>
<dt>【 在 royma520 (fly) 的大作中提到: 】</dt>
<dd>真国企要怎么知道是不是真国企呢？去论坛搜信息吗？</dd>
</dl>
<hr />
<p>xuebao</p>
<p>我在这个年龄和楼主很像 建议楼主找个可长期呆着的业务（这一条可以删除很多方向）</p>
<hr />
<p>royma520</p>
<p>删除哪些方向呢？能举个例子么？比如飞书？</p>
<dl>
<dt>【 在 xuebao 的大作中提到: 】</dt>
<dd>我在这个年龄和楼主很像 建议楼主找个可长期呆着的业务（这一条可以删除很多方向）</dd>
</dl>
<hr />
<p>xuebao</p>
<p>并且不要太看重年龄。。。现在永远是你最年轻的时候（正确的废话，哈哈）</p>
<hr />
<p>xuebao</p>
<p>从你的描述，我感觉互联网你就别去了。。。。真的</p>
<p>你应该处于一个成长期，好像有些自卑 还需要一段时间才能充分自恰</p>
<p>现在互联网从业同学需要内心强大，不是每次都能碰到nice的团队</p>
<hr />
<p>azbx5223195</p>
<p>我挂了五六科，该去哪找就去哪找，楼主很优秀，不收你的公司只是他们不合适你，世界上公司可太多了</p>
<hr />
<p>zwj1992</p>
<p>lz还需要帮忙吗？</p>
<p>我现在在京东，有很多内推岗位，你可以加我微信（15210805135），我帮你内推。</p>
<p>除此之外，如果需要的话，我可以帮你梳理一下简历，帮你做一些面试准备。加油</p>
<hr />
<p>Cyclotron</p>
<p>别想着32岁前要干什么，32岁之后又要抓紧干什么。确实有一种逐利的心理在，每一步都很想踩在自己认为的最优解上。但是你已经用实践说明一部分认知里的最优解并不是你想要的样子。何况闭塞的状态下认知是很局限的</p>
<hr />
<p>royma520</p>
<p>是的，我觉得我可能更适合宽松一些自由一些的环境，目前准备考虑外企、国企和考公，先冲一波外企，先复习leetcode和项目，看看八股</p>
<dl>
<dt>【 在 xuebao 的大作中提到: 】</dt>
<dd>
<p>从你的描述，我感觉互联网你就别去了。。。。真的</p>
</dd>
<dd>
<p>你应该处于一个成长期，好像有些自卑 还需要一段时间才能充分自恰</p>
</dd>
</dl>
<hr />
<p>royma520</p>
<p>好的，谢谢安慰呀</p>
<dl>
<dt>【 在 azbx5223195 的大作中提到: 】</dt>
<dd>我挂了五六科，该去哪找就去哪找，楼主很优秀，不收你的公司只是他们不合适你，世界上公司可太多了</dd>
</dl>
<hr />
<p>royma520</p>
<p>确实，之前的履历看着每一步好像都挺好，其实也并没有，哈哈，比如保研了没有鼓起勇气去找个好导师比如算法导师，而是最后随便找了个“坑”，导致研究生更加emo。自己确实因为一些原因不够自信，没有勇气去做更好的选择。就比如秋招没有像身边的offer收割机一样拿遍offer，选择一个最高价去。楼主好像一直就是差不多就行，没有那么有欲望野心，或者说害怕自己不配。就像现在其实自己努力好好准备，对自己有些自信心，其实也是可以的，想到之前前老板说我怎么有些不自信呢，我想这份不自信从10年前甚至更早就已经埋下，只是长大之后会更明显，空窗期也有好好整理回顾自己的痛苦和原因，有尝试看一些人文书籍，比如《反正竞赛还很长》、《你要去相信》、《恰到好处的敏感》、《斯坦福人生设计课》这类的书籍，然后就开始被爸妈催着找工作，焦虑拉满</p>
<dl>
<dt>【 在 Cyclotron 的大作中提到: 】</dt>
<dd>别想着32岁前要干什么，32岁之后又要抓紧干什么。确实有一种逐利的心理在，每一步都很想踩在自己认为的最优解上。但是你已经用实践说明一部分认知里的最优解并不是你想要的样子。何况闭塞的状态下认知是很局限的</dd>
</dl>
<hr />
<p>a123Sophia</p>
<p>和学姐太像了，简直一模一样。99年的今年毕业，去互联网提前实习了几个月，已经很焦虑很内耗了。感觉互联网只适合有技术热情or脸皮厚能卷的人，而且我也会经常纠结自己问题太多，会不会让人觉得“女生就是技术不行”。感觉自己应付日常的业余需求都有点困难，更别说像其他同事那样负责一些优化类的工作了。所以还是想问下学姐正文里说的“技术能力提升”是怎么提升的呢？</p>
<hr />
<p>eee1</p>
<p>感觉楼主还是要对自己自信一些。别觉得这个世界那么困难。极端情况下 感觉不到自信的哈实在不行的话就follow your heart  ，觉得那些否定你的/你觉得不顺心的那些人/事都是sb。先从内心把自己培养强大。从你对自己的描述里 看得出来你还是很出色的。少一些对自己内心的否定 少一些对于外界非议得关心。我觉得你自己内心是对未来有想法的。</p>
<p>国企的话我现在感觉一般都是稍微有点卷 但是你可以稍微躺一些。不至于跟互联网一样得一直卷。</p>
<p>有的时候工作/生活中就是需要做一些果断的决定。两眼一闭做个自己不反感的决定吧。</p>
<p>哦 楼主现在也经常保持与朋友的一些线下交流/保持一些轻微的运动什么的。保持心情愉悦吧</p>
<hr />
<p>royma520</p>
<p>做多了就提升了 变成熟练工</p>
<dl>
<dt>【 在 a123Sophia 的大作中提到: 】</dt>
<dd>和学姐太像了，简直一模一样。99年的今年毕业，去互联网提前实习了几个月，已经很焦虑很内耗了。感觉互联网只适合有技术热情or脸皮厚能卷的人，而且我也会经常纠结自己问题太多，会不会让人觉得“女生就是技术不行”。感觉自己应付日常的业余需求都有点困难，更别说像其他同事那样负责一些优化类的工作了。所以还是想问下学姐正文里说的“技术能力提升”是怎么提升的呢？</dd>
</dl>
<hr />
<p>royma520</p>
<p>嗯嗯！我最近疯狂和亲朋好友前同事聊天，感觉多了些信心。哈哈，我之前的组可以说是前端技术超好，前同事说可以称为清华，他觉得我不菜，也算有实力的，不要放弃开发这条路。我决定再相信自己一下</p>
<dl>
<dt>【 在 eee1 的大作中提到: 】</dt>
<dd>感觉楼主还是要对自己自信一些。别觉得这个世界那么困难。极端情况下 感觉不到自信的哈实在不行的话就follow your heart  ，觉得那些否定你的/你觉得不顺心的那些人/事都是sb。先从内心把自己培养强大。从你对自己的描述里 看得出来你还是很出色的。少一些对自己内心的否定 少一些对于外界非议得关心。我觉得你自己内心是对未来有想法的。</dd>
</dl>
<hr />
<p>royma520</p>
<p>以及看着周围同事优秀的代码，你就会学到很多，然后模仿运用，就提升了</p>
<dl>
<dt>【 在 a123Sophia 的大作中提到: 】</dt>
<dd>和学姐太像了，简直一模一样。99年的今年毕业，去互联网提前实习了几个月，已经很焦虑很内耗了。感觉互联网只适合有技术热情or脸皮厚能卷的人，而且我也会经常纠结自己问题太多，会不会让人觉得“女生就是技术不行”。感觉自己应付日常的业余需求都有点困难，更别说像其他同事那样负责一些优化类的工作了。所以还是想问下学姐正文里说的“技术能力提升”是怎么提升的呢？</dd>
</dl>
<hr />
<p>a1270001737</p>
<p>首先我觉得你身心健康是最重要的，其次都是其次。不要太在意外人的眼光，做好自己。看得出来有能力，找个氛围好，没那么大压力的班上吧，人就活一次，别被亲人的眼光束缚自己。而且结婚也不一定会很快乐吧，先把自己的事情搞定，让自己每天都活的开心有意义。做好自己所能及的事情。知道自己几斤几两，互联网感觉你不好待下去。去个轻松的地方闯出一片新天地。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>嗯嗯，有考虑过职业发展，当时想的是32左右考公务员或者去国企事业单位的来着</dd>
</dl>
<hr />
<p>royma520</p>
<p>指的是不干互联网，去国企事业单位那种么</p>
<dl>
<dt>【 在 a1270001737 的大作中提到: 】</dt>
<dd>首先我觉得你身心健康是最重要的，其次都是其次。不要太在意外人的眼光，做好自己。看得出来有能力，找个氛围好，没那么大压力的班上吧，人就活一次，别被亲人的眼光束缚自己。而且结婚也不一定会很快乐吧，先把自己的事情搞定，让自己每天都活的开心有意义。做好自己所能及的事情。知道自己几斤几两，互联网感觉你不好待下去。去个轻松的地方闯出一片新天地。</dd>
</dl>
<hr />
<p>phm1234567</p>
<p>你很优秀，相信自己，努力的认识真实的自己</p>
<hr />
<p>royma520</p>
<p>嗯嗯 想了下，我就是个懒人，想有自己的生活，干点自己喜欢的事情，压力不大，安稳，工资养活自己再有点盈余，就是好日子了。</p>
<hr />
<p>PhonChen</p>
<p>加油，我是15年本科毕业的，一开始在两家小公司呆了几年， 然后再某互联网公司边缘部门卷了5年多，突然有一天厌倦了，极度讨厌工作，于是就辞职，目前在家躺平了九个月了，实在是不想上班，不过继续躺下去也不是办法，准备开始找工作了，我觉得楼主不妨试试海外，在海外如果能躺的话应该还是挺舒服的</p>
<hr />
<p>PhonChen</p>
<p>我也准备试试数字游民，一起加油啊</p>
<hr />
<p>royma520</p>
<p>是指润出国的意思吗？</p>
<dl>
<dt>【 在 PhonChen 的大作中提到: 】</dt>
<dd>加油，我是15年本科毕业的，一开始在两家小公司呆了几年， 然后再某互联网公司边缘部门卷了5年多，突然有一天厌倦了，极度讨厌工作，于是就辞职，目前在家躺平了九个月了，实在是不想上班，不过继续躺下去也不是办法，准备开始找工作了，我觉得楼主不妨试试海外，在海外如果能躺的话应该还是挺舒服的</dd>
</dl>
<hr />
<p>PhonChen</p>
<p>是啊，美帝去不了，还可以去欧洲日本之类的地方，那边挺舒服的</p>
<hr />
<p>WXVANS</p>
<p>我不知道说什么，但是想回复一下。说一下最近的经历。我本人是22年北邮硕士毕业。</p>
<p>毕业之前，我觉得自己就是一个往前冲的人（感觉更多的是虚荣心），对于找工作就像一场期末考试，想要拿到一个高分。实习、工作都是在杭州阿里。现在已经被裁回武汉了，还是在互联网，但是相较阿里轻松多了。</p>
<p>去年这时候，是我想裸辞的情绪波动期，甚至直接和主管说了我想走。当时在阿里真的越待越不想待，组织架构频繁变动，技术方向也一直在变，但我只想做个后端开发。那段时间，每天跟着老板的要求，在一些新方向上研究，我也不知道是我不想研究，还是就是学不会……反正真的很痛苦，看不到明天的希望。后来，组织架构又变动了一次，组里来了一个传统的软件开发的项目，我又拖了半年，直到去年元旦前被裁。</p>
<p>被裁之后，我先休息了一个月，当时一直在思考人生的意义，工作的意义……极端想法就是，我觉得如果啥都不考虑，在农村种种地，有个自己的菜园也能过日子啊，为什么非要出来社会和别人竞争呢？当然这是极端想法。</p>
<p>休息一个月后就过年了，过完年回杭州待了两周，就回武汉找工作了。</p>
<p>我也很迷茫，当时也不知道找什么工作，感觉还是只能找互联网，武汉的国企央企啥的我也没看到靠谱的。最后还是去了一家互联网公司，降薪了一点，也没啥福利，五险一金也交的很低。</p>
<p>我也不确定以后是不是就在武汉待着了，我感觉我还是想出去，但是没找到自己真正想干的事情，我只是觉得一辈子这么长，总得干点自己喜欢的工作。我感觉</p>
<p>我还是不想躺平，更不想进体制内。哎，现在工作也不累，也没啥压力，感觉在安于现状，得过且过。</p>
<hr />
<p>royma520</p>
<p>中间的心态很像</p>
<dl>
<dt>【 在 WXVANS 的大作中提到: 】</dt>
<dd>
<p>我不知道说什么，但是想回复一下。说一下最近的经历。我本人是22年北邮硕士毕业。</p>
</dd>
<dd>
<p>毕业之前，我觉得自己就是一个往前冲的人（感觉更多的是虚荣心），对于找工作就像一场期末考试，想要拿到一个高分。实习、工作都是在杭州阿里。现在已经被裁回武汉了，还是在互联网，但是相较阿里轻松多了。</p>
</dd>
<dd>
<p>去年这时候，是我想裸辞的情绪波动期，甚至直接和主管说了我想走。当时在阿里真的越待越不想待，组织架构频繁变动，技术方向也一直在变，但我只想做个后端开发。那段时间，每天跟着老板的要求，在一些新方向上研究，我也不知道是我不想研究，还是就是学不会……反正真的很痛苦，看不到明天的希望。后来，组织架构又变动了一次，组里来了一个传统的软件开发的项目，我又拖了半年，直到去年元旦前被裁。</p>
</dd>
</dl>
<hr />
<p>museaii</p>
<p>前两段简直是我本人马上秋招了好慌也是前端方向</p>
<hr />
<p>dgy200374</p>
<p>约了面试就尽量去面吧 无论你说到的国企还是互联网公务员 都去做吧 做的过程能缓解内耗 也能更清晰你自己</p>
<hr />
<p>a123Sophia</p>
<p>好的好的。感觉过来人说起来都是很轻松的样子，但是自己实操起来没那么容易。尤其自己不是科班的，感觉要学的东西还很多。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>以及看着周围同事优秀的代码，你就会学到很多，然后模仿运用，就提升了</dd>
</dl>
<hr />
<p>Freyr</p>
<p>感觉楼主可以把这帖子留着，和楼主相似的问题我不少朋友包括我自己都有。评论区的兄弟姐妹们也提了很多宝贵的意见，感觉可以激励到很多人。祝楼主好，我们这代人或许就是不可避免地要经历这些，希望都能找到一点点快乐。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>甚至有想过去pdd这种，只干活不汇报不内卷的公司，只要不要干什么其他幺蛾子，卷汇报卷技术分享卷表演，我觉得我还是可以干开发的。只要不精神内耗，而且希望组里的氛围好一些，因为本人性格敏感，但是之前对办公室政治挺迟钝的，后面经过一个男同事给我疯狂点拨，我才拨云见雾察觉出这里面的风起云涌。感受到大家在勾心斗角，我这个佛系人在里面真的很难受</dd>
</dl>
<hr />
<p>royma520</p>
<p>嗯嗯 会留着的</p>
<dl>
<dt>【 在 Freyr 的大作中提到: 】</dt>
<dd>感觉楼主可以把这帖子留着，和楼主相似的问题我不少朋友包括我自己都有。评论区的兄弟姐妹们也提了很多宝贵的意见，感觉可以激励到很多人。祝楼主好，我们这代人或许就是不可避免地要经历这些，希望都能找到一点点快乐。</dd>
</dl>
<hr />
<p>ada001</p>
<p>我很理解，其实问题不大，现在想想自己想要什么样的生活，然后降低期待吧，反正都不咋地，没有什么完美的工作，找个班上做自己想做的事情。关键不是什么是最优选项，而是你想干嘛。先搞清楚主要矛盾，你想轻松还是想赚钱，想离家近还是无所谓，想国企那就去试，不行就再换。最后能养活了自己就行。就那回事</p>
<dl>
<dt>【 在 wqsnlzxq 的大作中提到: 】</dt>
<dd>看的人着急。1.我的建议直接江西公务员，你户口在杭州有啥用，你亲戚朋友在杭州吗?不在的话你考上了不还是自己一个人孤独?去江西考上了下班亲戚朋友一堆不好吗，刚好治愈你i人性格。2.成绩单挂科。你该投就投，挂科就挂科，挂科了难道hr还打电话通知你说你因为挂科了不能来我们公司然后顺便羞辱你一番?如果不是那有什么关系，你收到笔试面试了，就证明你这家公司不看重你的挂科了。3.反复提空窗期，说实话九个月空窗期和十个月有啥区别，你自己反复在意的空窗期，多少一个月在hr眼里很重要?4.不能卷没有内驱力就建议一步</dd>
</dl>
<hr />
<p>royma520</p>
<p>对的。不对自己抱太高的要求了，感觉之前的职业规划都是完美卡住那个世人眼中好的选择，或者是全局最优解。忽略了自己内心的感受，为什么要太在乎自己的学历经历呢，想做什么就去做。生活是自己的</p>
<dl>
<dt>【 在 ada001 的大作中提到: 】</dt>
<dd>我很理解，其实问题不大，现在想想自己想要什么样的生活，然后降低期待吧，反正都不咋地，没有什么完美的工作，找个班上做自己想做的事情。关键不是什么是最优选项，而是你想干嘛。先搞清楚主要矛盾，你想轻松还是想赚钱，想离家近还是无所谓，想国企那就去试，不行就再换。最后能养活了自己就行。就那回事</dd>
</dl>
<hr />
<p>AXXE</p>
<p>一样的想法。其实我觉得学历带给我最大的好处是更多的选择，机会摆在自己面前了，好好想想自己想要什么，选自己最想要的。</p>
<dl>
<dt>【 在 royma520 的大作中提到: 】</dt>
<dd>对的。不对自己抱太高的要求了，感觉之前的职业规划都是完美卡住那个世人眼中好的选择，或者是全局最优解。忽略了自己内心的感受，为什么要太在乎自己的学历经历呢，想做什么就去做。生活是自己的</dd>
</dl>
<hr />
<p>mutex</p>
<p>同江西，上岸了分享一下经验，最好拉个群</p>
<hr />
<p>Ekko</p>
<p>感谢楼主保留此帖</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
  </entry>
  <entry>
    <title>优雅地监控显卡(GPU)使用情况:nvitop</title>
    <url>/2023/12/06/%E4%BC%98%E9%9B%85%E5%9C%B0%E7%9B%91%E6%8E%A7%E6%98%BE%E5%8D%A1-GPU-%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p>想要拥有nvtop那样详细的展示，又想拥有gpustat那样彩色的界面，并且希望能够像gpustat一样通过pip快速安装，那就不得不提nvitop工具了。</p>
<br>
<p>展示的模式有三种：</p>
<ul>
<li>auto (默认)</li>
<li>compact</li>
<li>full</li>
</ul>
<br>
<p>安装方式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install nvitop</span><br></pre></td></tr></table></figure>
<br>
<p>运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvitop -m full</span><br></pre></td></tr></table></figure>
<p>完整地显示出每个进程的执行用户、运行时长、执行指令以及每个进程所使用的GPU编号。可谓是集其他工具的优势于一身的实用主义工具了！<br />
<img src="https://pic4.zhimg.com/80/v2-f611ee84ebf97c55e813e55573fbf32f_1440w.webp" alt="" /></p>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>多类分类下为什么用softmax?</title>
    <url>/2024/03/16/%E5%A4%9A%E7%B1%BB%E5%88%86%E7%B1%BB%E4%B8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8softmax/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<p><strong>Softmax函数的形式</strong>:<br />
公式为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>a</mi><mrow><msubsup><mi>w</mi><mi>i</mi><mi>T</mi></msubsup><mi>x</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>a</mi><mrow><msubsup><mi>w</mi><mi>j</mi><mi>T</mi></msubsup><mi>x</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(y=i) = \frac{\exp(a_{w_i^Tx})}{\sum_j \exp(a_{w_j^Tx})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.33335em;vertical-align:-0.970285em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.363065em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.14964714285714287em;"><span style="top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.46032428571428574em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.19516666666666668em;"></span><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3447999999999999em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.7343785714285715em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.02813em;"><span style="top:-2.1726099999999997em;margin-left:-0.02691em;margin-right:0.1em;"><span class="pstrut" style="height:2.6833299999999998em;"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span><span style="top:-3.02813em;margin-right:0.1em;"><span class="pstrut" style="height:2.6833299999999998em;"></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.70516em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8932642857142857em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.8380650000000003em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.7343785714285715em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.02813em;"><span style="top:-2.1726099999999997em;margin-left:-0.02691em;margin-right:0.1em;"><span class="pstrut" style="height:2.6833299999999998em;"></span><span class="mord mathnormal mtight">i</span></span><span style="top:-3.02813em;margin-right:0.1em;"><span class="pstrut" style="height:2.6833299999999998em;"></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5107200000000001em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7543785714285716em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.970285em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。原因之一在于softmax设计的初衷,是希望特征对概率的影响是乘性的。</p>
<p><strong>多类分类问题的目标函数</strong>:<br />
通常选择为cross-entropy,即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mo>−</mo><mo>∑</mo><msub><mi>t</mi><mi>x</mi></msub><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L = -\sum t_{x} \log P(y = k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span>,其中目标类的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>等于1,其它类的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>等于0。</p>
<p>在神经网络模型中(最简单的logistic regression也可看成没有隐含层的神经网络),输出层第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span>个神经元的输入为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub><mo>=</mo><mo>∑</mo><msub><mi>a</mi><mrow><msub><mi>w</mi><mi>i</mi></msub><mi>x</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">a_{i} = \sum a_{w_{i}xd}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0001em;vertical-align:-0.2501em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:-0.02691em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span>。神经网络是用error back-propagation训练的,在这个过程中有一个关键的量是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>a</mi><mi>i</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial a_{i}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.325208em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。可以算出,同时使用softmax和cross-entropy时,<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>a</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mi>i</mi><mo stretchy="false">)</mo><mo>−</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial a_{i}} = P(y=i) - t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.325208em;vertical-align:-0.44509999999999994em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3280857142857143em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.44509999999999994em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span>。这个形式非常简洁,而且与线性回归(采用最小均方误差目标函数)、两类分类(采用cross-entropy目标函数)时的形式一致。</p>
<p>softmax的<strong>优点</strong>：</p>
<ul>
<li>直观看来，是因为它能够将神经网络输出的定义在实数域的<strong>logits(神经网络输出值)</strong> 变为非负值，且归一化到[0,1]区间，所以很适合作为概率值。</li>
<li>Softmax 函数还能<strong>拉开大小值之间的差距</strong>，通常更突出最大值，在某些情况下，这也是深度学习所期望的。</li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]就读科软这三年</title>
    <url>/2024/03/24/%E5%B0%B1%E8%AF%BB%E7%A7%91%E8%BD%AF%E8%BF%99%E4%B8%89%E5%B9%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h3 id="写在前面"><a class="markdownIt-Anchor" href="#写在前面"></a> 写在前面</h3>
<p>因看到学弟学妹会在考研板块或者悄悄话（毕业生能看不能评）cue到科软，因此撰写本文记述并总结就读科软三年的经历和感受，希望能给学弟学妹提供帮助。本文仅描述本人经历和科软现状，不进行学校学院间的生源质量、学术能力、就业质量比较，不对各学校学院进行评价（求生欲拉满）。同时作为北邮和科软的学生，我只希望二者都越办越好，学生都能学有所成。如读完本文仍有困惑，或对计算机类考研择校，就业规划感到迷茫，均可论坛私信。</p>
<h3 id="更新日志"><a class="markdownIt-Anchor" href="#更新日志"></a> 更新日志</h3>
<ul>
<li>06.24：更新目录与总结</li>
<li>04.14: 更新22年选调生数据</li>
<li>03.28：更新历年报考分数</li>
<li>12.02：更新秋招部分</li>
</ul>
<h3 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h3>
<ol>
<li><strong>背景</strong>
<ul>
<li>1.1 成绩情况</li>
<li>1.2 报考历程</li>
<li>1.3 科软报考情况</li>
</ul>
</li>
<li><strong>培养方案</strong>
<ul>
<li>2.1 自主实习</li>
<li>2.2 联合培养
<ul>
<li>2.2.1 校内联合培养</li>
<li>2.2.2 校外单位联合培养</li>
<li>2.2.3 国际联合培养</li>
</ul>
</li>
<li>2.3 培养地与专业方向</li>
<li>2.4 学费与奖助学金
<ul>
<li>2.4.1 学费</li>
<li>2.4.2 奖助学金</li>
</ul>
</li>
</ul>
</li>
<li><strong>经历</strong>
<ul>
<li>3.1 学习过程</li>
<li>3.2 实习过程
<ul>
<li>3.2.1 初次实习</li>
<li>3.2.2 换实习</li>
<li>3.2.3 秋招情况</li>
<li>3.2.4 实习秋招之后</li>
</ul>
</li>
</ul>
</li>
<li><strong>学位论文、毕业和落户</strong>
<ul>
<li>4.1 时间</li>
<li>4.2 毕业情况</li>
<li>4.3 落户</li>
</ul>
</li>
<li><strong>考公与选调</strong>
<ul>
<li>5.1 条件</li>
<li>5.2 往年情况</li>
<li>5.3 其他</li>
</ul>
</li>
<li><strong>总结</strong></li>
</ol>
<hr />
<p><strong>一、背景</strong></p>
<ol>
<li>
<p><strong>成绩情况</strong><br />
2016级山东生源，2020届北邮计算机学院，计算机科学与技术专业学生。实验班菜鸡，成绩加权82.88/100，平均绩点3.32/4.0，专业排名137/301，一个美赛H水奖，无其他学科竞赛获奖，无个人项目，只有一个大创结业，和大创队友送的两篇水文的三作四作。2020年一战一志愿报考中科大软件工程（085405），初试成绩378，复试成绩84.58，加权总成绩80.04。初试与加权成绩均排名前10%。</p>
</li>
<li>
<p><strong>报考历程</strong><br />
2019年3月份开始复习考研，因初步计划去南方发展，在没有详细了解各学校的情况下，根据学科评估，考虑报考浙江大学计算机学院。3月报考PAT甲级，因仅准备了半个月，60分飘过，9月再次报考PAT甲级，取得92分。9月份考PAT时偶遇一个北航的老哥一起考试，经过交流，开始了解到择校的重要性，同时大部分同学在进行秋招，发觉到读研并不是人生目的，读研后仍要就业。由此开始思考自己想要的生活和想要的工作，因此决定9月更换志愿，报考中科大软件工程（说实话就是报浙大怂了。）</p>
</li>
<li>
<p><strong>科软报考情况</strong><br />
2019年开始科软不再接受校外调剂，2020年开始调剂学生到校内其他学院（如网络空间安全学院）。各年份分数线及平均分如下：</p>
<ul>
<li>2020年分数线320，平均分356，单科线50/50/87/87</li>
<li>2021年分数线388，平均分409，单科线60/60/100/100</li>
<li>2022年分数线335，平均分391，单科线60/60/80/80</li>
<li>2023年分数线367，平均分397，单科线55/55/100/100</li>
</ul>
</li>
</ol>
<p><strong>二、培养方案</strong></p>
<ol>
<li>
<p><strong>自主实习</strong><br />
根据个人实习和论文计划，学制2.5-3年灵活变动。在研一课程结束后，开展不少于10个月的实习实践（其中与毕业论文相关的实习不少于7个月）。学生需要在实习期间完成毕业论文的开题与撰写，期间学院安排老师对论文进行指导，学院统一进行审查。无专利与科研论文发表要求。</p>
</li>
<li>
<p><strong>联合培养</strong><br />
学制更改为3年，主要是软件学院与国内外其他单位对学生进行联合培养，学生研一需要在软院完成专业课学习，研二开始去协议单位进行培养。包括校内联合培养、校外单位联合培养和国际联合培养三种形式。</p>
</li>
<li>
<p><strong>培养地与专业方向</strong><br />
科软的培养地有合肥和苏州可选，绝大部分学生会选择苏州。培养地的选择发生在录取后入学前，学生任选专业方向。</p>
</li>
<li>
<p><strong>学费与奖助学金</strong></p>
<ul>
<li><strong>学费</strong>：2023级前，学费共4万，每年2万，分两次缴纳。2023级开始，学费共6万，每年3万，分两次缴纳。</li>
<li><strong>奖助学金</strong>：助学金每个月700，从开学的9月开始，月初打到卡里，直到毕业。奖学金按班级分配，每个班级50人左右。研一时保研学生提供12000的一等奖学金，考研学生成绩前30%提供10800的二等奖学金。研二时，每班1名国家奖学金名额，按成绩综合排名前30%学生提供10800的二等奖学金，其中校内联合培养学生自动获得奖学金，不参与排名。研三时，奖学金评选大约30%，其中校内联合培养学生自动获得奖学金。</li>
</ul>
</li>
</ol>
<p><strong>三、经历</strong></p>
<ol>
<li>
<p><strong>学习过程</strong><br />
在通过复试后（还未入学），收到学院副院长的短信，邀请参与其实验室的联合培养项目，选择了拒绝。学院组织了工程实践双选，每个同学都需要选择并完成。通过参与工程实践和专业学习，最终在班级中综合排名提升。</p>
</li>
<li>
<p><strong>实习过程</strong></p>
<ul>
<li><strong>初次实习</strong>：早期投递实习，先后收获多家大厂的实习offer，大部分选择了去字节跳动实习。</li>
<li><strong>换实习</strong>：7个月满后，部分学生选择更换实习地，去向各不相同，体现了灵活的实习安排和个性化的职业规划。</li>
<li><strong>秋招情况</strong>：秋招过程中，虽然市场竞争激烈，但多数同学都获得了满意的工作机会，其中不乏大厂offer和国企岗位。</li>
<li><strong>实习秋招之后</strong>：学校为实习秋招结束后的学生提供宿舍申请，确保有稳定的生活环境进行毕业论文撰写和后续生活规划。</li>
</ul>
</li>
</ol>
<p><strong>四、学位论文、毕业和落户</strong></p>
<ol>
<li><strong>时间</strong>：毕业时间灵活，最早可在研二12月毕业，最晚延至5年取消学籍。科软毕业时间一般在3月份。</li>
<li><strong>毕业情况</strong>：中科大对毕业论文要求较高，需通过盲审。科软毕业生占科大研究生毕业人数的一定比例，学院和学校重视就业情况。</li>
<li><strong>落户</strong>：中科大位于上海和北京的落户高校或计划单列名单内，提供直接落户或计划单列落户的机会。</li>
</ol>
<p><strong>五、考公与选调</strong></p>
<ol>
<li><strong>条件</strong>：科软选调和中科大完全一致，毕业证的专业名称是软件工程，满足绝大多数省份的选调要求。</li>
<li><strong>往年情况</strong>：近年来有多名学长学姐成功上岸中央和地方优选公务员岗位，反映了科软学生的综合实力和学校的影响力。</li>
<li><strong>其他</strong>：选调不仅需要学校的支持，还需要党员身份、综合荣誉等条件。科软在这些方面为学生提供了充分的支持和机会，从而使学生在选调和考公方面有更好的表现。</li>
</ol>
<p><strong>六、总结</strong></p>
<p>入学两年多的时间里，我深感对科软的感激之情。尽管科软经常处在考研舆论的漩涡中心，这并没有影响到我对科软带来的实习、就业机会以及在江南生活的美好体验的感恩之心。</p>
<p>我所经历的科软，提供了灵活的学习与实习方案，丰富的奖助学金体系，以及对学生未来发展的多方面支持。无论是选择直接进入职场的学生，还是决定参与考公与选调的学生，科软都提供了良好的平台和资源。</p>
<p>科软的教育和实践，让我不仅学到了专业知识，更重要的是学会了如何规划自己的未来，如何在职业道路上做出选择。这些经历和教训，将伴随我一生，成为我职业生涯和人生旅途中宝贵的财富。</p>
<p>现在，虽然已经毕业，但我仍然会以“红专并进，理实交融”和“厚德博学，敬业乐群”的校训为行动指南，以感谢两所母校的培养恩情。对于考虑科软的学弟学妹们，我希望我的经历能够提供一些参考和帮助，帮助你们更好地做出选择，规划自己的未来。</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>科软</tag>
      </tags>
  </entry>
  <entry>
    <title>强com VS 弱com</title>
    <url>/2023/10/19/%E5%BC%BAcom-VS-%E5%BC%B1com/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="强com-vs-弱com"><a class="markdownIt-Anchor" href="#强com-vs-弱com"></a> 强com VS 弱com</h1>
<h2 id="t1-fighting"><a class="markdownIt-Anchor" href="#t1-fighting"></a> T1 fighting!!!</h2>
<p>🔗：<a href="https://www.bilibili.com/video/BV1Aw411X7vM/?spm_id_from=444.41.list.card_archive.click&amp;vd_source=818709367b66eca23fb19fc37329dccb">为了结出过程的果实</a></p>
<br>
<h2 id="thu"><a class="markdownIt-Anchor" href="#thu"></a> THU</h2>
<table>
<thead>
<tr>
<th>系所</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机科学与技术系</td>
<td>强com</td>
<td>主要看机试成绩,机试难度大</td>
</tr>
<tr>
<td>软件学院</td>
<td>强com</td>
<td>主要看机试成绩,机试难度大</td>
</tr>
<tr>
<td>交叉信息研究院</td>
<td>弱com</td>
<td>没有上机考试,材料提交之后,如果老师对你感兴趣,会直接跟你联系,进行一对一的交流、考核</td>
</tr>
<tr>
<td>深圳国际研究生院</td>
<td>中弱com</td>
<td>需要机试,并且需要联系导师</td>
</tr>
<tr>
<td>智能网络研究中心</td>
<td>弱com</td>
<td>无机试,但是需要提前联系好老师,面试难度大,基础知识涉及的较多</td>
</tr>
<tr>
<td>自动化系</td>
<td>博士弱com、硕士强com</td>
<td>无机试,博士需要提前联系老师可以拿到直博,硕士不需要提前联系老师,只有面试</td>
</tr>
<tr>
<td>电机系</td>
<td>强com</td>
<td>只有预推免需要提前联系导师,外校基本只有直博的机会</td>
</tr>
<tr>
<td>生物医学工程系</td>
<td>弱com</td>
<td>计算机可入营并拿到offer,不论什么专业都需要提前联系好老师</td>
</tr>
</tbody>
</table>
<br>
<h2 id="pku"><a class="markdownIt-Anchor" href="#pku"></a> PKU</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机学院</td>
<td>22年为超弱com</td>
<td>完全取决于老师是否接收学生,需要尽早联系导师,尽可能进组实习。夏令营无机试,如果老师答应给offer,面试相当于走过程(今年情况有所不同,夏令营有机试)</td>
</tr>
<tr>
<td>软件与微电子学院</td>
<td>强com</td>
<td>入营主要看排名</td>
</tr>
<tr>
<td>智能学院</td>
<td>超弱com</td>
<td>完全取决于老师是否接收学生,需要尽早联系导师,尽可能进组实习。夏令营无机试,如果老师答应给offer,面试相当于走过程</td>
</tr>
<tr>
<td>深圳研究生院</td>
<td>超弱com</td>
<td>完全取决于老师是否接收学生,需要尽早联系导师,尽可能进组实习。夏令营无机试,如果老师答应给offer,面试相当于走过程</td>
</tr>
<tr>
<td>前沿交叉学科研究院</td>
<td>强com</td>
<td>大数据科学,硕士项目不需要提前联系老师,博士需要</td>
</tr>
<tr>
<td>未来技术学院</td>
<td>弱com</td>
<td>无机试,但是需要提前联系好老师,进行1v1面试,才有可能入营并获得offer</td>
</tr>
<tr>
<td>医学技术学院</td>
<td>弱com</td>
<td>需要提前联系老师,没有机试,只有面试</td>
</tr>
<tr>
<td>工学院</td>
<td>弱com</td>
<td>只有面试,需要保证入营之后联系好老师才可以获得offer</td>
</tr>
</tbody>
</table>
<br>
<h2 id="fdu"><a class="markdownIt-Anchor" href="#fdu"></a> FDU</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机科学技术学院</td>
<td>强com</td>
<td>有机试和英文面试和专业面试</td>
</tr>
<tr>
<td>信息科学与工程学院</td>
<td>弱com</td>
<td>需要联系导师</td>
</tr>
<tr>
<td>工程与应用技术研究院</td>
<td>强com</td>
<td>硕士多,不需要提前联系,优营必然会有offer</td>
</tr>
<tr>
<td>航空航天学院</td>
<td>弱com</td>
<td>需要提前联系老师才能入营并offer</td>
</tr>
<tr>
<td>数字医学中心</td>
<td>强com</td>
<td>进去以后老师会找的</td>
</tr>
</tbody>
</table>
<br>
<h2 id="sjtu"><a class="markdownIt-Anchor" href="#sjtu"></a> SJTU</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>软件学院</td>
<td>强com</td>
<td>考核方式是机试和面试</td>
</tr>
<tr>
<td>电子信息与电气工程学院</td>
<td>弱com</td>
<td>需要提前联系导师。优营并不代表拟录取,考核分为学院考核即夏令营考核和导师考核,只有通过学院考核获得优秀营员才有资格与导师进行面试。与导师双选成功才能拿到offer</td>
</tr>
<tr>
<td>密西根学院</td>
<td>弱com</td>
<td>入营后进行群面和双选,和电院的offer获得方式一致,硕士只需要群面,不需要双选</td>
</tr>
<tr>
<td>博渊未来技术学院</td>
<td>弱com</td>
<td>入营后进行群面和双选,和电院的offer获得方式一致,硕士只需要群面,不需要双选</td>
</tr>
<tr>
<td>高级金融学院-计算机方向</td>
<td>强com</td>
<td>计算机可报名且拿到offer,国际化金融,薪资高,不需要联系老师</td>
</tr>
<tr>
<td>智慧能源创新学院</td>
<td>强com</td>
<td>不需要提前联系导师,主要是面试,门槛比电院低</td>
</tr>
</tbody>
</table>
<br>
<h2 id="ruc"><a class="markdownIt-Anchor" href="#ruc"></a> RUC</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>高瓴人工智能学院</td>
<td>强com</td>
<td>拿了优营之后导师还有一轮比较复杂的考核</td>
</tr>
<tr>
<td>信息学院</td>
<td>强com</td>
<td>入营bar较高,笔试+面试,笔试可以拿csp成绩抵,面试包括自我介绍、抽签专业问题和英语面试</td>
</tr>
</tbody>
</table>
<br>
<h2 id="zju"><a class="markdownIt-Anchor" href="#zju"></a> ZJU</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机科学与技术学院</td>
<td>弱com</td>
<td>入营方式是弱com,每位同学选择一位导师,导师审核你是否入营。入营后,每位导师可以选择一名同学进入院系答辩,通过答辩即可获得优营</td>
</tr>
<tr>
<td>软件学院</td>
<td>弱com</td>
<td>通过面试筛选后,老师建群按课题分配到不同的项目组完成任务,任务考核导师满意就会获得优营</td>
</tr>
<tr>
<td>网络空间安全学院</td>
<td>弱com</td>
<td>考核:共20min的面试,8min展示自己的学习经历和科研成果,老师们主要围绕展示内容、专业问题和思想品德提问题</td>
</tr>
<tr>
<td>控制科学与工程学院</td>
<td>弱com</td>
<td>入营后会做项目,从而获得offer并答辩</td>
</tr>
<tr>
<td>电气工程学院</td>
<td>强com</td>
<td>只有预推免,可以提前联系导师,但面试还是得看自己能力</td>
</tr>
<tr>
<td>工程师学院</td>
<td>强com</td>
<td>硕士多,不需要提前联系,优营必然会有offer</td>
</tr>
<tr>
<td>生物医学工程与仪器科学学院</td>
<td>强com</td>
<td>招生人数较少,学院考核优营才有效力</td>
</tr>
</tbody>
</table>
<br>
<h2 id="ustc"><a class="markdownIt-Anchor" href="#ustc"></a> USTC</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机科学与技术学院</td>
<td>弱com</td>
<td>考核方式是面试,面试合格后需要有老师接收才能获得优营</td>
</tr>
<tr>
<td>信息与科学工程学院</td>
<td>强com</td>
<td>学院考核优营才有效力</td>
</tr>
<tr>
<td>六系(信息学部)</td>
<td>强com</td>
<td>不联系导师可以入营,但是优营后要进行导师选择</td>
</tr>
<tr>
<td>大数据学院</td>
<td>强com</td>
<td>优营后要进行导师选择</td>
</tr>
<tr>
<td>先进技术研究院</td>
<td>弱com</td>
<td>入营方式是弱com,导师推荐入营(越早联系越好)</td>
</tr>
</tbody>
</table>
<br>
<h2 id="nju"><a class="markdownIt-Anchor" href="#nju"></a> NJU</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机学院</td>
<td>强com</td>
<td>需要通过笔试和面试,才能获得offer</td>
</tr>
<tr>
<td>软件学院</td>
<td>强com</td>
<td>考核:笔试+面试,面试不同组风格不一样。联系不联系导师作用不大。</td>
</tr>
<tr>
<td>人工智能学院</td>
<td>强com</td>
<td>lamda组在学院夏令营前会有自己的夏令营,有两轮面试,即使拿了offer后还是要参加学院的夏令营获优营才能录取</td>
</tr>
<tr>
<td>电子院</td>
<td>强com</td>
<td>学院考核优营才有效力</td>
</tr>
</tbody>
</table>
<br>
<h2 id="cas"><a class="markdownIt-Anchor" href="#cas"></a> CAS</h2>
<table>
<thead>
<tr>
<th>研究所</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算技术研究所</td>
<td>弱com</td>
<td>有霸面的传统,通过实验室面试即可</td>
</tr>
<tr>
<td>沈阳自动化研究院(非自所)</td>
<td>弱com</td>
<td>可以直接联系老师并获得offer,面试就是过场</td>
</tr>
<tr>
<td>信工所</td>
<td>强com</td>
<td>夏令营和预推免考核优营才有效力,往年会有九推</td>
</tr>
<tr>
<td>声学所</td>
<td>弱com</td>
<td>导师权力比较小,夏令营和预推免考核优营才有效力</td>
</tr>
</tbody>
</table>
<br>
<h2 id="usac"><a class="markdownIt-Anchor" href="#usac"></a> USAC</h2>
<table>
<thead>
<tr>
<th>学院/所</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>自动化所</td>
<td>强com</td>
<td>考核形式为面试,面试通过后需要跟导师达成双选才可以被正式录取。</td>
</tr>
<tr>
<td>空间科学中心</td>
<td>强com</td>
<td>学院考核优营才有效力</td>
</tr>
</tbody>
</table>
<br>
<h2 id="buaa"><a class="markdownIt-Anchor" href="#buaa"></a> BUAA</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机学院</td>
<td>强com</td>
<td>机试过线进入面试,机试不合格不接收</td>
</tr>
<tr>
<td>自动化学院</td>
<td>强com</td>
<td>无机试,有笔试和面试,不需要提前联系</td>
</tr>
</tbody>
</table>
<br>
<h2 id="nku"><a class="markdownIt-Anchor" href="#nku"></a> NKU</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机学院</td>
<td>弱com</td>
<td>主要以实验室考核为主,部分强组考核较难</td>
</tr>
<tr>
<td>软件学院</td>
<td>弱com</td>
<td>导师的权力较大,提前联系导师更有机会进入该院</td>
</tr>
</tbody>
</table>
<br>
<h2 id="tongji"><a class="markdownIt-Anchor" href="#tongji"></a> Tongji</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>电子与信息工程学院计算机科学与技术系</td>
<td>强com</td>
<td>考核方式是笔试、机试和面试</td>
</tr>
</tbody>
</table>
<br>
<h2 id="bupt"><a class="markdownIt-Anchor" href="#bupt"></a> BUPT</h2>
<table>
<thead>
<tr>
<th>学院</th>
<th>com情况</th>
<th>考试情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算机学院</td>
<td><a href="https://scs.bupt.edu.cn/info/1020/2302.htm">弱com</a></td>
<td>分小组进行招生,需要自己联系老师,各小组一般是独立的,预报名之后需要联系导师,各小组导师组织面试,学校没有固定通知面试</td>
</tr>
<tr>
<td>人工智能学院</td>
<td><a href="https://ai.bupt.edu.cn/szdw/szyl/nrzyznyxx.htm">https://ai.bupt.edu.cn/szdw/szyl/nrzyznyxx.htm</a></td>
<td>一定要提前联系导师,并且尽可能地早</td>
</tr>
<tr>
<td>信息与通信工程学院</td>
<td>弱com</td>
<td>夏令营要做项目,入营联系导师即可</td>
</tr>
<tr>
<td>现代邮政学院</td>
<td>强com</td>
<td>需要提前联系导师,过了导师的小组面试一般就稳了</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>AimGraduate</category>
      </categories>
      <tags>
        <tag>AimGraduate</tag>
        <tag>强弱com</tag>
        <tag>T1 fighting</tag>
      </tags>
  </entry>
  <entry>
    <title>抱抱脸被GFW端了T.T</title>
    <url>/2024/02/28/%E6%8A%B1%E6%8A%B1%E8%84%B8%E8%A2%AB%E5%A2%99%E4%BA%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<!-- - [Linux操作系统下的全局代理配置与实践](https://cloud.tencent.com/developer/article/2129796)
- [Linux 上的 Squid 代理配置教程](https://cn.linux-console.net/?p=10607) -->
<br>
<h2 id="说在前面"><a class="markdownIt-Anchor" href="#说在前面"></a> 说在前面</h2>
<p>面对huggingface被墙的情况，我想了很多种办法：</p>
<ul>
<li>1.Linux服务器中设置代理</li>
<li>2.将模型下载到本地在上传到服务器上</li>
<li>3.使用huggface镜像站(<strong>神中神！！强烈推荐</strong>)</li>
</ul>
<p>由于最后一种方法是在太简便，所以我们这里直介绍最后一种方法</p>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<p>还是和往常一样贴几个参考链接：</p>
<ul>
<li><a href="https://hf-mirror.com/">🤗 Huggingface 镜像站</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/663712983">如何快速下载huggingface模型——全方法总结</a></li>
<li><a href="https://blog.csdn.net/weixin_43303286/article/details/134342476">解决Huggingface被墙下载模型的问题</a></li>
</ul>
<br>
<h2 id="问题"><a class="markdownIt-Anchor" href="#问题"></a> 问题</h2>
<p><img src="https://pbs.twimg.com/media/GHZ_8mLXgAAgY3k?format=png&amp;name=medium" alt="" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>, line <span class="number">108</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/train.py&quot;</span>, line <span class="number">97</span>, <span class="keyword">in</span> main</span><br><span class="line">    model = task.build_model(cfg)</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/tasks/base_task.py&quot;</span>, line <span class="number">33</span>, <span class="keyword">in</span> build_model</span><br><span class="line">    <span class="keyword">return</span> model_cls.from_config(model_config)</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/models/blip2_models/blip2_opt.py&quot;</span>, line <span class="number">412</span>, <span class="keyword">in</span> from_config</span><br><span class="line">    model = cls(</span><br><span class="line">  File <span class="string">&quot;/cyb/LAVIS/lavis/models/blip2_models/blip2_opt.py&quot;</span>, line <span class="number">85</span>, <span class="keyword">in</span> __init__</span><br><span class="line">    self.opt_tokenizer = AutoTokenizer.from_pretrained(opt_model, use_fast=<span class="literal">False</span>)</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py&quot;</span>, line <span class="number">667</span>, <span class="keyword">in</span> from_pretrained</span><br><span class="line">    config = AutoConfig.from_pretrained(</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py&quot;</span>, line <span class="number">983</span>, <span class="keyword">in</span> from_pretrained</span><br><span class="line">    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/transformers/configuration_utils.py&quot;</span>, line <span class="number">617</span>, <span class="keyword">in</span> get_config_dict</span><br><span class="line">    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/transformers/configuration_utils.py&quot;</span>, line <span class="number">672</span>, <span class="keyword">in</span> _get_config_dict</span><br><span class="line">    resolved_config_file = cached_file(</span><br><span class="line">  File <span class="string">&quot;/root/anaconda3/envs/ab/lib/python3.9/site-packages/transformers/utils/hub.py&quot;</span>, line <span class="number">452</span>, <span class="keyword">in</span> cached_file</span><br><span class="line">    <span class="keyword">raise</span> EnvironmentError(</span><br><span class="line">OSError: We couldn<span class="string">&#x27;t connect to &#x27;</span>https://huggingface.co<span class="string">&#x27; to load this file, couldn&#x27;</span>t find it <span class="keyword">in</span> the cached files <span class="keyword">and</span> it looks like facebook/opt-<span class="number">2.7</span>b <span class="keyword">is</span> <span class="keyword">not</span> the path to a directory containing a file named config.json.</span><br></pre></td></tr></table></figure>
<p>尝试从Hugging Face Hub下载<code>facebook/opt-2.7b</code>模型失败了，具体代码位于blip2_opt.py文件的初始化方法中，调用AutoTokenizer.from_pretrained(opt_model, use_fast=False)时出现的。</p>
<br>
<h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2>
<h3 id="安装依赖"><a class="markdownIt-Anchor" href="#安装依赖"></a> 安装依赖</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br></pre></td></tr></table></figure>
<h3 id="设置环境变量"><a class="markdownIt-Anchor" href="#设置环境变量"></a> 设置环境变量</h3>
<p>Linux：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HF_ENDPOINT=https://hf-mirror.com</span><br></pre></td></tr></table></figure>
<p>Windows Powershell,对于有梯子的用户应该不用使用此方法就可以下载:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$env</span>:HF_ENDPOINT = <span class="string">&quot;https://hf-mirror.com&quot;</span></span><br></pre></td></tr></table></figure>
<p>同时建议，将上面这一行写入 <code>~/.bashrc</code>中，这样就不需要每次都输入该指令了。</p>
<h3 id="下载模型"><a class="markdownIt-Anchor" href="#下载模型"></a> 下载模型</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">huggingface-cli download --resume-download gpt2 --local-dir gpt2</span><br></pre></td></tr></table></figure>
<ul>
<li><code>--resume-download</code>:后面填模型地址</li>
<li><code>--local-dir</code>：后面填指定路径(可以不填，默认<code>.~/cache/huggingface/hub</code>)</li>
</ul>
<h3 id="下载数据集"><a class="markdownIt-Anchor" href="#下载数据集"></a> 下载数据集</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">huggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitext</span><br></pre></td></tr></table></figure>
<p>可以添加 <code>--local-dir-use-symlinks False</code> 参数禁用文件软链接，这样下载路径下所见即所得，详细解释请见上面提到的教程。</p>
<br>
<h2 id="后记"><a class="markdownIt-Anchor" href="#后记"></a> 后记</h2>
<p>这是<code>/cyb</code>下的目录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── LAVIS</span><br><span class="line">├── apt-cache</span><br><span class="line">└── opt-2.7b</span><br></pre></td></tr></table></figure>
<p>我之前一直不懂<code>opt-2.7b</code>是什么用，现在才发现就是上面我需要下载的那个<code>facebook/opt-2.7b</code>,我也是刚理解的学姐的这番话(所以其实我不用下载对吧…废了这么大劲全走弯路了T.T)</p>
<p><img src="https://pbs.twimg.com/media/GHaBMPQWoAAc4NS?format=jpg&amp;name=medium" alt="" /></p>
]]></content>
      <categories>
        <category>bug</category>
      </categories>
      <tags>
        <tag>bug</tag>
        <tag>Linux</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title>使用VSCode在服务器上单步调试代码</title>
    <url>/2023/11/28/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%8D%95%E6%AD%A5%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="说在前面"><a class="markdownIt-Anchor" href="#说在前面"></a> 说在前面</h1>
<p>如果想要在服务器中使用以下这种方法来单步调试python文件,那么直接点起单步调试按钮即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python xx.py</span><br></pre></td></tr></table></figure>
<br>
<p>在文章中，针对的是以下这种情况来单步调试文件,即无法点击调试按钮就可以开始调试的情况：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python xx.py --train_file ... </span><br></pre></td></tr></table></figure>
<br>
<p>直接点击调试按钮会出现以下这样的画面：<br />
<img src="https://pbs.twimg.com/media/F_9S-XDXAAADq43?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h1 id="操作步骤"><a class="markdownIt-Anchor" href="#操作步骤"></a> 操作步骤</h1>
<h2 id="1找到最上面的窗口然后输入debug-open-launchjson"><a class="markdownIt-Anchor" href="#1找到最上面的窗口然后输入debug-open-launchjson"></a> 1.找到最上面的窗口，然后输入<code>Debug: Open launch.json</code></h2>
<p><img src="https://pbs.twimg.com/media/F_9Qx3pW0AAlzuy?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="2打开launchjson文件如下"><a class="markdownIt-Anchor" href="#2打开launchjson文件如下"></a> 2.打开<code>launch.json</code>文件如下：</h2>
<p><img src="https://pbs.twimg.com/media/F_9RthdW8AAS4hl?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="3修改launchjson添加args字段"><a class="markdownIt-Anchor" href="#3修改launchjson添加args字段"></a> 3.修改<code>launch.json</code>,添加<code>args</code>字段：</h2>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 使用 IntelliSense 了解相关属性。 </span></span><br><span class="line">    <span class="comment">// 悬停以查看现有属性的描述。</span></span><br><span class="line">    <span class="comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: 当前文件&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;file&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;--train_file&quot;</span><span class="punctuation">,</span><span class="string">&quot;path_to_train_file&quot;</span><span class="punctuation">,</span> <span class="string">&quot;--validation_file&quot;</span><span class="punctuation">,</span> <span class="string">&quot;path_to_validation_file&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<br>
<h2 id="4具体示例"><a class="markdownIt-Anchor" href="#4具体示例"></a> 4.具体示例</h2>
<p>2024.02.27更新：示例可能有些问题，请移步<a href="https://abinzzz.github.io/2024/02/18/vscode%E8%B0%83%E8%AF%95torch-distributed-run/">这里</a></p>
<p>脚本文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m torch.distributed.run \</span><br><span class="line">--nproc_per_node 8  --master_port 44144 \</span><br><span class="line">run_pretrain_binary.py \</span><br><span class="line"> \</span><br><span class="line">--dataset_name /data10/static_10000 \</span><br><span class="line">--model_name_or_path bert-base-uncased \</span><br><span class="line">--per_device_train_batch_size 32 \</span><br><span class="line">--per_device_eval_batch_size 32 \</span><br><span class="line">--learning_rate 2e-4 \</span><br><span class="line">--max_train_steps 500 \</span><br><span class="line">--num_warmup_steps 50 \</span><br><span class="line">--output_dir /data10/sqy/spikeBert_Sqy/output \</span><br><span class="line">--max_seq_length 128 \</span><br><span class="line">--checkpointing_steps 50</span><br></pre></td></tr></table></figure>
<br>
<p>launch.json文件：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: 模块&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;torch.distributed.run&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python: Distributed Torch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/sqy/spikeBert_Sqy/run_pretrain_binary.py&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="comment">//&quot;module&quot;: &quot;torch.distributed.run&quot;,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="comment">//&quot;--nproc_per_node=8&quot;</span></span><br><span class="line">                <span class="comment">//,&quot;--master_port=44144&quot;,</span></span><br><span class="line">                <span class="string">&quot;--dataset_name&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;/data10/static_10000&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--model_name_or_path&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;/data10/sqy/spikeBert_Sqy/bert-base-uncased&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--per_device_train_batch_size&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;32&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--per_device_eval_batch_size&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;32&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--learning_rate&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;2e-4&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--max_train_steps&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;500&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--num_warmup_steps&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;50&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--output_dir&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;/data10/sqy/spikeBert_Sqy/output&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--max_seq_length&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;128&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--checkpointing_steps&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;50&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;MASTER_PORT&quot;</span><span class="punctuation">:</span> <span class="string">&quot;44144&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;NPROC_PER_NODE&quot;</span><span class="punctuation">:</span> <span class="string">&quot;8&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ul>
<li><code>moudel / program</code> 这两者只能存在一个</li>
<li><code>&quot;program&quot;:&quot;$&#123;workspaceFolder&#125;/sqy/spikeBert_Sqy/run_pretrain_binary.py&quot;</code>,我不知道为什么，一旦调试就会进入根目录，所以这里<strong>workspaceFolder</strong>指的就是根目录，所以记得填写好路径，才能运行</li>
<li><code>&quot;--model_name_or_path&quot;,&quot;/data10/sqy/spikeBert_Sqy/</code>这里之前也用的是相对路径，导致我报了不少错误，很大的一个debug工程捏，相对路径害死人呜呜</li>
</ul>
<br>
<h2 id="常用-launchjson-配置参数详解"><a class="markdownIt-Anchor" href="#常用-launchjson-配置参数详解"></a> 常用 launch.json 配置参数详解</h2>
<p>在使用 <code>launch.json</code> 配置调试环境时，会涉及到多个参数，用于定义调试器的行为和目标执行环境。以下是一些常用的配置参数：</p>
<ul>
<li><strong>“type”</strong>：指定调试器的类型，例如 <code>&quot;node&quot;</code> 表示 Node.js 调试器，<code>&quot;python&quot;</code> 表示 Python 调试器，<code>&quot;java&quot;</code> 表示 Java 调试器等。</li>
<li><strong>“request”</strong>：指定调试的请求类型，可以是 <code>&quot;launch&quot;</code>（启动一个新的进程）或 <code>&quot;attach&quot;</code>（附加到已有的进程）。</li>
<li><strong>“name”</strong>：为配置提供一个友好的名称，方便识别不同的调试配置。</li>
<li><strong>“program”</strong>：用于指定程序的入口文件路径，可以是绝对路径或相对于工作目录的路径。</li>
<li><strong>“args”</strong>：传递给程序的命令行参数，以数组形式提供。</li>
<li><strong>“cwd”</strong>：指定程序的工作目录，可以是绝对路径或相对于工作目录的路径。</li>
<li><strong>“env”</strong>：设置程序运行时的环境变量，以对象形式提供。</li>
<li><strong>“stopOnEntry”</strong>：设置为 <code>true</code> 时，在启动后会在入口处停止，等待调试器连接。</li>
<li><strong>“preLaunchTask”</strong>：指定在启动调试前运行的任务，通常是一个编译任务。</li>
<li><strong>“postDebugTask”</strong>：指定在调试结束后运行的任务，比如清理任务。</li>
<li><strong>“outFiles”</strong>：设置输出文件的路径，用于映射源代码和编译后的文件。</li>
<li><strong>“sourceMaps”</strong>：控制是否启用源代码映射，可以是 <code>&quot;inline&quot;</code>、<code>&quot;both&quot;</code> 或 <code>&quot;false&quot;</code>。</li>
<li><strong>“sourceMapPathOverrides”</strong>：用于根据源代码映射调整文件路径。</li>
<li><strong>“externalConsole”</strong>：设置为 <code>true</code> 时，将在外部控制台中运行程序。</li>
<li><strong>“internalConsoleOptions”</strong>：控制内部控制台的显示方式，可以是 <code>&quot;neverOpen&quot;</code>、<code>&quot;openOnSessionStart&quot;</code> 或 <code>&quot;openOnFirstSessionStart&quot;</code>。</li>
<li><strong>“showAsyncStacks”</strong>：设置为 <code>true</code> 时，在堆栈跟踪中显示异步调用的信息。</li>
<li><strong>“stopOnError”</strong>：设置为 <code>true</code> 时，当发生错误时暂停调试。</li>
<li><strong>“smartStep”</strong>：设置为 <code>true</code> 时，跳过无需调试的代码。</li>
<li><strong>“skipFiles”</strong>：指定不需要调试的文件或文件夹。</li>
<li><strong>“justMyCode”</strong>：设置为 <code>true</code> 时，只调试自己的代码。</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>服务器</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title>快捷键</title>
    <url>/2023/07/25/%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="快捷键"><a class="markdownIt-Anchor" href="#快捷键"></a> 快捷键</h1>
<h2 id="1剪切-拷贝-粘贴和其他常用快捷键"><a class="markdownIt-Anchor" href="#1剪切-拷贝-粘贴和其他常用快捷键"></a> 1.剪切、拷贝、粘贴和其他常用快捷键</h2>
<ul>
<li>Command-X：剪切所选项并拷贝到剪贴板。</li>
<li><strong>Command-C：将所选项拷贝到剪贴板。这同样适用于“访达”中的文件。</strong></li>
<li><strong>Command-V：将剪贴板的内容粘贴到当前文稿或 App 中。这同样适用于“访达”中的文件。</strong></li>
<li>Command-Z：撤销上一个命令。随后你可以按 Shift-Command-Z 来重做，从而反向执行撤销命令。在某些 App 中，你可以撤销和重做多个命令。</li>
<li>Command-A：全选各项。</li>
<li><strong>Command-F：查找文稿中的项目或打开“查找”窗口。</strong></li>
<li>Command-G：再次查找：查找之前所找到项目出现的下一个位置。要查找出现的上一个位置，请按 Shift-Command-G。</li>
<li>Command-H：隐藏最前面的 App 的窗口。要查看最前面的 App 但隐藏所有其他 App，请按 Option-Command-H。</li>
<li>Command-M：将最前面的窗口最小化至“程序坞”。要最小化最前面的 App 的所有窗口，请按 Option-Command-M。</li>
<li>Command-O：打开所选项，或打开一个对话框以选择要打开的文件。</li>
<li>Command-P：打印当前文稿。</li>
<li>Command-S：存储当前文稿。</li>
<li><strong>Command-T：打开新标签页。</strong></li>
<li>Command-W：关闭最前面的窗口。要关闭 App 的所有窗口，请按下 Option-Command-W。</li>
<li><strong>Option-Command-Esc：强制退出 App。</strong></li>
<li>Command-空格键：显示或隐藏“聚焦”搜索栏。要从“访达”窗口执行“聚焦”搜索，请按 Command–Option–空格键。（如果你使用多种输入法以便用不同的语言键入内容，这些快捷键会更改输入法而非显示“聚焦”。了解如何更改冲突的键盘快捷键。）</li>
<li>Control-Command-空格键：显示字符检视器，你可以从中选取表情符号和其他符号。</li>
<li><strong>Control-Command-F：全屏使用 App（如果 App 支持）。</strong></li>
<li>空格键：使用“快速查看”来预览所选项目。</li>
<li><strong>Command-Tab：在打开的 App 中切换到下一个最近使用的 App。</strong></li>
<li>Command-重音符 (`)：在你当前所用 App 的各个窗口之间切换。（第二个按键上的字符因键盘而异，通常是在 Tab 键上方，数字 1 的左侧。）</li>
<li><strong>Shift-Command-5：在 macOS Mojave 或更高版本中，拍摄截屏或录制屏幕。也可以使用</strong></li>
<li><strong>Shift-Command-3 或 Shift-Command-4 来拍摄截屏。进一步了解截屏。</strong></li>
<li>Shift-Command-N：在“访达”中创建一个新文件夹。</li>
<li>Command-逗号 (,)：打开最前面的 App 的偏好设置</li>
</ul>
<h2 id="2睡眠-退出登录和关机快捷键"><a class="markdownIt-Anchor" href="#2睡眠-退出登录和关机快捷键"></a> 2.睡眠、退出登录和关机快捷键</h2>
<p>在这些快捷键中，你可能需要按住其中一些快捷键稍长时间。这样有助于避免无意中使用了这些快捷键。</p>
<ul>
<li>电源按钮：按下可将 Mac 开机或将 Mac 从睡眠状态唤醒。按住这个按钮 1.5 秒可使 Mac 进入睡眠状态*。继续按住则会强制 Mac 关机。</li>
<li>Option-Command-电源按钮* 或 Option-Command-介质推出键 ：将 Mac 置于睡眠状态。</li>
<li>Control-Shift-电源按钮* 或 Control-Shift-介质推出键 ：将显示器置于睡眠状态。</li>
<li><strong>Control-电源按钮 或 Control-介质推出键 ：显示一个对话框，询问你要让 Mac 重新启动、睡眠还是关机。</strong></li>
<li>Control-Command-电源按钮*：强制 Mac 重新启动，系统不会提示你存储任何已打开且未存储的文稿。</li>
<li>Control-Command-介质推出键 ：退出所有 App，然后重新启动 Mac。如果任何打开的文稿有未存储的更改，系统会询问你要不要存储这些更改。</li>
<li><strong>Control-Option-Command-电源按钮 或 Control-Option-Command-介质推出键 ：退出所有 App，然后将 Mac 关机。如果任何打开的文稿有未存储的更改，系统会询问你要不要存储这些更改。</strong></li>
<li>Control-Command-Q：立即锁定屏幕。</li>
<li>Shift-Command-Q：退出登录你的 macOS 用户帐户。系统将提示你确认。要在不确认的情况下立即退出登录，请按下 Option-Shift-Command-Q。</li>
</ul>
<h2 id="3访达和系统快捷键"><a class="markdownIt-Anchor" href="#3访达和系统快捷键"></a> 3.访达和系统快捷键</h2>
<ul>
<li><strong>Command-D：复制所选文件。</strong></li>
<li>Command-E：推出所选磁盘或宗卷。</li>
<li>Command-F：在“访达”窗口中开始“聚焦”搜索。</li>
<li>Command-I：显示所选文件的“显示简介”窗口。</li>
<li><strong>Command-R：(1) 如果在“访达”中选择了某个替身：显示所选替身对应的原始文件。(2) 在某些 App（如“日历”或 Safari 浏览器）中，刷新或重新载入页面。(3) 在“软件更新”中，再次检查有没有软件更新。</strong></li>
<li><strong>Shift-Command-C：打开“电脑”窗口。</strong></li>
<li><strong>Shift-Command-D：打开“桌面”文件夹。</strong></li>
<li>Shift-Command-F：打开“最近使用”窗口，其中会显示你最近查看或更改过的所有文件。</li>
<li><strong>Shift-Command-G：打开“前往文件夹”窗口。</strong></li>
<li><strong>Shift-Command-H：打开当前 macOS 用户帐户的个人文件夹。</strong></li>
<li>Shift-Command-I：打开 iCloud 云盘。</li>
<li>Shift-Command-K：打开“网络”窗口。</li>
<li>Option-Command-L：打开“下载”文件夹。</li>
<li><strong>Shift-Command-N：新建文件夹。</strong></li>
<li>Shift-Command-O：打开“文稿”文件夹。</li>
<li>Shift-Command-P：在“访达”窗口中显示或隐藏预览面板。</li>
<li>Shift-Command-R：打开“隔空投送”窗口。</li>
<li>Shift-Command-T：显示或隐藏“访达”窗口中的标签页栏。</li>
<li>Ctrl-Shift-Command-T：将所选的“访达”项目添加到“程序坞”（OS X Mavericks 或更高版本）</li>
<li>Shift-Command-U：打开“实用工具”文件夹。</li>
<li><strong>Option-Command-D：显示或隐藏“程序坞”。</strong></li>
<li>Control-Command-T：将所选项添加到边栏（OS X Mavericks 或更高版本）。</li>
<li>Option-Command-P：隐藏或显示“访达”窗口中的路径栏。</li>
<li>Option-Command-S：隐藏或显示“访达”窗口中的边栏。</li>
<li>Command–斜线 (/)：隐藏或显示“访达”窗口中的状态栏。</li>
<li>Command-J：显示“显示”选项。</li>
<li>Command-K：打开“连接服务器”窗口。</li>
<li>Control-Command-A：为所选项制作替身。</li>
<li><strong>Command-N：打开一个新的“访达”窗口。</strong></li>
<li>Option-Command-N：新建智能文件夹。</li>
<li>Command-T：在当前“访达”窗口中有单个标签页开着的状态下显示或隐藏标签页栏。</li>
<li>Option-Command-T：在当前“访达”窗口中有单个标签页开着的状态下显示或隐藏工具栏。</li>
<li>Option-Command-V：将剪贴板中的文件从原始位置移动到当前位置。</li>
<li>Command-Y：使用“快速查看”预览所选文件。</li>
<li>Option-Command-Y：显示所选文件的快速查看幻灯片显示。</li>
<li>Command-1：以图标方式显示“访达”窗口中的项目。</li>
<li>Command-2：以列表方式显示“访达”窗口中的项目。</li>
<li>Command-3：以分栏方式显示“访达”窗口中的项目。</li>
<li>Command-4：以画廊方式显示“访达”窗口中的项目。</li>
<li><strong>Command-左中括号 ([)：前往上一个文件夹。</strong></li>
<li><strong>Command-右中括号 (])：前往下一个文件夹。</strong></li>
<li>Command-上箭头：打开包含当前文件夹的文件夹。</li>
<li>Command-Control-上箭头：在新窗口中打开包含当前文件夹的文件夹。</li>
<li>Command-下箭头：打开所选项。</li>
<li>右箭头：打开所选文件夹。这个快捷键仅在列表视图中有效。</li>
<li>左箭头：关闭所选文件夹。这个快捷键仅在列表视图中有效。</li>
<li><strong>Command-Delete：将所选项移到废纸篓。</strong></li>
<li><strong>Shift-Command-Delete：清倒废纸篓。</strong></li>
<li>Option-Shift-Command-Delete：清倒废纸篓而不显示确认对话框。</li>
<li>Command-调低亮度：当 Mac 连接到多台显示器时，打开或关闭视频镜像功能。</li>
<li>Option-调高亮度：打开“显示器”偏好设置。这个快捷键可与任一亮度键搭配使用。</li>
<li>Control-调高亮度或 Control-调低亮度：更改外接显示器的亮度（如果显示器支持）。</li>
<li>Option-Shift-调高亮度或 Option-Shift-调低亮度：以较小的幅度调节显示器亮度。如果- 你的显示器支持，可以将 Control 键添加到此快捷键，以便在外接显示器上进行调节。</li>
<li>Option-调度中心：打开“调度中心”偏好设置。</li>
<li>Command-调度中心：显示桌面。</li>
<li>Control-下箭头：显示最前面的 App 的所有窗口。</li>
<li>Option-调高音量：打开“声音”偏好设置。这个快捷键可与任一音量键搭配使用。</li>
<li>Option-Shift-调高音量或 Option-Shift-调低音量：以较小的幅度调节音量。</li>
<li>Option-键盘调高亮度：打开“键盘”偏好设置。这个快捷键可与任一键盘亮度键搭配使用。</li>
<li>Option-Shift-键盘调高亮度或 Option-Shift-键盘调低亮度：以较小的幅度调节键盘亮度。</li>
<li>连按 Option 键：在单独的窗口中打开项目，然后关闭原始窗口。</li>
<li>连按 Command 键：在单独的标签页或窗口中打开文件夹。</li>
<li>按住 Command 键拖移到另一个宗卷：将拖移的项目移到另一个宗卷，而不是拷贝它。</li>
<li>按住 Option 键拖移：拷贝托移的项目。拖移项目时，指针会发生变化。</li>
<li>拖移时按住 Option-Command：为拖移的项目制作替身。拖移项目时指针会发生变化。</li>
<li>按住 Option 键点按开合三角：打开所选文件夹内的所有文件夹。这个快捷键仅在列表视图中有效。</li>
<li>按住 Command 键点按窗口标题：查看包含当前文件夹的文件夹。</li>
</ul>
<h2 id="4文稿快捷键"><a class="markdownIt-Anchor" href="#4文稿快捷键"></a> 4.文稿快捷键</h2>
<p>这些快捷键的行为可能因你使用的 App 而异。</p>
<ul>
<li><strong>Command-B：以粗体显示所选文本，或者打开或关闭粗体显示功能。</strong></li>
<li><strong>Command-I：以斜体显示所选文本，或者打开或关闭斜体显示功能。</strong></li>
<li>Command-K：添加网页链接。</li>
<li>Command-U：对所选文本加下划线，或者打开或关闭加下划线功能。</li>
<li>Command-T：显示或隐藏“字体”窗口。</li>
<li>Command-D：从“打开”对话框或“存储”对话框内选择“桌面”文件夹。</li>
<li>Control-Command-D：显示或隐藏所选字词的定义。</li>
<li>Shift-Command-冒号 (😃：显示“拼写和语法”窗口。</li>
<li>Command-分号 (😉：查找文稿中拼写错误的字词。</li>
<li>Option-Delete：删除插入点左边的字词。</li>
<li>Control-H：删除插入点左边的字符。也可以使用 Delete 键。</li>
<li>Control-D：删除插入点右边的字符。也可以使用 Fn-Delete。</li>
<li>Fn-Delete：在没有向前删除键的键盘上向前删除。也可以使用 Control-D。</li>
<li>Control-K：删除插入点与行或段落末尾处之间的文本。</li>
<li><strong>Fn-上箭头：Page Up：向上滚动一页。</strong></li>
<li><strong>Fn-下箭头：Page Down：向下滚动一页。</strong></li>
<li>Fn-左箭头：Home：滚动到文稿开头。</li>
<li>Fn-右箭头：End：滚动到文稿末尾。</li>
<li><strong>Command-上箭头：将插入点移至文稿开头。</strong></li>
<li><strong>Command-下箭头：将插入点移至文稿末尾。</strong></li>
<li><strong>Command-左箭头：将插入点移至当前行的行首。</strong></li>
<li><strong>Command-右箭头：将插入点移至当前行的行尾。</strong></li>
<li><strong>Option-左箭头：将插入点移至上一字词的词首。</strong></li>
<li><strong>Option-右箭头：将插入点移至下一字词的词尾。</strong></li>
<li><strong>Shift-Command-上箭头：选中插入点与文稿开头之间的文本。</strong></li>
<li><strong>Shift-Command-下箭头：选中插入点与文稿末尾之间的文本。</strong></li>
<li><strong>Shift-Command-左箭头：选中插入点与当前行行首之间的文本。</strong></li>
<li><strong>Shift-Command-右箭头：选中插入点与当前行行尾之间的文本。</strong></li>
<li><strong>Shift-上箭头：将文本选择范围扩展到上一行相同水平位置的最近字符处。</strong></li>
<li><strong>Shift-下箭头：将文本选择范围扩展到下一行相同水平位置的最近字符处。</strong></li>
<li><strong>Shift-左箭头：将文本选择范围向左扩展一个字符。</strong></li>
<li><strong>Shift-右箭头：将文本选择范围向右扩展一个字符。</strong></li>
<li>Option-Shift-上箭头：将文本选择范围扩展到当前段落的段首，再按一次则扩展到下一段落的段首。</li>
<li>Option-Shift-下箭头：将文本选择范围扩展到当前段落的段尾，再按一次则扩展到下一段落的段尾。</li>
<li>Option-Shift-左箭头：将文本选择范围扩展到当前字词的词首，再按一次则扩展到下一字词的词首。</li>
<li>Option-Shift-右箭头：将文本选择范围扩展到当前字词的词尾，再按一次则扩展到下一字词的词尾。</li>
<li>Control-A：移至行或段落的开头。</li>
<li>Control-E：移至行或段落的末尾。</li>
<li>Control-F：向前移动一个字符。</li>
<li>Control-B：向后移动一个字符。</li>
<li>Control-L：将光标或所选内容置于可见区域中央。</li>
<li>Control-P：上移一行。</li>
<li>Control-N：下移一行。</li>
<li>Control-O：在插入点后新插入一行。</li>
<li>Control-T：将插入点后面的字符与插入点前面的字符交换。</li>
<li><strong>Command-左花括号 ({)：左对齐。</strong></li>
<li><strong>Command-右花括号 (})：右对齐。</strong></li>
<li>Shift-Command-竖线 (|)：居中对齐。</li>
<li>Option-Command-F：前往搜索栏。</li>
<li>Option-Command-T：显示或隐藏 App 中的工具栏。</li>
<li>Option-Command-C：拷贝样式：将所选项的格式设置拷贝到剪贴板。</li>
<li>Option-Command-V：粘贴样式：将拷贝的样式应用到所选项。</li>
<li>Option-Shift-Command-V：粘贴并匹配样式：将周围内容的样式应用到粘贴在该内容中的项目。</li>
<li>Option-Command-I：显示或隐藏检查器窗口。</li>
<li>Shift-Command-P：页面设置：显示用于选择文稿设置的窗口。</li>
<li>Shift-Command-S：显示“存储为”对话框或复制当前文稿。</li>
<li>Shift-Command-减号 (-)：缩小所选项。</li>
<li>Shift-Command-加号 (+)：放大所选项。Command-等号 (=) 可实现相同的功能。</li>
<li>Shift-Command-问号 (?)：打开“帮助”菜单。</li>
</ul>
<h2 id="5辅助功能快捷键"><a class="markdownIt-Anchor" href="#5辅助功能快捷键"></a> 5.辅助功能快捷键</h2>
<p>要使用以下视觉辅助功能快捷键，请先选取苹果菜单  &gt;“系统设置”（或“系统偏好设置”），然后点按“键盘”。点按“键盘快捷键”，在左侧选择“辅助功能”，然后在右侧选择“反转颜色”和“对比度”。</p>
<ul>
<li>Control-Option-Command-8：反转颜色。</li>
<li>Control-Option-Command-逗号 (,) 和 Control-Option-Command-句点 (.)：降低对比度和增强对比度。</li>
</ul>
<p>使用以下快捷键可更改键盘焦点。要使用其中的某些快捷键，请先选取苹果菜单  &gt;“系统设置”（或“系统偏好设置”），然后点按“键盘”。点按“键盘快捷键”，在左侧选择“键盘”，然后在右侧选择相应快捷键的设置。</p>
<ul>
<li>Control-F2 或 Fn-Control-F2：将焦点移到菜单栏。随后，你可以使用箭头键来浏览菜单，按下 Return 键来打开选中的菜单或选取选中的菜单项，或键入菜单项的名称以跳转到选中菜单中的这个项目。</li>
<li>Control-F3 或 Fn-Control-F3：将焦点移到程序坞。</li>
<li>Control-F4 或 Fn-Control-F4：将焦点移到活跃窗口或下一个窗口。</li>
<li>Control-F5 或 Fn-Control-F5：将焦点移到窗口工具栏。</li>
<li>Control-F6 或 Fn-Control-F6：将焦点移到浮动窗口。</li>
<li>Control-Shift-F6：将焦点移到上一个面板。</li>
<li>Control-F7 或 Fn-Control-F7：更改 Tab 键移动焦点的方式 - 浏览屏幕上的所有控制，或仅浏览文本框和列表。</li>
<li>Control-F8 或 Fn-Control-F8：将焦点移到菜单栏中的状态菜单</li>
<li>Command–重音符 (`)：激活前台 App 中下一个打开的窗口。</li>
<li>Shift–Command–重音符 (`)：激活前台 App 中上一个打开的窗口</li>
<li>Option–Command–重音符 (`)：将焦点移到窗口抽屉。</li>
<li>Tab 和 Shift-Tab：移到下一个控制，移到上一个控制。</li>
<li>Control-Tab：选定文本栏时移到下一个控制。</li>
<li>Control-Shift-Tab：移到上一组控制。</li>
<li>箭头键：移到列表、标签组或菜单中的相邻项，或移动滑块和调整器（上箭头键可增大值，下箭头键可减小值）</li>
<li>Control–箭头键：移到与文本栏相邻的控制。</li>
</ul>
<h2 id="6safari浏览器"><a class="markdownIt-Anchor" href="#6safari浏览器"></a> 6.Safari浏览器</h2>
<ul>
<li>
<p>下载：</p>
<p>下载该链接文件：option+按键</p>
</li>
<li>
<p>书签边栏和书签视图：</p>
<p>打开或隐藏书签栏：control+command+1</p>
</li>
</ul>
]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title>机器翻译学术论文写作方法和技巧--刘洋</title>
    <url>/2024/03/22/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A7-%E5%88%98%E6%B4%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="审稿过程"><a class="markdownIt-Anchor" href="#审稿过程"></a> 审稿过程</h2>
<p>（审稿人）审稿时往往先看题目、摘要，扫一下introduction（知道你做什么），然后直接翻到最后找核心实验结果（做得好不好），然后基本确定录还是不录（也许只用5分钟！）。如果决定录，剩下就是写些赞美的话，指出些次要的小毛病。如果决定拒，下面的过程就是细看中间部分找理由拒了。”</p>
<p>为此，我们的观念应当有所转变：以作者为核心整理工作 =&gt; 以读者为核心阐述工作</p>
<Br>
<h2 id="为读者服务"><a class="markdownIt-Anchor" href="#为读者服务"></a> 为读者服务</h2>
<p>信息的呈现符合读者的<strong>认知惯性</strong>：深入浅出，引人入胜，让读者快速找到想要的信息<br />
<strong>尽量降低读者的理解难度</strong>：图 &gt; 曲线 &gt; 表 &gt; 正文 &gt; 公式<br />
尽量<strong>提高读者阅读时的愉悦感</strong>：思想新颖、组织合理、逻辑严密、论证充分、文笔优美、排版美观<br />
<strong>tip</strong>：降低信息理解难度是关键。</p>
<br>
<h2 id="标题"><a class="markdownIt-Anchor" href="#标题"></a> 标题</h2>
<p>关键词+概括所做的工作</p>
<br>
<h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> abstract</h2>
<p>⼏句话概括你的⼯作：⽤语要简单，让外⾏能看懂</p>
<p>误区</p>
<ul>
<li>⼒图把所有细节都说清楚</li>
<li>⽤很专业的术语来描述</li>
<li>出现数学符号</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GJSGyKMWsAANUam?format=jpg&amp;name=medium" alt="" /></p>
<p>传统的 n-best 重排序技术常常因为 n-best 列表的有限范围而受限，这排除了许多潜在的好选择。// 相反，我们提出了森林重排序，一种对指数级数量的解析进行重排序的方法。// 由于在非局部特征下进行精确推断是不可行的，我们提出了一种近似算法，该算法受到森林重新评分的启发，使得在整个树库上进行判别式训练变得可行。// 我们的最终结果，一个 91.7 的 F 分数，超过了 50-best 和 100-best 重排序基线，并且比任何之前在树库上训练的系统都要好。</p>
<br>
<p><strong>改正前</strong>：<br />
本文考虑可循环智能包装在循环过程中的经济和环境影响，建立可循环智能包装多级逆向物流系统；构建多目标优化模型，建立激励机制以促进客户的回收行为，并采用排放因子法进行碳排放估算；基于多种改进算子，提出多目标遗传-禁忌搜索混合算法（MOHGATS），与多目标遗传算法和多目标禁忌搜索算法相比，该算法在计算精度和寻优能力上具有明显优势，从目标函数值、求解时间、评价指标等方面验证了在多个算例下的有效性；选取北京市沙河高教园相关数据进行实例分析，验证了该网络设计方案的可行性。探讨了客户对不同激励成本的心理接受程度对逆向物流系统的影响</p>
<p><strong>改正后</strong>：<br />
尽管可循环智能包装为人们的生活带来了诸多便利，但其循环过程对经济和环境产生了重大影响。//面对这一挑战，我们设计并实施了一个多级逆向物流系统，专为可循环智能包装而设。// 通过开发一种多目标优化模型，我们不仅建立了促进消费者回收行为的激励机制，还采用排放因子法来估算碳排放量。此外，我们还创新性地提出了一种融合多目标遗传算法和禁忌搜索的混合算法（MOHGATS），在解决方案的计算精度和优化能力方面，相较于现有技术展现了显著优势。// 基于北京市沙河高教园的实际数据进行的案例分析不仅证明了我们网络设计方案的实用性，还探讨了不同激励成本下消费者心理接受度对逆向物流系统影响的重要性。实验数据显示，我们的方法在提升可循环智能包装系统的经济与环境效益方面取得了显著成效。</p>
<br>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> introduction</h2>
<p>比题目和摘要更进一步，用几段话说清你的⼯作，要点是充分论证你所做⼯工作的必要性和重要性,要让审稿⼈人认同并迫不及待想往下看,⾏⽂逻辑严密，论证充分</p>
<p><strong>简单的逻辑</strong>：</p>
<ul>
<li>说明问题是什么</li>
<li>简单罗列前⼈人⼯工作</li>
<li>描述我们的⼯工作</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GJaANuaWsAAR_Rp?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h3 id="段落的写法"><a class="markdownIt-Anchor" href="#段落的写法"></a> 段落的写法</h3>
<p>段落的写法:</p>
<ul>
<li>每段都有论断性的<strong>中心句</strong></li>
<li>其余部分都是<strong>支撑句</strong>，围绕中心句展开论证，且论证要严密
<ul>
<li><strong>前人工作</strong></li>
<li><strong>具体数据</strong></li>
</ul>
</li>
<li>支撑句之间可分类组织（关联词 …）</li>
<li>段位可以加上<strong>衔接句</strong>（适当的总结：Therefore, … ）</li>
</ul>
<p>tips:</p>
<ul>
<li>在首页放置一张图或表，让读者一目了然所做的工作；</li>
<li>不要去写“This paper is organized as follow. Section 2 …”，而是直接列出自己的贡献。</li>
</ul>
<br>
<p>基于句法的统计机器翻译方法利用带有句法注释的平行数据，这些注释可能是短语结构树或依存树的形式。|| 这些方法大致可以分为三类：字符串到树模型（例如，Galley等人，2006年；Marcu等人，2006年；Shen等人，2008年），树到字符串模型（例如，Liu等人，2006年；Fu等人，2006年），以及树到树模型（例如，Eisner，2003年；Ding与Palmer，2005年；Cowan等人，2006年；Zhang等人，2008年）。通过建模源语言和目标语言的句法，树到树方法有潜在的好处，可以提供在语言学上更有动机的规则。然而，尽管字符串到树和树到字符串模型在实证评估中显示出有希望的结果，树到树模型仍然表现不佳。</p>
<p>//</p>
<p>我们认为树到树模型面临两大挑战。|| 首先，树到树模型对解析错误更为敏感。获取大量句法注释通常需要在平行语料库上运行自动解析器。由于用于训练解析器的数据量和领域相对有限，解析器在处理现实世界文本时不可避免地会输出格式不正确的树。在这样的含有噪声的句法信息指导下，依赖于最佳解析的基于句法的模型倾向于在训练阶段学习到噪声翻译规则，并在解码阶段产生退化的翻译（Quirk和Corston-Oliver，2006）。对于在双方都使用句法的树到树模型，这种情况变得更加严重。</p>
<p>其次，树到树规则提供的规则覆盖率较差。|| 由于树到树规则要求两边都必须有树，树到树模型会丢失大量在语言学上无动机的映射。研究显示，这种非句法映射的缺失将极大地损害翻译质量（Marcu等人，2006年；Liu等人，2007年；DeNeefe等人，2007年；Zhang等人，2008年）。</p>
<p>//</p>
<p>为了紧凑地编码指数级的解析，打包的森林被证明是缓解上述两个问题的绝佳选择（Mi等人，2008年；Mi和Huang，2008年）。|| 在本文中，我们提出了一种基于森林的树到树模型。为了从对齐的森林对中学习STSG（同步树替换文法）规则，我们引入了一系列概念来识别最小的树到树规则。我们的解码器首先将源森林转换为翻译森林，然后找到具有源森林中某棵树源产出的最佳衍生物。与Moses相比，我们的基于森林的树到树模型在传统基于树的模型上实现了3.6 BLEU分的绝对改进。</p>
<br>
<h3 id="图与表"><a class="markdownIt-Anchor" href="#图与表"></a> 图与表</h3>
<p><strong>图和表是论文的骨架</strong>，争取让读者按照顺序看就能理解论⽂的主要思想，不用通过看正文才能懂（⼀般第⼀遍看，都会看图、找例子，然后翻到后面找主要结果，再从头看正⽂）</p>
<p>把论文的元素放在<strong>最应该被放在的地方</strong>，符合读者的认知惯性，降低理解难度</p>
<p><img src="https://pbs.twimg.com/media/GJaBHigXcAAgCXV?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="方法"><a class="markdownIt-Anchor" href="#方法"></a> 方法</h2>
<p><strong>注意</strong>：不要一上来就描述你的工作，可以先介绍背景知识(往往就是baseline)</p>
<ul>
<li>有利于降低初学者或其他领域学者的理解难度</li>
<li>有利于对introduction中的论文做<strong>更详细的解释</strong></li>
<li>有利于<strong>对比</strong>baseline和你的⽅法</li>
</ul>
<p><strong>逻辑顺序</strong>：</p>
<ul>
<li>首先给出running example</li>
<li>然后利用running example，用通俗语言描述自己的想法</li>
<li>形式化的描述</li>
</ul>
<h3 id="running-example"><a class="markdownIt-Anchor" href="#running-example"></a> Running Example</h3>
<ul>
<li>全篇统一使用一个running example，用来阐释自己的方法（甚至是baseline）</li>
<li>围绕着running example，展开描述自己的工作</li>
<li>审稿人能从running example中更舒服地了解自己的工作，读正文会花掉他/她更多时间</li>
<li>看完running example，审稿人便能知道核心思想</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GJaDK3tWwAAQwyY?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="实验"><a class="markdownIt-Anchor" href="#实验"></a> 实验</h2>
<ul>
<li>公认的标准数据和state-of-the-art系统</li>
<li>实验先辅后主
<ul>
<li>辅助实验(开发集):参数的影响</li>
<li>主实验(测试集):证明显著超过baseline 必须有显著性检验</li>
</ul>
</li>
<li>不辞辛劳，做到极致</li>
</ul>
<h3 id="先辅后主"><a class="markdownIt-Anchor" href="#先辅后主"></a> 先辅后主</h3>
<p><img src="https://pbs.twimg.com/media/GJaEabVWQAANSYa?format=jpg&amp;name=medium" alt="" /></p>
<h3 id="用图误区"><a class="markdownIt-Anchor" href="#用图误区"></a> 用图误区</h3>
<ul>
<li>左边太密集了</li>
<li>交叉、不对应<br />
<img src="https://pbs.twimg.com/media/GJaGGL7W0AAEqZ2?format=jpg&amp;name=medium" alt="" /></li>
</ul>
<h3 id="用表误区"><a class="markdownIt-Anchor" href="#用表误区"></a> 用表误区</h3>
<ul>
<li>描述要包含充分信息，不用看原文就能理解</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GJaGneCW8AE5FTQ?format=jpg&amp;name=medium" alt="" /></p>
<br>
<h2 id="相关工作"><a class="markdownIt-Anchor" href="#相关工作"></a> 相关工作</h2>
<p>trap：</p>
<ul>
<li>没有引用重要论文(可以直接被reject)</li>
<li>简单的罗列和堆砌，缺乏深刻到位的评论</li>
<li>通过批评/攻击前人工作来证明个人工作地创新性(有没有一种可能，前人的工作就是审稿人的工作呢，那么你是不是G了)</li>
</ul>
<p>tips：</p>
<ul>
<li>向审稿人显示你对本领域全面深刻的把握</li>
<li>通过与前人工作的对比来凸显个人工作的创新性</li>
</ul>
<h3 id="传承与创新"><a class="markdownIt-Anchor" href="#传承与创新"></a> 传承与创新</h3>
<p><img src="https://pbs.twimg.com/media/GJaIVYZWcAAE6zU?format=png&amp;name=900x900" alt="" /><br />
<img src="https://pbs.twimg.com/media/GJaIQZWXYAAOTXI?format=png&amp;name=900x900" alt="" /></p>
<h2 id="写作技巧"><a class="markdownIt-Anchor" href="#写作技巧"></a> 写作技巧</h2>
<p>常见问题，详细内容请见<a href="https://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt14_tut.pdf">这里</a>：</p>
<ul>
<li>句子过长</li>
<li>经常被动句式</li>
<li>口语化</li>
<li>the，a的使用</li>
<li>公式后面文字的缩进</li>
<li>引用的写法</li>
</ul>
<p>工具：</p>
<ul>
<li>latex代替word</li>
<li>bibtex：自动生成参考文献</li>
<li>metapost：编程画矢量图</li>
</ul>
<p>时间管理和获得反馈：</p>
<ul>
<li>coarse-to-fine：
<ul>
<li>截稿前一个月开始写</li>
<li>每隔两天改一次</li>
</ul>
</li>
<li>听取不同背景读者的意见
<ul>
<li>专家</li>
<li>非专家</li>
</ul>
</li>
</ul>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://www.cnblogs.com/RyanXing/p/10015028.html">《机器翻译学术论文写作方法和技巧》</a></li>
<li><a href="https://blog.csdn.net/qq_39087432/article/details/115445395">【笔记】机器翻译学术论文写作方法和技巧（作者：清华大学 刘洋）</a></li>
<li><a href="https://blog.csdn.net/sdu_hao/article/details/104562372">学术论文写作 | (7)NLP学术论文写作方法和技巧</a></li>
<li><a href="https://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt14_tut.pdf">[PPT]机器翻译学术论⽂写作⽅法和技巧</a></li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>写作技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]校招被裁后的心路历程</title>
    <url>/2024/06/30/%E6%A0%A1%E6%8B%9B%E8%A2%AB%E8%A3%81%E5%90%8E%E7%9A%84%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="原文"><a class="markdownIt-Anchor" href="#原文"></a> 原文</h2>
<p>首先我给学校丢脸了，去年毕业入职今年被卡转正裁员，后续在java这个赛道找工作几个月一事无成。这家公司叫做新华三h3c，我一定要好好fuck一下它！ 先是延期2个月入职，然后23年12月底裁员一大波人，后续又对应届生卡转正，我只恨自己不争气校招去了这样一个辣鸡公司，希望学弟学妹看见引以为戒。裁员还不给补偿，只给一个月离职时间，那段时间真让人焦虑，但没想到找工作时更是处处碰壁，经历了很多次kpi面试（互联网以高级工程师的职位来面你）后，从希望到绝望太多回em22…</p>
<p>现在我想也许是换一个赛道了（不知道对不对），最后拿到这几个offer：</p>
<p>1.北京——和利时的高铁信号列控反向  C语言嵌入式  总包28<br />
2.家乡省会贵阳——航天科工单位  emc电磁兼容工程师 总包12<br />
3.重庆——太平洋保险省分 java全栈 总包10</p>
<p>虽然我本身就是贵阳的，但是我对于航天的奉献精神还是有一点抵触，面试的时候也告诉我航天是讲奉献的，出差加班多。不知道C语言嵌入式未来好跳槽吗，和利时的hr跟我说他们是传统稳定的私企，也不知道真假…只是感觉方向确实也挺小众。</p>
<p>目前不太考虑钱，只希望未来的反向。</p>
<h2 id="对话"><a class="markdownIt-Anchor" href="#对话"></a> 对话</h2>
<p><strong>xinhong</strong></p>
<p>北京和利时</p>
<hr />
<p><strong>xinhong</strong></p>
<p>航天军工</p>
<hr />
<p><strong>xinhong</strong></p>
<p>重庆太平洋保险</p>
<hr />
<p><strong>buptseven</strong></p>
<p>人生的际遇总是难以预料，也许就柳暗花明，未来可期</p>
<hr />
<p><strong>intmain</strong></p>
<p>讲奉献…确实很令人反感，嵌入式岗位在二三线城市也有不少，方便找退路。</p>
<hr />
<p><strong>christmas258</strong></p>
<p>目前在嵌入式，只能说这个行业比Java更看重经验。</p>
<hr />
<p><strong>lsx0871</strong></p>
<p>省公司好一点</p>
<hr />
<p><strong>AshSnow</strong></p>
<p>省分这点钱不是开发吧</p>
<hr />
<p><strong>qhf23771002</strong></p>
<p>为什么没有赔偿，N+1不是底线吗</p>
<hr />
<p><strong>Cyclotron</strong></p>
<p>毕业一年内互联网都是按照校招面试的，是不是没有准备好八股和项目？</p>
<hr />
<p><strong>xinhong</strong> 回复 Cyclotron</p>
<p>项目这一块不好表述，自己工作半年也没积累啥</p>
<hr />
<p><strong>xinhong</strong> 回复 qhf23771002</p>
<p>是这样的，很坑</p>
<hr />
<p><strong>s1225418211</strong></p>
<p>首先排除军工</p>
<hr />
<p><strong>xinhong</strong> 回复 AshSnow</p>
<p>信息技术岗吧，说是前端也要会，一个人做前后端和测试</p>
<hr />
<p><strong>pendicool</strong></p>
<p>老兄也是贵州的嘛，唉北漂真的很难…</p>
<hr />
<p><strong>youngless</strong></p>
<p>都这样了不如赌一把和利时，反正Java没啥门槛随时转</p>
<hr />
<p><strong>youngless</strong></p>
<p>主要2和3都很劝退，一个奉献一个总包</p>
<hr />
<p><strong>youngless</strong></p>
<p>没啥丢脸的，加油兄弟，这公司为啥不给赔偿啊</p>
<hr />
<p><strong>xinhong</strong> 回复 youngless</p>
<p>去年12月底的都给了，卡转正就死活不给，会想起年会时说继续降低研发投入，我就应该知道下场</p>
<hr />
<p><strong>zzh98</strong></p>
<p>新华三去年面试…不是国企吗</p>
<hr />
<p><strong>idjsvhjd</strong></p>
<p>本科毕业还是硕士毕业？</p>
<hr />
<p><strong>xinhong</strong> 回复 idjsvhjd</p>
<p>已经是硕了…</p>
<hr />
<p><strong>Novlumos</strong></p>
<p>插句话：这学期本科刚用完H3C的软件，巨垃圾巨难用</p>
<hr />
]]></content>
      <categories>
        <category>Future</category>
      </categories>
  </entry>
  <entry>
    <title>留学规划</title>
    <url>/2023/07/23/%E7%95%99%E5%AD%A6%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><ul>
<li>港新：一年，港三新二学费+生活费35w-40w，生活费1月1.5w-1.8w，综合考量，和美国很像，没有bar，文书会多，有个专门的网站可以看到录取人的backgroud，必须申请时有语言</li>
</ul>
<br>
<br>
<ul>
<li>英：强调学术能力，有清单，分数北邮80，85分两档，会涨88分，英国先申请再交成绩，G5能带语言带语言
<ul>
<li>1.伦敦地区：UCL，50w</li>
<li>​2.非伦敦：35w-40w</li>
</ul>
</li>
</ul>
<br>
<br>
<ul>
<li>
<p>澳洲：好移民，除了墨大部分school list，分数80+可</p>
<ul>
<li>1.悉尼1.5年（必须本专业）2年（可以跨申80w）</li>
<li>2.墨尔本（70w）</li>
<li>3.士兰（60w）</li>
</ul>
</li>
<li>
<p>加拿大：多伦多，麦吉尔 25w左右<br />
留下来难度：加拿大40%留下来 澳洲30%留下来</p>
</li>
</ul>
<p>留学不是考研的兜底方案，考研考不上，出国也申请不了好学校，九月份准备好所有材料</p>
<p>低分高录怎么办：舍弃专业，如果也要保专业澳大利亚</p>
<p>实习：motivation contribution</p>
<p>工科科研大于实习，如果实习大厂加核心</p>
<p>phd去对应国家老师扒老师的研究，一定要有paper，rp（你写的研究计划，即：<em>Research Proposal</em> （RP）），语言</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>fee</tag>
      </tags>
  </entry>
  <entry>
    <title>深度可分离卷积</title>
    <url>/2024/02/28/%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a href="https://blog.csdn.net/kangdi7547/article/details/117925389">【通俗易懂系列】深度可分离卷积</a></li>
</ul>
<br>
<h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h2>
<p>对于移动设备，计算资源比较受限，而卷积操作的计算量又很大，于是深度可分离卷积应运而生。</p>
<br>
<h2 id="常规卷积"><a class="markdownIt-Anchor" href="#常规卷积"></a> 常规卷积</h2>
<p>输入：128×128×3<br />
卷积核：3x3x4</p>
<p><img src="https://pbs.twimg.com/media/GHZUgvLWoAATZbZ?format=jpg&amp;name=medium" alt="" /></p>
<p>卷积层共有4个Filter，每个Filter包含3个Kernel，每个Kernel的大小为3×3。因此卷积层的参数数量可以用如下公式来计算：</p>
<p>N_std = 4 × 3 × 3 × 3 = <strong>108</strong></p>
<br>
<h2 id="深度可分离卷积"><a class="markdownIt-Anchor" href="#深度可分离卷积"></a> 深度可分离卷积</h2>
<p>深度可分离卷积是将一个完整的卷积运算分解为两步进行：</p>
<ul>
<li>Depthwise卷积</li>
<li>Pointwise卷积</li>
</ul>
<br>
<h3 id="depthwise卷积"><a class="markdownIt-Anchor" href="#depthwise卷积"></a> Depthwise卷积</h3>
<p>不同于常规卷积操作，Depthwise卷积的一个卷积核负责一个通道,所以一个三通道的图像经过运算后生成了3个特征图，如下图所示:</p>
<p><img src="https://pbs.twimg.com/media/GHZYJENWcAAgDpB?format=jpg&amp;name=medium" alt="" /></p>
<p>其中一个Filter只包含一个大小为3×3的Kernel，卷积部分的参数个数计算如下：</p>
<p>N_depthwise = 3 × 3 × 3 = <strong>27</strong></p>
<br>
<p>Depthwise卷积的<strong>缺点</strong>：完成后的特征图数量与输入层的通道数相同，无法扩展特征图数目。而且这种运算对输入层的每个通道独立进行卷积运算，没有有效地利用不同通道在相同空间位置上的特征信息。</p>
<p>因此需要Pointwise卷积来将这些特征图进行组合生成新的特征图</p>
<br>
<h3 id="pointwise卷积"><a class="markdownIt-Anchor" href="#pointwise卷积"></a> Pointwise卷积</h3>
<p>Pointwise卷积的运算与常规卷积运算类似，它的卷积核的尺寸为 1×1×M，<strong>M为上一层的通道数</strong>。这里的卷积运算会将上一步的特征图在通道方向上进行加权组合，生成新的特征图,有几个卷积核就有几个输出特征图。</p>
<p><img src="https://pbs.twimg.com/media/GHZYyRVWsAM5zT6?format=jpg&amp;name=medium" alt="" /></p>
<p>由于采用的是1×1卷积的方式，此步中卷积涉及到的参数个数可以计算为：</p>
<p>N_pointwise = 1 × 1 × 3 × 4 = <strong>12</strong></p>
<br>
<h2 id="参数对比及优势"><a class="markdownIt-Anchor" href="#参数对比及优势"></a> 参数对比及优势</h2>
<p>相同的输入，同样是得到4张特征图，深度可分离卷积的参数个数是常规卷积的约三分之一。因此，在参数量相同的前提下，采用深度可分离卷积的神经网络层数可以做的更深。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>留学DIY指北</title>
    <url>/2023/07/13/%E7%95%99%E5%AD%A6DIY%E6%8C%87%E5%8C%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="留学diy指北"><a class="markdownIt-Anchor" href="#留学diy指北"></a> 留学DIY指北</h1>
<h2 id="1选校"><a class="markdownIt-Anchor" href="#1选校"></a> 1.选校</h2>
<p>  首先讲讲选校，一般情况下中介会给你选择几个冲刺学校，保底学校，等等如此规划。但实际上学校的申请本就没有任何门槛，也不存在保底，冲刺之说，中介只是拿着一张QS学校排名，根据往年经验给你划一个区域，告诉你，这些学校需要好好申请，往上的是冲刺，往下的是保底。这其实是个伪命题，因为如果你有时间，你大可以从QS排名第一申请到QS排名200，这些学校全申请，所花费的申请费可能都不到中介费的一半。如果你自己DIY，完全不需要大费周折的选择出中介给你的10个院校左右，甚至更少。你大可以从QS排名第一申请到QS100，完全没有问题。选校只是中介因为客户众多，所以给自己减少工作量的一种方式，而越大的中介，增加预选院校的费用也会越高，不是因为他们专业，而是因为他们客户太多，没时间给你搞那么多申请，别的客户的钱一样好赚。</p>
<p>  如果想要自己DIY，选校阶段需要做的只有两件事：1. 去一亩三分地这类的留学论坛，查找和你差不多水平的学生，了解他们往年的录取情况，只需要找到一个参考，再从参考院校上下划出一些院校，到底多少个呢？自己决定，我相信你一定能从名单上选择出50个院校，然后根据位置，校风做个初筛，接下来的假设30个院校，一周的时间认真调研也足够能够调研的非常清楚。</p>
<h2 id="2调研"><a class="markdownIt-Anchor" href="#2调研"></a> 2.调研</h2>
<p>  具体参考你自己的需求，做研究生申请一定要注意，是你在为自己的未来负责，所以一定要参考你自己的喜好，例如：学术氛围，院校强项，国际生比例，种族歧视，地理位置是否偏僻，学制如何，毕业条件是否苛刻，教师是否负责任，生活费用高不高，住宿条件，租房困难程度。没有等等了，基本上这些完全可以涵盖你需要考虑的点，这个时候，请从这些点中筛选出5-8点，并且将你的院校设为纵列，关注点设为行，得到一个表格。通过一周左右的调研（论坛如：一亩三分地，知乎，等等）相信你能够对所有你喜欢的院校进行打分，并且做一个初步筛查，这样又可以排除掉一些你完全不能接受的院校。这时候，一份由你自己为自己量身打造的院校列表就新鲜出炉了，这份列表不仅参考了你的均分绩点等自身条件，还融入了你对院校的要求，所以，相信你自己不会对这份院校名单后悔的。</p>
<p>  至此为止，如果认真做调查，需要的时间不会超过1周。</p>
<h2 id="3文书cv"><a class="markdownIt-Anchor" href="#3文书cv"></a> 3.文书,CV</h2>
<p>  现在，我们正式进入到文书部分，首先要说的是，很多中介都有自己的文书老师，看起来很专业。一些其他的DIY教程也会教你去淘宝，去找在国外的学长学姐修改。其实这样写出来的文书不具有优势。有一些自由职业者聚集的网站，例如<a href="https://www.fiverr.com">Fiverr</a>, <a href="https://www.upwork.com/nx/client/dashboard/">Upwork</a>，这两个网站堪称神站，中介都很少知道这两个网站，因为本身没有用到他们的时候，楼主也是近期创业中，需要做文案校对，才使用了Fiverr，和一个UCLA毕业的美国小姐姐视频连线修改文案，整整30页的白皮书校对只要120刀。。。你能想象到的任何服务它都有，种类及其丰富，而且质量很过关，我会建议DIY申请的同学，到这个网站上，找到那些评分高的application eassy writer和CV writer，这些都是英语母语者，而且有的是语言学硕士或博士，而且做申请文书多年，往往具有非常棒的经验，能够根据你的经历，量身定做一封属于你的文书，同学们不需要害怕交流困难，你有翻译软件呀！并且，其实你只需要有一个自己的大致思路，讲清楚自己的过往经历就可以了，其他的这些writers和editors会帮你搞定的（不过还是要和淘宝一样，注意擦亮眼睛哦），CV的话，当然就是有什么写什么，如果内容比较多的话，要注意把内容压缩。接下来就讲讲文书和CV的内容部分。</p>
<h2 id="4内容准备"><a class="markdownIt-Anchor" href="#4内容准备"></a> 4.内容准备</h2>
<p>  首先，把你所有的经历罗列出来，能想到的都想到。然后进行下一步：删减。大部分同学都存在一个误区：我需要在文书中表现出我有多强，尽可能的把所有技术细节和项目都写进去。其实这是一个普遍错误的想法，无论申请学校，还是找工作，最重要的思路是了解对方的想法，master往往很短，所以学校往往会关注你对学校的就业率和就业质量有什么贡献，对于那些开放转博的master position，学校更关注你的学术水平，以及对学术的追求和渴望。如果你能表现出自己在实习期的成绩，或者表现出你对某一学科的学术追求（再去院校网站上看看这个学科老师的信息，提一嘴，说我太想去某老师门下读博了，我一定会转博的）这样你的申请就非常容易成功。即使你什么都没有，无论文无实习，但是你能表现出对读博的渴望，对某一学科的认真思考，提出几个未来可能的发展方向，并且选择一个作为未来学习的深入研究点，这样你会给学校一个积极进取的形象，那么学校也会认为你是一个未来可期的孩子。</p>
<h2 id="5推荐信"><a class="markdownIt-Anchor" href="#5推荐信"></a> 5.推荐信</h2>
<p>  推荐信尽量找认识的老师/学科相关的老师，这样会节约不少和老师磨的时间，有的老师爽快的就给你签了字。其实对于海外院校来说，只要是你在北邮找的老师，差别并不大，不需要特意找一些很牛的老师。如果有在外校如清北实验室实习的同学，也可以找到实习实验室的老师帮忙写封推荐信。推荐信如果不是牛推，其实差别并不大，牛推是指院校好+老师出名，这类的推荐信是最珍贵的。其次是院校普通，这类型推荐信除非老师在国际上很有名望，不然很难加分。所以不用纠结于每个地方都做到完美，尽量把最好的自己展示给学校，告诉学校你的实力（没有实力也要装的有实力！）就好。</p>
<h2 id="6申请"><a class="markdownIt-Anchor" href="#6申请"></a> 6.申请</h2>
<p>  终于来到了申请环节，其实有了之前的准备，申请过程无非是注意每个院校开始申请的时间，自己制作一个表格，然后根据开放时间第一时间申请，虽然申请时间会有些说道，不过自身实力才是硬道理，申请时间往往并不重要，楼主建议在申请开放的0-15天内申请，或是在申请结束的0-15天内申请。其实差别不是很大，中介帮你申请其实也只是说，帮你上传资料，点一点鼠标而已，自己多做research，根本不难<sub>而且大把的论坛上会有提交申请的指南，此处特指上传资料的部分，当你上传完所有资料，自己点提交的那一瞬间，是非常有成就感的</sub>这也是楼主非常鼓励的，对自己的未来负责。其中有部分学校会有申请费一说，记得准备一张VISA卡付款就好~</p>
<h2 id="7写在最后"><a class="markdownIt-Anchor" href="#7写在最后"></a> 7.写在最后</h2>
<p>  其实，当你跟着楼主走完这个流程，不会超过15天，但整个申请过程是为你量身定制的，花销只有CV+文书不超过2000人民币的预算，但你获得了所有中介都无法给你的精细化流程，所以就像我说的，找中介不会因为他们专业，而带给你更好的申请结果，相反，中介有可能给你条条框框+千篇一律的文书+只看重GPA的选校。你花了几万块钱，得到的是一个相对普通的申请流程+非要死命催的文书创作过程+提醒申请老师帮你申请，这些心思用在DIY上，其实所有同学，都可以做的比中介更好。DIY也能够让你对世界各地的学校有充分认识，增长见识，想要出国留学，就一定要对自己的未来负责</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>DIY</tag>
      </tags>
  </entry>
  <entry>
    <title>美国签证类型汇总</title>
    <url>/2024/06/29/%E7%BE%8E%E5%9B%BD%E7%AD%BE%E8%AF%81%E7%B1%BB%E5%9E%8B%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<!-- omit in toc -->
<h1 id="移民签证与非移民签证详解"><a class="markdownIt-Anchor" href="#移民签证与非移民签证详解"></a> 移民签证与非移民签证详解</h1>
<p>在美国签证体系中，移民签证和非移民签证分别用于长期和短期的不同需求。本文将详细介绍各种签证类型，方便读者了解各类签证的申请条件及其用途。</p>
<!-- omit in toc -->
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E4%B8%80%E4%BA%B2%E5%B1%9E%E7%B1%BB%E7%A7%BB%E6%B0%91%E7%AD%BE%E8%AF%81family-based-immigrant-visas">一、亲属类移民签证（Family-Based Immigrant Visas）</a>
<ul>
<li><a href="#ir%E7%B1%BBimmediate-relative-immigrant-visas">IR类（Immediate Relative Immigrant Visas）</a></li>
<li><a href="#f%E7%B1%BBfamily-preference-immigrant-visas">F类（Family Preference Immigrant Visas）</a></li>
</ul>
</li>
<li><a href="#%E4%BA%8C%E8%81%8C%E4%B8%9A%E7%B1%BB%E7%A7%BB%E6%B0%91%E7%AD%BE%E8%AF%81employment-based-immigrant-visas">二、职业类移民签证（Employment-Based Immigrant Visas）</a>
<ul>
<li><a href="#eb-1">EB-1</a></li>
<li><a href="#eb-2">EB-2</a></li>
<li><a href="#eb-3">EB-3</a></li>
<li><a href="#eb-4">EB-4</a></li>
<li><a href="#eb-5">EB-5</a></li>
</ul>
</li>
<li><a href="#%E4%B8%89%E7%89%B9%E6%AE%8A%E7%B1%BB%E7%A7%BB%E6%B0%91%E7%AD%BE%E8%AF%81special-immigrant-visas">三、特殊类移民签证（Special Immigrant Visas）</a></li>
<li><a href="#%E5%9B%9B%E9%9D%9E%E7%A7%BB%E6%B0%91%E7%B1%BB%E7%AD%BE%E8%AF%81non-immigrant-visas">四、非移民类签证（Non-Immigrant Visas）</a>
<ul>
<li><a href="#%E6%97%85%E6%B8%B8%E8%AE%BF%E9%97%AE%E7%B1%BB%E7%AD%BE%E8%AF%81b%E7%B1%BB">旅游/访问类签证（B类）</a></li>
<li><a href="#%E8%BF%87%E5%A2%83%E7%AD%BEc%E7%B1%BB">过境签（C类）</a></li>
<li><a href="#%E6%9C%BA%E7%BB%84%E4%BA%BA%E5%91%98%E7%AD%BE%E8%AF%81d%E7%B1%BB">机组人员签证（D类）</a></li>
<li><a href="#%E5%B7%A5%E7%AD%BE%E7%B1%BB">工签类</a>
<ul>
<li><a href="#l%E7%B1%BB%E8%B7%A8%E5%9B%BD%E4%BC%81%E4%B8%9A%E6%B4%BE%E9%81%A3%E7%AD%BE%E8%AF%81">L类（跨国企业派遣签证）</a></li>
<li><a href="#h%E7%B1%BB%E9%9B%87%E4%B8%BB%E7%B1%BB%E5%B7%A5%E7%AD%BE">H类（雇主类工签）</a></li>
<li><a href="#e%E7%B1%BB%E8%B4%B8%E6%98%93%E6%8A%95%E8%B5%84%E7%AD%BE%E8%AF%81">E类（贸易投资签证）</a></li>
<li><a href="#p%E7%B1%BB%E6%96%87%E8%89%BA%E4%BD%93%E8%A1%8C%E4%B8%9A%E7%9A%84%E6%9D%B0%E5%87%BA%E4%BA%BA%E6%89%8D%E7%AD%BE%E8%AF%81">P类（文艺体行业的杰出人才签证）</a></li>
<li><a href="#r%E7%B1%BB%E5%AE%97%E6%95%99%E5%B7%A5%E4%BD%9C%E8%80%85%E7%AD%BE%E8%AF%81">R类（宗教工作者签证）</a></li>
<li><a href="#g%E7%B1%BB%E5%9B%BD%E9%99%85%E6%9C%BA%E6%9E%84%E5%B7%A5%E4%BD%9C%E8%80%85%E7%AD%BE%E8%AF%81">G类（国际机构工作者签证）</a></li>
<li><a href="#a%E7%B1%BB%E6%94%BF%E5%BA%9C%E5%B7%A5%E4%BD%9C%E8%80%85%E7%AD%BE%E8%AF%81">A类（政府工作者签证）</a></li>
<li><a href="#i%E7%B1%BB%E6%96%B0%E9%97%BB%E5%B7%A5%E4%BD%9C%E8%80%85%E7%AD%BE%E8%AF%81">I类（新闻工作者签证）</a></li>
<li><a href="#opt%E5%AE%9E%E4%B9%A0%E7%AD%BE%E8%AF%81">OPT（实习签证）</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%BA%94%E5%AD%A6%E4%B9%A0%E7%B1%BB%E7%AD%BE%E8%AF%81student-visas">五、学习类签证（Student Visas）</a>
<ul>
<li><a href="#f%E7%B1%BB%E5%9B%BD%E9%99%85%E7%95%99%E5%AD%A6%E7%94%9F%E7%AD%BE%E8%AF%81">F类（国际留学生签证）</a></li>
<li><a href="#j%E7%B1%BB%E8%AE%BF%E9%97%AE%E5%AD%A6%E8%80%85%E7%AD%BE%E8%AF%81">J类（访问学者签证）</a></li>
<li><a href="#m%E7%B1%BB%E5%9F%B9%E8%AE%AD%E7%B1%BB%E7%AD%BE%E8%AF%81">M类（培训类签证）</a></li>
<li><a href="#q%E7%B1%BB%E6%96%87%E5%8C%96%E4%BA%A4%E6%B5%81%E6%B4%BB%E5%8A%A8%E7%AD%BE%E8%AF%81">Q类（文化交流活动签证）</a></li>
</ul>
</li>
<li><a href="#%E5%85%AD%E6%9D%B0%E5%87%BA%E6%8A%80%E8%83%BD%E7%B1%BB%E7%AD%BE%E8%AF%81extraordinary-ability-visas">六、杰出技能类签证（Extraordinary Ability Visas）</a>
<ul>
<li><a href="#o%E7%B1%BB%E6%9D%B0%E5%87%BA%E4%BA%BA%E6%89%8D%E7%AD%BE%E8%AF%81">O类（杰出人才签证）</a></li>
<li><a href="#p%E7%B1%BB%E6%96%87%E8%89%BA%E4%BD%93%E6%9D%B0%E5%87%BA%E4%BA%BA%E6%89%8D%E7%AD%BE%E8%AF%81">P类（文艺体杰出人才签证）</a></li>
</ul>
</li>
<li><a href="#%E4%B8%83%E5%8F%97%E5%AE%B3%E8%80%85%E7%8A%AF%E7%BD%AA%E7%B1%BB%E7%9B%B8%E5%85%B3%E7%AD%BE%E8%AF%81victimcrime-related-visas">七、受害者/犯罪类相关签证（Victim/Crime-Related Visas）</a>
<ul>
<li><a href="#t%E7%B1%BB%E4%BA%BA%E5%8F%A3%E8%B4%A9%E5%8D%96%E5%8F%97%E5%AE%B3%E8%80%85%E7%AD%BE%E8%AF%81">T类（人口贩卖受害者签证）</a></li>
<li><a href="#u%E7%B1%BB%E5%88%91%E4%BA%8B%E7%8A%AF%E7%BD%AA%E5%8F%97%E5%AE%B3%E8%80%85%E7%AD%BE%E8%AF%81">U类（刑事犯罪受害者签证）</a></li>
<li><a href="#s%E7%B1%BB%E7%8A%AF%E7%BD%AA%E7%BA%BF%E7%B4%A2%E6%8F%90%E4%BE%9B%E7%AD%BE%E8%AF%81">S类（犯罪线索提供签证）</a></li>
</ul>
</li>
<li><a href="#%E5%85%AB%E5%85%B6%E4%BB%96%E7%AD%BE%E8%AF%81other-visas">八、其他签证（Other Visas）</a></li>
</ul>
<h2 id="一-亲属类移民签证family-based-immigrant-visas"><a class="markdownIt-Anchor" href="#一-亲属类移民签证family-based-immigrant-visas"></a> 一、亲属类移民签证（Family-Based Immigrant Visas）</h2>
<h3 id="ir类immediate-relative-immigrant-visas"><a class="markdownIt-Anchor" href="#ir类immediate-relative-immigrant-visas"></a> IR类（Immediate Relative Immigrant Visas）</h3>
<ul>
<li><strong>IR1/CR1</strong>：美国公民的配偶。IR1适用于结婚满两年的配偶，CR1适用于结婚未满两年的配偶。</li>
<li><strong>IR2/CR2</strong>：IR1或CR1签证持有人的21岁以下未婚子女。</li>
<li><strong>IR3</strong>：美国公民在国外领养的孤儿。</li>
<li><strong>IR4</strong>：美国公民在美国领养的孤儿。</li>
<li><strong>IR5</strong>：21岁以上的美国公民申请父母团聚。</li>
</ul>
<h3 id="f类family-preference-immigrant-visas"><a class="markdownIt-Anchor" href="#f类family-preference-immigrant-visas"></a> F类（Family Preference Immigrant Visas）</h3>
<ul>
<li><strong>F1</strong>：美国公民未婚子女及其未成年子女。</li>
<li><strong>F2</strong>：美国绿卡持有者的配偶、未成年子女及未婚子女（21岁及以上）。</li>
<li><strong>F3</strong>：美国公民的已婚儿女及其未成年子女。</li>
<li><strong>F4</strong>：年龄至少21岁的美国公民的兄弟姐妹及其配偶和未成年子女。</li>
</ul>
<h2 id="二-职业类移民签证employment-based-immigrant-visas"><a class="markdownIt-Anchor" href="#二-职业类移民签证employment-based-immigrant-visas"></a> 二、职业类移民签证（Employment-Based Immigrant Visas）</h2>
<h3 id="eb-1"><a class="markdownIt-Anchor" href="#eb-1"></a> EB-1</h3>
<ul>
<li><strong>EB1A</strong>：杰出人才，无需雇主。</li>
<li><strong>EB1B</strong>：杰出教授或研究人员。</li>
<li><strong>EB1C</strong>：跨国公司高级管理人员。</li>
</ul>
<h3 id="eb-2"><a class="markdownIt-Anchor" href="#eb-2"></a> EB-2</h3>
<ul>
<li>高等学位外国专业人才或特别能力人才。需雇主（NIW国家利益豁免除外）。</li>
</ul>
<h3 id="eb-3"><a class="markdownIt-Anchor" href="#eb-3"></a> EB-3</h3>
<ul>
<li>非技术劳工。需雇主证明劳工短缺。</li>
</ul>
<h3 id="eb-4"><a class="markdownIt-Anchor" href="#eb-4"></a> EB-4</h3>
<ul>
<li>宗教人士签证。</li>
</ul>
<h3 id="eb-5"><a class="markdownIt-Anchor" href="#eb-5"></a> EB-5</h3>
<ul>
<li><strong>直投项目</strong>：100万美金创业或50万美金在TEA创业，需直接雇佣10个全职员工。</li>
<li><strong>区域中心项目</strong>：100万美金或50万美金在TEA参与项目，间接雇佣10个全职员工。</li>
</ul>
<h2 id="三-特殊类移民签证special-immigrant-visas"><a class="markdownIt-Anchor" href="#三-特殊类移民签证special-immigrant-visas"></a> 三、特殊类移民签证（Special Immigrant Visas）</h2>
<ul>
<li><strong>SD/SR</strong>：宗教工作者签证。</li>
<li><strong>SQ</strong>：为美国政府工作的阿富汗人/伊拉克人签证。</li>
<li><strong>DV</strong>：多元化移民签证。</li>
<li><strong>SB</strong>：因未能持续居住导致永久居民身份失效者的重新入境签证。</li>
</ul>
<h2 id="四-非移民类签证non-immigrant-visas"><a class="markdownIt-Anchor" href="#四-非移民类签证non-immigrant-visas"></a> 四、非移民类签证（Non-Immigrant Visas）</h2>
<h3 id="旅游访问类签证b类"><a class="markdownIt-Anchor" href="#旅游访问类签证b类"></a> 旅游/访问类签证（B类）</h3>
<ul>
<li><strong>B1</strong>：商务访问签证。</li>
<li><strong>B2</strong>：旅游访问签证。</li>
<li><strong>B1/B2</strong>：商务/旅游签证。</li>
</ul>
<h3 id="过境签c类"><a class="markdownIt-Anchor" href="#过境签c类"></a> 过境签（C类）</h3>
<ul>
<li><strong>C1</strong>：美国过境签证。</li>
<li><strong>C2</strong>：过境去美国纽约总部的外国人。</li>
<li><strong>C3</strong>：过境的外国政府官员及其随从。</li>
</ul>
<h3 id="机组人员签证d类"><a class="markdownIt-Anchor" href="#机组人员签证d类"></a> 机组人员签证（D类）</h3>
<ul>
<li><strong>D</strong>：海员/飞行员签证。</li>
</ul>
<h3 id="工签类"><a class="markdownIt-Anchor" href="#工签类"></a> 工签类</h3>
<h4 id="l类跨国企业派遣签证"><a class="markdownIt-Anchor" href="#l类跨国企业派遣签证"></a> L类（跨国企业派遣签证）</h4>
<ul>
<li><strong>L1A</strong>：高管派遣。</li>
<li><strong>L1B</strong>：技术人员派遣。</li>
<li><strong>L2</strong>：L1签证持有者的配偶和21岁以下未婚子女。</li>
</ul>
<h4 id="h类雇主类工签"><a class="markdownIt-Anchor" href="#h类雇主类工签"></a> H类（雇主类工签）</h4>
<ul>
<li><strong>H1B</strong>：工作签证，适用于本科以上学历的专业人士。</li>
<li><strong>H1B1</strong>：自由贸易协定专业人士。</li>
<li><strong>H1C</strong>：护理工作签证。</li>
<li><strong>H2A</strong>：农务人员签证。</li>
<li><strong>H2B</strong>：技术或非技术工人签证。</li>
<li><strong>H3</strong>：临时受训人员签证。</li>
<li><strong>H4</strong>：H1/H2/H3签证持有人的配偶及未满21岁的子女。</li>
</ul>
<h4 id="e类贸易投资签证"><a class="markdownIt-Anchor" href="#e类贸易投资签证"></a> E类（贸易投资签证）</h4>
<ul>
<li><strong>E1</strong>：贸易者签证。</li>
<li><strong>E2</strong>：投资者签证。</li>
<li><strong>E3</strong>：适用于澳大利亚国民及其子女（E3D）。</li>
</ul>
<h4 id="p类文艺体行业的杰出人才签证"><a class="markdownIt-Anchor" href="#p类文艺体行业的杰出人才签证"></a> P类（文艺体行业的杰出人才签证）</h4>
<ul>
<li><strong>P1</strong>：运动员及文娱团体成员。</li>
<li><strong>P2</strong>：交流活动的艺术家和演艺人员。</li>
<li><strong>P3</strong>：独特文化活动的表演艺术家或演艺人员。</li>
<li><strong>P4</strong>：P1/P2/P3签证持有人的配偶及小孩。</li>
</ul>
<h4 id="r类宗教工作者签证"><a class="markdownIt-Anchor" href="#r类宗教工作者签证"></a> R类（宗教工作者签证）</h4>
<ul>
<li><strong>R1</strong>：宗教工作者签证。</li>
<li><strong>R2</strong>：R1签证持有人的配偶和未满21岁子女。</li>
</ul>
<h4 id="g类国际机构工作者签证"><a class="markdownIt-Anchor" href="#g类国际机构工作者签证"></a> G类（国际机构工作者签证）</h4>
<ul>
<li><strong>G1</strong>：国际机构常驻工作人员及其直系亲属。</li>
<li><strong>G2</strong>：国际机构其他工作人员及其直系亲属。</li>
<li><strong>G3</strong>：未被美国承认的外国政府代表及直系亲属。</li>
<li><strong>G4</strong>：国际组织工作人员及其直系亲属。</li>
<li><strong>G5</strong>：G1-G4签证持有人的随行人员。</li>
</ul>
<h4 id="a类政府工作者签证"><a class="markdownIt-Anchor" href="#a类政府工作者签证"></a> A类（政府工作者签证）</h4>
<ul>
<li><strong>A1</strong>：大使、部长、职业外交官及其直系亲属。</li>
<li><strong>A2</strong>：其他外国政府官员和员工及其直系亲属。</li>
<li><strong>A3</strong>：A1/A2签证持有人的随从人员及直系亲属。</li>
</ul>
<h4 id="i类新闻工作者签证"><a class="markdownIt-Anchor" href="#i类新闻工作者签证"></a> I类（新闻工作者签证）</h4>
<ul>
<li><strong>I</strong>：新闻从业人员及其配偶和未满21岁未婚子女。</li>
</ul>
<h4 id="opt实习签证"><a class="markdownIt-Anchor" href="#opt实习签证"></a> OPT（实习签证）</h4>
<ul>
<li><strong>OPT</strong>：美国毕业的F1留学生毕业后申请的实习签证。</li>
</ul>
<h2 id="五-学习类签证student-visas"><a class="markdownIt-Anchor" href="#五-学习类签证student-visas"></a> 五、学习类签证（Student Visas）</h2>
<h3 id="f类国际留学生签证"><a class="markdownIt-Anchor" href="#f类国际留学生签证"></a> F类（国际留学生签证）</h3>
<ul>
<li><strong>F1</strong>：全日制在美国读书的国际生。</li>
<li><strong>F2</strong>：F1签证持有者的配偶或未满21岁子女。</li>
<li><strong>F3</strong>：对加拿大和墨西哥人的语言培训项目签证。</li>
</ul>
<h3 id="j类访问学者签证"><a class="markdownIt-Anchor" href="#j类访问学者签证"></a> J类（访问学者签证）</h3>
<ul>
<li><strong>J1</strong>：交流访问学者签证。</li>
<li><strong>J2</strong>：J1签证持有人的配偶或未满21岁子女。</li>
</ul>
<h3 id="m类培训类签证"><a class="markdownIt-Anchor" href="#m类培训类签证"></a> M类（培训类签证）</h3>
<ul>
<li><strong>M1</strong>：非学术或职业教育机构的学习、培训签证。</li>
<li><strong>M2</strong>：M1签证持有人的配偶或未满21岁子女。</li>
<li><strong>M3</strong>：只发放给加拿大或墨西哥学生。</li>
</ul>
<h3 id="q类文化交流活动签证"><a class="markdownIt-Anchor" href="#q类文化交流活动签证"></a> Q类（文化交流活动签证）</h3>
<ul>
<li><strong>Q1</strong>：国际文化交流短期签证。</li>
<li><strong>Q2</strong>：为爱尔兰和平项目参与者设立的签证。</li>
<li><strong>Q3</strong>：Q2签证持有人的配偶及21岁以下子女。</li>
</ul>
<h2 id="六-杰出技能类签证extraordinary-ability-visas"><a class="markdownIt-Anchor" href="#六-杰出技能类签证extraordinary-ability-visas"></a> 六、杰出技能类签证（Extraordinary Ability Visas）</h2>
<h3 id="o类杰出人才签证"><a class="markdownIt-Anchor" href="#o类杰出人才签证"></a> O类（杰出人才签证）</h3>
<ul>
<li><strong>O1</strong>：杰出人才签证，适用于科学、艺术、教育、商业、体育等行业的杰出人士。</li>
<li><strong>O2</strong>：O1签证持有人的助理或随从人员。</li>
<li><strong>O3</strong>：O1和O2的配偶及未满21岁子女。</li>
</ul>
<h3 id="p类文艺体杰出人才签证"><a class="markdownIt-Anchor" href="#p类文艺体杰出人才签证"></a> P类（文艺体杰出人才签证）</h3>
<ul>
<li><strong>P1</strong>：运动员或娱乐组合成员。</li>
<li><strong>P2</strong>：参加交流活动的艺术家或演艺人员。</li>
<li><strong>P3</strong>：独特文化活动的表演艺术家或演艺人员。</li>
<li><strong>P4</strong>：P1-P3的配偶和21岁以下子女。</li>
</ul>
<h2 id="七-受害者犯罪类相关签证victimcrime-related-visas"><a class="markdownIt-Anchor" href="#七-受害者犯罪类相关签证victimcrime-related-visas"></a> 七、受害者/犯罪类相关签证（Victim/Crime-Related Visas）</h2>
<h3 id="t类人口贩卖受害者签证"><a class="markdownIt-Anchor" href="#t类人口贩卖受害者签证"></a> T类（人口贩卖受害者签证）</h3>
<ul>
<li><strong>T1</strong>：人口贩卖受害者签证。</li>
<li><strong>T2</strong>：T1签证持有者的配偶。</li>
<li><strong>T3</strong>：T1签证持有者的子女。</li>
<li><strong>T4</strong>：未满21岁T1签证持有者的父母。</li>
<li><strong>T5</strong>：未满21岁T1签证持有者的18岁以下未婚兄弟/姐妹。</li>
</ul>
<h3 id="u类刑事犯罪受害者签证"><a class="markdownIt-Anchor" href="#u类刑事犯罪受害者签证"></a> U类（刑事犯罪受害者签证）</h3>
<ul>
<li><strong>U1</strong>：刑事犯罪受害者签证。</li>
<li><strong>U2</strong>：U1签证持有者的配偶。</li>
<li><strong>U3</strong>：U1签证持有者的子女。</li>
<li><strong>U4</strong>：未满21岁U1签证持有者的父母</li>
<li><strong>U5</strong>：未满21岁U1签证持有者的18岁以下未婚兄弟/姐妹。</li>
</ul>
<h3 id="s类犯罪线索提供签证"><a class="markdownIt-Anchor" href="#s类犯罪线索提供签证"></a> S类（犯罪线索提供签证）</h3>
<ul>
<li><strong>S5</strong>：提供犯罪组织关键信息的签证。</li>
<li><strong>S6</strong>：提供恐怖组织关键信息的签证。</li>
<li><strong>S7</strong>：S5/S6签证持有者的家庭成员。</li>
</ul>
<h2 id="八-其他签证other-visas"><a class="markdownIt-Anchor" href="#八-其他签证other-visas"></a> 八、其他签证（Other Visas）</h2>
<ul>
<li><strong>NATO</strong>：北大西洋公约组织成员国代表及其家庭成员。</li>
<li><strong>TN/TD</strong>：北美自由贸易协定专业人士签证。</li>
<li><strong>V类</strong>：绿卡持有人的家庭成员在等待移民排期时申请的签证。</li>
</ul>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
  </entry>
  <entry>
    <title>虚拟货币扫盲</title>
    <url>/2025/12/17/%E8%99%9A%E6%8B%9F%E8%B4%A7%E5%B8%81%E6%89%AB%E7%9B%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="比特币bitcoin与虚拟货币入门"><a class="markdownIt-Anchor" href="#比特币bitcoin与虚拟货币入门"></a> 比特币（Bitcoin）与虚拟货币入门</h1>
<p>在这个“比特币（Bitcoin）”和“Web3”频繁登上热搜的时代，你是否也对**虚拟货币（Cryptocurrency）**感到好奇，却又被一堆专业术语劝退？</p>
<p>别担心，这篇博客将剥去复杂的技术外壳，用最通俗的语言带你走进虚拟货币的世界。</p>
<h2 id="1-核心概念解析"><a class="markdownIt-Anchor" href="#1-核心概念解析"></a> 1. 核心概念解析</h2>
<h3 id="11-什么是虚拟货币-cryptocurrency"><a class="markdownIt-Anchor" href="#11-什么是虚拟货币-cryptocurrency"></a> 1.1 什么是虚拟货币 (Cryptocurrency)？</h3>
<ul>
<li>
<p><strong>定义</strong>：一种不依赖中央机构（如央行、政府）发行，而是基于<strong>密码学</strong>和<strong>分布式网络</strong>技术的数字货币。</p>
</li>
<li>
<p><strong>本质</strong>：它是互联网上的价值传输协议。如果说 Email 是传输信息的，Crypto 就是传输价值（钱）的。</p>
</li>
<li>
<p><strong>特点</strong>：</p>
<ul>
<li><strong>去中心化 (Decentralized)</strong>：没有唯一的管理员。</li>
<li><strong>抗审查性</strong>：只要你有私钥，没人能冻结你的资产。</li>
<li><strong>全球流通</strong>：无国界，转账像发邮件一样快（取决于具体币种）。</li>
</ul>
</li>
</ul>
<h3 id="12-区块链-blockchain-信任的基石"><a class="markdownIt-Anchor" href="#12-区块链-blockchain-信任的基石"></a> 1.2 区块链 (Blockchain) —— 信任的基石</h3>
<ul>
<li>
<p><strong>通俗理解</strong>：一个全网公开、所有人共同维护、不可篡改的<strong>超级账本</strong>。</p>
</li>
<li>
<p><strong>运作机制</strong>：</p>
<ol>
<li><strong>区块 (Block)</strong>：相当于账本的“一页纸”，记录了一段时间内的所有交易。</li>
<li><strong>链 (Chain)</strong>：每一页纸都标上了页码，并按顺序装订在一起，形成“区块链”。</li>
<li><strong>分布式 (Distributed)</strong>：这个账本不是锁在银行保险柜里，而是网络里每个人手里都有一本<strong>完全一样</strong>的副本。</li>
</ol>
</li>
<li>
<p><strong>不可篡改性</strong>：一旦交易被写入区块并获得确认，修改历史记录需要巨大的算力成本（几乎不可能），这保证了安全性。</p>
</li>
</ul>
<h3 id="13-账户体系公钥与私钥-关键"><a class="markdownIt-Anchor" href="#13-账户体系公钥与私钥-关键"></a> 1.3 账户体系：公钥与私钥 (关键！)</h3>
<ul>
<li>
<p><strong>私钥 (Private Key)</strong>：</p>
<ul>
<li><em>形式</em>：一长串随机字符，或者由12/24个英文单词组成（<strong>助记词</strong>）。</li>
<li><em>作用</em>：<strong>最高权限</strong>。拥有私钥 = 拥有资产所有权。</li>
<li><em>注意</em>：<strong>绝对不能</strong>告诉任何人，丢失无法找回（去中心化意味着没有客服帮你重置密码）。</li>
</ul>
</li>
<li>
<p><strong>公钥/地址 (Public Key/Address)</strong>：</p>
<ul>
<li><em>形式</em>：由私钥通过算法生成的一串字符（如 <code>0x</code> 开头或 <code>bc1</code> 开头）。</li>
<li><em>作用</em>：相当于<strong>银行卡号</strong>。这是公开的，用于接收转账。</li>
</ul>
</li>
<li>
<p><strong>关系</strong>：<code>私钥</code> -&gt; 生成 -&gt; <code>公钥</code> -&gt; 生成 -&gt; <code>地址</code>（不可逆推）。</p>
</li>
</ul>
<h2 id="2-主要币种分类-category"><a class="markdownIt-Anchor" href="#2-主要币种分类-category"></a> 2. 主要币种分类 (Category)</h2>
<h3 id="21-比特币-bitcoin-btc-数字黄金"><a class="markdownIt-Anchor" href="#21-比特币-bitcoin-btc-数字黄金"></a> 2.1 比特币 (Bitcoin, BTC) —— 数字黄金</h3>
<ul>
<li><strong>地位</strong>：加密货币的鼻祖（2009年诞生），市值最大。</li>
<li><strong>共识机制</strong>：<strong>PoW (工作量证明)</strong>。即“挖矿”，通过消耗电力计算哈希值来维护网络安全。</li>
<li><strong>核心叙事</strong>：<strong>价值存储</strong>。</li>
<li><strong>总量恒定</strong>：上限2100万枚，永不增发（抗通胀）。</li>
<li><strong>减半机制</strong>：约每4年产量减半，稀缺性随时间增加。</li>
</ul>
<h3 id="22-以太坊-ethereum-eth-世界计算机"><a class="markdownIt-Anchor" href="#22-以太坊-ethereum-eth-世界计算机"></a> 2.2 以太坊 (Ethereum, ETH) —— 世界计算机</h3>
<ul>
<li>
<p><strong>地位</strong>：公链之王，生态最繁荣。</p>
</li>
<li>
<p><strong>核心创新</strong>：<strong>智能合约 (Smart Contract)</strong>。</p>
<ul>
<li><em>解释</em>：比特币只能记账，以太坊可以运行程序。它是一个平台，开发者可以在上面通过代码编写自动执行的合约（如：如果A在明天这个时候没付钱，就自动扣除抵押物）。</li>
</ul>
</li>
<li>
<p><strong>共识机制</strong>：已从 PoW 转为 <strong>PoS (权益证明)</strong>，不再依赖矿机挖矿，而是通过质押ETH来验证交易，更环保。</p>
</li>
<li>
<p><strong>Gas费</strong>：在以太坊上进行任何操作（转账、交易）都需要支付ETH作为“燃料费”给验证者。</p>
</li>
</ul>
<h3 id="23-稳定币-stablecoins-避险港湾"><a class="markdownIt-Anchor" href="#23-稳定币-stablecoins-避险港湾"></a> 2.3 稳定币 (Stablecoins) —— 避险港湾</h3>
<ul>
<li>
<p><strong>代表</strong>：USDT (Tether), USDC (Circle)。</p>
</li>
<li>
<p><strong>作用</strong>：价格与法币（通常是美元）1:1 挂钩。</p>
</li>
<li>
<p><strong>场景</strong>：</p>
<ul>
<li>在币价大跌时，将资产换成稳定币避险。</li>
<li>作为不同加密货币之间交易的媒介（如 BTC -&gt; USDT -&gt; ETH）。</li>
</ul>
</li>
</ul>
<h2 id="3-存储与交易-storage-trading"><a class="markdownIt-Anchor" href="#3-存储与交易-storage-trading"></a> 3. 存储与交易 (Storage &amp; Trading)</h2>
<h3 id="31-钱包-wallets-资产归宿"><a class="markdownIt-Anchor" href="#31-钱包-wallets-资产归宿"></a> 3.1 钱包 (Wallets) —— 资产归宿</h3>
<table>
<thead>
<tr>
<th>类型</th>
<th>名称</th>
<th>特点</th>
<th>适用场景</th>
<th>安全性</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>冷钱包 (Cold Wallet)</strong></td>
<td>Ledger, Trezor</td>
<td><strong>不联网</strong>的硬件设备，私钥永不触网。</td>
<td>长期存储大额资产</td>
<td>⭐⭐⭐⭐⭐ (最高)</td>
</tr>
<tr>
<td><strong>热钱包 (Hot Wallet)</strong></td>
<td>MetaMask, Trust</td>
<td>软件APP/插件，实时联网。</td>
<td>频繁交互、体验DeFi</td>
<td>⭐⭐⭐ (中等，防黑客)</td>
</tr>
<tr>
<td><strong>交易所账户</strong></td>
<td>币安, OKX账户</td>
<td>资产托管在交易所，类似存银行。</td>
<td>新手入门、频繁炒币</td>
<td>⭐⭐ (依赖交易所信用)</td>
</tr>
</tbody>
</table>
<blockquote>
<p>⚠️ <strong>黄金法则</strong>：Not your keys, not your coins. (资产放在交易所里，本质上只是交易所欠你的债；只有在自己的钱包里，才是你的钱。)</p>
</blockquote>
<h3 id="32-交易场所"><a class="markdownIt-Anchor" href="#32-交易场所"></a> 3.2 交易场所</h3>
<ol>
<li>
<p><strong>CEX (中心化交易所)</strong>：</p>
<ul>
<li><em>例子</em>：Binance, OKX, Coinbase。</li>
<li><em>特点</em>：体验像股票软件，需要KYC（实名认证），资金有托管风险。</li>
</ul>
</li>
<li>
<p><strong>DEX (去中心化交易所)</strong>：</p>
<ul>
<li><em>例子</em>：Uniswap, Curve。</li>
<li><em>特点</em>：无需注册，连接钱包直接在链上交易，代码自动执行，门槛较高。</li>
</ul>
</li>
</ol>
<h2 id="4-常见风险与陷阱-risks"><a class="markdownIt-Anchor" href="#4-常见风险与陷阱-risks"></a> 4. 常见风险与陷阱 (Risks)</h2>
<ul>
<li>
<p><strong>波动性风险</strong>：</p>
<ul>
<li>没有涨跌停限制，24小时交易。一天腰斩（-50%）或翻倍是常态。</li>
</ul>
</li>
<li>
<p><strong>操作风险</strong>：</p>
<ul>
<li><strong>转错链/地址</strong>：将BTC转到了ETH的地址上，或者选错了区块链网络（如ERC20 vs TRC20），资产可能<strong>永久丢失</strong>。</li>
<li><strong>丢失助记词</strong>：一旦丢失或忘记，没有任何手段能找回资产。</li>
</ul>
</li>
<li>
<p><strong>诈骗风险</strong>：</p>
<ul>
<li><strong>庞氏骗局</strong>：承诺高额固定回报（如“每天1%利息”），通常是资金盘。</li>
<li><strong>假钱包/假应用</strong>：下载了带后门的App，输入助记词后资产被秒盗。</li>
<li><strong>授权钓鱼</strong>：点击不明链接，误授权给黑客，钱包被清空。</li>
</ul>
</li>
</ul>
<h2 id="5-进阶术语速查-glossary"><a class="markdownIt-Anchor" href="#5-进阶术语速查-glossary"></a> 5. 进阶术语速查 (Glossary)</h2>
<ul>
<li><strong>DeFi (Decentralized Finance)</strong>：去中心化金融。在链上进行借贷、交易，无需银行中介。</li>
<li><strong>NFT (Non-Fungible Token)</strong>：非同质化代币。代表独一无二的数字资产（如数字艺术品、游戏道具）。</li>
<li><strong>Web3</strong>：基于区块链构建的下一代互联网，强调用户拥有数据和资产的所有权。</li>
<li><strong>FOMO (Fear Of Missing Out)</strong>：害怕错过的心理。看到暴涨就忍不住追高买入。</li>
<li><strong>FUD (Fear, Uncertainty, Doubt)</strong>：惧、惑、疑。市场传播负面消息引发恐慌。</li>
</ul>
<h2 id="6-特别提示-disclaimer"><a class="markdownIt-Anchor" href="#6-特别提示-disclaimer"></a> 6. 特别提示 (Disclaimer)</h2>
<blockquote>
<p><strong>🇨🇳 中国大陆用户注意</strong>：<br />
2021年9月24日，中国人民银行等十部门发布通知，明确<strong>虚拟货币相关业务活动属于非法金融活动</strong>。境外虚拟货币交易所通过互联网向我国境内居民提供服务同样属于非法金融活动。</p>
<ul>
<li><strong>挖矿</strong>：全面禁止。</li>
<li><strong>交易</strong>：不再提供法币出入金保护，风险自担。</li>
</ul>
</blockquote>
<hr />
<h1 id="比特币"><a class="markdownIt-Anchor" href="#比特币"></a> 比特币</h1>
<h2 id="1-比特币的诞生与愿景"><a class="markdownIt-Anchor" href="#1-比特币的诞生与愿景"></a> 1. 比特币的诞生与愿景</h2>
<ul>
<li><strong>背景</strong>：</li>
</ul>
<p>2008年全球金融危机。</p>
<ul>
<li>
<p><strong>创始人</strong>：中本聪 (Satoshi Nakamoto)，真实身份至今未明。</p>
</li>
<li>
<p><strong>标志事件</strong>：2008年11月1日发表白皮书《比特币：一种点对点的电子现金系统》。</p>
</li>
<li>
<p><strong>核心目标</strong>：建立一个<strong>去中心化的电子记账系统</strong>。</p>
<ul>
<li><em>传统模式（中心化）</em>：依赖银行（中心机构）记账，基于国家信用。</li>
<li><em>比特币模式（去中心化）</em>：无需中心机构，<strong>每个人手里都有一本公开的账本</strong>，所有人共同记账。</li>
</ul>
</li>
</ul>
<h2 id="2-区块链的运作机制"><a class="markdownIt-Anchor" href="#2-区块链的运作机制"></a> 2. 区块链的运作机制</h2>
<h3 id="21-交易广播与区块打包"><a class="markdownIt-Anchor" href="#21-交易广播与区块打包"></a> 2.1 交易广播与区块打包</h3>
<ul>
<li>
<p><strong>交易流程</strong>：当A向B转账时，A将这笔交易信息广播给全网所有人（B、C、D…）。</p>
</li>
<li>
<p><strong>区块 (Block)</strong>：全网用户将一段时间内的交易记录收集起来，打包成一个“块”。</p>
<ul>
<li><em>容量</em>：约1MB，可容纳约4000条交易记录。</li>
</ul>
</li>
<li>
<p><strong>区块链 (Blockchain)</strong>：新产生的区块被链接到旧区块的后面，形成一条链式结构。</p>
</li>
</ul>
<h3 id="22-去中心化面临的五大挑战"><a class="markdownIt-Anchor" href="#22-去中心化面临的五大挑战"></a> 2.2 去中心化面临的五大挑战</h3>
<ol>
<li><strong>共识问题</strong>：账本以谁的为准？（每个人收到的交易顺序可能因网络延迟而不同）。</li>
<li><strong>激励问题</strong>：为什么要记账？（为什么要消耗自己的电脑资源去维护公共账本？）。</li>
<li><strong>防伪问题</strong>：如何防止伪造交易？</li>
<li><strong>双重支付</strong>：如何防止同一笔钱花两次（双花问题）？</li>
<li><strong>隐私问题</strong>：账本公开如何保密？</li>
</ol>
<blockquote>
<p><em>本期视频主要解决前两个问题：<strong>激励</strong>与<strong>共识（挖矿）</strong>。</em></p>
</blockquote>
<h2 id="3-激励机制为什么要记账"><a class="markdownIt-Anchor" href="#3-激励机制为什么要记账"></a> 3. 激励机制：为什么要记账？</h2>
<p>记账是有利可图的，收益来源有两部分：</p>
<ol>
<li>
<p><strong>手续费</strong>：交易发起方支付给打包者的小额费用。</p>
</li>
<li>
<p><strong>打包奖励（Coinbase Reward）</strong>：系统凭空生成比特币奖励给成功打包区块的人。</p>
<ul>
<li>
<p><strong>减半机制</strong>：</p>
<ul>
<li>初始奖励：50 BTC / 块。</li>
<li>规则：每4年减半一次（50 -&gt; 25 -&gt; 12.5 …）。</li>
</ul>
</li>
</ul>
</li>
</ol>
<ul>
<li><strong>总量恒定</strong>：根据几何级数求和公式计算，比特币总量上限约为 <strong>2100万个</strong>。</li>
</ul>
<h2 id="4-挖矿原理工作量证明-pow"><a class="markdownIt-Anchor" href="#4-挖矿原理工作量证明-pow"></a> 4. 挖矿原理：工作量证明 (PoW)</h2>
<p>既然记账有奖励，大家都抢着记账。系统规定：<strong>每10分钟只能有一个人打包成功</strong>。谁能打包？——<strong>谁先解开一道极难的数学题，谁就有权打包</strong>。这个过程被称为“挖矿”。</p>
<h3 id="41-核心算法sha256-哈希函数"><a class="markdownIt-Anchor" href="#41-核心算法sha256-哈希函数"></a> 4.1 核心算法：SHA256 哈希函数</h3>
<p>挖矿的数学题基于 SHA256 算法（由美国国家安全局发明）。</p>
<ul>
<li>
<p><strong>特点</strong>：</p>
<ol>
<li><strong>正向容易，反向极难</strong>：输入 x 求 y 很容易，知道 y 求 x 几乎不可能。</li>
<li><strong>雪崩效应</strong>：输入稍微改动一点点（如加一个点），输出结果会天翻地覆。</li>
<li><strong>定长输出</strong>：无论输入多少内容，输出永远是256位的二进制数。</li>
</ol>
</li>
</ul>
<h3 id="42-挖矿的这道数学题长什么样"><a class="markdownIt-Anchor" href="#42-挖矿的这道数学题长什么样"></a> 4.2 挖矿的这道“数学题”长什么样？</h3>
<p>矿工需要构造一个字符串，对其进行两次 SHA256 运算，使得结果满足特定条件。</p>
<ul>
<li>
<p><strong>输入内容</strong>：</p>
<ol>
<li>前一个区块的头部信息（Pre-block Header）。</li>
<li>当前区块的交易账单信息（Merkle Root）。</li>
<li>时间戳等其他信息。</li>
<li><strong>随机数 (Nonce)</strong> —— <em>这是唯一可以改变的变量</em>。</li>
</ol>
</li>
<li>
<p><strong>公式</strong>：</p>
<ul>
<li><strong>通俗要求</strong>：算出来的256位二进制数，<strong>前面 N 位必须全都是 0</strong>。</li>
</ul>
</li>
</ul>
<h3 id="43-为什么这很难暴力穷举"><a class="markdownIt-Anchor" href="#43-为什么这很难暴力穷举"></a> 4.3 为什么这很难？（暴力穷举）</h3>
<p>由于哈希函数无法反推，矿工无法通过解方程找到这个随机数。</p>
<ul>
<li>
<p><strong>唯一方法</strong>：试错（Trial and Error）。</p>
<ul>
<li>试 <code>Nonce = 0</code>，算一下哈希值，看前N位是不是0？不是。</li>
<li>试 <code>Nonce = 1</code>，再算一次…</li>
<li>试 <code>Nonce = 2</code>…</li>
<li>一直试到算出符合要求的哈希值为止。</li>
</ul>
</li>
</ul>
<h3 id="44-难度调整-n的确定"><a class="markdownIt-Anchor" href="#44-难度调整-n的确定"></a> 4.4 难度调整 (N的确定)</h3>
<p>系统通过调整 N 的大小（即要求前面有多少个0），来控制挖矿难度，保证全网平均每10分钟出一个块。</p>
<ul>
<li>
<p><strong>概率计算</strong>：</p>
<ul>
<li>每一位是0的概率是 1/2。</li>
<li>前 N 位都是0的概率是 (1/2)^N。</li>
<li>N 越大，概率越低，难度越大。</li>
</ul>
</li>
<li>
<p><strong>视频中的算力举例</strong>：</p>
<ul>
<li>假设全网有 10,000 台矿机，每台算力 14T (1.4×10^13 次/秒)。</li>
<li>10分钟内全网能计算的总次数约为 8 \times 10^{19} 次。</li>
<li>这大约等于 2^{66}。</li>
<li>结论：系统会将难度 N 设定为 <strong>66</strong>。这意味着平均进行 2^{66} 次尝试，才能碰巧找到一个满足条件的随机数。</li>
</ul>
</li>
</ul>
<h2 id="5-总结"><a class="markdownIt-Anchor" href="#5-总结"></a> 5. 总结</h2>
<ul>
<li><strong>挖矿的本质</strong>：利用计算机不停地进行哈希碰撞（做数学题），争夺记账权。</li>
<li><strong>运气与算力</strong>：虽然单个矿工挖到矿有运气成分，但长期来看，<strong>算力（计算速度）越强，挖到的概率越大</strong>。</li>
<li><strong>安全性</strong>：要篡改区块链，需要拥有全网51%以上的算力，成本极高。</li>
</ul>
<hr />
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<h3 id="比特币-bitcoin"><a class="markdownIt-Anchor" href="#比特币-bitcoin"></a> 🪙 比特币 (Bitcoin)</h3>
<ul>
<li><a href="https://youtu.be/7B-1vDFuYRk">【震撼】比特幣，人類進入虛擬世界的第一步 | 老高與小茉 Mr &amp; Mrs Gao</a></li>
<li><a href="https://youtu.be/g_fSistU3MQ">比特币和区块链啥原理？矿机挖矿咋回事？李永乐老师讲比特币(1)</a></li>
<li><a href="https://youtu.be/pbAVauYsqP0">比特币交易如何防伪？私钥公钥地址啥意思？李永乐老师讲比特币(2)</a></li>
<li><a href="https://youtu.be/hDkCf4FIbfI">【比特币资本战】十年翻10000倍，20万人一夜血亏400亿，背后究是谁在获益？| 小Lin说</a></li>
<li><a href="https://youtu.be/De3uqNiHyc4">我在越南挖比特幣，每月電費60萬，堅信將來一個比特幣就能在一線城市買房｜摩的司機徐師傅</a></li>
<li><a href="https://bitcoin.org/bitcoin.pdf">Bitcoin Whitepaper: A Peer-to-Peer Electronic Cash System (比特币白皮书)</a></li>
</ul>
<h3 id="区块链-blockchain"><a class="markdownIt-Anchor" href="#区块链-blockchain"></a> 🔗 区块链 (Blockchain)</h3>
<ul>
<li><a href="https://youtu.be/TVlo66aOZE0">Vol 112.区块链到底是什么？| 回形针PaperClip</a></li>
<li><a href="https://youtu.be/sjx_rpay9rk">更改世界的“區塊鏈” | 老高與小茉 Mr &amp; Mrs Gao</a></li>
<li><a href="https://youtu.be/B5iIbdCpjCc">一口氣搞懂 ETH 以太坊 | 腦哥 Chill塊鏈</a></li>
<li><a href="https://www.google.com/search?q=https://youtu.be/5thVJLgWW7Q">什么是区块链？一个视频带你看懂 | 清月已经不困了</a></li>
</ul>
<h3 id="web3"><a class="markdownIt-Anchor" href="#web3"></a> 🌐 Web3</h3>
<ul>
<li><a href="https://youtu.be/Ks_QkNTbGJY">終將徹底改變一切的Web3.0，人類走向全面虛擬的開端 | 老高與小茉 Mr &amp; Mrs Gao</a></li>
<li><a href="https://www.google.com/search?q=https://youtu.be/YdWP-wJh9jA">Web3.0到底是怎么回事儿？| 小Lin说</a></li>
</ul>
<h3 id="其他-other"><a class="markdownIt-Anchor" href="#其他-other"></a> 📂 其他 (Other)</h3>
<ul>
<li><a href="https://youtu.be/tm09cMTBTSU">一口气了解稳定币 | 小Lin说</a></li>
<li>[从Circle火爆IPO，看稳定币与美元霸权的现代化金融战【深度】| 硅谷101](<a href="https://www.google.com/search?q=https://youtu">https://www.google.com/search?q=https://youtu</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>实习经验总结</title>
    <url>/2024/01/28/%E5%AE%9E%E4%B9%A0%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<ol>
<li>
<p><strong>八股文学习</strong>：</p>
<ul>
<li>八股文没有想象中那么重要，但还是值得一看,基础知识建议多加关注。</li>
<li>推荐使用网上的资源（例如推荐小林），这些资源基本够用, 无需购买知识星球等付费资源，避免成为“韭菜”。</li>
</ul>
</li>
<li>
<p><strong>刷题策略</strong>：</p>
<ul>
<li>刷题不宜贪多。专注于熟练掌握 Hot 100。</li>
<li>做到对题目迅速有思路，并能在不依赖 IDE 的情况下写出无 Bug 的代码。</li>
<li>在此基础上，可以适当扩展其他题目。</li>
</ul>
</li>
<li>
<p><strong>简历撰写技巧</strong>：</p>
<ul>
<li>简历中避免写不会或不太会的内容。</li>
<li>避免写入没有营养的内容。</li>
<li>完成后，可以让室友、同学等帮忙审核，群众的眼睛是雪亮的。</li>
</ul>
</li>
<li>
<p><strong>自我介绍准备</strong>：</p>
<ul>
<li>背熟自我介绍。</li>
<li>提前准备项目的难点和亮点。</li>
<li>自我介绍时要自圆其说，并适当强调。</li>
</ul>
</li>
<li>
<p><strong>项目与实习经历的描述</strong>：</p>
<ul>
<li>使用 STAR 法则描述项目和实习经历。</li>
<li>尽量量化任务背景和产出。</li>
</ul>
</li>
<li>
<p><strong>投递策略</strong>：</p>
<ul>
<li>投递顺序很重要，不要将最想去的公司放在最后投递。</li>
</ul>
</li>
<li>
<p><strong>面试准备</strong>：</p>
<ul>
<li>面试前了解岗位，针对性地包装项目的难点和亮点。</li>
<li>面试时语速适中，留时间给自己思考。</li>
</ul>
</li>
<li>
<p><strong>实习经验</strong>：</p>
<ul>
<li>过往的实习经验能加分。</li>
<li>对于低年级（如大三）学生，如果条件允许，可以尝试寻找实习机会。</li>
<li>若无实习经验，做一个好的项目也是有益的。</li>
</ul>
</li>
<li>
<p><strong>项目选择建议</strong>：</p>
<ul>
<li>不必追求大型项目（如XX商城）。</li>
<li>小而美的项目也很好，重要的是体现出自己的能力（设计模型、架构、细节处理、新技术运用等）。</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>internship</tag>
      </tags>
  </entry>
  <entry>
    <title>计算模型以及中间变量的显存占用大小</title>
    <url>/2024/01/10/%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B%E4%BB%A5%E5%8F%8A%E4%B8%AD%E9%97%B4%E5%8F%98%E9%87%8F%E7%9A%84%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%A4%A7%E5%B0%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="计算模型以及中间变量的显存占用大小"><a class="markdownIt-Anchor" href="#计算模型以及中间变量的显存占用大小"></a> 计算模型以及中间变量的显存占用大小</h1>
<h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> <strong>前言</strong></h2>
<p>亲,显存炸了,你的显卡快冒烟了!</p>
<pre><code>torch.FatalError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCStorage.cu:58
</code></pre>
<p>想必这是所有炼丹师们最不想看到的错误,没有之一。</p>
<p><code>OUT OF MEMORY</code>,显然是显存装不下你那么多的模型权重还有中间变量,然后程序奔溃了。怎么办,其实办法有很多,及时清空中间变量,优化代码,减少batch,等等等等,都能够减少显存溢出的风险。</p>
<p>但是这篇要说的是上面这一切优化操作的基础,如何去计算我们所使用的显存。学会如何计算出来我们设计的模型以及中间变量所占显存的大小,想必知道了这一点,我们对自己显存也就会得心应手了。</p>
<br>
<h2 id="如何计算"><a class="markdownIt-Anchor" href="#如何计算"></a> <strong>如何计算</strong></h2>
<p>首先我们应该了解一下基本的数据量信息:</p>
<ul>
<li>1 G = 1000 MB</li>
<li>1 M = 1000 KB</li>
<li>1 K = 1000 Byte</li>
<li>1 B = 8 bit</li>
</ul>
<p>好,肯定有人会问为什么是1000而不是1024,这里不过多讨论,只能说两种说法都是正确的,只是应用场景略有不同。这里统一按照上面的标准进行计算。</p>
<p>然后我们说一下我们平常使用的向量所占的空间大小,以Pytorch官方的数据格式为例(所有的深度学习框架数据格式都遵循同一个标准):<br />
<img src="https://pbs.twimg.com/media/GDfhjFGboAAZIqj?format=jpg&amp;name=medium" alt="" /></p>
<p>我们只需要看左边的信息,在平常的训练中,我们经常使用的一般是这两种类型:</p>
<ul>
<li>float32 单精度浮点型</li>
<li>int32 整型</li>
</ul>
<p>一般一个8-bit的整型变量所占的空间为<code>1B</code>也就是<code>8bit</code>。而32位的float则占<code>4B</code>也就是<code>32bit</code>。而双精度浮点型double和长整型long在平常的训练中我们一般不会使用。</p>
<p>ps:消费级显卡对单精度计算有优化,服务器级别显卡对双精度计算有优化。</p>
<p>也就是说,<strong>假设有一幅RGB三通道真彩色图片,长宽分别为500 x 500,数据类型为单精度浮点型,那么这张图所占的显存的大小为:500 x 500 x 3 x 4B = 3M</strong>。</p>
<p>而一个(256,3,100,100)-(N,C,H,W)的FloatTensor所占的空间为256 x 3 x 100 x 100 x 4B = 31M</p>
<p>不多是吧,没关系,好戏才刚刚开始。</p>
<br>
<h2 id="显存去哪儿了"><a class="markdownIt-Anchor" href="#显存去哪儿了"></a> <strong>显存去哪儿了</strong></h2>
<p>看起来一张图片(3x256x256)和卷积层(256x100x100)所占的空间并不大,那为什么我们的显存依旧还是用的比较多,原因很简单,占用显存比较多空间的并不是我们输入图像,而是神经网络中的中间变量以及使用optimizer算法时产生的巨量的中间参数。</p>
<p>我们首先来简单计算一下Vgg16这个net需要占用的显存:</p>
<p>通常一个模型占用的显存也就是两部分:</p>
<ul>
<li>模型自身的参数(params)</li>
<li>模型计算产生的中间变量(memory)</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GDfjndMaIAAz1PB?format=jpg&amp;name=medium" alt="" /></p>
<p>图片来自cs231n，这是一个典型的sequential-net，自上而下很顺畅，我们可以看到我们输入的是一张224x224x3的三通道图像，可以看到一张图像只占用150x4k，但上面标注的是150k，这是因为上图中在计算的时候默认的数据格式是8-bit而不是32-bit，所以最后的结果要乘上一个4。</p>
<p>我们可以看到，左边的memory值代表：图像输入进去，图片以及所产生的中间卷积层所占的空间。我们都知道，这些形形色色的深层卷积层也就是深度神经网络进行“思考”的过程：</p>
<p>图片从3通道变为64 -&gt; 128 -&gt; 256 -&gt; 512 … 这些都是卷积层,而我们的显存也主要是他们占用了。</p>
<p>还有上面右边的params,这些是神经网络的权重大小,可以看到第一层卷积是3×3,而输入图像的通道是3,输出通道是64,所以很显然,第一个卷积层权重所占的空间是 (3 x 3 x 3) x 64。</p>
<br>
<p>另外还有一个需要注意的是中间变量在backward的时候会翻倍!</p>
<p>为什么,举个例子,下面是一个计算图,输入<code>x</code>,经过中间结果<code>z</code>,然后得到最终变量<code>L</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x -&gt; z -&gt; L</span><br></pre></td></tr></table></figure>
<p>在forward阶段,我们只需要计算并存储<code>z</code>。但是在backward阶段,我们不仅需要<code>z</code>,还需要计算<code>dz/dx</code>,所以需要同时存储<code>z</code>和<code>dz/dx</code>,因此中间变量在backward时会翻倍。</p>
<p><img src="https://pbs.twimg.com/media/GDfkUmYbUAAW18j?format=jpg&amp;name=medium" alt="" /></p>
<p>我们在backward的时候需要保存下来的中间值。输出是<code>L</code>,然后输入<code>x</code>,我们在backward的时候要求<code>L</code>对<code>x</code>的梯度,这个时候就需要在计算链<code>L</code>和<code>x</code>中间的<code>z</code></p>
<p><img src="https://pbs.twimg.com/media/GDflAr1bYAAnnFR?format=png&amp;name=900x900" alt="" /></p>
<p><code>dz/dx</code>这个中间值当然要保留下来以用于计算,所以粗略估计,<code>backward</code>的时候中间变量的占用了是<code>forward</code>的两倍(<strong>除了在正向传播中已经计算出的中间变量外，反向传播还需要存储这些中间变量的梯度</strong>)!</p>
<br>
<h2 id="优化器和动量"><a class="markdownIt-Anchor" href="#优化器和动量"></a> <strong>优化器和动量</strong></h2>
<p>要注意,优化器也会占用我们的显存!</p>
<p>为什么,看这个式子:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>W</mi><mi>t</mi></msub><mo>−</mo><mi>η</mi><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W_{t+1} = W_{t} - \eta \nabla L(W_{t})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">η</span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>上式是典型的SGD随机下降法的总体公式,权重<code>W</code>在进行更新的时候,会产生保存中间变量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi>L</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\nabla L(W_{t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>,也就是在优化的时候,模型中的params参数所占用的显存量会翻倍。</p>
<p>当然这只是SGD优化器,其他复杂的优化器如果在计算时需要的中间变量多的时候,就会占用更多的内存。</p>
<br>
<h2 id="模型中哪些层会占用显存"><a class="markdownIt-Anchor" href="#模型中哪些层会占用显存"></a> <strong>模型中哪些层会占用显存</strong></h2>
<p>有参数的层即会占用显存的层。我们一般的卷积层都会占用显存,而我们经常使用的激活层Relu没有参数就不会占用了。</p>
<p>占用显存的层一般是:</p>
<ul>
<li>
<p>卷积层,通常的conv2d</p>
</li>
<li>
<p>全连接层,也就是Linear层</p>
</li>
<li>
<p>BatchNorm层</p>
</li>
<li>
<p>Embedding层</p>
</li>
</ul>
<p>而不占用显存的则是:</p>
<ul>
<li>
<p>刚才说到的激活层Relu等</p>
</li>
<li>
<p>池化层</p>
</li>
<li>
<p>Dropout层</p>
</li>
</ul>
<p>具体计算方式:</p>
<ul>
<li>
<p>Conv2d(Cin, Cout, K): 参数数目:Cin × Cout × K × K</p>
</li>
<li>
<p>Linear(M-&gt;N): 参数数目:M×N</p>
</li>
<li>
<p>BatchNorm(N): 参数数目: 2N</p>
</li>
<li>
<p>Embedding(N,W): 参数数目: N × W</p>
</li>
</ul>
<br>
<h2 id="额外的显存"><a class="markdownIt-Anchor" href="#额外的显存"></a> 额外的显存</h2>
<p>总结一下，我们在总体的训练中，占用显存大概分以下几类：</p>
<ul>
<li>模型中的参数(卷积层或其他有参数的层)</li>
<li>模型在计算时产生的中间参数(也就是输入图像在计算时每一层产生的输入和输出)</li>
<li>backward的时候产生的额外的中间参数</li>
<li>优化器在优化时产生的额外的模型参数</li>
</ul>
<p>但其实，我们占用的显存空间为什么比我们理论计算的还要大，原因大概是因为深度学习框架一些额外的开销吧，不过如果通过上面公式，理论计算出来的显存和实际不会差太多的。</p>
<br>
<h2 id="如何优化"><a class="markdownIt-Anchor" href="#如何优化"></a> <strong>如何优化</strong></h2>
<p>优化除了算法层的优化,最基本的优化无非也就一下几点:</p>
<ul>
<li>
<p>减少输入图像的尺寸</p>
</li>
<li>
<p>减少batch,减少每次的输入图像数量</p>
</li>
<li>
<p>多使用下采样,池化层</p>
</li>
<li>
<p>一些神经网络层可以进行小优化,利用relu层中设置<code>inplace</code></p>
</li>
<li>
<p>购买显存更大的显卡</p>
</li>
<li>
<p>从深度学习框架上面进行优化</p>
</li>
</ul>
<p>下篇文章我会说明如何在<code>Pytorch</code>这个深度学习框架中跟踪显存的使用量,然后针对<code>Pytorch</code>这个框架进行有目的显存优化。</p>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]自动驾驶感知算法/模型部署岗秋招总结(NVIDIA)</title>
    <url>/2024/07/09/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95-%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E5%B2%97%E7%A7%8B%E6%8B%9B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在秋招过程中，平台上的内容和博主对自己帮助很大，也来分享下自己的秋招经历，作为对自己研究生三年的总结，也希望可以帮助到大家~</p>
<p>先介绍下楼主BG，楼主211本硕，车辆本计算机硕，无论文，4实习，在2023年秋招中，拿到了元戎，地平线，字节AI Lab，旷视，美团，百度，NVIDIA，图森等offer，最终选择了NVIDIA作为职业生涯的第一站。</p>
<p>秋招秋招投递方向主要为自动驾驶感知算法岗和模型部署岗，进面的公司基本都拿到了offer。</p>
<p>首先说下对工业界就业的整体认知，工业界比较在意能不能进来就上手干活，能证明这件事情的，楼主觉得主要就两个：相关实习项目和强相关论文。除非实验室的方向和工业界非常一致，且有稳定的论文产出，否则优先级都是实习&gt;论文，因为论文有可能花了很长时间，最后没中或者不是公司需要的方向，但是实习一方面大概率是各种公司都需要的项目，另一方面进去发现方向不好想换项目也比较方便（和leader说或者直接换公司）。当然如果老师不放实习的话就得具体情况具体分析，可能需要一些因人而异的trick：)</p>
<p>秋招的经验单独说的话可能有些抽象，就和实习经历结合着来说吧，没有说到的后面再补充一些。</p>
<p>楼主第一份实习因为简历上没有太多拿得出手的项目，而且当时只是了解基于图像的2D感知算法，想找一家可以带我零基础搞点云算法的公司，只好从小自驾公司开始实习起，主要做一些基于传统聚类算法的点云目标检测。这些工作现在看起来很简单，但是确实让我对一个完全不熟悉的领域有了比较清晰的认识，发现比起自己乱七八糟学一堆理论，最快的成长路径还是直接去工业界中，直接做项目，看大家是怎么用这个技术的，找到其中核心的部分，或者说能放到简历（听起来比较有难度，能体现自己思考/工作量）的部分进行深入学习。</p>
<p>有了第一份实习，再找实习的时候感觉不管是对面试的把握还是简历的充实程度上都比第一份好了很多。第二份实习在某家新势力做一些数据挖掘的工作，主要就是通过离线感知或者无监督/设计规则的方法挖一些bad case数据出来（比如异形车）给到感知组，让他们基于这些数据进一步微调模型。有些工作实际没什么，但是要学会包装，就是把和项目相关的上下游都整明白，比如我们为什么要做这件事，前期调研了哪些方案，为什么选择这个方案，以及这个方案最后的效果，如果可以进一步拓展到实际使用过程中这个方案遇到的问题，并且自己解决了，这个在面试中是非常加分的。但是在实际中，这个过程是非常费时间的，如果时间不允许，也可以只走一遍思考的过程，想一想哪些地方可以做contribution，可以不实现，面试时候被问住了再查缺补漏：）</p>
<p>第三份实习在某自驾大厂，当时投递的是感知算法岗位，但是进去以后被安排用NV的工具做线上模型的量化压缩。这个方向之前完全没有接触过，是mentor带着从头开始。一开始还比较抵触，因为本来是想做感知算法的，模型部署感觉比较边缘，但是尝试做了一下发现还蛮有兴趣，没想到这个项目也成为了后面NVIDIA面试时候面试官最看重的一个项目，因为和NV组内的工作很像，但是当时是完全没有想到这一步的，当时想的是赶快把这个项目搞完去做算法hh，后来也确实是这么干的，做了几个月量化压缩后，就去搞BEV算法了，主要是一些打杂的工作，但是从公司内部的知识库多学学还是可以基本吃透整套算法框架，了解了公司模型如何从刚开始的baseline迭代到当前的版本，每一步遇到了什么问题或者bad case，是通过什么方式改进的，这个是非常重要的。现在总结来看，当时只是觉得算法岗高大上，所以想搞算法，但是忽略了同行的数量haha，从我自己的面试体验来看，算法岗位的竞争远远大于模型部署，所以我们在选择方向的时候，不仅要考虑技术，也要考虑好卷度（大佬请忽略）。不过，这里取舍是在对各个方向有基本了解的前提下的，如果你是刚决定入行的小白，还是推荐各个方向都去实习体验一下再做决定，以了解为目的的话，一两个月的实习就够用了。总之有很多事情确实是我们当时想不到的，当时觉得最不可能的路线反而有可能成为了我们的最终选择，interesting ：）</p>
<p>第四份实习在某自驾独角兽，同样是做模型部署相关的工作。之所以来这里是因为在上一份实习中被10105毒打了，想找一家技术好也不那么卷的公司转正（小命要紧，所以也没有执着于感知算法，刚开始工作也遇到了一些问题，比如leader希望我遇到问题尽量自己想清楚解决，即使代价是项目会拖得久一点，当时我的想法是尽快完成项目，有些问题能直接问就不用费时间自己调研了，但是leader会觉得我自己思考能力比较弱。。。这个我感觉就很因人而异了，因为在之前的实习中，leader是把不要让项目block住放在第一位的。后面和leader沟通了之后，遇到问题就自己琢磨解决了，效果还不错，在这里最终也是拿到了转正offer。所以，如果感觉leader对自己不是很满意，了解leader的想法还是很重要的，最笨的办法，可以直接去问哈哈，你希望我遇到问题怎么思考，怎么解决。</p>
<p>在最后一段实习中，秋招就已经开始了，从7月份开始，就开始陆续投递各家公司了，基本处于一个边实习边面试的状态，在这里还是奉劝大家即使确定转正，还是要去投一投面一面，一是可以让你知道你在市场上的价值，二是有可能找到比当前更好的但是之前不了解的公司（e.g. NVIDIA），最重要的就是在和现在这家公司谈薪的时候有了议价权，不然大概率开的是比你的市场价更低的。这个也不能怨公司，毕竟HR的绩效就是用便宜的价钱招到合适的人：）如果你有其他offer拿来议价，HR也会觉得很正常，而且如果档次比现在的高一个level的话，能明显感觉到你在谈判中可以掌握主动权~</p>
<p>最终还是选择了NV作为自己的第一站，薪资肯定不是最高的，但是原因主要有下面几个，列出来供大家参考，以后如果有一天后悔的时候也翻回来看看自己当时选择的理由：）比较主观，大家有不同看法欢迎讨论：</p>
<ol>
<li>
<p>觉得应届生其实不用特别在意薪资，多/少出来的钱对于职业中后期可能都不算个事，还是发展前景/公司背书比较重要</p>
</li>
<li>
<p>楼主觉得模型部署这个偏计算的赛道还是比自驾算法稳定一些，现在各家公司都在降本增效，辅助驾驶作为一个不是那么核心的卖点，让各个抠门的甲方持续投入大量的钱感觉还是比较困难的，现在的高薪不确定是否可以持续</p>
</li>
<li>
<p>自驾算法的适用面实在是太窄了，基本以后只能在自驾公司了，和这个行业是强绑定的，风险一下子就上去了，而计算赛道可以有很多选择，现在LLM兴起后更是这样（楼主当时做决定时AI还没有现在这么火）</p>
</li>
<li>
<p>感觉自己工作方向的壁垒很重要，做算法有可能出来一个新算法后，分分钟被应届生卷下去了，由于更新换代太快很难有技术积累（大佬忽略hh）最后选择也是一个平衡风险和收益的决定吧~</p>
</li>
<li>
<p>当然还有最重要的wlb 😉，图个身心健康</p>
</li>
</ol>
<p>不过强调一下，如果对感知算法很感兴趣也有2个及以上拿得出手的项目，或者有相关顶会，秋招还是可以冲一波感知算法的，因为1. 薪资会比部署略高 2. 在自动驾驶公司更容易成长为leader，不过在NV这种芯片公司就还好</p>
<p>然后再说几个秋招/面试注意事项：</p>
<p>做完一个项目后，一定要及时总结到简历上，突出其中有自己贡献，最有挑战性的部分，时间长自己也会忘。。<br />
简历上的一个项目，在至少经历了2家公司的拷打，并把被问住的地方搞清楚后，才算基本合格，在秋招时候理想的状态是你基本都知道面试官要问什么问题，回答接近于背诵的程度（每次面试都一样。。想记不住都难）<br />
如果面试时候被问住了，可以回答：这个时间太久有点忘了，不过我知道XXX(一些相关的)，面试官的思路有可能就被引导到你熟悉的地方去了<br />
目前就想到这些，想到其他的再补充</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
  </entry>
  <entry>
    <title>语义空间</title>
    <url>/2024/03/11/%E8%AF%AD%E4%B9%89%E7%A9%BA%E9%97%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<p><strong>语义学（Semantics）</strong> 涉及到<strong>表达</strong>内容的解释和含义。  在自然语言处理（<strong>NLP</strong>）领域，语义主要涵盖了与语言学相关的各种概念。在计算机视觉（<strong>CV</strong>）领域，语义通常指图像中像素或物体的性质和含义。</p>
<p>在机器学习中，<strong>表达</strong>（Expression）通常指数据的形式，无论是在NLP任务中的文本，还是在CV任务中的图像或视频。而这些表达的解释（Interpretation）则涉及到从中提取的类别等信息，这在形式上仍然是数据，只是以更统一、更精练的结构出现。这表明，在此上下文中，语义代表了对数据的结构化表示，包括但不限于其中蕴含的类别信息。</p>
<p>这些结构化的表示所处的空间，被称为<strong>语义空间</strong>，与原始数据（如文本、视觉数据等）所处的空间不同。通过基于数据集构建适当的结构，来包含样本点对应的概念类别、关系等语义信息，即构成了语义分析的核心任务。</p>
<p>以计算机视觉的语义分割为例，这一过程涉及根据物体的种类和性质来分割图像，使得相同种类的物体被归为同一类别。实际上，这相当于对图像中的每个像素点进行分类。</p>
<br>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ol>
<li><a href="https://blog.csdn.net/txpp520/article/details/105536254">CSDN博客 - 语义理解及其在NLP中的应用</a></li>
<li><a href="https://www.zhihu.com/question/561584849">知乎 - 什么是计算机视觉中的“语义”？</a></li>
</ol>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>语义空间</tag>
      </tags>
  </entry>
  <entry>
    <title>[待完成]转载:机器学习面试经验</title>
    <url>/2024/03/05/%E8%BD%AC%E8%BD%BD-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2>
<ul>
<li><a href="https://blog.csdn.net/qian2213762498/article/details/80480888">面试知识点</a></li>
</ul>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>ML</tag>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title>量化</title>
    <url>/2024/01/13/%E9%87%8F%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="1量化是什么"><a class="markdownIt-Anchor" href="#1量化是什么"></a> 1.量化是什么</h2>
<p>简而言之，所谓的模型量化就是将<strong>浮点存储（运算）转换为整型存储（运算）<strong>的一种</strong>模型压缩</strong>技术。简单直白点讲，即原来表示一个权重需要使用float32表示，量化后只需要使用int8来表示就可以啦，仅仅这一个操作，我们就可以获得接近4倍的网络加速！</p>
<br>
<h2 id="2为什么需要做模型量化"><a class="markdownIt-Anchor" href="#2为什么需要做模型量化"></a> 2.为什么需要做模型量化</h2>
<p>随着深度学习技术在多个领域的快速应用，具体包括计算机视觉-CV、自然语言处理-NLP、语音等，出现了大量的基于深度学习的网络模型。这些模型都有一个特点，即大而复杂、适合在N卡上面进行推理，并不适合应用在手机等嵌入式设备中，而客户们通常需要将这些复杂的模型部署在一些低成本的嵌入式设备中，因而这就产生了一个矛盾。<strong>为了很好的解决这个矛盾，模型量化应运而生，它可以在损失少量精度的前提下对模型进行压缩，使得将这些复杂的模型应用到手机、机器人等嵌入式终端中变成了可能。</strong></p>
<p>随着模型预测越来越准确，网络越来越深，神经网络消耗的内存大小成为一个核心的问题，尤其是在移动设备上。通常情况下，目前的手机一般配备 4GB 内存来支持多个应用程序的同时运行，而三个模型运行一次通常就要占用1GB内存。</p>
<p><strong>模型大小不仅是内存容量问题，也是内存带宽问题</strong>。模型在每次预测时都会使用模型的权重，图像相关的应用程序通常需要实时处理数据，这意味着至少 30 FPS。因此，如果部署相对较小的 ResNet-50 网络来分类，运行网络模型就需要 3GB/s 的内存带宽。网络运行时，内存，CPU 和电池会都在飞速消耗，我们无法为了让设备变得智能一点点就负担如此昂贵的代价。</p>
<br>
<h2 id="3模型量化的动机"><a class="markdownIt-Anchor" href="#3模型量化的动机"></a> 3.模型量化的动机</h2>
<ul>
<li>
<p><strong>更少的存储开销和带宽需求</strong>。即使用更少的比特数存储数据，有效减少应用对存储资源的依赖，但现代系统往往拥有相对丰富的存储资源，这一点已经不算是采用量化的主要动机；</p>
</li>
<li>
<p><strong>更快的计算速度</strong>。即对大多数处理器而言，整型运算的速度一般（但不总是）要比浮点运算更快一些；</p>
</li>
<li>
<p><strong>更低的能耗与占用面积</strong>。</p>
</li>
</ul>
<p><img src="https://pbs.twimg.com/media/GDuIvT8WIAAJlQN?format=jpg&amp;name=medium" alt="" /></p>
<p>从上图中可以看到，<strong>FP32乘法运算的能耗是INT8乘法运算能耗的18.5倍，芯片占用面积则是int8的27.3倍</strong>，而对于芯片设计和FPGA设计而言，更少的资源占用意味着相同数量的单元下可以设计出更多的计算单元；而更少的能耗意味着更少的发热，和更长久的续航。</p>
<ul>
<li>
<p><strong>尚可接受的精度损失</strong>。即量化相当于对模型权重引入噪声，所幸CNN本身对噪声不敏感（在模型训练过程中，模拟量化所引入的权重加噪还有利于防止过拟合），在合适的比特数下量化后的模型并不会带来很严重的精度损失。按照gluoncv提供的报告，经过int8量化之后，ResNet50_v1和MobileNet1.0 _v1在ILSVRC2012数据集上的准确率仅分别从77.36%、73.28%下降为76.86%、72.85%。</p>
</li>
<li>
<p><strong>支持int8是一个大的趋势</strong>。即无论是移动端还是服务器端，都可以看到新的计算设备正不断迎合量化技术。比如NPU/APU/AIPU等基本都是支持int8（甚至更低精度的int4）计算的，并且有相当可观的TOPs，而Mali GPU开始引入int8 dot支持，Nvidia也不例外。除此之外，当前很多创业公司新发布的边缘端芯片几乎都支持int8类型。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Accumulate</category>
      </categories>
      <tags>
        <tag>Accumulate</tag>
        <tag>量化</tag>
      </tags>
  </entry>
  <entry>
    <title>陈天奇:ML科研的十年</title>
    <url>/2024/01/31/%E9%99%88%E5%A4%A9%E5%A5%87-ML%E7%A7%91%E7%A0%94%E7%9A%84%E5%8D%81%E5%B9%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p>陈天奇是机器学习领域著名的青年华人学者之一，本科毕业于上海交通大学ACM班，博士毕业于华盛顿大学计算机系，研究方向为大规模机器学习。上个月，陈天奇在Twitter上宣布自己将于2020年秋季加入CMU任助理教授，成为加入CMU的年轻华人学者之一。在本文中，陈天奇回顾了自己做机器学习科研的十年。</p>
<p>十年前，MSRA 的夏天，刚开始尝试机器学习研究的我面对科研巨大的不确定性，感到最多的是困惑和迷茫。十年之后，即将跨出下一步的时候，未来依然是如此不确定，但是期待又更多了一些。这其中的变化也带着这十年经历的影子。</p>
<br>
<h2 id="起始-科研是什么"><a class="markdownIt-Anchor" href="#起始-科研是什么"></a> 起始： 科研是什么</h2>
<p>我从大三开始进入交大 APEX 实验室，有幸随着戴文渊学长做机器学习，当时的我觉得「机器学习」这个名字十分高大上然后选择了这个方向，但是做了一年之后依然摸不着头脑，心中十分向往可以做科研，独立写论文的生活，却总是不知道如何下手。文渊在我进实验室的一年后去了百度。当时还没有得到学长真传的我，开始了我科研的第一阶段，从大四到硕士的第二年，期间一直自己摸索，不断地问自己「科研是什么」。</p>
<p>和课程作业不同，学术研究没有具体的问题，具体的方法，具体的答案。文渊的离开让我一下子不知道该怎么做，当时的我的想法很简单，快点寻找一个具体的方向，完成一篇论文。因为 ACM 班的机会暑假在 MSRA 的短暂实习，虽然学会了很多东西，但并没有给我答案。MSRA 回来之后，在实验室薛老师的建议下，我选择了一个现在看来正确而又错误的方向 – 深度学习。那是 AlexNet 出现之前两年，深度学习的主流热点是非监督学习和限制玻尔兹曼机。没有导师的指导，没有工具，当时我靠着实验室的两块显卡和自己写的 CUDA 代码开始了死磕深度学习的两年半。实验室的学长问我，你准备要干啥，我说：「我要用卷积 RBM 去提升 ImageNet 的分类效率。」这一个回答开启了图书馆和实验室的无数个日日夜夜，为了给实验室的老机器多带一块高功率的显卡，我们打开了一台机器的机箱，在外面多塞了一个外接电源。我的生活就持续在调参的循环中：可视化权重的图片, 看上去那么有点像人脸，但是精度却总是提不上来，再来一遍。从一开始 hack 显卡代码的兴奋，到一年之后的焦虑，再到时不时在树下踱步想如何加旋转不变的模型的尝试，在这个方向上，我花费了本科四年级到硕士一年半的所有时间，直到最后还是一无所获。现在看来，当时的我犯了一个非常明显的错误 – 常见的科学研究要么是问题驱动，比如「如何解决 ImageNet 分类问题」；要么是方法驱动，如「RBM 可以用来干什么」。当时的我同时锁死了要解决的问题和用来解决问题的方案，成功的可能性自然不高。如果我在多看一看当时整个领域的各种思路，比如 Lecun 在很早的时候就已经做 end to end，或许结局会不那么一样吧。</p>
<p>当然没有如果，赌上了两年半的时间的我留下的只是何时能够发表论文的紧张心情。焦虑的我开始打算换一个方向，因为 RBM 当时有一个比较经典的文章应用在了推荐系统上，我开始接触推荐系统和 kddcup。比较幸运的是，这一次我并没有把 RBM 作为唯一的一个方法，而是更加广泛地去看了推荐系统中的矩阵分解类的算法，并且在实验室搭建了一个比较泛用的矩阵分解系统。推荐系统方向的耕耘逐渐有了收获，我们在两年 KDDCup11 中获得了不错的成绩。KDD12 在北京，放弃了一个过年的时间，我完成了第一篇关于基于特征的分布式矩阵分解论文，并且非常兴奋地投到了 KDD。四月底的时候，我们收到了 KDD 的提前拒搞通知 – 论文连第一轮评审都没有过。收到拒搞通知时候的我的心情无比沮丧，因为这是第一篇自己大部分独立推动完成的文章。转折在五月，KDDCup12 封榜，我们拿到了第一个 track 的冠军，我依然还记得拿到 KDDCup12 冠军的那一个瞬间，我在状态里面中二地打了 excalibur，仿佛硕士期间的所有阴霾一扫而尽。那时候的我依然还不完全知道科研是什么，但是隐隐之中觉得似乎可以继续试试。</p>
<br>
<h2 id="第零年-可以做什么"><a class="markdownIt-Anchor" href="#第零年-可以做什么"></a> 第零年： 可以做什么</h2>
<p>我对于科研看法的第一个转折，在于我硕士临近毕业的时候。李航老师来到我们实验室给了关于机器学习和信息检索的报告，并且和我们座谈。在报告的过程中，我异常兴奋，甚至时不时地想要跳起来，因为发现我似乎已经知道如何可以解决这么多有趣问题的方法，但是之前却从来没有想过自己可以做这些问题。联系了李航老师之后，在同一年的夏天，我有幸到香港跟随李航和杨强老师实习。实验室的不少学长们曾经去香港和杨强老师工作，他们回来之后都仿佛开了光似地在科研上面突飞猛进。去香港之后，我开始明白其中的原因 – 研究视野。经过几年的磨练，那时候的我或许已经知道如何去解决一个已有的问题，但是却缺乏其他一些必要的技能 – 如何选择一个新颖的研究问题，如何在结果不尽人意的时候转变方向寻找新的突破点，如何知道整个领域的问题之间的关系等等。「你香港回来以后升级了嘛。」-- 来自某大侠的评论。这也许是对于我三个月香港实习的最好概括的吧。香港实习结束的时候我收获了第一篇正式的一作会议论文 (在当年的 ICML)。因为 KDDCup 的缘故，我认识了我现在博士导师 Carlos 的 postdoc Danny，Danny 把我推荐给了 Carlos(UW) 和 Alex(CMU)。我在申请的时候幸运地拿到了 UW 和 CMU 的 offer。在 CMU visit 的时候我见到了传说中的大神学长李沐，他和我感叹，现在正是大数据大火的时候，但是等到我们毕业的时候，不知道时代会是如何，不过又反过来说总可以去做更重要的东西。现在想起这段对话依然依然唏嘘不已。我最后选择了 UW 开始了我六年的博士生活。</p>
<p>感谢博士之前在 APEX 实验室和香港的经历，在博士开始的时候我似乎已经不再担心自己可以做什么了。</p>
<br>
<h2 id="第一年-意外可以收获什么"><a class="markdownIt-Anchor" href="#第一年-意外可以收获什么"></a> 第一年： 意外可以收获什么</h2>
<p>如果给我在 UW 的第一年一个主题的话，或许是「意外」。在交大时候因为兴趣的关系一直去蹭系统生物研究员敖平老师的组会探讨随机过程和马尔可夫链。到 UW 的第一个学期，我无意看到一篇探讨如何用 Lagevin 过程做采样的文章，我想这不就是之前组会上探讨过的东西么，原来这些方法也可以用到机器学习上。我直接借用了原来的交大学会的知识完成了第一篇高效采样 HMC 的文章。我后来并没有继续在这个方向上面耕耘下去，不过另外一位同在组会的学弟继续基于这个方向完成了他的博士论文。</p>
<p>同样的在这一年，我和导师开始「质疑深度学习」-- 如果别的的机器学习模型，有足够大的模型容量和数据，是否可以获得和深度学习一样的效果呢？当时 Carlos 看好 kernel methods，而我因为过去的一些经历决定尝试 Tree Boosting。虽然最后在 vision 领域依然被卷积网络打败而尝试挑战失败，但是为了挑战这一假说而实现高效 Tree boosting 的系统经过小伙伴建议开源成为了后来的 XGBoost。</p>
<p>在第一年暑假结束的时候，因为偶然的原因，我开始对 quantile sketch 算法感兴趣。这里主要的问题是如何设计一个近似的可以合并的数据结构用来查找 quantile。这个方向有一个经典的方案 GK-sketch 的论文，但是只能够解决数据点没有权重的情况。经过一两天的推导，我在一次去爬山的路上终于把结论推广到了有权重的情况。有趣的是新的证明比起原来的证明看起来简单很多。这个结论没有单独发表，但是后来意想不到地被用到了分布式 XGBoost 算法中，证明也收录在了 XGboost 文章的附录中。</p>
<p>研究并不是一朝一夕，做想做的事情把它做好，开始的时候兴趣使然，而在几年之后意想不到的地方获得的收获，这样的感觉走非常不错。</p>
<br>
<h2 id="第二年和第三年-选择做什么"><a class="markdownIt-Anchor" href="#第二年和第三年-选择做什么"></a> 第二年和第三年： 选择做什么</h2>
<p>在新生聚会上，Carlos 对我说，你已经有论文的发表经历了，接下来要静下心来做发大的，「只做 best paper 水平的研究」。和很多 nice 的导师不同，Carlos 对于学生的要求非常严格，说话也是非常直白甚至于「尖刻「。很多的老师不论我们提出什么样的想法，总会先肯定一番，而 Carlos 则会非常直接地提出质疑。一开始的时候会非常不习惯，感觉到信心受到了打击，但是慢慢习惯之后开始习惯这样风格。到现在看来，诚实的反馈的确是我收益最大的东西。我进入博士的一年之后，主要在想的问题是做什么样的问题，可以值得自己深入付出，做扎实有影响力的工作。</p>
<p>在博士的第三年，Carlos 在建议我把 XGBoost 写成论文，用他的话说：「写一篇让读者可以学到东西的文章」。和传统的写法不同，我们在文章的每一个章节插入了实验结果验证当章节提出的观点。而他对于做图的处理也成为了我现在的习惯，直接在图里面插入箭头注释，减少读者的阅读负担。经过几次打磨论文终于成为了我们想要的模样。</p>
<p>博士前对于深度学习遗憾让我又逐渐把目光转回到深度学习。这个时候，我选择了不再一个人作战，在博士的第二年和第三年，我和兴趣使然的小伙伴们合作，一起开始了 MXNet 的项目。项目从零开始，在短短的一年时间里面做出完整的架构。我第一次看到集合了大家的力量齐心协力可以创造出什么样的东西。研究的乐趣不光是发表论文，更多还是可以给别人带来什么，或者更加大胆地说 – 如何一起改变世界。</p>
<p>博士第二年暑假，我在小伙伴的介绍下进入 Google Brain 跟随 Ian Goodfellow 实习。当时 GAN 的论文刚刚发表，我也有幸在成为 Ian 的第一个实习生。实习的开始，我们讨论需要做的问题，Ian 和我把可能要做的项目画在一个风险和回报的曲线上，让我选择。到最后我选择了自己提出的一个课题，在这个曲线里面风险最高，回报也最高。我一直有一个理想，希望可以构建一个终身学习的机器学习系统，并且解决其中可能出现的问题。这个理想过于模糊，但是我们想办法拿出其中的一个可能小的目标 – 知识迁移。如果一个机器学习系统要终生学习，那么在不断收集数据之后必然需要扩充模型的规模来学习更广或者更深，按照现在的做法我们在模型改变之后只能抛弃原来的模型重新训练，这显然是不够高效的。是否有一个方法可以从已经训练好的网络上面进行知识迁移也就成为了一个重要的问题。我先花了一个半月的时间尝试了比较显然的 Knowledge distillation 的方法一直没有得到正面的结果。在最后的一个月，我改变了思路。实习结束的前一个星期，我打开 Tensorborard 上最近一组实验的结果：实验表明新的思路正面的效果。这最后几步的幸运也让我的这一个冒险之旅有了一个相对圆满的结果。这篇论文最后被发表在了 ICLR 上，也是我最喜欢的结果之一。</p>
<p>博士的第三年，我和小伙伴们开发了一种可以用低于线性复杂度就可以训练更深模型的内存优化算法。当时我非常兴奋地把这一结果写下来然后把稿子后给导师看。他和我说：Hmm, 这个结果如果投到 NeurIPS 的话或许可以中一篇 poster，但是这并不是特别有意思。在我沉默之后他又补充了一句：论文并非越多越好，相反你可能要尝试优化你的论文里面最低质量的那一篇。最后我们只是把这篇论文挂在了 Arxiv 上。Carlos 的说法或许比较极端（这篇论文依然影响了不少后面的工作），但也的确是对的，用李沐之前说过的一句话概括，保证每一篇论文的质量接近单调提升，已经是一件难以做到但是又值得最求的事情。</p>
<p>选择做什么眼光和做出好结果的能力一样重要，眼界决定了工作影响力的上界，能力决定了到底是否到达那个上界。交大时敖平老师曾经和我说过，一个人做一件简单的事情和困难的事情其实是要花费一样多的时间。因为即使再简单的问题也有很多琐碎的地方。要想拿到一些东西，就必然意味着要放弃一些其他东西，既然如此，为什么不一直选择跳出舒适区，选一个最让自己兴奋的问题ne.</p>
<br>
<h2 id="第四年之后-坚持做什么"><a class="markdownIt-Anchor" href="#第四年之后-坚持做什么"></a> 第四年之后： 坚持做什么</h2>
<p>博士第三年，我和小伙伴们参加 GTC，结束后老黄 party 的角落里，我一个人在发呆。深度学习的框架发展已经铺开，可接下来应该做什么，我一下子感到迷茫。第三年的暑假我没有去实习，而是决定一个人在学校尝试开发脑海中显现的抽象概念 – 深度学习中间表示。暑假结束之后，我完成了第一个版本，可以比较灵活地支持深度学习系统里面的计算图内存优化。但是总是觉得还缺少着什么 – 系统的瓶颈依然在更接近底层的算子实现上。暑假之后在去加州的飞机上，我尝试在纸上画出为了优化矩阵乘法可能的循环变换，回来之后，我们决定推动一个更加大胆的项目 – 尝试用自动编译生成的方式优化机器学习的底层代码。</p>
<p>这个项目早在之前我也有一些想法，但是一直没有敢去吃这个螃蟹。原因是它的两个特点：从零开始，横跨多领域。因为要做底层代码生成和想要支持新的硬件，我们需要重新重新搞清楚很多在之前被现有的操作系统和驱动隐藏掉的问题，这就好象是在一个荒岛上一无所有重新搭建起一个城堡一样。而这里面也涉及了系统，程序语言，体系结构和机器学习等领域。这让我想起之前在 ACM 班时候重头搭建编译器和 MIPS 处理器并且连接起来的经历。也是那段经历让我觉得为了解决问题去吃多个领域的螃蟹是个让人兴奋的事情。那段经历给我留下的第二个印记是理解了合作和传承的重要性。这门课程设计有一个传统，每一门课程的老师都由上一届学长担任。每一届的同学都会在之前的基础上有所改进。我也曾经为这门课做过一些微小的贡献。演化到现在，这门课程已经从只做简单的答辩，到现在已经有在线评测的 OJ。大家一起的合作塑造了这个课程。推动新的机器学习系统和塑造这门课程一行，需要各个团队的同学合作，足够时间的耐心关注和不断地改进。</p>
<p>我的合作者们也被「卷入」到了这个项目中。我的体系结构合作者一直想要设计新的 AI 硬件，我在雏形完成之后花了大量的时间讨论如何协同设计新的硬件的问题。我们开始讨论怎么管理片上内存，怎么可以比较容易地生成指令集，甚至怎么调度内存读写和计算并行的问题都暴露出来。有一天，我和合作者说我们需要引入虚拟线程的概念来隐藏内存读写开销，然后他很快和我说，这是体系结构里面经典的超线程技术，发明人正是我们的系主任 Hank。我们也在不断地重新发现经典的问题的解决方法在新场景的应用，让我觉得上了一堂最好的体系结构课程。</p>
<p>两年间的不少关键技术问题的突破都是在有趣的时候发生的。我在排队参观西雅图艺术博物馆的 infinity mirror 展览的途中把加速器内存拷贝支持的第一个方案写在了一张星巴克的餐巾纸上。到后来是程序语言方向的同学们也继续参与进来。我们争论最多的是如何如何平衡函数式语言和经典计算图做让大家都可以搞懂的中间表达，这一讨论还在不断继续。经过大家的努力，TVM 的第一篇论文在项目开始的两年之后终于发表。两年间参与项目的同学也从两个人，到一个团队，再到一个新的 lab 和一个社区，这两年也是我博士期间最充实的两年。</p>
<p>因为做了不少「跨界」的工作，我常被问起你到底属于哪个领域。过去半年一直在各地给报告，报告这样开头：算法突破，数据的爆发，计算硬件的提升三者支撑了机器学习的变革，而整合这三者的，则是机器学习系统。这也是为什么我要做机器学习系统的原因。曾经一个教授问我这样的问题，如果明天有一样新的化学反应过程可能带来机器学习的变革，你会怎么做。我答道：「我投入会去学习研究这个化学过程」。虽然我不知道遥远的未来会需要什么，到底是系统，算法，还是化学，从问题出发，用尽所有可能的方法去最好地解决机器学习问题，应该这就是我想要坚持的研究风格吧。</p>
<br>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>在写这篇总结的时候，心中有不少感叹。我常想，如果我在焦虑死磕深度学习的时候我多开窍一些会发生什么，如果我并没有在实习结束的时候完成当时的实验，又会是什么。但现在看来，很多困难和无助都是随机的涨落的一部分，付出足够多的时间和耐心，随机过程总会收敛到和付出相对的稳态。</p>
<p>每个人的研究道路都各不相同，我的经历应该也是千万条道路中其中一条罢了。博士的经历就好像是用五年多时间作为筹码投资给自己，去突破自己做自己原来想不到的事情。中不管坎坷曲折都是无可替代的一部分。</p>
<p>科研从来不是一个人的事情，对于我来说特别是如此。我在交大的时候和一群年轻的同学一起摸索推荐系统的算法，而在博士期间搭建的每一个系统都包含了很多合作者一起的努力。也正是大家一起的努力才带来了现在的成果。我个人在这十年间受到了不少老师，同学，家人的鼓励和帮助，感谢他们他们给予了我这无比珍贵的十年时光。</p>
]]></content>
      <categories>
        <category>Future</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>论坛悄悄话板块保研问题</title>
    <url>/2024/03/05/%E8%AE%BA%E5%9D%9B%E6%82%84%E6%82%84%E8%AF%9D%E6%9D%BF%E5%9D%97%E4%BF%9D%E7%A0%94%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<!-- omit in toc -->
<h2 id="目录"><a class="markdownIt-Anchor" href="#目录"></a> 目录</h2>
<ul>
<li><a href="#%E9%80%89%E6%8B%A9%E7%A0%94%E7%A9%B6%E7%94%9F%E8%BF%98%E6%98%AF%E5%B0%B1%E4%B8%9A">选择研究生还是就业？</a></li>
<li><a href="#%E5%AF%BC%E5%B8%88%E9%80%89%E6%8B%A9%E4%B8%8E%E7%A7%91%E7%A0%94%E5%AE%9E%E4%B9%A0%E7%AD%96%E7%95%A5">导师选择与科研实习策略</a></li>
<li><a href="#%E5%AF%B9%E7%89%B9%E5%AE%9A%E5%AF%BC%E5%B8%88%E7%9A%84%E8%A7%81%E8%A7%A3">对特定导师的见解</a></li>
<li><a href="#%E4%B8%8E%E5%AF%BC%E5%B8%88%E8%A7%81%E9%9D%A2%E8%AE%A8%E8%AE%BA%E5%86%85%E5%AE%B9">与导师见面讨论内容</a></li>
<li><a href="#%E9%83%AD%E5%86%9B%E7%BB%84%E5%AF%BC%E5%B8%88%E6%8E%A8%E8%8D%90">郭军组导师推荐</a></li>
<li><a href="#%E8%82%96%E6%B3%A2%E8%80%81%E5%B8%88%E7%9A%84%E5%AF%BC%E5%B8%88%E9%A3%8E%E6%A0%BC">肖波老师的导师风格</a></li>
<li><a href="#%E5%85%B3%E4%BA%8E%E4%B8%8E%E5%AF%BC%E5%B8%88%E8%81%94%E7%B3%BB%E7%9A%84%E8%AE%A8%E8%AE%BA">关于与导师联系的讨论</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2%E5%AF%BC%E5%B8%88%E6%83%85%E5%86%B5">计算机学院导师情况</a></li>
<li><a href="#%E6%95%99%E6%8E%92%E7%99%BE%E5%88%86%E4%B9%8B%E5%85%AB%E6%83%B3%E5%B0%9D%E8%AF%95%E5%8D%8E%E4%BA%94%E4%BD%86%E7%AE%80%E5%8E%86%E4%B8%8D%E5%BC%BA%E4%B8%8D%E7%9F%A5%E5%A6%82%E4%BD%95%E5%8A%AA%E5%8A%9B">教排百分之八想尝试华五，但简历不强，不知如何努力。</a></li>
<li><a href="#%E6%89%BE%E4%BF%9D%E7%A0%94%E5%AF%BC%E5%B8%88">找保研导师</a></li>
<li><a href="#%E9%83%AD%E5%86%9B%E7%BB%84%E6%83%85%E5%86%B5">郭军组情况</a></li>
<li><a href="#%E8%AE%BA%E5%9D%9B%E5%AF%B9%E8%AF%9D%E6%8E%A2%E7%B4%A2%E8%B4%B5%E7%B3%BB%E7%9A%84%E5%90%AB%E4%B9%89">论坛对话：探索“贵系”的含义</a></li>
<li><a href="#%E8%AE%BA%E5%9D%9B%E8%AE%A8%E8%AE%BA%E7%A0%94%E7%A9%B6%E7%94%9F%E5%AE%9E%E4%B9%A0%E5%AE%89%E6%8E%92%E8%AE%A8%E8%AE%BA">论坛讨论：研究生实习安排讨论</a></li>
<li><a href="#%E7%A7%91%E7%A0%94or%E6%94%BE%E5%85%BB">科研or放养</a></li>
<li><a href="#%E7%A5%9Dchuang%E6%9D%8Eke%E5%AF%BC%E5%B8%88%E4%BC%9A%E7%BB%99%E7%A7%91%E7%A0%94%E6%8C%87%E5%AF%BC%E5%90%97%E7%A0%94%E4%BA%8C%E6%9A%91%E5%81%87%E5%AE%9E%E4%B9%A0%E6%94%BE%E4%B8%8D%E6%94%BEpush%E4%B8%8D">祝chuang，李ke导师会给科研指导吗，研二暑假实习放不放，push不</a></li>
<li><a href="#%E4%BF%9D%E6%9C%AC%E6%A0%A1%E5%8F%AF%E4%BB%A5%E5%A4%9A%E8%81%94%E7%B3%BB%E5%87%A0%E4%B8%AA%E8%80%81%E5%B8%88%E5%90%97">保本校可以多联系几个老师吗？</a></li>
<li><a href="#%E5%8E%89%E5%AE%B3%E7%9A%84%E5%AF%BC%E5%B8%88%E6%89%8B%E5%BA%95%E4%B8%8B%E7%9A%84%E5%AD%A6%E7%94%9F%E6%98%AF%E9%83%BD%E5%8E%BB%E7%AE%97%E6%B3%95%E4%BA%86%E5%90%97">厉害的导师手底下的学生是都去算法了吗？</a></li>
<li><a href="#%E6%89%93%E5%90%AC%E5%AF%BC%E5%B8%88">打听导师</a></li>
<li><a href="#%E6%A0%A1%E5%86%85%E4%BF%9D%E7%A0%94%E6%89%BE%E8%80%81%E5%B8%88%E4%BC%9A%E7%9B%B4%E6%8E%A5%E5%9B%A0%E4%B8%BArk%E6%8C%82%E4%BA%BA%E5%90%97%E8%BE%B9%E7%BC%98%E4%BA%BA%E4%B8%8D%E5%A4%AA%E9%AB%98">校内保研找老师会直接因为rk挂人吗？边缘人不太高</a></li>
<li><a href="#%E6%83%B3%E7%9F%A5%E9%81%93%E5%AD%A6%E6%9C%AF%E5%A5%BD%E7%9A%84%E5%B9%B4%E8%BD%BB%E8%80%81%E5%B8%88%E6%88%96%E8%80%85%E7%BB%84%E5%86%85%E7%A0%94%E7%A9%B6%E6%B0%9B%E5%9B%B4%E5%A5%BD%E7%9C%9F%E7%9A%84%E9%83%BD%E8%83%BD%E5%8F%91%E5%87%BA%E8%AE%BA%E6%96%87%E5%90%97">想知道学术好的年轻老师或者组内研究氛围好，真的都能发出论文吗？</a></li>
<li><a href="#%E5%90%8C%E6%97%B6%E5%9C%A8%E5%87%A0%E4%B8%AA%E8%80%81%E5%B8%88%E7%9A%84%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%AE%9E%E4%B9%A0">同时在几个老师的实验室实习</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E8%81%94%E7%B3%BB%E5%AF%BC%E5%B8%88%E7%BB%99%E5%88%86%E9%85%8D%E4%BA%86%E5%B8%88%E5%85%84">保研联系导师给分配了师兄</a></li>
<li><a href="#%E8%81%94%E7%B3%BB%E5%AF%BC%E5%B8%88%E6%B2%A1%E5%A3%B0%E9%9F%B3">联系导师没声音</a></li>
<li><a href="#%E4%B9%8B%E5%89%8D%E4%B8%80%E4%B8%AA%E5%9B%A0%E4%B8%BA%E4%B8%B4%E6%97%B6%E9%B8%BD%E8%80%81%E5%B8%88%E8%A2%AB%E9%AA%82%E4%B8%8A%E8%AE%BA%E5%9D%9B%E7%83%AD%E6%90%9C%E7%9A%84%E4%BA%BA">之前一个因为临时鸽老师被骂上论坛热搜的人</a></li>
<li><a href="#%E4%B8%93%E7%A1%95%E5%92%8C%E5%AD%A6%E7%A1%95">专硕和学硕</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E6%89%BE%E4%BA%86%E4%B8%80%E4%B8%AA%E6%A0%A1%E5%86%85%E8%80%81%E5%B8%88%E5%90%8E%E8%B7%9F%E9%9A%8F%E4%BA%86%E4%B8%80%E4%B8%AA%E6%9C%88%E8%BF%98%E6%94%B6%E5%88%B0%E4%BA%86%E8%96%AA%E6%B0%B4">保研找了一个校内老师后，跟随了一个月还收到了薪水</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E6%89%BE%E5%AF%BC%E5%B8%88">保研找导师</a></li>
<li><a href="#%E5%A4%A7%E4%B8%89%E4%BF%9D%E7%A0%94%E4%BA%BA%E6%B1%82%E9%97%AE">大三保研人求问</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E6%B1%82%E9%97%AE">保研求问</a></li>
<li><a href="#%E5%8D%95%E7%BA%AF%E4%B8%BA%E4%BA%86985%E4%BF%9D%E7%A0%94%E5%8D%8E%E4%BA%94%E6%9C%89%E5%BF%85%E8%A6%81%E5%90%97">单纯为了985保研华五有必要吗</a></li>
<li><a href="#%E8%AF%B7%E9%97%AE%E4%BF%9D%E7%A0%94%E8%AE%A1%E9%99%A2%E9%83%AD%E8%BF%8E%E8%80%81%E5%B8%88%E8%83%BD%E6%8A%A5%E5%90%97">请问保研计院郭迎老师能报吗</a></li>
<li><a href="#%E6%8F%90%E9%97%AE%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%A6%82%E6%9E%9C%E8%A6%81%E6%B1%82%E6%89%93%E5%8D%A1%E4%BD%86%E6%98%AF%E4%B8%8D%E6%89%93%E6%9C%89%E4%BB%80%E4%B9%88%E6%83%A9%E7%BD%9A">提问，实验室如果要求打卡，但是不打有什么惩罚</a></li>
<li><a href="#%E8%BF%99%E6%A0%B7%E7%9A%84%E5%AF%BC%E5%B8%88%E7%AE%97%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90%E7%9A%84">这样的导师算什么样子的</a></li>
<li><a href="#%E6%B1%82ai%E9%99%A2%E5%AF%BC%E5%B8%88%E7%9A%84%E6%8E%A8%E8%8D%90">求AI院导师的推荐</a></li>
<li><a href="#%E5%AF%BB%E6%B1%82%E6%9C%89%E5%85%B3%E8%80%83%E7%A0%94%E5%AF%BC%E5%B8%88%E9%A1%B9%E5%88%98%E5%AE%87%E8%80%81%E5%B8%88%E7%9A%84%E4%BF%A1%E6%81%AF">寻求有关考研导师项刘宇老师的信息</a></li>
<li><a href="#%E8%80%83%E7%A0%94%E8%81%94%E7%B3%BB%E5%AF%BC%E5%B8%88%E5%B7%B2%E8%AF%BB%E4%B8%8D%E5%9B%9E">考研联系导师已读不回</a></li>
<li><a href="#%E8%AE%BA%E5%9D%9B%E8%AE%A8%E8%AE%BA%E6%91%98%E8%A6%81%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E9%80%89%E6%8B%A9%E7%9A%84%E5%92%A8%E8%AF%A2">论坛讨论摘要：关于职业选择的咨询</a></li>
<li><a href="#%E8%AE%BA%E5%9D%9B%E8%AE%A8%E8%AE%BA%E4%BF%9D%E7%A0%94%E8%BF%98%E6%98%AF%E5%87%BA%E5%9B%BD%E4%BD%95%E5%8E%BB%E4%BD%95%E4%BB%8E">论坛讨论：保研还是出国，何去何从？</a></li>
<li><a href="#%E5%8C%97%E9%82%AE%E4%BA%BA%E8%AE%BA%E5%9D%9B%E8%AE%A8%E8%AE%BA%E6%91%98%E8%A6%81%E8%AE%A1%E9%99%A212%E7%BB%84%E5%AF%BC%E5%B8%88%E6%8E%A8%E8%8D%90">北邮人论坛讨论摘要：计院12组导师推荐</a></li>
<li><a href="#%E5%8C%97%E9%82%AE%E7%A1%95%E5%A3%AB%E4%B8%8E%E6%96%B0%E5%8A%A0%E5%9D%A1%E4%B8%80%E5%B9%B4%E7%A1%95%E5%A3%AB%E8%AE%A8%E8%AE%BA%E6%91%98%E8%A6%81">北邮硕士与新加坡一年硕士讨论摘要</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E6%B5%81%E7%A8%8B">保研流程</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E9%97%AE%E9%A2%98">保研问题</a></li>
<li><a href="#%E4%BF%9D%E7%A0%94%E6%89%BE%E5%AF%BC%E5%B8%88%E7%9B%B8%E5%85%B3%E8%AE%A8%E8%AE%BA"><strong>保研找导师相关讨论</strong></a></li>
</ul>
<br>
<h2 id="选择研究生还是就业"><a class="markdownIt-Anchor" href="#选择研究生还是就业"></a> 选择研究生还是就业？</h2>
<p>ai院大三，预计可以保研，但是对科研不是很感兴趣。问题如下</p>
<p>如果要读ai方向研的话：</p>
<ul>
<li>1.提前学开发方向的技术会不会有利于以后找工作，但会不会耽误读研本职工作的时间？</li>
<li>2.现阶段应该先尝试联系老师还是尝试找实习？</li>
<li>3.导师里最放的[emoji]导放到什么程度？（比如知道你打算就业，就不会在科研上要求太高，而且该放实习放实习）这样的导师大概占比多少</li>
</ul>
<p>如果本科就业的话：<br />
因为本人只有课内的项目经历加上一个大创，所以本科就业的起点和最初几年的发展会不会明显低于读研后就业？也就是找到好工作的希望非常渺茫？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.会的  </span><br><span class="line">2.联系导师，现在有的好导师还有坑，早点占一个，有的导师联系了之后也不会找你，你想找实习可以同步   </span><br><span class="line">3，放到你只要一周开一次组会，自己能毕业就行，占比未知但必定极小</span><br><span class="line">就业问题看个人，无法解答   </span><br></pre></td></tr></table></figure>
<br>
<h2 id="导师选择与科研实习策略"><a class="markdownIt-Anchor" href="#导师选择与科研实习策略"></a> 导师选择与科研实习策略</h2>
<p><strong>楼主：</strong> 联系了老师，老师让在组内实习一段时间看看。那要是实习了一两个月以后老师没要，再联系其他老师，好老师估计都没了，该怎么办？</p>
<p><strong>IWhisper#842：</strong> 海投，别只找一个啊。</p>
<p><strong>IWhisper#632：</strong> 但是总不能一个人同时做两份科研实习吧。</p>
<p><strong>IWhisper#385：</strong> 那要是两个老师都要，那难道直接和其中一位老师说我不想去你那里了吗？</p>
<p><strong>IWhisper#141：</strong> 为啥不可以呢？我觉得他要考验你，你也要留后手的吧。</p>
<p><strong>IWhisper#101：</strong> 有啥不可以吗，给你offer就接？</p>
<p><strong>IWhisper#809：</strong> 没办法，还见过有同学同时做五个，现在在学五个方向。我想的是能找到个竞争小点的导，最好是能早点确实下来。</p>
<p><strong>IWhisper#632：</strong> 这么可怕么哥们？</p>
<p><strong>IWhisper#803：</strong> 我也有这个困扰，该怎么办啊。同时几个实习怕hold不住啊。</p>
<p><strong>IWhisper#253：</strong> 什么五边形战士。</p>
<Br>
<h2 id="对特定导师的见解"><a class="markdownIt-Anchor" href="#对特定导师的见解"></a> 对特定导师的见解</h2>
<p><strong>IWhisper#467：</strong> 想问下李佩佩、李睿凡、张曼、胡梦婕、宋琦、宋晴、董譞、何召锋，这几位老师有了解的不？</p>
<p><strong>IWhisper#699：</strong> 小心卤肉饭。</p>
<p><strong>IWhisper#824：</strong> 老师你好香。</p>
<p><strong>IWhisper#576：</strong> lrf~</p>
<p><strong>IWhisper#625：</strong> 李博士：😅</p>
<p><strong>IWhisper#789：</strong> 这几个老师学科都不一样。</p>
<p><strong>IWhisper#873：</strong> 感觉何召峰不错，也很有实力。</p>
<Br>
<h2 id="与导师见面讨论内容"><a class="markdownIt-Anchor" href="#与导师见面讨论内容"></a> 与导师见面讨论内容</h2>
<p><strong>IWhisper#444:</strong> 老师让线下见一面聊一聊，一般会聊些啥？</p>
<p><strong>IWhisper#756:</strong> 想线下看看水平，意向，还有一些相处上的感觉。然后可能包括一些不方便文字说的内容。</p>
<p><strong>IWhisper#444:</strong> 好的，谢谢沙发。感觉自己太水了。</p>
<p><strong>IWhisper#171:</strong> [无具体回复内容，可能是表示关注。]</p>
<Br>
<h2 id="郭军组导师推荐"><a class="markdownIt-Anchor" href="#郭军组导师推荐"></a> 郭军组导师推荐</h2>
<p><strong>IWhisper#694:</strong> 郭军组导师求推荐。</p>
<p><strong>IWhisper#127:</strong> gj。</p>
<p><strong>IWhisper#944:</strong> gj。</p>
<p><strong>IWhisper#773:</strong> 排除刚子。</p>
<p><strong>IWhisper#318:</strong> 我要，我要，我要！我就是要刚子！【在IWhisper#773的大作中提到: 排除刚子。】</p>
<p><strong>IWhisper#773:</strong> 请欣赏著名作品：《刚子今天拉了跨了》。</p>
<p><strong>IWhisper#577:</strong> 牢邓。</p>
<Br>
<h2 id="肖波老师的导师风格"><a class="markdownIt-Anchor" href="#肖波老师的导师风格"></a> 肖波老师的导师风格</h2>
<p><strong>IWhisper#167:</strong> 真诚发文：AI院研究生导师。肖波老师怎么样，是什么类型的导师？因为这位老师似乎很受欢迎所以来问一下。</p>
<p><strong>IWhisper#167:</strong> 自顶。</p>
<p><strong>IWhisper#55/377/231:</strong> bd（表示占位或关注）。</p>
<p><strong>IWhisper#167:</strong> 再次自顶。</p>
<p><strong>IWhisper#430:</strong> d。</p>
<p><strong>IWhisper#407:</strong> 据说还行，怎么这么多踩的？</p>
<p><strong>IWhisper#293:</strong> bd。</p>
<p><strong>IWhisper#327:</strong> 我认识他的一个学生，感觉挺爽的。</p>
<p><strong>IWhisper#310:</strong> 为什么这么多点踩的啊？</p>
<p><strong>IWhisper#310:</strong> 有无老哥细嗦。</p>
<p><strong>IWhisper#167:</strong> 不知道呀。</p>
<p><strong>IWhisper#983:</strong> 我一朋友在那，我替他说，看踩赞比就行。</p>
<p><strong>IWhisper#904:</strong> 哪个朋友，现在在实验室吗，我来问问他为啥有这么大怨气。</p>
<p><strong>IWhisper#449:</strong> 室友是他学生，感觉还可以吧。属于放养的。</p>
<p><strong>IWhisper#948:</strong> 那个朋友细说。</p>
<Br>
<h2 id="关于与导师联系的讨论"><a class="markdownIt-Anchor" href="#关于与导师联系的讨论"></a> 关于与导师联系的讨论</h2>
<p><strong>IWhisper#62:</strong> 提出了与导师联系的问题，询问如果导师让完成大创后再联系是否意味着机会已经没有了。</p>
<p><strong>IWhisper#49:</strong> 提出质疑，如果楼主因为大创忙碌而没有时间进行科研，为什么还要联系导师。</p>
<p><strong>IWhisper#752:</strong> 对楼主的做法表示惊讶，暗示这是论坛上看到的另一个奇葩行为。</p>
<p><strong>IWhisper#387:</strong> 建议楼主先完成大创项目，表明先处理手头的事情再考虑保研的事宜。</p>
<p><strong>IWhisper#614:</strong> 指出现在找导师的目的主要是为了科研工作，如果说自己没有时间，这种做法是不合适的。</p>
<p><strong>IWhisper#752:</strong> 强调这种做法是不合理的，暗示楼主的行为很奇怪。</p>
<Br>
<h2 id="计算机学院导师情况"><a class="markdownIt-Anchor" href="#计算机学院导师情况"></a> 计算机学院导师情况</h2>
<p><strong>IWhisper#421:</strong> 询问关于计算机学院几位导师的情况，包括15组的双锴老师，11组的孙海峰老师，戚琦老师和2组的白婷老师，问是否都是白名单。</p>
<p><strong>IWhisper#368:</strong> 提到11组实行统一管理。</p>
<p><strong>IWhisper#567:</strong> 推荐“白婷冲”。</p>
<p><strong>IWhisper#912:</strong> 对上一条回复表示疑问，并提出听说qq可以。</p>
<p><strong>IWhisper#809:</strong> 指出所有提到的都是热门。</p>
<p><strong>IWhisper#673:</strong> 提到11组似乎都是热门。</p>
<p><strong>IWhisper#421:</strong> 对11组是否比较push表示担忧。</p>
<p><strong>IWhisper#32:</strong> 推荐考虑15组的wyl老师，描述为人非常好，不push，不打卡，补贴充足，科研能力强，项目少，支持实习，很为学生考虑。</p>
<p><strong>IWhisper#784:</strong> 对IWhisper#32的描述表示疑问，问是否是早中晚打卡。</p>
<p><strong>IWhisper#707:</strong> 怀疑IWhisper#32的发言是否是开玩笑。</p>
<p><strong>IWhisper#421:</strong> 要求证实信息的真实性，提出“北邮人不骗北邮人”。</p>
<p><strong>IWhisper#384:</strong> 借楼询问关于4组的情况。</p>
<p><strong>IWhisper#463:</strong> 借楼询问关于8组的情况。</p>
<p><strong>IWhisper#278:</strong> 对8组的询问回复说“牛马组”。</p>
<p><strong>IWhisper#206:</strong> 对之前发问号的回复表示疑惑。</p>
<p><strong>IWhisper#458:</strong> 同问关于bt的情况。</p>
<br>
<h2 id="教排百分之八想尝试华五但简历不强不知如何努力"><a class="markdownIt-Anchor" href="#教排百分之八想尝试华五但简历不强不知如何努力"></a> 教排百分之八想尝试华五，但简历不强，不知如何努力。</h2>
<p><strong>moliyu (heywhf):</strong> 各位学长学姐好，我是AI院21级AI专业的一名学生，大三，教务排名大约百分之八，有一点五的竞赛加分，但科研经历少，编程能力弱，有雏雁和未完成的大创项目。想尝试华五，但简历不强，不知如何努力。希望得到建议。</p>
<p><strong>poppin:</strong> 建议大三参加一两个竞赛，充实简历。</p>
<p><strong>moliyu (heywhf):</strong> 谢谢，但现在已经大三下了，感觉普通学科竞赛没什么用，已报了一个大英，还有什么能报的吗？</p>
<p><strong>llh666:</strong> 同学你好，建议联系本校实验室老师做科研实习，华五套磁导师没用，不如本校方便。有余力的话，参加相关比赛，但最好这学期就完成。</p>
<p><strong>moliyu (heywhf):</strong> 谢谢同学！建议很好，意思是现在联系导师只能陶瓷而华五老师不吃这套吗？祝你好运。</p>
<p><strong>Koreyoshii:</strong> 可考虑华五工程硕博。AI方向竞争激烈，背景弱可以提前套磁，但没科研，老师不看重竞赛，陶瓷难，先多试试。</p>
<p><strong>Vergil31245:</strong> 华五硕强com，导师同意未必有用，除非考虑直博。</p>
<p><strong>c2021212770:</strong> 百分之八和弱背景，夏令营能否进去不好说。</p>
<p><strong>deer15160:</strong> bd (占位或关注)。</p>
<h2 id="找保研导师"><a class="markdownIt-Anchor" href="#找保研导师"></a> 找保研导师</h2>
<p><strong>IWhisper#414:</strong> 发帖抱怨找保研导师难，表示导师加了微信但一句话没说。</p>
<p><strong>IWhisper#368:</strong> 回复问楼主为什么不先开口说话。</p>
<p><strong>IWhisper#526:</strong> 同样建议楼主应该先主动发言。</p>
<p><strong>IWhisper#395:</strong> 强调既然是求人，应该主动谦逊些，不应期待导师主动问。</p>
<p><strong>IWhisper#617:</strong> 提醒楼主别人同意加微信已经不错了。</p>
<p><strong>IWhisper#414:</strong> 解释说加导师微信前已经说明了来意，但害怕被拒绝。</p>
<h2 id="郭军组情况"><a class="markdownIt-Anchor" href="#郭军组情况"></a> 郭军组情况</h2>
<p><strong>IWhisper#310:</strong> 发起询问关于郭军组是否有需要避开的情况。</p>
<p><strong>IWhisper#541:</strong> 简短回复“lg”。</p>
<p><strong>IWhisper#987:</strong> 也简短地回复“lg”。</p>
<p><strong>IWhisper#985:</strong> 指出只有一个需要避雷，其他都没有问题。</p>
<p><strong>IWhisper#310:</strong> 对大家的回复表示感谢。</p>
<h2 id="论坛对话探索贵系的含义"><a class="markdownIt-Anchor" href="#论坛对话探索贵系的含义"></a> 论坛对话：探索“贵系”的含义</h2>
<p><strong>IWhisper#310:</strong><br />
发信人: IWhisper#310 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> 【问题】贵系<br />
<strong>内容:</strong> rt，这个词到底指什么，出现很多次了<br />
※ 来源:·北邮人论坛 <a href="http://bbs.byr.cn">http://bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#201 回复 IWhisper#310:</strong><br />
发信人: IWhisper#201 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 【问题】贵系<br />
<strong>内容:</strong> 清华计算机<br />
※ 来源:·北邮人论坛 <a href="http://bbs.byr.cn">http://bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<h2 id="论坛讨论研究生实习安排讨论"><a class="markdownIt-Anchor" href="#论坛讨论研究生实习安排讨论"></a> 论坛讨论：研究生实习安排讨论</h2>
<p><strong>IWhisper#849:</strong><br />
发信人: IWhisper#849 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> 导师放实习<br />
<strong>内容:</strong> 研二下五一开始放，什么水平<br />
※ 来源:·北邮人论坛 <a href="http://bbs.byr.cn">http://bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#832 回复 IWhisper#849:</strong><br />
发信人: IWhisper#832 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 导师放实习<br />
<strong>内容:</strong> 好的水平<br />
※ 来源:·北邮人论坛手机客户端 <a href="http://bbs.byr.cn">bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#68 回复 IWhisper#849:</strong><br />
发信人: IWhisper#68 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 导师放实习<br />
<strong>内容:</strong> 是不是中上ema1<br />
※ 来源:·北邮人论坛手机客户端 <a href="http://bbs.byr.cn">bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#276 回复 IWhisper#849:</strong><br />
发信人: IWhisper#276 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 导师放实习<br />
<strong>内容:</strong> 挺好的<br />
※ 来源:·北邮人论坛手机客户端 <a href="http://bbs.byr.cn">bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#321 回复 IWhisper#849:</strong><br />
发信人: IWhisper#321 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 导师放实习<br />
<strong>内容:</strong> 挺好了啊<br />
※ 来源:·北邮人论坛手机客户端 <a href="http://bbs.byr.cn">bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#520 回复 IWhisper#849:</strong><br />
发信人: IWhisper#520 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 导师放实习<br />
<strong>内容:</strong> 很不错，有机会刷两段实习了都<br />
※ 来源:·北邮人论坛手机客户端 <a href="http://bbs.byr.cn">bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<p><strong>IWhisper#113 回复 IWhisper#520:</strong><br />
发信人: IWhisper#113 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 导师放实习<br />
<strong>内容:</strong> 能刷两段吗？5-7？8-10？<br />
【 在 IWhisper#520 的大作中提到: 】很不错，有机会刷两段实习了都<br />
※ 来源:·北邮人论坛手机客户端 <a href="http://bbs.byr.cn">bbs.byr.cn</a>·[FROM: 匿名天使的家]</p>
<br>
<h2 id="科研or放养"><a class="markdownIt-Anchor" href="#科研or放养"></a> 科研or放养</h2>
<p><strong>发信站：北邮人论坛 (Fri Mar 8 13:45:52 2024), 站内</strong></p>
<p>楼主写道：“小东西不太懂。看论坛的观点基本就是想科研找学术水平高的导师，想多实习找好工作找放养的导师。然而大部分人是要硕士毕业工作的，在不读博的情况下，即使科研也肯定是为了找好工作。那么科研和实习二者哪个更利于找好工作呢？还是说二者赛道不太一样，科研偏算法，实习偏开发呢？既然二者都利于工作，为什么往往会建议放养多实习呢？”</p>
<p><strong>回复1：IWhisper#865</strong></p>
<p>“校内除非是极其牛的导师，要不然出不了好成果。成果一般就算想做算法也得多出去实习。大厂实习对于算法和开发都重要。”</p>
<p><strong>回复2：IWhisper#574</strong></p>
<p>“专心科研无实习≠硕士毕业找到好工作。”</p>
<p><strong>回复3：IWhisper#520</strong></p>
<p>“有一定的科研水平+有实习操作空间+自己使劲卷，就很无敌了。”</p>
<p><strong>回复4：IWhisper#100</strong></p>
<p>“科研不科研如果你不介意其实都无所谓。不压榨不放养＞不压榨放养＞压榨放养＞压榨不放养。”</p>
<h2 id="祝chuang李ke导师会给科研指导吗研二暑假实习放不放push不"><a class="markdownIt-Anchor" href="#祝chuang李ke导师会给科研指导吗研二暑假实习放不放push不"></a> 祝chuang，李ke导师会给科研指导吗，研二暑假实习放不放，push不</h2>
<p><strong>IWhisper#212:</strong><br />
“祝chuang，李ke导师会给科研指导吗，研二暑假实习放不放，push不” - 北邮人论坛，发信时间: 2024年3月9日 15:56。</p>
<p><strong>IWhisper#573:</strong><br />
“这俩导师都是直接指导的” - 北邮人论坛，发信时间: 2024年3月9日 15:57。</p>
<p><strong>IWhisper#743:</strong><br />
“bd” - 北邮人论坛，发信时间: 2024年3月9日 16:14。</p>
<p><strong>IWhisper#566:</strong><br />
“请问啥时候放实习呢？” - 北邮人论坛，发信时间: 2024年3月9日 16:15。</p>
<p><strong>IWhisper#840:</strong><br />
“bd” - 北邮人论坛，发信时间: 2024年3月9日 16:26。</p>
<p><strong>IWhisper#743 (再次回复):</strong><br />
“bd” - 北邮人论坛，引用IWhisper#573：“这俩导师都是直接指导的”，发信时间: 2024年3月9日 16:47。</p>
<p><strong>IWhisper#573 (再次回复):</strong><br />
“研二结束的那个暑假放实习” - 北邮人论坛，引用IWhisper#743：“bd”，发信时间: 2024年3月9日 17:06。</p>
<p><strong>IWhisper#524:</strong><br />
“算是比较push” - 北邮人论坛，发信时间: 2024年3月9日 17:07。</p>
<p><strong>IWhisper#743 (第三次回复):</strong><br />
“是哪个老师比较push啊？李ke还是祝chuang老师？” - 北邮人论坛，引用IWhisper#524：“算是比较push”，发信时间: 2024年3月9日 17:23。</p>
<p><strong>IWhisper#527:</strong><br />
“bd” - 北邮人论坛，发信时间: 2024年3月9日 17:49。</p>
<p><strong>IWhisper#955:</strong><br />
“为什么不选胡晓峰呢” - 北邮人论坛，引用IWhisper#743：“是哪个老师比较push啊？李ke还是祝chuang老师？”，发信时间: 2024年3月9日 18:33。</p>
<p><strong>IWhisper#743 (第四次回复):</strong><br />
“bd” - 北邮人论坛，发信时间: 2024年3月9日 20:47。</p>
<p><strong>IWhisper#743 (第五次回复):</strong><br />
“这是哪位导师啊？人怎么样？” - 北邮人论坛，引用IWhisper#955：“为什么不选胡晓峰呢”，发信时间: 2024年3月9日 20:47。</p>
<p><strong>IWhisper#955 (再次回复):</strong><br />
“永远的神” - 北邮人论坛，引用IWhisper#743：“这是哪位导师啊？人怎么样？”，发信时间: 2024年3月9日 20:57。</p>
<p><strong>IWhisper#743 (第六次回复):</strong><br />
“bd” - 北邮人论坛，发信时间: 2024年3月9日 22:57。</p>
<Br>
<h2 id="保本校可以多联系几个老师吗"><a class="markdownIt-Anchor" href="#保本校可以多联系几个老师吗"></a> 保本校可以多联系几个老师吗？</h2>
<p><strong>用户IWhisper#564:</strong> [在北邮人论坛上提问] 保本校可以多联系几个老师吗？</p>
<p><strong>用户IWhisper#564:</strong> 和老师见面聊过之后没有确定要不要，只告诉了大致需要学习的内容，需要再联系别的老师吗？</p>
<p><strong>用户IWhisper#181:</strong> 建议联系，这种的越拖对自己越不利。</p>
<p><strong>用户IWhisper#185:</strong> 现在没有哪个老师能给你打包票说一定要啊，这才三月，有哪个老师能现在就跟你确定的啊……</p>
<p><strong>用户IWhisper#181:</strong> 我跟我周围的同学这几天联系老师，了解到已经有不少老师跟学生确认好了，没有确认的也让进组打工了。这种让自己大致学点的不是很适合明确希望现在做的事情对保过去有帮助的同学。</p>
<p><strong>用户IWhisper#313:</strong> 不少老师确认好了？能问一下是哪里的什么样的老师吗，以及你同学是排名很靠前的吗？我联系的没有现在确认的，都是有几个在实习的，之后要夏令营时期组内面试才能确认。</p>
<p><strong>用户IWhisper#185:</strong> 真能有三月就确定的吗？是排名很靠前的吗？就我了解到的像11组那种保研实习一段时间再决定的才是常态吧，不理解怎么会有“不少老师”才三月份就已经“确定”了。</p>
<p><strong>用户IWhisper#331:</strong> 因为某个院硬卷，疯狂进组，造成了这种假象。</p>
<p><strong>用户IWhisper#185:</strong> 现在进组不也是做保研实习的嘛。咋就已经确认了，不会觉得进组实习了就是确认了吧。</p>
<p><strong>用户IWhisper#256:</strong> 借楼问一般什么时候能确定啊？</p>
<p><strong>用户IWhisper#753:</strong> 不然还有哪里？（回复到关于计院的提问）</p>
<p><strong>用户IWhisper#753:</strong> 计院保外多，最后会鸽不少。</p>
<p><strong>用户IWhisper#256:</strong> 鸽了会顺延其他人吗？</p>
<p><strong>用户IWhisper#185:</strong> 啥叫顺延。。老师名额空出来了也得你自己去联系啊，还等着老师主动联系你给你顺延吗。</p>
<p><strong>用户IWhisper#331:</strong> AI（模糊回应，可能是对话题的转移）</p>
<p><strong>用户IWhisper#256:</strong> 我的意思是同组里其他的实习同学。</p>
<p><strong>用户IWhisper#270:</strong> 同问（关于确定时间的提问）</p>
<p><strong>用户IWhisper#185:</strong> 那应该行，一般来说提前实习的会有优势吧，不过也不一定，有可能会再来高rk的跟你竞争。</p>
<br>
<h2 id="厉害的导师手底下的学生是都去算法了吗"><a class="markdownIt-Anchor" href="#厉害的导师手底下的学生是都去算法了吗"></a> 厉害的导师手底下的学生是都去算法了吗？</h2>
<p><strong>[北京时间2024年3月10日pm19:04:36]</strong> IWhisper#912 发起了讨论：“厉害的导师手底下的学生是都去算法了吗？” 提问未具体详述，只留下了简单的疑问。</p>
<p><strong>[北京时间2024年3月10日pm19:36:27]</strong> IWhisper#544 回复说：“是。” 提供了简洁的答案，没有进一步的解释。</p>
<p><strong>[北京时间2024年3月10日pm19:37:18]</strong> IWhisper#977 提出：“看方向。” 指出学生去向取决于研究方向。</p>
<p><strong>[北京时间2024年3月10日pm21:50:17]</strong> IWhisper#965 同样简短回复：“是的。” 与IWhisper#544相似，没有给出详细说明。</p>
<p><strong>[北京时间2024年3月11日am00:06:51]</strong> IWhisper#643 补充说，如果定义厉害为在顶级会议上发表论文，那么答案是肯定的。</p>
<br>
<h2 id="打听导师"><a class="markdownIt-Anchor" href="#打听导师"></a> 打听导师</h2>
<p><strong>[北京时间2024年3月8日am07:09:12]</strong> IWhisper#876 发布了一个帖子，回忆起自己去年保研时选导师的纠结。他表示，当时应该更加明确自己的需求或者多打听一些信息。虽然他目前还没有进入任何研究组，也认为自己所在的组不算是坑，但对于导师的选择仍有后悔之情。</p>
<p><strong>[北京时间2024年3月8日am07:42:02]</strong> IWhisper#792 回复，正忙于找导师，希望得到一些建议，以弥补IWhisper#876的遗憾。</p>
<p><strong>[北京时间2024年3月8日am08:21:28]</strong> IWhisper#892 建议IWhisper#792多寻找其他人咨询，表示自己也不清楚该怎么办。</p>
<p><strong>[北京时间2024年3月8日am08:31:40]</strong> IWhisper#892 又提出，既然有论坛号，应该能找到人。</p>
<p><strong>[北京时间2024年3月8日am11:12:21]</strong> IWhisper#892 表示自己被舍友认出来了，觉得很好笑。</p>
<p><strong>[北京时间2024年3月8日pm12:07:06]</strong> IWhisper#965 询问一般什么时候找导师合适。</p>
<p><strong>[北京时间2024年3月10日am11:02:06]</strong> IWhisper#718 对IWhisper#965的问题表示同问。</p>
<p><strong>[北京时间2024年3月11日am09:09:08]</strong> IWhisper#918 简单地回复了“bd”。</p>
<br>
<h2 id="校内保研找老师会直接因为rk挂人吗边缘人不太高"><a class="markdownIt-Anchor" href="#校内保研找老师会直接因为rk挂人吗边缘人不太高"></a> 校内保研找老师会直接因为rk挂人吗？边缘人不太高</h2>
<p>IWhisper#722: “校内保研找老师会直接因为rk挂人吗？边缘人不太高。”</p>
<p>IWhisper#936: “会的，不过搏一搏也没损失。”</p>
<p>IWhisper#255: “不会，但是可能会给你一些小任务考核一下。不过早联系名额多也可能不考核。”</p>
<p>IWhisper#368: “真的假的？那像11组这种考核是不是属于比较困难的那种？”</p>
<p>IWhisper#563: “学长，求问这种会因为之后有rk更高的同学来联系导致自己被已经打了一段时间工的老师抛弃吗？”</p>
<p>IWhisper#329: “考核最起码给你发挥的机会。”</p>
<p>IWhisper#255: “emmm只能说一般不会。确实会有一些高排名的同学保外失败回本校找老师，不过大部分老师名额满了就不会再要了。对你最大的影响可能是他们可以优先选择学硕还是专硕之类的。不过说实话你要是很边缘老师也不会叫你打工，会叫你等保研名单确定。还是主动要和老师保持联系咯。”</p>
<p>IWhisper#118: “会有的…因为老师本来就希望要更好的学生来干活。”</p>
<p>IWhisper#153: “只能说有可能会因为rk直接挂人，也有可能会有rk更高的过来竞争然后老师收了更高的。这个也无可厚非，因为每个老师收学生的标准都不一样，不用因为这个对老师有怨气，也不用自己泄气，做好心理准备和其他退路就行。”</p>
<p>IWhisper#561: “名额真的多吗？感觉每个老师就一两个保研名额，名额挺紧张的啊。”</p>
<br>
<h2 id="想知道学术好的年轻老师或者组内研究氛围好真的都能发出论文吗"><a class="markdownIt-Anchor" href="#想知道学术好的年轻老师或者组内研究氛围好真的都能发出论文吗"></a> 想知道学术好的年轻老师或者组内研究氛围好，真的都能发出论文吗？</h2>
<p>IWhisper#446: “想知道学术好的年轻老师或者组内研究氛围好，真的都能发出论文吗？研究生自己研究做一个方向，啥也没搞出来，怀疑是自己的问题还是实验室的问题。有没有高手能在线讲一讲顶会顶刊都是怎么做出来的？”</p>
<p>IWhisper#517: “针对领域内痛点问题有自己的想法，并且能work的，就算好一点。稍微差一点的，在有些影响力的文章基础上做些改进，能work就差不多可以了。如果真想发文章，就多看，看大家都在做什么，然后执行力强一点，有想法就试试，出问题不work就分析为什么，work了好好包装一下就差不多了。”</p>
<br>
<h2 id="同时在几个老师的实验室实习"><a class="markdownIt-Anchor" href="#同时在几个老师的实验室实习"></a> 同时在几个老师的实验室实习</h2>
<p>2024-03-11pm16:25 Whisper#256: 大家好，我现在只有一个导师名额，但我想找其他的导师。请问你们最多同时在几个老师的实验室实习呢？</p>
<p>2024-03-11pm16:26 IWhisper#195回复：其实没必要同时在多个实验室实习，参加一个实验室的两次组会就足以了解那里是否适合自己。</p>
<p>2024-03-11pm16:26 IWhisper#69回复：我同时在10个实验室实习。</p>
<p>2024-03-11pm16:32 Whisper#256再次发言：如果我想联系第二个导师，是不是应该在决定是否加入他们的实验室前就先联系呢？之前有人说，没必要同时实习，在一个实验室开两次组会就能知道是否合适。</p>
<br>
<h2 id="保研联系导师给分配了师兄"><a class="markdownIt-Anchor" href="#保研联系导师给分配了师兄"></a> 保研联系导师给分配了师兄</h2>
<p><strong>[2024-03-11pm4:16] Whisper#256:</strong><br />
标题: 保研联系导师给分配了师兄<br />
发信站: 北邮人论坛 (Mon Mar 11 16:16:01 2024), 站内</p>
<p>内容: 需要多和师兄闲聊吗，如果和师兄不熟的话师兄会不会不给我美言?</p>
<p><strong>[2024-03-11pm4:20] IWhisper#356:</strong><br />
标题: Re: 保研联系导师给分配了师兄<br />
发信站: 北邮人论坛 (Mon Mar 11 16:20:28 2024), 站内</p>
<p>内容: bd</p>
<p><strong>[2024-03-11pm4:20] IWhisper#882:</strong><br />
标题: Re: 保研联系导师给分配了师兄<br />
发信站: 北邮人论坛 (Mon Mar 11 16:20:47 2024), 站内</p>
<p>内容: 我也是被分配给了师兄，现在连导师微信都没加上</p>
<p><strong>[2024-03-11pm4:23] Whisper#256:</strong><br />
标题: Re: 保研联系导师给分配了师兄<br />
发信站: 北邮人论坛 (Mon Mar 11 16:23:04 2024), 站内</p>
<p>内容: 唉，就担心导师根本不知道我干的怎么样，感觉全凭师兄怎么说</p>
<br>
<h2 id="联系导师没声音"><a class="markdownIt-Anchor" href="#联系导师没声音"></a> 联系导师没声音</h2>
<p><strong>IWhisper#254:</strong><br />
发信人: IWhisper#254 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午4:39<br />
我排名也不算边缘，给6个导师发过邮件了，除了11组让等面试，其他一点声音都没有。<br />
※ 来源: 北邮人论坛手机客户端</p>
<hr />
<p><strong>IWhisper#185:</strong><br />
发信人: IWhisper#185 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午4:47<br />
可能你联系的都是热门老师？都满了？<br />
※ 来源: 北邮人论坛手机客户端</p>
<hr />
<p><strong>IWhisper#811:</strong><br />
发信人: IWhisper#811 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午4:49<br />
我也是。<br />
※ 来源: 北邮人论坛手机客户端</p>
<hr />
<p><strong>IWhisper#254:</strong><br />
发信人: IWhisper#254 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午4:53<br />
基本上论坛里见过的老师我都联系了，没见过的我也不知道老师怎么样呢。<br />
※ 来源: 北邮人论坛手机客户端</p>
<hr />
<p><strong>IWhisper#523:</strong><br />
发信人: IWhisper#523 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午4:57<br />
别慌，有的老师是记录下来等复试后联系的，我联系了十几个了。<br />
※ 来源: 北邮人论坛手机客户端</p>
<p><strong>IWhisper#523:</strong><br />
<strong>时间:</strong> 2024年3月11日下午4:58<br />
大部分都没回。<br />
※ 来源: 北邮人论坛手机客户端</p>
<hr />
<p><strong>IWhisper#921:</strong><br />
发信人: IWhisper#921 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午5:19<br />
没事的，我去年从这个时候开始发，发了快四十个。<br />
※ 来源: 北邮人论坛手机客户端</p>
<hr />
<p><strong>IWhisper#617:</strong><br />
发信人: IWhisper#617 (我爱北邮人!), 信区: IWhisper<br />
<strong>标题:</strong> Re: 联系导师没声音<br />
<strong>时间:</strong> 2024年3月11日下午5:38<br />
是保研还是考研？<br />
※ 来源: 北邮人论坛手机客户端</p>
<br>
<h2 id="之前一个因为临时鸽老师被骂上论坛热搜的人"><a class="markdownIt-Anchor" href="#之前一个因为临时鸽老师被骂上论坛热搜的人"></a> 之前一个因为临时鸽老师被骂上论坛热搜的人</h2>
<p><strong>IWhisper#465</strong>: 好像是通过学长的介绍找的老师，然后填系统当天鸽老师，学长和老师还是通过她朋友圈才知道的，最后去了浙软，删了所有的北邮人。刚发现这姐现在加了好多北邮人的实习群。</p>
<p><strong>IWhisper#696</strong>: srds，每年鸽学生的老师也不少吧。</p>
<p><strong>IWhisper#753</strong>: 填系统当天有点过分。</p>
<p><strong>IWhisper#345</strong>: 填系统当天才鸽，而且都不通知人家，朋友圈通知就不合适了吧。</p>
<p><strong>IWhisper#615</strong>: 精致的利己主义者捏。</p>
<p><strong>IWhisper#480</strong>: t了。</p>
<p><strong>IWhisper#527</strong>: 是LYH吗？</p>
<p><strong>comeon6752</strong>: 邮奸。</p>
<p><strong>IWhisper#204</strong>: 我想起来了，这姐和我一届的，好像先是问同专业保研的学长他们实验室咋样，然后学长肯定夸自己实验室啊（因为确实很好），之后这人就拿着和学长的聊天截图，和导师说是学长推荐她来的blabla，导师就同意要她了。她还蹭了组里聚会的海鲜大餐，发了朋友圈说仙女就是吃吃喝喝。结果最后一天去了浙大把导师鸽了。那个学长发了好几条朋友圈骂她但是也没办法了，导师好像浪费一个名额然后之后也不太想招这个学院得学生了。</p>
<p><strong>IWhisper#942</strong>: 浙软算什么厉害啊…浙软是华五所有院系最垃圾的一个了，这女的也真是作，必须永久拉黑。</p>
<p><strong>IWhisper#527</strong>: 这个人为什么现在还在实习群里 浙软两年制她今年应该快毕业了吧。</p>
<p><strong>IWhisper#465</strong>: 北邮人实习群哪里有啊？</p>
<p><strong>IWhisper#527</strong>: 同问。</p>
<p><strong>IWhisper#462</strong>: 知道这人 但是我还是有她的pyq的。</p>
<p><strong>IWhisper#593</strong>: 那她估计能看到这个帖子？</p>
<p><strong>IWhisper#995</strong>: 哦对了她还蹭了实验室的聚财，最后还发了个很作的pyq。</p>
<p><strong>IWhisper#753</strong>: 倒反天罡。</p>
<p><strong>IWhisper#527</strong>: 请ta吃的第六季。</p>
<p><strong>IWhisper#523</strong>: 我擦 第六季老贵了 这老师真好 哪个组。</p>
<p><strong>IWhisper#792</strong>: 为啥要请她吃饭。</p>
<p><strong>IWhisper#257</strong>: 太精致利己了吧。</p>
<p><strong>IWhisper#185</strong>: 妈呀 老师还请吃饭 哪个神仙老师 她不要我要！！！</p>
<p><strong>IWhisper#429</strong>: 我记得这个人！22届是不？</p>
<p><strong>IWhisper#792</strong>: 两种都该骂。</p>
<p><strong>IWhisper#792</strong>: 有人挖坟吗，想看看之前的帖子。</p>
<p><strong>IWhisper#64</strong>: 当年xsh公关部消失的事也有她。</p>
<p><strong>IWhisper#465</strong>: 什么瓜？</p>
<p><strong>IWhisper#527</strong>: 这几个瓜都是</p>
<p>一个套一个的 再深挖下去怕不是要把当事人本科四年的老底都扒出来了。</p>
<p><strong>IWhisper#741</strong>: 洗耳恭听。</p>
<p><strong>IWhisper#811</strong>: 天哪!!!。</p>
<p><strong>IWhisper#38</strong>: 这种出生真的纯纯缺德。</p>
<p><strong>IWhisper#410</strong>: 北邮名人堂加一邮奸姐。</p>
<p><strong>IWhisper#93</strong>: 再怎么说总得道个歉吧，拍拍屁股就走了属实把社交玩明白了。</p>
<p><strong>IWhisper#233</strong>: 22届，网管12组，后面补招了。贼恶心。</p>
<p><strong>IWhisper#391</strong>: 哪个院的学生。</p>
<p><strong>IWhisper#233</strong>: “谁说美女只会吃喝玩乐”。</p>
<p><strong>IWhisper#687</strong>: 哪个院的。</p>
<p><strong>IWhisper#930</strong>: 什么瓜？</p>
<br>
<h2 id="专硕和学硕"><a class="markdownIt-Anchor" href="#专硕和学硕"></a> 专硕和学硕</h2>
<p>IWhisper#882 发起了一个讨论，提出了关于专硕和学硕之间的区别。他提到，尽管论坛上说两者差别不大，但似乎大家更倾向于选择学硕，尽管专硕似乎更容易毕业。</p>
<p>紧接着，IWhisper#626 回应说，如果有计划去上海发展，可以选择学硕；否则，选择专硕更为合适。</p>
<p>IWhisper#745 补充说，专硕和学硕的学科代码不同，在某些情况下，比如落户时，专硕可能不被认可。</p>
<p>IWhisper#471 引用了IWhisper#626的回复，没有添加新的观点。</p>
<p>IWhisper#456 认为，即使是在上海，专硕也不难落户，只需缴纳一年两倍的社保基数即可。</p>
<p>IWhisper#510 指出，学硕主要的优势在于考公时更有优势，除此之外，专硕在其他方面似乎更胜一筹。</p>
<p>IWhisper#140 认为，选择学硕的人大多是在报考时不了解学硕和专硕的区别，很多人最终都会后悔。</p>
<p>IWhisper#691 表示，如果有能力选择学硕，就选择学硕；如果没有，选择专硕也是好的，多条路总是好的。他也提到了专硕学科代码和学硕不同，落户时可能不被认可。</p>
<p>最后，IWhisper#188 说，今年在报考选调公务员时，学硕和专硕之间的区别变得明显，专硕的专业代码在某些情况下不被认可。</p>
<br>
<h2 id="保研找了一个校内老师后跟随了一个月还收到了薪水"><a class="markdownIt-Anchor" href="#保研找了一个校内老师后跟随了一个月还收到了薪水"></a> 保研找了一个校内老师后，跟随了一个月还收到了薪水</h2>
<p>IWhisper#942 分享了自己保研找了一个校内老师后，跟随了一个月还收到了薪水的经历，并表达了对老师好感。</p>
<p>IWhisper#413 第一个回复，表示发钱只能说明老师是正常人，并不能直接说明老师人好。</p>
<p>IWhisper#869 询问了导师的名字，但未得到直接回应。</p>
<p>IWhisper#942 在第三楼回复了IWhisper#413，表示他觉得实习期间发钱并不是很常见。</p>
<p>IWhisper#354 认为这取决于做了多少工作，似乎觉得收到的钱并不多。</p>
<p>IWhisper#185 强调了实习发薪水和老师人好之间没有必然联系。</p>
<p>IWhisper#791 和 IWhisper#391 都对发了多少钱感到好奇，但没有更多信息透露。</p>
<br>
<h2 id="保研找导师"><a class="markdownIt-Anchor" href="#保研找导师"></a> 保研找导师</h2>
<p><strong>IWhisper#471</strong>: (我爱北邮人!) 在 IWhisper 信区发表了一篇帖子。标题为【问题】保研找导师，发表于北邮人论坛 (2024年3月11日 21:31:04)。内容如下：<br />
“求问北邮信通院许晓东导师，老师人好么，会猛PUSH吗，会不会放实习？以及有无其他信通院牛导可以推荐一下嘛emc32。来自北邮人论坛 <a href="http://bbs.byr.cn">http://bbs.byr.cn</a> [FROM: 匿名天使的家]。楼主好评 (+5) 楼主差评 (+0)。”</p>
<p><strong>IWhisper#877</strong>: (我爱北邮人!) 回复称：“不push，巨好”。这条回复发表于北邮人论坛手机客户端 (2024年3月11日 23:51:55)。</p>
<p><strong>IWhisper#195</strong>: (我爱北邮人!) 也回复了该帖子：“这老师一般抢不到，热门导师”。回复时间为2024年3月12日 00:22:19。</p>
<br>
<h2 id="大三保研人求问"><a class="markdownIt-Anchor" href="#大三保研人求问"></a> 大三保研人求问</h2>
<p>IWhisper#727: 大三保研人求问。无科研无实习，还没联系导师，这种情况还会有书读嘛?</p>
<p>IWhisper#873: 急啥呢……我们导人很好最后也被捡漏了。</p>
<p>IWhisper#727: 捡漏大概是什么时候呀?</p>
<p>IWhisper#193: 都会有的。</p>
<p>IWhisper#937: 预推免 九推。</p>
<p>IWhisper#649: 现在才三月啊 还早的很呢。</p>
<br>
<h2 id="保研求问"><a class="markdownIt-Anchor" href="#保研求问"></a> 保研求问</h2>
<p><strong>IWhisper#220:</strong><br />
发信人: IWhisper#220 (我爱北邮人!), 信区: IWhisper<br />
标题: 保研求问<br />
发信站: 北邮人论坛 (Tue Mar 12 12:07:52 2024), 站内</p>
<p>鼠鼠现在计院约15％，一段数模一段大英，没科研没实习，还没联系导师，还能有书读吗。<br />
好哥哥好姐姐能不能救一下，这两天狂暴焦虑，脑子里好像有蔡徐坤在爬</p>
<p><strong>IWhisper#220:</strong><br />
[沙发] 回复 IWhisper#220<br />
救救救救救救你们都是我爹</p>
<p><strong>IWhisper#888:</strong><br />
[板凳] 回复 IWhisper#220<br />
bdbd</p>
<p><strong>IWhisper#743:</strong><br />
[第3楼] 回复 IWhisper#220<br />
不像计科人问出来的话</p>
<p><strong>IWhisper#718:</strong><br />
[第4楼] 回复 IWhisper#743<br />
为啥<br />
【 在 IWhisper#743 的大作中提到: 】<br />
: 不像计科人问出来的话</p>
<br>
<h2 id="单纯为了985保研华五有必要吗"><a class="markdownIt-Anchor" href="#单纯为了985保研华五有必要吗"></a> 单纯为了985保研华五有必要吗</h2>
<p><strong>IWhisper#478:</strong><br />
发信人: IWhisper#478 (我爱北邮人!), 信区: IWhisper<br />
标题: 单纯为了985保研华五有必要吗<br />
发信站: 北邮人论坛 (Tue Mar 12 09:57:29 2024), 站内</p>
<p>？</p>
<p><strong>IWhisper#783:</strong><br />
[沙发] 回复 IWhisper#478<br />
看你追求是什么，一线还是二线，考公还是互联网，科研还是赚钱</p>
<p><strong>IWhisper#870:</strong><br />
[板凳] 回复 IWhisper#478<br />
科软/浙软吗<br />
这俩考研比保研容易去</p>
<p><strong>IWhisper#809:</strong><br />
[第3楼] 回复 IWhisper#870<br />
还搁着壳软呢，马上出复试线你看看吧</p>
<p><strong>IWhisper#559:</strong><br />
[第4楼] 回复 IWhisper#478<br />
单纯为了985，那你保研应该保北理。你目标是华五说明你已经有更高的追求了。</p>
<p><strong>IWhisper#679:</strong><br />
[第5楼] 回复 IWhisper#870<br />
浙软怎么和科软比啊，完全不是一个量级的</p>
<p><strong>IWhisper#113:</strong><br />
[第6楼] 回复 IWhisper#809<br />
人家是保研，还复试线 笑死</p>
<p><strong>IWhisper#186:</strong><br />
[第7楼] 回复 IWhisper#809<br />
22408考个390很难吗？70+80+125+115就390了</p>
<p><strong>IWhisper#809:</strong><br />
[第8楼] 回复 IWhisper#113<br />
笑你个头，刚才那哥们不是说考研壳软比保研简单</p>
<p><strong>IWhisper#809:</strong><br />
[第9楼] 回复 IWhisper#186<br />
都觉得390简单啊？每年有三分之二人连本校都考不上勒</p>
<p><strong>IWhisper#185:</strong><br />
[第10楼] 回复 IWhisper#186<br />
真不是那么回事哥们，别口嗨，自己亲自考一次研就知道这个分数可以吊打80％的人了</p>
<br>
<h2 id="请问保研计院郭迎老师能报吗"><a class="markdownIt-Anchor" href="#请问保研计院郭迎老师能报吗"></a> 请问保研计院郭迎老师能报吗</h2>
<p><strong>IWhisper#311:</strong><br />
发信人: IWhisper#311 (我爱北邮人!), 信区: IWhisper<br />
标题: 请问保研计院郭迎老师能报吗<br />
发信站: 北邮人论坛 (Tue Mar 12 02:51:06 2024), 站内</p>
<p>rt</p>
<p><strong>IWhisper#119:</strong><br />
[沙发] 回复 IWhisper#311<br />
bd</p>
<p><strong>IWhisper#23:</strong><br />
[板凳] 回复 IWhisper#311<br />
bd</p>
<p><strong>IWhisper#866:</strong><br />
[第3楼] 回复 IWhisper#311<br />
中南的主任。我的研究生都不打游戏，在我的帮助下戒掉了游戏，他们想出去玩我都给报销。以上为他的自述。</p>
<p><strong>IWhisper#605:</strong><br />
[第4楼] 回复 IWhisper#311<br />
本科给我们上数据库，要求手写笔记，第一节课还说上课不允许带电子设备（虽然后来没再说），你可以掂量掂量</p>
<p><strong>IWhisper#585:</strong><br />
[第5楼] 回复 IWhisper#311<br />
老头犟的要死，学术不评价，他要是不想让你干某件事你就别想说服他</p>
<br>
<h2 id="提问实验室如果要求打卡但是不打有什么惩罚"><a class="markdownIt-Anchor" href="#提问实验室如果要求打卡但是不打有什么惩罚"></a> 提问，实验室如果要求打卡，但是不打有什么惩罚</h2>
<p><strong>IWhisper#576:</strong><br />
<strong>发帖人:</strong> IWhisper#576 (我爱北邮人!), <strong>区域:</strong> IWhisper<br />
<strong>标题:</strong> 提问，实验室如果要求打卡，但是不打有什么惩罚<br />
<strong>时间:</strong> 2024年3月12日 16:17<br />
<strong>内容:</strong><br />
我先来，一个月超过三天不打卡，当月没工资了…<br />
※ 来源: 北邮人论坛手机客户端 [FROM: 匿名天使的家]</p>
<p><strong>IWhisper#783:</strong><br />
<strong>回复 IWhisper#576</strong><br />
<strong>发帖人:</strong> IWhisper#783 (我爱北邮人!), <strong>区域:</strong> IWhisper<br />
<strong>标题:</strong> Re: 提问，实验室如果要求打卡，但是不打有什么惩罚<br />
<strong>时间:</strong> 2024年3月12日 16:21<br />
<strong>内容:</strong><br />
我愿意倒给老师一个月实验室工资，放我去实习吧<br />
※ 来源: 北邮人论坛手机客户端 [FROM: 匿名天使的家]</p>
<p><strong>IWhisper#355:</strong><br />
<strong>回复 IWhisper#783</strong><br />
<strong>发帖人:</strong> IWhisper#355 (我爱北邮人!), <strong>区域:</strong> IWhisper<br />
<strong>标题:</strong> Re: 提问，实验室如果要求打卡，但是不打有什么惩罚<br />
<strong>时间:</strong> 2024年3月12日 16:22<br />
<strong>内容:</strong><br />
+1<br />
【在 IWhisper#783 的帖子中提到:】 我愿意倒给老师一个月实验室工资，放我去实习吧<br />
※ 来源: 北邮人论坛 [FROM: 匿名天使的家]</p>
<p><strong>IWhisper#100:</strong><br />
<strong>回复 IWhisper#576</strong><br />
<strong>发帖人:</strong> IWhisper#100 (我爱北邮人!), <strong>区域:</strong> IWhisper<br />
<strong>标题:</strong> Re: 提问，实验室如果要求打卡，但是不打有什么惩罚<br />
<strong>时间:</strong> 2024年3月12日 16:24<br />
<strong>内容:</strong><br />
那点工资说实话。谁爱要谁要<br />
※ 来源: 北邮人论坛手机客户端 [FROM: 匿名天使的家]</p>
<p><strong>IWhisper#576:</strong><br />
<strong>回复 IWhisper#100</strong><br />
<strong>发帖人:</strong> IWhisper#576 (我爱北邮人!), <strong>区域:</strong> IWhisper<br />
<strong>标题:</strong> Re: 提问，实验室如果要求打卡，但是不打有什么惩罚<br />
<strong>时间:</strong> 2024年3月12日 16:28<br />
<strong>内容:</strong><br />
表面是扣工资，但是我不知道真不打卡，就算我不要求，也不知道他会不会搞我<br />
【在 IWhisper#100 的帖子中提到:】 那点工资说实话。谁爱要谁要<br />
※ 来源: 北邮人论坛手机客户端 [FROM: 匿名天使的家]</p>
<br>
<h2 id="这样的导师算什么样子的"><a class="markdownIt-Anchor" href="#这样的导师算什么样子的"></a> 这样的导师算什么样子的</h2>
<p>IWhisper#680: 发信人: IWhisper#680 (我爱北邮人!), 信区: IWhisper 标题: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 12:58:23 2024), 站内</p>
<p>我在外校读研，导师非北邮，给我一个没人想做的方向。可以用深度学习水文章，但难上顶会，无人指导。不打卡，两周一组会，除此无交流，要求一篇期刊如IOTJ才能毕业。导师年轻但不详细，喜欢变卦，有点爱操纵。</p>
<p>IWhisper#806: 发信人: IWhisper#806 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 12:59:11 2024), 站内</p>
<p>我感觉挺好的？</p>
<p>IWhisper#895: 发信人: IWhisper#895 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:00:36 2024), 站内</p>
<p>挺好的啊，平时直接实习，毕业的事和导师商量能换方向。</p>
<p>IWhisper#842: 发信人: IWhisper#842 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:03:51 2024), 站内</p>
<p>不放实习≠不能实习。</p>
<p>IWhisper#352: 发信人: IWhisper#352 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:06:11 2024), 站内</p>
<p>比我导师好多了。</p>
<p>IWhisper#895: 发信人: IWhisper#895 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:06:39 2024), 站内</p>
<p>你是呆逼吗? 这还不叫放实习啊。</p>
<p>IWhisper#371: 发信人: IWhisper#371 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:06:46 2024), 站内</p>
<p>差强人意吧。</p>
<p>IWhisper#64: 发信人: IWhisper#64 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:07:58 2024), 站内</p>
<p>能水文章，说明好毕业。不打卡，不咋管，说明能实习。</p>
<p>IWhisper#860: 发信人: IWhisper#860 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:51:07 2024), 站内</p>
<p>如果不读博，这就是没有缺点的导师。</p>
<p>IWhisper#974: 发信人: IWhisper#974 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:54:43 2024), 站内</p>
<p>通信的吗？iotj还是要点工作量的，没那么好水。</p>
<p>IWhisper#977: 发信人: IWhisper#977 (我爱北邮人!), 信区: IWhisper 标题: Re: 这样的导师算什么样子的 发信站: 北邮人论坛 (Thu Mar 14 13:56:23 2024), 站内</p>
<p>梦中情导，等读研了就知道这个老师的好处了。</p>
<h2 id="求ai院导师的推荐"><a class="markdownIt-Anchor" href="#求ai院导师的推荐"></a> 求AI院导师的推荐</h2>
<p>在北邮人论坛的IWhisper信区，IWhisper#826发起了一个讨论，寻求AI院导师的推荐。</p>
<p><strong>IWhisper#826：</strong></p>
<ul>
<li><strong>主题：</strong> ai院求推荐导师</li>
<li><strong>内容：</strong> 想问下有没有能给科研指导的老师，push一点也没关系ema23</li>
<li><strong>时间：</strong> 2024年3月22日 10:42:33</li>
</ul>
<p>接着，几位论坛成员回复了此贴，分享了他们的推荐。</p>
<p><strong>IWhisper#219回复：</strong></p>
<ul>
<li><strong>回复内容：</strong> xy</li>
<li><strong>时间：</strong> 2024年3月22日 10:49:48</li>
</ul>
<p><strong>IWhisper#329回复：</strong></p>
<ul>
<li><strong>回复内容：</strong> 推荐牛凯老师，科研能力很强，也会给学生指导。</li>
<li><strong>时间：</strong> 2024年3月22日 12:15:57</li>
</ul>
<p><strong>IWhisper#893回复：</strong></p>
<ul>
<li><strong>回复内容：</strong> gj组老师不错。</li>
<li><strong>时间：</strong> 2024年3月22日 12:32:09</li>
</ul>
<p><strong>IWhisper#650回复：</strong></p>
<ul>
<li><strong>回复内容：</strong> 那必须是北邮最强组郭军组了。</li>
<li><strong>时间：</strong> 2024年3月22日 13:17:50</li>
</ul>
<p><strong>IWhisper#608回复：</strong></p>
<ul>
<li><strong>回复内容：</strong> 借楼问问有没有适合10%左右学生投的老师ema1</li>
<li><strong>时间：</strong> 2024年3月22日 13:19:48</li>
<li><strong>备注：</strong> 这是对IWhisper#329的回复。</li>
</ul>
<p><strong>IWhisper#791回复：</strong></p>
<ul>
<li><strong>回复内容：</strong> gbx</li>
<li><strong>时间：</strong> 2024年3月22日 14:55:16</li>
</ul>
<p>共有七条回复，涵盖了不同的导师推荐和查询，构成了一个富有信息的讨论串。</p>
<br>
<h2 id="寻求有关考研导师项刘宇老师的信息"><a class="markdownIt-Anchor" href="#寻求有关考研导师项刘宇老师的信息"></a> 寻求有关考研导师项刘宇老师的信息</h2>
<p>在北邮人论坛的IWhisper信区，IWhisper#920启动了一个讨论，寻求有关考研导师项刘宇老师的信息。</p>
<p><strong>IWhisper#920：</strong></p>
<ul>
<li><strong>主题：</strong> 考研导师求助 ai院项刘宇老师</li>
<li><strong>内容：</strong> 学弟外校考研，求助万能的大家，项刘宇老师怎么样，以及还有没有名额呀，感谢感谢</li>
<li><strong>时间：</strong> 2024年3月22日 10:17:26</li>
</ul>
<p>紧接着，IWhisper#920自己顶了一下帖子。</p>
<p><strong>IWhisper#920回复：</strong></p>
<ul>
<li><strong>内容：</strong> 顶顶</li>
<li><strong>时间：</strong> 2024年3月22日 10:40:59</li>
</ul>
<p>其他论坛成员也加入了讨论。</p>
<p><strong>IWhisper#365回复：</strong></p>
<ul>
<li><strong>内容：</strong> bd</li>
<li><strong>时间：</strong> 2024年3月22日 13:30:55</li>
</ul>
<p><strong>IWhisper#201回复：</strong></p>
<ul>
<li><strong>内容：</strong> 挺好的</li>
<li><strong>时间：</strong> 2024年3月22日 13:33:05</li>
</ul>
<p>IWhisper#920对IWhisper#201的回复表示感谢。</p>
<p><strong>IWhisper#920回复：</strong></p>
<ul>
<li><strong>内容：</strong> 感谢感谢</li>
<li><strong>时间：</strong> 2024年3月22日 14:22:55</li>
</ul>
<p><strong>IWhisper#145回复：</strong></p>
<ul>
<li><strong>内容：</strong> 超级超级好的老师</li>
<li><strong>时间：</strong> 2024年3月22日 14:50:23</li>
</ul>
<p>这个讨论共有六条回复，提供了关于项刘宇老师的正面评价和社区支持。</p>
<br>
<h2 id="考研联系导师已读不回"><a class="markdownIt-Anchor" href="#考研联系导师已读不回"></a> 考研联系导师已读不回</h2>
<p>在北邮人论坛的IWhisper信区，发生了一场关于考研联系导师已读不回的讨论。</p>
<p><strong>IWhisper#815</strong> 发起讨论，表达了对考研联系导师已读不回的失落：“考研联系导师已读不回，我碎了。ema1ema1ema1ema1ema1”</p>
<p><strong>IWhisper#302</strong> 建议：“那等复试结束再联系吧。”</p>
<p><strong>IWhisper#897</strong> 简短回复：“emc4。”</p>
<p><strong>IWhisper#785</strong> 提出疑问：“怎么知道已读的，你不会用已读回执了吧。”</p>
<p>对此，<strong>IWhisper#815</strong> 解释：“用的是网易163的邮件追踪ema1那边应该不知道吧。”</p>
<p><strong>IWhisper#216</strong> 补充说：“一般会提示有链接然后自动屏蔽em12。”</p>
<p><strong>IWhisper#225</strong> 忧心忡忡地回复：“啊！啥意思啊 所以对面知道开了邮件追踪吗！我也碎了。”</p>
<p><strong>IWhisper#902</strong> 同感：“我也是，咋办呀ema1。”</p>
<p><strong>IWhisper#815</strong> 尝试自我安慰：“omg 不过应该不会是这种小细节而不回我 应该只是单纯看不上我吧ema1 还是先好好准备复试吧。”</p>
<p><strong>IWhisper#785</strong> 给出了一些建议：“应该能看到，千万别再开这种东西了，你是去求人的不是去命令人的，谁让你用这个你打他一顿。”</p>
<p><strong>IWhisper#393</strong> 对<strong>IWhisper#225</strong> 的情绪表示共鸣：“细说。”</p>
<p><strong>IWhisper#225</strong> 解释自己的感受：“呜呜呜不是命令人，主要是我太内耗了，联系老师如果不回复的话会一直紧张。相比之下知道老师已读不回可能对我来说还是一种仁慈ema1之前看好多人都说网易的邮件追踪看不到。”</p>
<p><strong>IWhisper#608</strong> 和<strong>IWhisper#747</strong> 也加入了讨论，提出了自己的疑问和看法。</p>
<p>最后，<strong>IWhisper#393</strong> 尝试实验：“不知道呀 我也想知道 刚刚用163尝试给自己的北邮邮箱发了一封带邮件追踪的，从北邮邮箱网站进去没看出来什么异常。”</p>
<p><strong>IWhisper#702</strong> 指出了一个可能的误解：“邮件追踪不是回执吧。”</p>
<p>这场讨论集中在考研过程中的导师沟通问题上，尤其是关于邮件已读不回的焦虑和对邮件追踪功能的担忧。</p>
<h2 id="论坛讨论摘要关于职业选择的咨询"><a class="markdownIt-Anchor" href="#论坛讨论摘要关于职业选择的咨询"></a> 论坛讨论摘要：关于职业选择的咨询</h2>
<p><strong>IWhisper#967:</strong> 大家好，我在中国科学院的某研究所实习已经有一段时间了。导师人很好，现在有机会留下来工作，薪资大约是20k左右。但是这里的项目规模很小，几乎没有团队，而且我们目前做的东西似乎不太可能实现。这里也没有人指导我们，大部分都是自己学习，感觉和读研究生差不多。在这种情况下，我还应该考虑留在这里吗？我还收到了一家国企的offer，提供户口，薪资和科学院差不多。你们认为我应该争取在科学院的机会吗？</p>
<p>**个人情况：**我来自农村家庭，买不起房子，对于户口也没有特别的执着，也不确定户口到底有多重要。希望大家能给我一些建议，谢谢！</p>
<p><strong>IWhisper#724:</strong> 我也倾向于选择中国科学院。你在哪个研究所？</p>
<p><strong>IWhisper#967:</strong> 自动化所。你怎么看？</p>
<p><strong>IWhisper#136:</strong> 你是考虑在硕士实习结束后转正吗？</p>
<p><strong>IWhisper#967:</strong> 差不多，有机会争取一下。</p>
<p><strong>IWhisper#292:</strong> 我打算再坚持一段时间，可能还会读个在职博士。</p>
<br>
<h2 id="论坛讨论保研还是出国何去何从"><a class="markdownIt-Anchor" href="#论坛讨论保研还是出国何去何从"></a> 论坛讨论：保研还是出国，何去何从？</h2>
<p><strong>IWhisper#828:</strong> 大家好，想请教一下保研（本校）和出国各有什么优缺点？我的未来目标是在国内找一份国企的工作，希望过一个细水长流的生活。</p>
<p><strong>IWhisper#828:</strong> 对学术没兴趣。</p>
<p><strong>IWhisper#384:</strong> 保研。</p>
<p><strong>IWhisper#417:</strong> 出国通常一年或两年，可以早点开始工作。</p>
<p><strong>IWhisper#926:</strong> 有条件的话就出国吧。</p>
<p><strong>IWhisper#555:</strong> 如果是国企的话，建议保研。</p>
<p><strong>IWhisper#949:</strong> 如果可以的话，还是选择出国吧，体验和本校无法比较，如果遇到不好的导师，可能还要痛苦三年。</p>
<p><strong>IWhisper#828:</strong> 为什么？（回复IWhisper#555）</p>
<p><strong>IWhisper#434:</strong> 其实应该反过来，国企才应该出国，体制内更看重这些。</p>
<p><strong>IWhisper#828:</strong> 听谁的呀？</p>
<p><strong>IWhisper#454:</strong> 他们看的不是排名，而是你背后的能力。能区分出谁真正有能力，谁只是混日子的。</p>
<p><strong>IWhisper#590:</strong> 如果对学术没兴趣，那就为了拿个学位找工作，那还是出国吧，拿到学位可以提前工作。</p>
<p><strong>IWhisper#83:</strong> 真不懂，早工作两年有什么意义。</p>
<p><strong>IWhisper#271:</strong> 并不是所有人都像你一样，不用担心生计的。</p>
<p><strong>IWhisper#910:</strong> 如果是以工作为导向，肯定是选择出国。</p>
<p><strong>IWhisper#163:</strong> 如果担心这两年的生计，想要出国也很困难。</p>
<p><strong>IWhisper#518:</strong> 一年出去花的确实多，两年也很难攒回来。</p>
<p><strong>IWhisper#585:</strong> 如果家里有经济能力，出国完全不是问题。如果你的目标是北京的互联网公司，本校还是有优势的。但如果目标是国企，那还是尽快出国吧。</p>
<p><strong>IWhisper#859:</strong> 国外的硕士没什么含金量，你觉得你能学到什么？</p>
<p><strong>IWhisper#859:</strong> 建议大家多做研究，不要因为自己没出去就劝别人出去。你没有去国外读一年的硕士，是出于什么原因？你都没去，为什么劝别人去？</p>
<p><strong>IWhisper#196:</strong> 穷啊，你给我钱我就去。</p>
<p><strong>IWhisper#859:</strong> 私信我。</p>
<p><strong>IWhisper#585:</strong> 穷啊，给我钱我立马就去了。</p>
<p><strong>IWhisper#722:</strong> 如果有条件，就去体验一下吧。我认为值得。</p>
<Br>
<h2 id="北邮人论坛讨论摘要计院12组导师推荐"><a class="markdownIt-Anchor" href="#北邮人论坛讨论摘要计院12组导师推荐"></a> 北邮人论坛讨论摘要：计院12组导师推荐</h2>
<p><strong>IWhisper#313:</strong> 发起讨论，询问计院12组的导师推荐。</p>
<p><strong>IWhisper#864:</strong> 推荐女神xsy，但遭到了多数踩（赞4踩9）。</p>
<p><strong>IWhisper#472:</strong> 推荐xa老师，表示人很好（赞6踩0）。</p>
<p><strong>IWhisper#633:</strong> 对IWhisper#864推荐xsy的踩票表示疑惑。</p>
<p><strong>IWhisper#456:</strong> 询问为什么xsy踩这么多（赞3踩0）。</p>
<p><strong>IWhisper#441:</strong> 提到yp老师，但具体评价未明（赞3踩2）。</p>
<p><strong>IWhisper#435:</strong> 分析xsy踩票多可能是因为大家都想去，但不想别人去（赞0踩2）。</p>
<p><strong>IWhisper#946:</strong> 指出虽然大家都想去xsy导师那里，但其实名额已经招满了（赞0踩2）。</p>
<br>
<h2 id="北邮硕士与新加坡一年硕士讨论摘要"><a class="markdownIt-Anchor" href="#北邮硕士与新加坡一年硕士讨论摘要"></a> 北邮硕士与新加坡一年硕士讨论摘要</h2>
<p><strong>IWhisper#176:</strong> 发起讨论，询问选择北邮硕士还是新加坡一年硕士的意见。表示自己未来打算在杭州江苏一带工作，不太想去大厂卷破头。</p>
<p><strong>IWhisper#841:</strong> 如果有考公务员的想法，建议选择双一流学硕，或选择QS排名高的学校。</p>
<p><strong>IWhisper#435:</strong> 对于国企工作而言，新加坡的学历也是不错的选择。</p>
<p><strong>IWhisper#369:</strong> 提到如果是北邮本科生，选择硕士新二的认可度较高。</p>
<p><strong>IWhisper#160:</strong> 补充说双一流学硕的认定不是学校说了算，而是要按照报考单位来。建议选择信通和计算机学院的不带字母的学硕。</p>
<p><strong>IWhisper#196:</strong> 简短地提出了“能润就润”的观点。</p>
<p><strong>IWhisper#841:</strong> 回应IWhisper#160的话题，强调了纯正的计算机科学与技术专业的选择。</p>
<p><strong>IWhisper#609:</strong> 询问关于考公务员时，特定专业代码（085400、085404、083500）是否会受限，以及是否必须是081200代码。</p>
<p><strong>IWhisper#569:</strong> 询问楼主准备的预算是多少。</p>
<p><strong>IWhisper#961:</strong> 回应IWhisper#609的提问，提到085404相比085400有更多岗位机会，而0835软件工程岗位也相对较多。</p>
<h2 id="保研流程"><a class="markdownIt-Anchor" href="#保研流程"></a> 保研流程</h2>
<p>好的，这是一段用户们在论坛上关于保研流程询问和回复的对话整理：</p>
<p>IWhisper#145：【求助】本校保研流程是什么？</p>
<p>IWhisper#307：在地上画个魔法阵，的灵气最多谁保研。</p>
<p>IWhisper#349：夏令营。</p>
<p>IWhisper#126：自己联系老师，有些老师的组会统一复试，有些老师就私下确定，然后九月底上系统。</p>
<br>
<h2 id="保研问题"><a class="markdownIt-Anchor" href="#保研问题"></a> 保研问题</h2>
<p><strong>IWhisper#71:</strong>  排名比较靠后以及没有什么经历，现在应该找导师吗</p>
<p><strong>IWhisper#83:</strong>  套一下普通导师吧，比较火的导师基本不会回，不过也可以投投</p>
<p><strong>IWhisper#830:</strong>  排名靠后是多少啊</p>
<p><strong>IWhisper#178:</strong><br />
<em>同问IWhisper#830提出的问题。</em></p>
<p><strong>IWhisper#71（再次发言）:</strong><br />
<em>对IWhisper#830的帖子进行了回复，提到了关于排名的问题，似乎是说至少要比20%多1。</em></p>
<p><strong>IWhisper#232:</strong>  现在就联系联系导师吧，最好可以提前进组了解学习，不要迟于6月份还没找到导师</p>
<br>
<h2 id="保研找导师相关讨论"><a class="markdownIt-Anchor" href="#保研找导师相关讨论"></a> <strong>保研找导师相关讨论</strong></h2>
<p><strong>IWhisper#57</strong>: 大家好，我有个关于保研找导师的问题。如果我之前联系过某个研究组的一位老师，但现在我不想去那位老师那里了，我还能在这个组里找其他老师吗？会不会在复试的时候有问题啊？</p>
<p><strong>IWhisper#57</strong>: zd</p>
<p><strong>IWhisper#13</strong>: 我觉得最好不要同时联系同一个组的两个导师。</p>
<p><strong>IWhisper#57</strong>: 我没有同时联系，但是我担心离开之后就再也回不来了。</p>
<p><strong>IWhisper#75</strong>: 我建议不要这样做，同一个组的老师都彼此认识，而且经常会有联系。如果碰面了，会非常尴尬。</p>
<p>这是一个北邮人论坛上关于保研寻找导师的讨论摘录，反映了学生在选择导师过程中的一些顾虑和建议。</p>
]]></content>
      <categories>
        <category>AimGraduate</category>
      </categories>
      <tags>
        <tag>AimGraduate</tag>
        <tag>悄悄话</tag>
      </tags>
  </entry>
  <entry>
    <title>陶瓷指北</title>
    <url>/2023/07/24/%E9%99%B6%E7%93%B7%E6%8C%87%E5%8C%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="陶瓷指北"><a class="markdownIt-Anchor" href="#陶瓷指北"></a> 陶瓷指北🧭</h1>
<h2 id="1什么是陶瓷"><a class="markdownIt-Anchor" href="#1什么是陶瓷"></a> 1.什么是陶瓷？</h2>
<p>套辞”顾名思义就是“套近乎”，它是留学申请者较为熟悉的一个术语，专指留学申请者和申请学校的有关教授通过Email联系，并通过联系达到增加自己被录取和获得奖学金的机会。申请者所拿到的奖学金其实就是教授的研究经费的一部分，因此与其说是学校给你发奖学金不如说是教授给你发。</p>
<h2 id="2为什么陶瓷"><a class="markdownIt-Anchor" href="#2为什么陶瓷"></a> 2.为什么陶瓷？</h2>
<p>海外求学对于申请者一个巨大的工程，需要投入大量精力和时间和金钱。因此在奖学金的争取上，有套辞的必要性。奖学金TA是院系招生办根据申请者教学能力而定。影响这个奖学金的主要因素是口语能力，包括推荐信中所涉及的内容。RA的决定权在教授手里，在审材料的过程中，如果某个教授对你表示出了强烈的兴趣，一般会从这个教授那里得到RA，也就是为教授打工的机会。套辞还有一个重要作用，就是通过和教授、同学的联系，加上专业的咨询，可以筛选最适合自己的学校，定位自己最适合的专业和方向，减少申请的盲目性，减少申请的费用，同时增加申请的准确性，增强自己的竞争力。</p>
<h2 id="3谁需要陶瓷"><a class="markdownIt-Anchor" href="#3谁需要陶瓷"></a> 3.谁需要陶瓷？</h2>
<p>套辞当然人人都可以做，但是并不是无差别的有效果，特定的专业/背景套辞往往会收到意想不到的效果。理工科学生套辞意义最大，尤其是要做项目的，进实验室的，比如EE，CS，化学，生物等等，数学、物理和经济学也不差。由于学业时间和内容的限制，本科生套辞的效果就没有研究生强。后者已经有确定的方向和实践的经验，与教授沟通和探讨起来顺畅得多，成功几率非常大；而前者只能在握专业的大体内容，表达某方面的兴趣（和教授的方向接近而吸引他的注意）以及表现自己的潜力，所以对于本科生来说更具挑战性。</p>
<h2 id="4和谁陶瓷"><a class="markdownIt-Anchor" href="#4和谁陶瓷"></a> 4.和谁陶瓷？</h2>
<h3 id="41-professor-教授"><a class="markdownIt-Anchor" href="#41-professor-教授"></a> 4.1 Professor 教授：</h3>
<p>年纪一般比较大，经历的套辞信也是多如牛毛，而且已经形成了固定的招生习惯，一般如果他对你感兴趣的话，一天之内就会回信，在这种情况下，希望很大；如果他迟迟不回的话，就代表基本没有戏了。</p>
<h3 id="42-associate-professor-副教授"><a class="markdownIt-Anchor" href="#42-associate-professor-副教授"></a> 4.2 Associate Professor 副教授：</h3>
<p>处世灵活，要求又高，当然这类型的教授水平也是很高的，套辞信种自我表现得宜是关键。</p>
<h3 id="43-assistant-professor-助理教授"><a class="markdownIt-Anchor" href="#43-assistant-professor-助理教授"></a> 4.3 Assistant Professor 助理教授：</h3>
<p>助理教授一般都有启动资金，需要人干活，而且还没有形成固定的招生习惯，所以套助理教授成功的可能性相对比较大。</p>
<h3 id="44-affiliated-professor"><a class="markdownIt-Anchor" href="#44-affiliated-professor"></a> 4.4 Affiliated Professor：</h3>
<p>这一类型的教授是已经转到别的学校去了，但学生没毕业又不跟着走，因此只是挂个名，不招生。</p>
<h3 id="45-emeritus-professor-名誉教授"><a class="markdownIt-Anchor" href="#45-emeritus-professor-名誉教授"></a> 4.5 Emeritus Professor 名誉教授：</h3>
<p>已退休，不招生。</p>
<br>
<p>建议套辞排序：招过本校学生的教授&gt;助理教授 &gt;老教授&gt;副教授</p>
<p>当然以上只是就统计结果得出来的一般性排序，事实上大部分硕士生都是由Assistant Professor 带的，博士生就是由professor带的。一定要找和自己研究方面相似或相同的，经历相似的更好。如果很相似就很有希望了，如果又是最感兴趣的而且老板又有着显赫的地位的话，就是最完美的了</p>
<h2 id="5如何找合适的教授"><a class="markdownIt-Anchor" href="#5如何找合适的教授"></a> 5.如何找合适的教授？</h2>
<h3 id="51-去学校网页上看教授的简介"><a class="markdownIt-Anchor" href="#51-去学校网页上看教授的简介"></a> 5.1 去学校网页上看教授的简介</h3>
<h3 id="52-去书店查你方向的american-academic-books"><a class="markdownIt-Anchor" href="#52-去书店查你方向的american-academic-books"></a> 5.2 去书店查你方向的American ACADEMIC books</h3>
<p>看作者是谁，或是上网查最近出学术书籍的人，就很有可能是教授。</p>
<h3 id="53-在网上找本领域的论文"><a class="markdownIt-Anchor" href="#53-在网上找本领域的论文"></a> 5.3 在网上找本领域的论文</h3>
<p>看看作者或是被引用文献的作者的背景，越新越好，比如NCBI， Science，IEEE等。</p>
<h3 id="54-每年有很多教授都会在office的门口贴想要招研究生的意愿和研究方向等等信息"><a class="markdownIt-Anchor" href="#54-每年有很多教授都会在office的门口贴想要招研究生的意愿和研究方向等等信息"></a> 5.4 每年有很多教授都会在office的门口贴想要招研究生的意愿，和研究方向等等信息</h3>
<p>可以让那个学校朋友去系里面帮忙查一下，这种信息还是比较有用的，你在套辞的时候可以有选择还有方向上的对应。如果你在某某学校一个人都不认识，可以查一下学校的graduate student的邮箱，找个是中国名字的发封信询问</p>
<h2 id="6什么时候陶瓷"><a class="markdownIt-Anchor" href="#6什么时候陶瓷"></a> 6.什么时候陶瓷？</h2>
<h3 id="61-早期套辞申请前78月"><a class="markdownIt-Anchor" href="#61-早期套辞申请前78月"></a> 6.1 早期套辞—申请前（7—8月）</h3>
<p>主要联系对象是在该校学习的朋友，校友，研究生院秘书等。本质上讲，是学校和专业调查的一个部分，询问该学校该专业的招生情况，如录取比例，奖学金发放比例以及学费等，该专业学生的组成，现在正在研究的项目，毕业去向等，还有该院系在哪方面的研究较强，学校设施以及在当地可以利用的资源等等。了解这些对于你是否选择该校，你的申请有几成胜算，是很有参考意义的。</p>
<p>在了解自己要申请的program和研究方向后，就可以和相关的教授联系了。联系教授的一种方式就是不谈申请而就教授的目前研究谈起，谈谈自己的认识和兴趣。这在学术上要求较高，因此比较难，比较适合正在做项目的研究生或帮助老师做相关项目的本科生。另外一种方式就是开门见山，直接表示对教授的研究方向感兴趣，并针对教授的研究项目和领域提一些自己的问题。这要求申请者的学术背景很强，能谈得长久。</p>
<p>好处：<br />
事先知道是否招人，有没有钱，避免浪费时间和金钱。如果教授招生或是没有钱，即使你背景再强，也没有录取的可能；如果教授资金充足，他会考虑给你RA，RA一般是教授的个人决定，他们一般都有决定权，无须系里面同意。另外如果教授是系里比较有地位有权力的人，他的支持对你Fellowship或者TA的申请常常能够起到一些帮助；有针对的选校和写PS。通过套辞你必然要看大量系里的教授的简介。你喜欢做什么，不喜欢什么都会渐渐清晰起来。对于自己背景和规划也是一个反思的过程。</p>
<h3 id="62-中期套辞申请材料寄出前后12月前"><a class="markdownIt-Anchor" href="#62-中期套辞申请材料寄出前后12月前"></a> 6.2 中期套辞—申请材料寄出前后（12月前）</h3>
<p>比较好的联系时机是在申请材料收到以后或是在路上的时候，大概在9、10、11月份。既可以和教授谈学术问题，又可以在他对你感兴趣之后及时看到你全部的申请材料。这要求申请者的学术背景很强，能谈得长久。</p>
<h3 id="63-后期套辞拿到ad或415之后-2月后"><a class="markdownIt-Anchor" href="#63-后期套辞拿到ad或415之后-2月后"></a> 6.3 后期套辞—拿到AD或4.15之后 （2月后）</h3>
<p>每个学校都会在第一轮审核（有的甚至在deadline之前）后得出一个初步的结论，这些同学会在第一时间（早的在12月末和一月初）就会得到offer。而对于大部分同学，特别是没有收到AD的同学来讲，大家并没有被拒绝，只是教授现在还拿不定主意到底选择谁。通常情况下，这说明你的材料是有竞争力的。一方面说明你确实申请的背景很强，同时也表示你的背景还没有强过那些第一轮便已早早胜出的申请者。但至少一切还都是有可能的。这个时候套辞的重要性也会发挥出来。同等背景的申请者，教授一般都倾向于选择与他联系过的人。过了415，套辞的作用也是很大的。尤其对工程的同学而言，因为工程类的奖学金较多，换而言之，有很多人将在415左右拒掉手里的多个offer。这个时候申请人即使学术背景不够强也可以去套辞。</p>
<br>
<br>
<h2 id="7注意事项"><a class="markdownIt-Anchor" href="#7注意事项"></a> 7.注意事项</h2>
<h3 id="71-信息对称"><a class="markdownIt-Anchor" href="#71-信息对称"></a> 7.1 信息对称：</h3>
<p>从自己学长学姐们那里得到的信息，以及学校的官方渠道和论坛上获得的信息都非常重要。</p>
<h3 id="72-陶瓷时间"><a class="markdownIt-Anchor" href="#72-陶瓷时间"></a> 7.2 陶瓷时间：</h3>
<p>准确把握教授的作息时间，以及日程安排。比如，在之前的陶瓷经历中，有些同学因为没有了解教授的休假时间（甚至最开始我连时差都没有考虑进去），以及remote semester，导致精心写的有些教授的陶瓷信石沉大海，杳无音讯。</p>
<h3 id="73-陶瓷量"><a class="markdownIt-Anchor" href="#73-陶瓷量"></a> 7.3 陶瓷量：</h3>
<p>每天坚持发2-3个套瓷信，同时坚持从各方获取新的可以暑研的途径。</p>
<h3 id="74-真诚的心"><a class="markdownIt-Anchor" href="#74-真诚的心"></a> 7.4 真诚的心：</h3>
<p>必须让教授感受到你的真诚，其他的一切才有可能继续下去。</p>
<br>
<br>
<h2 id="8陶瓷信的书写"><a class="markdownIt-Anchor" href="#8陶瓷信的书写"></a> 8.陶瓷信的书写</h2>
<h3 id="81-表明来意"><a class="markdownIt-Anchor" href="#81-表明来意"></a> 8.1 表明来意：</h3>
<p>我给您发邮件是请求您允许我在20XX年暑期能到您的实验室进行科研实习。</p>
<h3 id="82-简单介绍"><a class="markdownIt-Anchor" href="#82-简单介绍"></a> 8.2 简单介绍：</h3>
<p>我的学校、专业、研究方向，以及契合对方研究方向的相应课程，还有就是自己的gpa以及做过的科研项目等等。</p>
<h3 id="83-简单谈谈对教授的了解"><a class="markdownIt-Anchor" href="#83-简单谈谈对教授的了解"></a> 8.3 简单谈谈对教授的了解：</h3>
<p>这一点在“学术套”的时候尤为重要。我觉得您在某个领域很牛逼，我看过您的那篇paper,里面的方法让我觉得很牛逼，我很希望能够在这个暑期到您的实验室学习。恳请您给我机会，这将对我的学术发展很有帮助。</p>
<h3 id="84-强调来意"><a class="markdownIt-Anchor" href="#84-强调来意"></a> 8.4 强调来意：</h3>
<p>希望教授能给个机会，并说明后文附上简历，并表达感谢。</p>
<p>总而言之，套瓷是一个非常磨人的过程，需要足够的热情和耐心，也需要强大的信念。在套瓷之前，一定要扪心自问自己是否有科研的热情和兴趣。如果只是为了暑研而暑研，对自己对教授都是一种浪费时间。</p>
<h2 id="9陶瓷的方式"><a class="markdownIt-Anchor" href="#9陶瓷的方式"></a> 9.陶瓷的方式</h2>
<p>套瓷信可以是用一个模版，在上面稍作变化进行海套，也可以根据你特别感兴趣的几个老师，专门写几封套瓷信。不过建议海套为主，因为你会发现大部分套瓷信都会石沉大海，要不怎么叫“海套”呢。但是，你也不要气馁，总会砸到一个欣赏你的教授的，就像总会有一个女生或者男生喜欢你的，总会有一个人在那个地方等你，这就是缘分。</p>
<h2 id="10陶瓷信模版"><a class="markdownIt-Anchor" href="#10陶瓷信模版"></a> 10.陶瓷信模版</h2>
<p>尊敬的xxx教授：<br />
您好！我是xxx，是xxx大学xxx专业大二的学生。由于对xxx方向的研究很有兴趣，我想通过邮件向您申请在xxx年暑假前往您的实验室进行学习。    在之前的研究中，我在xxx老师的实验室中重点关注xxx的研究，包括xxx等，主要研究方法是xxx（更多研究内容请看附件中我的CV）。    我曾在xxx期刊上阅读过您的《xxx》，对xxx领域的研究十分感兴趣，因此十分希望能够在您的实验室中对这个方向有更深入的研究，同时也希望我的能力能为您的实验室研究做出一定帮助。我的空余研究时间是xxxx（可协商）。    非常感谢您百忙之中抽空阅读这封邮件，期待您的回复！</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
        <tag>陶瓷</tag>
      </tags>
  </entry>
  <entry>
    <title>飞榜</title>
    <url>/2023/09/08/%E9%A3%9E%E6%A6%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="2023"><a class="markdownIt-Anchor" href="#2023"></a> 2023</h1>
<p>🔗：<a href="https://bbs.byr.cn/#!article/GoAbroad/391790">2023飞榜</a></p>
<h2 id="1超低均分英港新澳荷混申"><a class="markdownIt-Anchor" href="#1超低均分英港新澳荷混申"></a> 1.超低均分英港新澳荷混申</h2>
<p>信息：</p>
<ul>
<li>物联网</li>
<li>gpa：83</li>
<li>申研究生</li>
<li>经历：一段北邮水科研，两段小厂实习</li>
<li>GRE/TOEFL/IELTS：IELTS 6.5(L7.5 R7 W6 S6)</li>
<li>VU：阿姆斯特丹自由大学</li>
</ul>
<br>
<p>AD：</p>
<ul>
<li>🇳🇱VU：CS/大数据工程</li>
<li>🇬🇧Glasgow(格拉斯哥大学)：CS</li>
<li>🇬🇧Durham(杜伦大学)：科学计算与数据分析</li>
<li>🇦🇺USydney：“IT：DA”</li>
<li>🇦🇺UNSW(新南威尔士大学)：DS</li>
</ul>
<p>REJ：</p>
<ul>
<li>🇬🇧Edinburgh(爱丁堡大学)：Operational Research with Data Science MSc</li>
</ul>
<p>PENDING：</p>
<ul>
<li>🇬🇧Manchester(曼彻斯特大学)：MIS</li>
<li>🇬🇧Southampton(南安普顿大学)：DS</li>
<li>🇭🇰PolyU(香港理工大学)：DSA</li>
<li>🇭🇰HKU：CS</li>
<li>🇸🇬NTU：EE/CCA/SP/CE</li>
<li>🇦🇺ANU(澳大利亚国立大学)：Computing</li>
<li>🇦🇺Melbourne(墨尔本大学)：SE</li>
</ul>
<p>最重要的事情说在前面，早点考出语言！早点考语言！<br />
大学前三年都比较混，具体不展开说了，目标不明确，大三寒假犹豫了一番还是选择出国，然后由于疫情和自己懒惰的问题，雅思首考一直拖着，纸笔考在8月底才出分，但是口语只有5，后续，回校之后和同学们交流留学事宜，自己的目标不明确，随大流去找了个中介，然后主申英国的学校。9月底又在北京考了次机考，很邪门，口语还是5。这个时候有些焦虑，10月开始准备文书材料，还是比较拖拉，同时还准备11月再去考雅思，因为英国可以后交，就没有着急。10月初又试了试港大的cs提前批，没有足够准备，直接通知笔试，应该考的也不咋样，加上均分很低，没进面试。同时10月家长联系了澳洲的中介，帮忙申了点澳洲的学校，除了墨尔本国院都可以免语言，澳洲的中介都是免费的或者参加学校活动免申请费，低均分的同学可以早早拿个保底校。</p>
<p>英国的文书和各种材料在10月拖拖拉拉的写着，中介效率也不高，后面还有疫情居家办公等等影响，反复修改，一直到11月中下旬才陆续完成。在这期间我又阴差阳错加了个kth申请群，渐渐的的了解了一些欧陆的留学情况。英国的递交基本在11月底完成了，同时我自己又去申了个港理工 dsa，好像是赶着一轮ddl申的，拖拉久了有ddl才有申请的动力。。。同时11月开始北京受疫情影响，雅思考点基本关了，10月其实也因为一些原因雅思考点关了，现在回首，大四上在北京考雅思基本只有9月有机会了（属实是没想到）。</p>
<p>12月初疫情加重，还好我也基本完成了申请，我也离开北京回老家了。然后的日子基本隔离在家，刚回家几天有了英国第一个offer，con了雅思口语6.5，留位费还是1.15，12月主要在备战期末和雅思，想加申一些ee和缝合专业，最后看了看课设又放弃了。就这样来到1月，得完新冠的我还是难受了半个月的，还收到了几个拒信，变得有点焦虑，2023的开头过的不是很好。同时还在考虑要不要交留位费，最终多方面考虑，感觉后续会有更好的，就勇敢的拒了第一个offer。1月中旬到2月初，我又投了几家春招，然后线上考试。预约雅思也是2月初，由于北邮的返校时间公布的晚，北京考位紧张，我决定在考了一场再回去，报名到了一场10天后的，准备的也一般，本以为出不了分了，没想到考的还可以，口语也上了6，不过我也是真的不想再考了。</p>
<p>2月中旬考完返校，这时候我其实手里没有offer，想想就焦虑。于是乎，只能行动起来让自己充实，这个时候我把目光放到了欧陆，我已经了解了很多欧陆的项目了，也有了合格的语言，开始加申，比较喜欢的阿姆斯特丹大学和阿自由cs joint项目，两年制的项目，选课比较自由，听说bar也不算高，但是课程压力有点大，只是没想到欧陆这一准备材料又是大工程，课程描述、动机信、论文写作等等，足足耗了三四天才完成，和英港新差别比较大，最后也是筋疲力尽，后面又看了几个德国项目，rwth，tum的申请系统都填完了结果rwth缺少gre，tum多方面考虑放弃了，鲁汶cs是雅思不够，北欧1.15基本都结束了，EIT犹犹豫豫，最后拿到阿大joint还没提交，综合考虑租房实习的问题，也放弃了（注：EIT 的bar是要低于单独申请其中最好的那个大学的，但是如果课程匹配度无法达到大学专业的最低要求，就会被调剂去差一些的学校，另外背景好的同学会有奖）。说起来我当时没继续申除了麻烦应该还有心疼申请费的问题，是100欧一个项目，还是有点贵的，还有就是当时投了很多春招和实习，2月底3月初一直在笔试面试，筋疲力尽。欧陆的申请都比较像，除了双e，tud，kth bar高一些，其他项目基本是看匹配度，均分和院校看得过去就行，今年的Aalto也很离谱（可能是没申请费还很多奖等多方面原因）。不像英港新那么强调均分，对低均分科班工作党友好，比如我看到阿大cs项目还有211 75分工作几年的录取了。</p>
<p>感觉陆陆续续说的有点多了，上文主要也算是给自己大四的留学申请之路做了个梳理。整个申请季我是作为一个开始低均分制申请英国的申请者，到后面思路打开，看到更多的欧陆项目，探寻了一些更适合自己的方向。</p>
<p>最后分享三个我觉得留学申请中比较关键的点：</p>
<p>第一个是信息差，你在整个申请中能够用到的资源交流分享群，官网项目的学生大使、学长学姐，寄托、一亩三分地或者是知乎、小红书那些留学信息交流共享平台也好，尽量去了解更多关于你这个项目的具体情况。包括就读情况，申请难度以及未来就业情况。</p>
<p>第二个比较重要的是心态问题，总而言之应该先拿到一个比较稳的保底offer，让自己踏实一点，然后有信心去申请其他算是冲刺和彩票的项目。像我虽然是一开始有早早的拿到一些offer，但是我没交留位费之后，整整两个月无offer，我都非常焦虑。但是在这个过程中，我觉得还是得有一定的自信，很多时候中国人的机心太重，总觉得就是现在，我必须在这一年得到什么。其实并不是，你可以大可以去gap年或者是半年去申请春季的项目，甚至于你去工作几年再去申请，我觉得都是不错的选择。</p>
<p>第三个是目标，应该说还是想清楚自己到底想要什么，而不是说随大流去申请一些英港新的那些项目，比如说你去英国目标是什么，是不是真的适合你，能给你镀金还是学到些想学的技能，如果是想留当地找工的话那还是比较难。</p>
<p>最后是在这个中介方面，如果真的是一筹莫展，建议可以去闲的时候听听这几个人的视频。第一个是如果对欧陆感兴趣，可以去看Marcsims的，所有的视频都可以，晚上听了助眠。其次是，如果你想去英国澳洲，可以听一下超哥留学。虽然他就是讲的不完全对，但是他整体的思路都是在线的。至于中介方面，我个人觉得中介主要是利用了一个所谓的信息差和你的心态的关系，他承诺给你的保底校，其实是不太值得的，文书不放心可以找人改改，但我认为中介大可不必。</p>
<p>还有一点就是GPT对以后申请的影响，我觉得一旦有了GPT之后，你在信息差和文书材料方面的完成度不会低于一般中介，如果你还需要一些更加细分领域的细分领域的知识和项目的，就读体验的话，我觉得问一下项目在读学长学姐和一些专门做细分领域的工作室会比较靠谱，他们一般会在知乎上有一些，非常详尽的回答，有项目对比和在读学生专访这种，（用于引流）比如说在欧陆CS这一块儿，有一个Paris工作室做的就很好，以及各个留学群都有不少信息。很多时候我就在想，为什么KTH会有那么多浙大、哈工大和东南的同学会去，第一个是因为3+2项目的原因，第二个我觉得是，不要很盲目的去选择了一些项目，就我认为就读体验来说。英国大部分一年硕是一个看得过去的title，你带着这样的镀金学历回来找工作应该是有一定帮助，很多时候看看外校的同学，他们想的有可能就，更加更加切合自己想要的东西，比如去kth学通信，鲁汶学微电子,阿尔托学ml，他们是真的希望能够有所深造，所以，我的感觉就是可以再去好好思考一下自己到底要什么。</p>
<p>简评下澳洲msc：看了一段时间澳洲签证，感觉澳洲如果能拿到pr还是很适合的，或者目标回国考公进国企还是适合的,不过确实有点贵。</p>
<p>最后说下低均分同学如果要追学校的话，可以多投一些英港新前50/100 ee，communication，包括一些混合项目，不过每年录取情况不一样，去多试试新开的项目总会有机会的。</p>
<h2 id="2microsoft实习选手"><a class="markdownIt-Anchor" href="#2microsoft实习选手"></a> 2.Microsoft实习选手</h2>
<p>个人信息：</p>
<ul>
<li>硕博混申</li>
<li>CS</li>
<li>GPA：84.05</li>
<li>GRE/TOEFL/IELTS： IELTS 7.0（6.0）</li>
<li>微软实习一段，实验室科研一年</li>
<li>B类会议一作x1，A类会议一作x1</li>
</ul>
<br>
<p>OFFER:</p>
<ul>
<li>🇭🇰CityU：CS</li>
<li>🇨🇦University of Alberta(阿尔伯特大学)：CS</li>
<li>🇨🇦University of Ottawa(渥太华大学)：CS</li>
<li>🇨🇦McGill University(麦吉尔大学)：ECE</li>
</ul>
<p>AD：</p>
<ul>
<li>🇭🇰CUHK：IE/EE</li>
<li>🇭🇰HKU：EEE</li>
<li>🇬🇧University of Bath(巴斯大学)：CS</li>
<li>🇬🇧University of Leeds(英国利兹大学)：CS</li>
</ul>
<br>
<p>自己之前在飞榜上认识了几位非常nice且有耐心的学长，也是得益于他们的经验，我对整个留学才有了初步的认识。现在我的申请基本结束后来写自己的经验贴，希望能帮到之后的BYR<sub>其实周围有很多人是申请出国的并且结果非常好，不过感觉今年飞榜数量很少，还是希望大家多多分享，多多交流</sub></p>
<p>我的均分很低，如果不加水课可能只有82。家乡是西北偏远地区的省会城市，刚来学校是各种跟不上，别说出国了，能在国内读个研究生就不错了。大一高数期中考了15分，期末被老师捞了后61分飘过，直到大二才慢慢跟上节奏，并且了解到很多外面的信息。说这些无关的话是想给均分不高的同学信心，均分不高也可以有好的选择~</p>
<p>关于项目选择和具体信息，其实最好就是自己时刻关注官网，因为每年都会有少些变化。其次，一定利用好官方给的邮箱，有不懂的及时问，一般都会得到官方回复的。</p>
<p>关于授课硕项目:个人比较推荐香港和新加坡，英国这两年Bar高的有点名不符其实了，并且对北邮（211）不太友好。由于港校扩招，北邮申港校是比较好申的，尤其推荐港大CS和EEE项目、港中文IE和EE项目，性价比很高。港大CS项目，周围同学有80、82和83录取的，并且软背景不强。港大EEE和港中文EE，均分感觉80+就有希望。港中文IE，周围同学基本均分都在82-85，但IE的课程设置个人认为很好。港科相比下难度要大很多，对北邮不太友善。</p>
<p>关于加国留学:加拿大今年有些授课项目改成Rolling制度的，周围有高均分同学因为交的太晚导致现在都没录取。所以不管是申请哪，还是尽量早点提交。之前总听别人说加硕玄学，我感觉还好。授课硕周围基本均分高的录取结果都很好。关于研硕，一定得先陶瓷（当然有少数被老师捞的）。但大部分人遇到的问题是陶瓷后老师不回复，我发出去的陶瓷邮件大部分都收到了回复。有两方面经验，一是既然申请研硕，那还是需要展示出GPA之外的扎实的科研经历（不一定是pape）；二是不要海套，一个学校跟你方向匹配的最多也就两三个老师，要展示出你跟他研究相一致的科研部分。另外，UBC和多大的研硕截至时间比较早需要注意。</p>
<p>关于日常实习：虽然很多人吐槽论坛的招聘板块很多帖子只是冲KPI，但如果每天抽空查看，我觉得还是有一些学长们发布的高质量实习，包括APPLE、MS等，至少我自己和周围同学很多都是因为论坛找到了一封不错的实习</p>
<p>关于科研实习：科研实习个人觉得对授课硕申请加成并不大。如果选择读博或研硕，可以多看看中科院、清北的实验室主页，尤其是青年老师，很多还是愿意带学生发论文的，大胆联系就好，一般都很愿意要北邮人的。如果去两周觉得方向不合适或者老师人不行，果断换就行。当然现在这个环境下要出成果，还是需要花大量时间和精力的。另外，外校很多实验室都有津贴，比在北邮打黑工强多了（既没指导还没补助）</p>
<p>关于我的博士选择：我最开始其实没有读博的打算，计划是去加拿大读研硕。当时被推荐NTU的机会后，那边老师说考个GRE问题就不大（NTU强导师制）。CityU是之前有关注过这位老师的工作后，自己陶瓷，老师约了面试后，给我的各种反馈都挺好的。但后面主要还是考虑女朋友（高中在一起异地四年了），感觉去香港可能对两个人的未来更好一点，自己也不想异地了。当然有时候可能也会想，是不是牺牲了一下自己（笑~）。总之，我觉得港新地区博士申请难度还可以（相比美国）。主要一个是看connection，一个是看科研成果。如果有强推的话，申请相对非常容易，很多强组的学生基本都是推荐过去的。如果自己陶瓷，paper不是必须的，本科直博也很少有人有太好的paper，关键还是方向是否匹配，以及你的科研经历是否solid（对这个方向了解的深度以及自己的看法），我组里的是师兄师姐本科直博的大多没paper。还有，港新里HKUST和NTU是强导师制的，剩下的现在基本都是委员会制，且这两年的要求越来越高。不过我自己感觉如果老师特别想要你，应该可以和委员会battle一下，我就属于均分不到85的那类。</p>
<p>出国留学是人生的一件大事，全都交给中介处理，不如将命运掌握在自己手里，我觉得DIY是一次很好的锻炼自己的机会~很多人认为最麻烦的是文书，但个人觉得文书在英港新申请中的重要性及其低。去一亩三分地、寄托天下等论坛，有很多前辈们分享自己文书和简历的精华帖，多看几篇自己花一下午时间写一下，更何况现在用ChatGPT帮你polish一下，无论是语法还是结构，比很多中介写的要好。我都是在一篇通用的基础上，改下不同项目的名称和学校，然后去官网找下这个项目下自己有什么感兴趣的课程写进去，让学校可能觉得你认真了解了这个项目。关于软背景提升，以计算机相关专业来说，或多或少会有一些课设（计网、操作系统等），把课设润色一下，包装的高大上一点（ChatGPT），足够写进简历和文书里了。</p>
<p>感觉这两三年国内外形势变化飞快，其实自己最开始是也只想润加拿大的，想先去读研硕再转PhD。但最后还是觉得加拿大可能并不适合自己，比如医疗效率低下、敏感专业安调、考虑女友和父母。不过当然，加拿大的好处就不用多说了<sub>总的来说，我觉得不管是国内还是国外，只要在认知清楚的前提下，做出最适合自己的选择就好</sub></p>
<h2 id="3科研选手"><a class="markdownIt-Anchor" href="#3科研选手"></a> 3.科研选手</h2>
<p>个人信息：</p>
<ul>
<li>申研究生</li>
<li>信息工程</li>
<li>gpa：88</li>
<li>研究/实习经历：申请时和去年背景完全一样【3北邮1中科院科研】，多了一个外企安卓开发的offer【但是当时还没去，最后也没有去成，后面会细说】</li>
<li>Paper：workshop一篇n作，2专利在审【其中有一个十一月份的时候因为没有及时材料被withdraw了】</li>
</ul>
<br>
<p><strong>OFFER:</strong></p>
<ul>
<li>🇨🇦UofT(多伦多大学)：ECE</li>
<li>🇨🇦UBC：EE</li>
<li>🇬🇧ICL(帝国理工学院)： ASCE</li>
<li>🇬🇧UCL：CS/CGVI</li>
<li>🇺🇸GaTech(佐治亚理工学院)：CS</li>
<li>🇳🇱TUD(代尔夫特理工大学)：EE</li>
<li>🇸🇬NUS：CS</li>
</ul>
<br>
<p>PS：因为签证被安全调查，被迫defer，我在2022年11月份决定重启申请季同时开始找实习。<br />
为了更好给学弟学妹们参考，我将22fall申请季的offer，23申请季的offer，和23申请季的rej都放上来了。2022.6-2023.1，安全调查6个月终于下签。在这一年里，我因为defer的身份被某德企withdraw过实习offer，也因为defer身份拿到了dream的美企研发intern机会；从0实习0leedcode题到上岸FLAAG SDE暑期实习；试了一些去年没有尝试的项目申请，也算圆满了心愿；开始做一些奇奇怪怪的专业相关小兼职。这一年发生太多事情了，过段时间有空了会单独开一个贴讲讲被安全调查后，突如其来的gap一年对我的影响&amp;我的选择，这里先简单写一些关于申请的碎碎念。希望能对申请中/找实习&amp;科研中/害怕安调中/考虑跳车中的学弟学妹们一些帮助和参考。</p>
<p>这次真的是全球混申了，我进一步确信了【中介无用】这件事。我自己也帮助了几个老同学搞申请、选校、搞文书这些，TA们拿到了NUS，TUD，KUL，UNSW，HKUST等offer。然后这一年也接到了不少学弟学妹的选校定位咨询，因此我想说：如果你真的觉得还是有中介更靠谱，不如先找我聊聊，因为我现在也给中介和文书机构做兼职了……具体的就不打广告了。本人咨询范围包括但不限于：10043/安全调查/全球混申/除了CS外的各类泛CS专业申请/名校bar低项目/拿卡/GAP Year规划/文书写作/背景提升…… 学弟学妹咨询的话我不会收费的。</p>
<p>当前签证政策和疫情影响下对留学选校和今后规划的影响和解决方案</p>
<p>先再贴一下本人情况，10043政策下EECS专业异国恋难民 兼 加拿大学签安全调查倒霉蛋 兼 不能头铁冲一些可能入境读书毕业前多年不敢回国的项目</p>
<p>22fall的byr签证情况喜忧参半吧，美签过了一些STEM专业的幸运儿，也有一些通过其他专业or方法曲线赴美读CS的猛人；加签安全调查（下称安调）比例激增，授课硕安调比例也很高，且无法知道“出狱”时间，很搞心态；澳洲PhD签证难下；欧陆签证没有太大问题。</p>
<p>23fall目前观察下来，签证进一步收紧，主要体现在欧陆STEM PhD签证出问题，以及加拿大签证安调上。因为目前还没有到8月，因此加签情况还需要再观察一下来下结论。美签头铁硬冲的人数变少了，但是入美的途径更明晰了。</p>
<p>我先写个框架，之后单独开一页写安调后的备选方案与我的思考选择。</p>
<p>跳车<br />
1.1 跳车时间的选择<br />
1.2 跳车国家的选择<br />
1.3 以后下签了是否要考虑读二硕<br />
1.4 交留位费防跳车还是重新申请<br />
1.4.1 重新申请如何定位选校</p>
<p>选校，尤其是在byr论坛信息这么丰富的情况下，基本上找几个学长学姐对标一下自己的背景，选校就能够八九不离十。再加上有了第一年申请的经验，我很清楚哪些学校和项目是我今年能稳录的。选校的框架一般是冲刺-主申-保底。今年对我来说，已经不再有主申的学校了。一是因为没有了美国，选择本身就很有限；二是因为我基本上都知道这个项目我是大概率能录还是完全彩票。那么对于defer跳车的uu们来说，只要确定冲刺和保底就可以，因为其实那个等待签证的项目就可以替换掉其他的主申了。</p>
<p>在11月份我决定重新申请后，我去询问了本科好友们的申请情况，翻了近两年byr飞榜、xhs的offer贴，看了1p3a，寄托天下这些常规公开的留学数据库里的我感兴趣的院校的全部ad&amp;rej的dp，最终确定：IC部分非主流专业，欧陆大部分院校非热门专业，澳洲香港授课硕，和新二某些专业我基本上可以确信必录。</p>
<p>接着就是根据我对排名的要求、专业的课程设置、地区的性质进行筛选。我有一定的排名癖、希望当地政策可以支持毕业后工作几年、希望专业有意思扎实不能太水也不能太苦、希望课程设置能偏cs一些。最后，还需要防止其他国家的签证也突然抽风，所以选择二次申请了TUD-荷兰好毕业后找工，但是太苦太村；ICL-排名太漂亮，签证很稳妥，当最后的backup plan；NUS-防止war的backup plan&amp;排名可&amp;录取bar低排名高；UBCO-防止加签下签太晚导致uoft offer无法再继续defer了，再留一个去加拿大读书的plan b。此外还申请了两个女神校的偏艺术/文科的交叉学科的专业来冲一把过过瘾，与一个欧洲奖学金项目dream一下全奖（录了但是没有给全奖就没去了）。11月初也一度疯狂套瓷想试试读博，然后迅速意识到这与我的规划不一致且与我当前最大的诉求–下签，存在一定程度上的互斥关系。因此就只考虑授课硕了。</p>
<p>1.4.2 重新申请如何卡时间线（避免太早下offer交留位费/避免没有学上）<br />
我基本上可以确定前面四个学校我选的项目是必录，但是因为去年发生了我交了ucl的留位费，最后gap了也没去上留位费打水漂的事情，今年就尤其想要避免花留位费这个事。我先进行了以下思路梳理：<br />
（1）英国rolling制度申请时间早但是放榜时间较晚，还会有面试，大致会在2-4月出结果。有较高留位费。<br />
（2）荷兰3.15后开始放榜。且似乎没有留位费，签证有学校帮忙处理。<br />
（3）冲刺校没有留位费，且只要下offer一定头铁去。<br />
（4）新加坡留位费高昂，下offer速度快，但是申请ddl晚。我需要晚一点申请这家的项目。<br />
接着是梳理了我的签证情况：<br />
（1）如果我的签证在2022.12前下签，此时均没有放榜，直接去CA即可。<br />
（2）如果我的签证在2023.1-2023.3内下签，我无法正常读23winter学期，且此时应该是正好在等待offer，纠结留位费&amp;新二最后一批ddl前。<br />
（3）如果我的签证在2023.3.30都没有下签，那么我要保证手上至少必须有一个可以下签的offer，且新二此时还没有出结果。<br />
（4）签证安调情况分3个月，6个月，12个月。那么我下签很可能会在10月初【已经过去了】，次年1月初，和次年7月【风险太大，赌徒心态太重】。再给这个次年1月初一个月的offset，因此我确定是否需要备胎offer的时间应该是2月份。<br />
因此，时间线就很清晰了。【2022.11月】我必须立刻完成冲刺项目们的申请，完成ICL的项目申请；【2023.1.31前】踩线完成TUD申请与UBCO申请；【2023.3】再根据情况判断是否进行NUS申请。根据加拿大签证的状态决定申请流程是否叫停、是否接offer等等。<br />
最后，时间线与我判断的完全一致，更幸运的是所有的offer都在下签后来了，前期的时间规划和推断都不用了。非常开心。不知道这一段有没有阐述清楚我当时的思路。【一边做规划，一边刷题满大街找实习，家里还出了点事情，搭配上当时封城高峰，心态真的炸裂】</p>
<p>东亚人的gap year–实习<br />
2.1 应届生身份&amp;在校生身份<br />
2.2 外企？国内大厂？高校RA？<br />
2.3 时间成本&amp;年龄焦虑<br />
签证<br />
3.1 心态调整<br />
3.2 可以尝试拯救签证措施<br />
学校的defer政策<br />
授课硕/研硕/phd<br />
本科做了一串科研，感觉到无比痛苦，确信自己至少在工科方向上没有什么学术追求和理想，因此除了11月份突然又三分钟热度去套瓷了一下，其余时间我很确信我不适合科研。但是对于申请来说，科研可以说是一个必须的经历，所以建议学弟学妹们可以大二大三去体验一下科研，看看适不适合，如果不适合的话，有了经历也能及时止损。没有必要为了所谓的认可度/或者研硕的小奖，去让自己花更长的时间做与职业规划不同的东西。选择适合自己的，和自己自洽就行。<br />
科研其实很好套瓷，我当时套到了一些海外的research intern机会，但是当时脑抽没去（见2022贴），去学校官网，1p3a，byr论坛这上面刷刷，然后好好发邮件，做到真诚、自信、认真，好的Research intern机会真的很多很多，市面上卖的背景提升项目真的没有必要。</p>
<h2 id="4研究生申博选手"><a class="markdownIt-Anchor" href="#4研究生申博选手"></a> 4.研究生申博选手</h2>
<p>个人信息：</p>
<ul>
<li>通信工程</li>
<li>gpa：3.94</li>
<li>GRE/TOEFL/IELTS： TOEFL 102 (23) GRE 151+169+4</li>
<li>4年RA</li>
<li>1篇1作C会 1篇3作A刊 + 其他会议期刊若干</li>
</ul>
<br>
<p>感觉研究生申博士对我的参考价值不大…</p>
<p>connection大于一切，尽量找导师要内推<br />
AI方向太卷了，可以看一些AI+X的方向<br />
如果有Top venue的publication的话会大大加分<br />
当前签证政策和疫情影响下对留学选校和今后规划的影响和解决方案<br />
PP10043好像暂时也没啥办法……</p>
<h2 id="5普通人选手"><a class="markdownIt-Anchor" href="#5普通人选手"></a> 5.普通人选手</h2>
<p>个人信息：</p>
<ul>
<li>电信工程</li>
<li>gpa：80.93</li>
<li>GRE/TOEFL/IELTS： IELTS 6.5 （L：7.5 S:5.5 R:7.0 W:6.0）</li>
<li>研究/实习经历： 一段HR实习，一段外企辅助技术岗位实习。 当前本科毕设在学校AI院实习。</li>
<li>Paper： IEEE大水会文章</li>
</ul>
<br>
<p><strong>AD:</strong></p>
<ul>
<li>🇬🇧曼彻斯特大学：健康数据分析</li>
<li>🇬🇧谢菲尔德大学：电子信息工程</li>
<li>🇬🇧伦敦玛丽女王大学（QM）：计算机游戏</li>
<li>🇦🇺悉尼大学：数据分析</li>
</ul>
<br>
<p>鄙人确实不才，在一众GPA85-90左右的大佬当中格格不入。不过我相信学校里面英国有不少情况与我类似的学弟学妹们想要出国，但是却不知道自己的大致能够去什么样的学校的情况。</p>
<p>除了上述学校我还试着申请日本的学校，但是因为一方面因为GRE考不出分，另一方面意识到语言和套词信的完成时间已经来到了二月初，准备有点晚了，遂作罢。</p>
<p>我计划出国的想法是大三上（2021.11前后）有的，之前是计划考研，后来因为一些事情决定出国。到现在为止，来来回回准备了一年半多左右。期间有坎坷（其实很多都是自己给自己的心理压力），不过基本上还是按部就班。</p>
<p>关于GPA和选修课，一般学校申请要求上都会写明专业限制和相关课程所占最低比例（大约是30%左右），这个要求是目前我唯一知道的选修课可能对申请的影响，因为选修课选多了会降低专业课的学分比例。目前我的拒信里面目前只有南安普顿和利兹大学提到了“课程匹配度不够”，而这两所学校对于课程匹配度要求高，其他学校全是模板拒。另外，如果可以的话学弟学妹们尽力把GPA上去，GPA高不一定有好学校上，但是GPA不高真的很要命，不过希望学弟学妹们不需要考虑这一点。另外万一GPA要是真的因为课程难度与个人能力不够匹配等原因提不上去，也不必过于焦躁，满足课程匹配度条件（要是不满足可以换学校换项目，光是QS前100的学校就有一百所，专业数量恐怕是更多）的前提下通过选修课提升（现在选修课均分应该是在90-94之间，线上可能会到96左右），也能充实一下人文素养。GPA如果非要拟订一条不可低于的底线，我会建议高于80分（算上选修课），多数一流院校要求都是80以上。少数（悉尼大学EE/CS专业约四年前有75分成行的）一流学校可能会低一些，但是这些学校可能会有学制时间、投资费用、毕业率以及地理位置等短板需要注意一下。</p>
<p>另外，如果有申请研究硕或者博士的项目的需求，不应该只看学校的排名（QS之类的），应该看校企合作以及学术声誉，学校排名靠后一点也是可以的，毕竟这类项目大概率会有奖学金或者研究补贴，可以看作是一份工作，含金量还是比授课硕高一些的。</p>
<p>如果我想得起来的话，之后成行出发的时候应该还是会在这个帖子上更新，敬请期待。</p>
<p>如果想问具体的的话站内私信。你说中介有没有用吧，老师人挺好的；你说选校专不专业吧，老师人挺好的；你说文书专不专业吧，老师人挺好的。很有意思的一点是，那边的老师可能会催着你交一些东西，而他们甚至连截止日期可能都搞不明白。也就是说像个脚本一样催着你交东西，弄不明白为什么也不明白你的背景，尽管这个东西的截止日期很久以后。</p>
<p>我的评价是中介属于一个很幽默的存在，必不可少也不算，但是总归有一个来提醒总归好过没有。授课硕中介的费用比起后面的学费/生活费基本上就是毛毛雨，研究硕/博士会可能会比较高（身边有同学中介费15w-30w不限制申请学校/项目数量）。不过越到后面申硕士博士特别是研究硕博项目越不需要中介，需要的是自己的目标背景和目标组的匹配度，最好DIY。</p>
<p>虽然本人没有成功申请研究型硕士，但是自己也试着动手看了看各个学校（主要是日本）的要求。研究硕博的申请应该是属于水到渠成的感觉，即本科期间做的项目的延续，文书和找对口的组最好要自己亲自完成。因此中介那种模板文书什么When I was a child…基本上没啥用。另外有同学提到过他申请日本的硕士（研究硕）的时候，中介负责文书的人对于他所选取的专业没有任何学科基础知识，甚至文书中还出现了很会用word写文章之类的离谱描述。</p>
<p>对于我致力于的授课硕项目。与研究硕/博不同，中介可以在这块干一些比较重复性的任务，比如说把学校的要求和门槛列出来选择。不过英国能选的就那么几所学校，大概跟往年评估一下就知道自己能去哪了，然后就申请就是了，中介作用仍然有限。</p>
<p>要真的找我感觉还不如请快毕业的大一届的学长学姐一顿饭或者发个红包问问怎么选校和准备的材料，然后淘宝找文书润色或者ChatGPT，最后自己上学校官网看看自己想要的专业的要求。毕竟中介干的也不过就是这些活。</p>
<p>当前签证政策和疫情影响下对留学选校和今后规划的影响和解决方案</p>
<p>之后出国只会越来越难，尤其是含金量高的研究硕或者博士。不仅仅是签证，各大院校的经费和HC也少了不少，举个例子：有同学告诉我马普所的HC缩小了50%左右。虽然不知准确度，但是这一的消息也不应该是无源之水，确实有类似的缩招情况存在。因此如果仅仅是为了硕士学位授课硕也是不错的选择，至少授课硕没有目前影响不是很大。至于硕士毕业后无论是国内工作还是海外找工作，最好多提升一下自己的能力。总之无论如何做好换乘或者跳车的准备，留一条后备之路。</p>
<h2 id="6nus-录取选手"><a class="markdownIt-Anchor" href="#6nus-录取选手"></a> 6.nus-录取选手</h2>
<p>个人信息：</p>
<ul>
<li>CS</li>
<li>gpa：3.74，均分取整到90</li>
<li>GRE/TOEFL/IELTS：IELTS 7(L7 S6 R7.5 W7) GRE 329+3.5</li>
<li>研究/实习经历：一个科研型大创，一段小厂实习</li>
</ul>
<br>
<p><strong>AD:</strong></p>
<ul>
<li>🇳🇱TU Delft：CS</li>
<li>🇳🇱TU Eindhoven：CS/</li>
<li>🇳🇱VU &amp; UvA：CS</li>
<li>🇨🇦UWaterloo：ECE</li>
<li>🇨🇦UCB：EE</li>
<li>🇨🇦UOttawa：ECE</li>
<li>🇳🇿UAuckland：IT</li>
<li>🇸🇬NUS：Computing</li>
</ul>
<br>
<p>23fall全球混申选手，总体来说申请结果还是比较满意的。我一开始是比较想去加拿大的，但是由于签证安调决定跳车荷兰了。这里给学弟学妹们提个醒，现在加拿大的安调情况仍不容乐观，最好有个备选方案。下面我介绍一下各个国家的申请情况。</p>
<p>首先是加拿大，加拿大的申请是比较难的，我由于比较菜主要申的是授课型。滑铁卢大学的ECE项目由于新加了coop所以成为了我的首选，需要注意的是他ECE下面有两个项目，一个带coop一个不带，学校建议同时申请两个，因为带coop的竞争很激烈。另外滑铁卢还有mdsai，据今年申上的同学说这个项目不卡语言，大家明年可以试一试。其他项目的话，ubco的ee和mcmaster的cas都不错，这两个项目都可以做实习，但是注意mcmaster的cas需要套磁，一定要尽早套磁，不然很可能录不上。至于mcgill和alberta这两个，由于地理位置不太好，所以不很推荐。</p>
<p>然后说下欧洲，欧洲的话我个人比较推荐的学校是IDEA联盟，这个联盟里有五所顶尖的理工大学，我申请的代尔夫特理工也是其中之一。欧洲整体学费会比北美便宜，而且他们授课型和研究型不区分，一般是第一年上课，第二年科研。这样的话毕业既能找工也能读博，性价比挺高的。荷兰对北邮比较友好，放心申就行了，但是瑞典的kth是真的歧视211，我申了三个项目全是waiting list。如果是cs专业想去瑞典，建议申请瑞典另一所学校cth。</p>
<p>最后说说其他地区。新加坡的项目我申了两个，目前收到了NUS的CS，听说这个项目无GRE也能录，学弟学妹们可以冲一下。至于澳洲和新西兰，这个是因为他们有的学校不收申请费，我就申着玩一玩，不过因为他们那边教育比较水，个人不建议去。</p>
<p>如果你对未来发展没有一个明确的方向，那就努力提高gpa吧。</p>
<p>如果使用中介，请尽量客观的谈谈和留学中介打交道过程中的不愉快和收获，以及你对中介的看法，和对你的实际帮助（请不要直接说中介的名称，请用首字母缩写代替）</p>
<p>我找的这个中介感觉还不错，建议大家找那种体量小一些的中介，他们往往比大中介靠谱。申请材料什么的其实主要还是自己准备，中介主要帮你润色翻译一下，找不找中介还是看个人了。</p>
<p>当前签证政策和疫情影响下对留学选校和今后规划的影响和解决方案</p>
<p>这个我上面已经说了。现在美国有10043，加拿大有安调，建议大家以后多考虑欧洲和港新。</p>
<h2 id="7软工之光"><a class="markdownIt-Anchor" href="#7软工之光"></a> 7.软工之光</h2>
<p>个人信息：</p>
<ul>
<li>gpa：92.12</li>
<li>GRE/TOEFL/IELTS： T: 105(30 27 22 26) G: 324(3.0)</li>
<li>研究/实习经历： 海外暑研一段，校内科研一段，外企实习6个月</li>
</ul>
<br>
<p><strong>AD:</strong></p>
<ul>
<li>🇨🇦UToronto：CS</li>
<li>🇨🇦UWaterloo：ECE/CS</li>
<li>🇬🇧IC：Computing(AI+ML)<br />
<br></li>
</ul>
<p>在我看来，申请主要可以分为两部分：背景提升 + 信息获取，要想取得一个不错的结果，二者缺一不可。</p>
<p>其中背景提升包括GPA，语言，科研，实习等等，需要在申请季之前做好，尤其是语言。一边申请一边考语言会非常痛苦，最终可能对申请期间的选校，文书等产生负面影响，得不偿失。之前针对背景提升相关讨论较多，就不赘述了。</p>
<p>下面我来具体讨论一下信息获取，对于选校，文书，面试等等都至关重要。目前看来，获取信息主要通过以下几个渠道：</p>
<ul>
<li>飞榜：虽然每年申请季的情况都有所不同，但是飞榜永远能提供给你最真实，最有借鉴意义的dp（因为都是本校的），并且可以联系学长学姐，咨询感兴趣的项目。</li>
<li>一亩三分地：可以获取现在和过去几年大量的申请dp，包括录取bg，timeline，面经等等。同时也有不少帖子提供选校，文书等等方法论，建议每天都刷一刷。</li>
<li>小红书：感觉是今年才流行起来的，上边有很多人分享自己的申请结果，可以当作一亩三分地的补充。</li>
<li>GradCafe：外国人的申请论坛，可以获取录取时间等信息，bg参考意义不大。<br />
如果使用中介，请尽量客观的谈谈和留学中介打交道过程中的不愉快和收获，以及你对中介的看法，和对你的实际帮助（请不要直接说中介的名称，请用首字母缩写代替）</li>
</ul>
<p>感觉有时间的话，多卷卷信息差就可以diy了，毕竟自己才能做最适合自己的选择<br />
文书的话建议是chatgpt，语言地道，无语法错误，真的很好用</p>
<p>加拿大phd和研究硕大概率安调（下签时间&gt;200天），授课硕也有一定概率，建议做好跳车方案<br />
瑞士两所很看本科学校，对bupt很不友好，貌似今年还缩招了，未来慎重申请（申请费贵）</p>
<h2 id="8科研大佬"><a class="markdownIt-Anchor" href="#8科研大佬"></a> 8.科研大佬</h2>
<ul>
<li>CS</li>
<li>gpa：86</li>
<li>GRE/TOEFL/IELTS： gre 318不考了/托福105</li>
<li>研究/实习经历： 科研上：清华一段，北大软微一段，上交一段。 工业：小厂（hillstone 山石网科）一段</li>
</ul>
<br>
<p><strong>OFFER:</strong></p>
<ul>
<li>🇦🇺UNSW：SE</li>
<li>🇭🇰HKUST：SE</li>
</ul>
<p><strong>AD：</strong></p>
<ul>
<li>🇺🇸JHU(约翰霍普金斯大学)：SE</li>
<li>🇧🇪KUL(荷语鲁汶大学)：CS</li>
<li>🇸🇪KTH(皇家理工学院)：communication system</li>
</ul>
<br>
<p>这两年，太难了。尤其是想读phd的，我想说能转学就早转学吧，出国被卡的问题只会越来越严重，不值得冒险。不是说学校有多不好，只是为自己未来打算。有任何问题随时联系就ok呀！一路上也是各位老师以及各位学长帮助下成长起来的，也会反馈论坛的！</p>
<p>今年硕士很多人都被拒麻了，比如我，感觉前两年能申请上的今年都不太行了。我其实弄了很多国家，一直一直在申请，但是最终也没有拿到满意的硕士offer。</p>
<p>硕士的话主要就是看GPA，你甭管是智慧树刷gpa还是水课刷gpa，那个数字只要高，在一部分学校里就是绝对有用的，至少我的经验来说是这样的。</p>
<p>博士的话我的经验不多，有人说paper大于一切，有的人说connection更重要，我是两方面都菜，但是怎么说呢，本科生直博，你没有论文也没大碍的其实。我一共了5个邮件，收到三个回复，其中两个是口头offer，另一个老师也表示愿意接收，但是对于签证有顾虑。感觉只要你有科研经验、喜欢科研、面试展示出来自己的热情和实力，往往都会有比较好的结果的。有的前辈一发套瓷信发几十封海投，结果可能收到的回复很少；我总感觉对于没有paper的本科生来说，博士申请不是量化的，发每一个邮件之前，我感觉如果仔细读一下老师的论文，比如5篇，做好笔记，在邮件里写出来：我对您在xxx领域使用的xxx方法感兴趣，因为我在实践中遇到了xxx问题，您的方法巧妙的解决了这样的问题等等。将心比心，如果咱比较有诚意的发邮件，相信老师也会有诚意的回复你的。</p>
<p>贴上一些同学们问我的一些问题嘿：</p>
<ul>
<li>
<p>校外科研有什么渠道找:<br />
如果你已经有了科研经历的话，那么可以让你的老师给你推荐；如果还没有的话，我的方法是在google scholar上找这个方向的大牛，然后发邮件，发之前好好看一下这个大牛的论文，确定自己是不是真正喜欢这个方向。</p>
</li>
<li>
<p>找科研如何选课题组/老师？<br />
:肯定是老师重要的！最主要最主要的是圈子，要看老师是不是在当前学术最顶尖的圈子里面。一些老师连论文都没有，这种老师大多数都是在学校混日子的，对学生成长帮助很小。我个人的理解是，可以看一下老师最近的动向，如果老师经常参加顶尖的学术会议、在google scholar上引用量比较大，这种老师往往是比较好的，踩坑几率比较小。</p>
</li>
<li>
<p>如何判断自己是否适合科研？<br />
:关于这点，我个人的理解就是，看你写代码或者读论文的时候，是不是会被吸引进去。论文为例，喜欢科研的人真的，看论文会上瘾的，就觉得看论文特别特别有意思，看看有没有新的idea、有没有前沿的方向。不喜欢的人看论文头发都炸了。</p>
</li>
<li>
<p>如果遇到不满意的导师该如何处理？<br />
:不满意的老师要及时换呀！千万别不好意思啥的，毕竟咱时间就那么几年，没必要浪费很多时间在不好的老师上</p>
</li>
</ul>
<p>我的中介真的很好！！！没有她我不可能能拿到今天的offer。从大二开始就一直催促我做科研、找实习等等，一只给我鼓励啥的，写文书等等的水平也很强做事情很认真。文书帮我改了无数无数无数遍。真的很感谢这位老师！</p>
<p>美国不用想了，澳洲现在也在卡，除了新加坡，任何一个国家基本上都会卡中国。哦当然俄罗斯不卡。能润早润吧，一刻都不要耽搁。主要是现在这个情况港新也卷起来了，基本上HK那边好一些的组直博都是要先做一下RA才能去phd，新加坡的位置也不是很多了，所以建议大家要申请的话尽早哦，最好可以就是，比如大四没课了，就直接去老师的组里做RA，境外的RA薪水都不错，一般都可以cover生活开销的</p>
]]></content>
      <categories>
        <category>GoAbroad</category>
      </categories>
      <tags>
        <tag>GoAbroad</tag>
      </tags>
  </entry>
  <entry>
    <title>智慧树问答规则</title>
    <url>/2023/11/06/%E6%99%BA%E6%85%A7%E6%A0%91%E9%97%AE%E7%AD%94%E8%A7%84%E5%88%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h1 id="1问答问答规则~必看必看必看"><a class="markdownIt-Anchor" href="#1问答问答规则~必看必看必看"></a> 1.【问答】问答规则~必看!必看!必看!</h1>
<p>我们将重点关注问答的“质量”而非“数量”。无效问答数量多,可能分数反而会更低哦,为什么这样说呢,我们先看下问答分的计算规则:</p>
<ul>
<li>互动分=(分子/分母)* 互动分总分数 * 百分比,最终四舍五入。若超出总分数的,取总分数,即满分</li>
</ul>
<p>那接下来我们来看下这个规则里各部分的数值是如何定义的:</p>
<ul>
<li><strong>分母</strong>:本人单门课程下所有的提问、回答数相加,包含无效的,即包含被阿里自动审核屏蔽的、审核人员删除的、老师删除的,不包含自己删除的。</li>
<li><strong>分子</strong>:本人单门课程下有有效回答(学生身份回答的)的有效提问数和本人有效回答数相加,然后乘以0.9。</li>
</ul>
<br>
<h2 id="11-有效提问"><a class="markdownIt-Anchor" href="#11-有效提问"></a> 1.1 有效提问</h2>
<p><strong>重要提醒</strong>: 很多学生直接用APP【成绩】模块中“我的有效提问”的条数去做分子,这是不对的哦,APP【成绩】模块 “我的有效提问”仅仅是针对提问的有效性,而作为分子的是有有效回答(学生身份回答的)的有效提问数,两者是不一样的。举个最简单的例子,你提问了10个问题,10个问题都是有效提问,但这10个提问都没有任何学生回答,那“10”是不作为分子的。</p>
<br>
<p><strong>正确打开方式</strong>:</p>
<ul>
<li><strong>电脑网页端</strong>：成绩分析—我的互动板块,学生可以将鼠标移动到有效提问的条数上,会悬停显示“有X条已获得其他学生的有效回答”。</li>
<li><strong>手机APP端</strong>：【成绩】——“查看我的平时分”——我的互动——“我的有效提问”下方查看到“有X条已获得的其他学生的有效回答”。</li>
</ul>
<br>
<p><strong>针对单个提问或单个回答</strong>,分子的附加项:</p>
<ul>
<li>1、有有效回答(学生身份回答的)的提问下有老师的回答,分子+2。不管老师回答几次,不管几个老师回答,仅+2。</li>
<li>2、有有效回答(学生身份回答的)的提问热度大于20,分子+2。热度与有效回答数(不含老师)、围观数、点赞数、评论数有关,由系统自动计算。</li>
<li>3、有效回答有老师点赞,分子+2。不管几个老师点赞,仅+2。</li>
<li>4、有效回答有其他同学点赞,点赞大于一定数量,以及 有效回答下方评论大于一定数量,也可以获得少许分子附加值,由系统自动计算。</li>
</ul>
<br>
<p><strong>百分比</strong>:</p>
<ul>
<li>若分母在5(含)以下,则最终得分*百分比为10%;</li>
<li>若分母在6-10之间,则最终得分*百分比为30%;</li>
<li>若分母在11-20之间,则最终得分*百分比为60%;</li>
<li>若分母在21-30之间,则最终得分*百分比为80%;</li>
<li>若分母在31及以上,则最终得分*百分比为100%。</li>
</ul>
<p><strong>隐藏攻略</strong>:只要保证自己分子高,那分母达到31及以上,百分比就是100%,这也就是为什么有的学生会问为什么我发了上百条,别人才发了三四十条,我分数还没别人高的关键之处。</p>
<p><strong>注意事项</strong>:</p>
<ul>
<li>1、被阿里自动审核屏蔽的、审核人员删除的、老师删除的提问和回答均为“无效”;</li>
<li>2、互动分在整个学期内都会有所浮动,如被系统审核为“有效”的问答,在审核人员复核为“无效”之后,相应的分母、分子数、附加项也会发生变化,分数也会产生相应变化;</li>
<li>3、回答字数少于3(含),系统将直接判为“无效”。任何符号均不计数。</li>
<li>4、学习时间结束后发布的提问和回答均为“无效”。</li>
<li>5、互动分在学习时间截止后固化,即最终的互动分会在学习时间结束后的凌晨进行计算,即次日上午学生看到的互动分即为最终得分。</li>
</ul>
<p><strong>举例1</strong> 假设学生发了10个帖子,包含提问和回答,有效的提问(提问下有有效回答)和回答数相加为6,有一条提问热度大于20,这门课程互动分总分为10,则学生的互动分=(6 <em>0.9 + 2)/ 10</em> 10 <em>30% =7.4 / 10</em> 10 <em>30%=0.7</em> 10 * 30%=2.1≈2</p>
<p><strong>举例2</strong> 假设学生发了11个帖子,包含提问和回答,有效的提问(提问下有有效回答)和回答数相加为10,有一条提问热度大于20,有一条回答有老师点赞,这门课程互动分总分为10,则学生的互动分=(10 <em>0.9 + 2 + 2)/ 11</em> 10 <em>60% =13 / 11</em> 10 <em>60%=1.2</em> 10 * 60%=7.2≈7</p>
<p><strong>举例3</strong> 假设学生发了31个帖子,包含提问和回答,有效的提问(提问下有有效回答)和回答数相加为22,附加项没有,这门课程互动分总分为10,则学生的互动分=(22 <em>0.9 /31)</em> 10 <em>100% =19.8 / 31</em> 10 <em>100%=0.6</em> 10 * 100%=6</p>
<h2 id="12-攻略及建议"><a class="markdownIt-Anchor" href="#12-攻略及建议"></a> 1.2 <strong>攻略及建议</strong></h2>
<p>1、提问方面,可以根据课程视频中的内容,提出一些自己的看法,然后针对这一看法与本课程的学生及老师进行互动交流。请不要提一些视频中已经有明确答案的“简单”问题,比如问时间、地点、人物等有固定答案的问题,因为这些问题一定被会系统屏蔽或被人工审核为“无效”。直白点,能“百度”出固定答案的问题,大概率最终都会成为“无效”提问,所以看见这类提问,学生也大可不必去回答,因为这类提问后期可能会被审核删除,被删的提问及提问下的回答都是“无效”的。 <strong>隐藏攻略</strong>:如果提不出高质量的问题,可以采取多“回答”少“提问”的方式。</p>
<p>2、请“原创”自己的提问及回答,不要照搬或抄袭其他学生的劳动成果。我们有AI智能审核把第一道关,重复提问会直接被判为“无效”提问,有漏网之鱼也会有人工复核为“无效”。另外,针对主观性问题的回答,若有复制粘贴行为的,审核人员将会人工审核为“无效”回答 。重要提醒:请不要去回答一些“简单”提问或者与课程毫不相干的水帖,这类提问有大概率会被人工审核删除,这样就会导致提问下的回答同时被删除(即记为无效回答)。 p.s.客服人员只能查看到您发的提问及回答,但客服人员是无法查看到您这些问答是否有效的。</p>
<p>3、若收到站内信通知,被系统屏蔽的提问及回答,请同学自行手动进行删除。分母数包含被屏蔽的,不包含自己删除的,分母越大分子越小则分数越低,这个道理我相信大家都能明白。同理,有些学生由于网络问题,相同的提问不小心发出了多条(重复提问会被AI自动审核为“无效”),也请自行删除重复提问。 p.s.被屏蔽的问答,只有自己可见,别人是无法回答/评论的,故可以自行删除;如果是自己不小心重复发的、亦或是已经知道自己的提问是无效的,若你的提问已经被人回答了,则无法对提问进行自行删除。更没必要联系审核人员去删除,因为由审核人员删除的问答也同样是记为“分母”的。</p>
<p>4、审核人员会进行一定的删帖操作,如纯灌水、辱骂性质的内容、直接复制粘贴热门帖或老师的问题、与课程无关的内容、涉政及黄赌毒类内容等等。被人工审核删除的也计为分母数,且已被人工审核删除的问答则学生无法自行删除,所以请各位学生一定不要“乱发”。其他重复类提问,审核人员仅做“有效性”审核,不做删帖处理,请不要抱有侥幸心理,同学发了一个重复提问那我也发一个,同上,重复提问发的越多那你的分母越大分子越小则分数也会越低。</p>
<br>
<h1 id="2问答什么是无效提问无效回答"><a class="markdownIt-Anchor" href="#2问答什么是无效提问无效回答"></a> 2.<strong>【问答】什么是无效提问/无效回答?</strong></h1>
<p><strong>无效提问主要分为两种类型</strong>:</p>
<ul>
<li>
<p>1、由系统自动判断的。当前课程下如果您的提问已经有其他同学问过了,且相似度在98%及以上,则系统就会自动判定为您的提问为无效提问</p>
<p>重要:近期我们发现有第三方刷帖行为,其提问格式为“请问XXXXXXXXX??”(另外还有诸如:“请问XXXXXXXXX。?”/“请问XXXXXXXXX—?”),即在正常的问题前面添加了“请问”,以及在结尾处添加了一个或多个问号,看到这类提问,请各位同学不要去回答,我们会每日清理此类重复刷帖。</p>
</li>
<li>
<p>2、由人工进行复审的。有些同学会“抄袭”其他人的提问,加个符号或表情符就把别人的提问“变成”自己的了,我们的审核人员发现后会对此提问审核为无效提问或直接进行删除处理。当然,与课程无关的问题,我们的审核人员也是会进行无效或删除处理的哦。</p>
</li>
</ul>
<br>
<p><strong>温馨提示</strong>:【问答】是给同学们对课程学习过程中的内容进行讨论的地方,一些同学仅仅是为了想要拿互动分所以在拼命“水”,其实越简单的问题越容易产生“无效提问”。【问答】的互动是针对同样在学习这门课的学生以及老师而言的,有的学生觉得自己的提问是为将来工作练手,比如幼儿类课程,在问答区去提问1+1等几,1×1等于几,抱歉,那可能您是弄错了【问答】的本质。</p>
<br>
<p><strong>举例一些无效提问的样式</strong>:什么是XXXX(什么叫XXXX)、XXXXX是什么、XXXXX是什么意思、XXXX的含义,即各类“名词解释”、指什么(指的是什么、指代的是什么)、是不是、对不对、好不好、好吗、对吗、可以吗、可以XXXX吗、是否可以、是不是、能不能、应该XXXX吗、是否应该、必须XXXX吗、是否必须、需要XXXX吗,是否需要、一定XXXX吗、是否一定、属于XXXX吗、是否属于、是否合理、是否相同、是否不同、喜欢XXXX吗(中英文版)、如何翻译某个词组/句子(中英文版) ←有且不止这些问题,另外还有一些错字提问,比如“哪”和“那”学生也容易打错,但“哪些”和“那些”,“哪里”和“那里”(举例)从提问的角度来说就完全不同了,或者说就构成不了一个问题。请大家格外注意,即使看到其他同学发了这些问题,建议您也别去回答,不然你的回答也可能会被判为无效(当这些无效提问被删除时)。部分此类问题阿里已会自动识别并屏蔽。</p>
<br>
<p><strong>无效回答主要有3种情景</strong>:</p>
<ul>
<li>1、您的回答字数小于等于3个字(符号不算字数);</li>
<li>2、您的回答对应的提问已被审核删除,则回答也会被一并删除;</li>
<li>3、您的回答被阿里屏蔽了(可在私信内查看)。</li>
</ul>
<p><strong>温馨提示</strong>:没必要特意去举报小于等于3个字(符号不算字数)的回答,因为即使没有人工干预,此类回答平台默认都是做“无效回答”处理的。</p>
<br>
<h1 id="3问答你必须知道的几件事~"><a class="markdownIt-Anchor" href="#3问答你必须知道的几件事~"></a> 3.<strong>【问答】你必须知道的几件事~</strong></h1>
<p>1、学习时间截止前问答分数每天都会根据自己问答的有效性发生浮动,无效越多,分数反而会越低。</p>
<p>2、问答模块切勿发无意义帖、灌水帖、抄袭帖、重复帖、不当言论帖等,系统会判为无效帖,审核团队也会进行删帖,以及禁言等处理。如果您本学期有多门课程,禁言后所有课程都无法参与问答。</p>
<p>3、请不要在问答内发布任何网址链接、QQ、微信、公众号等信息,此类信息平台会以“广告”自动进行屏蔽处理。</p>
<p>4、问答请以问号结尾正常提问即可。包含:括号()、下划线__、选择题(单选题、多选题)&amp;判断题&amp;填空题类型的,会是重点“处理”,特此说明。</p>
<p>5、回复历史学期的提问均为无效回帖(老师的章讨论除外),23秋冬学期建议回复2023年8月15日之后的提问。</p>
<p>6、学习时间结束后发的帖均为无效发帖。学习时间的最后一天请在23:45分之前参与问答,最后15分钟为冷却期,学生可以参与问答,但可能会造成无法获得相应问答数量及贡献度。</p>
<br>
<h2 id="4问答审核人员一般都会删哪些帖"><a class="markdownIt-Anchor" href="#4问答审核人员一般都会删哪些帖"></a> 4.<strong>【问答】审核人员一般都会删哪些帖?</strong></h2>
<p>有些学生会收到被系统管理员删帖的推送,然后就纳闷为什么会被删帖,那今天我们就来说说审核人员一般都会删哪些帖:</p>
<p>1、与课程无关的帖。这个不用多解释了吧,其中以纯水帖为主,比如:今天天气怎么样?你吃过饭了吗?你几点睡觉的?How are you? Do you like XXX? 诸如此类和课程一点关系都没有的帖。</p>
<p>2、虽然帖子和课程有关,但毫无意义(包括灌水)的帖。这里说的“无意义”/“灌水”主要指的是那些答案人尽皆知的帖,比如:新中国是什么时候成立的? 劳动节是哪一天? 李白是什么朝代的? 谁领导的虎门销烟? 《本草纲目》是谁写的?孙子兵法的作者是谁? 床前明月光的下一句是什么? 什么是艺术? abandon是什么意思? 当然这些都只是一些很“小白”问题的举例,拓展开来但凡那种问“谁”、“什么时间/时候”、“哪一年”、各类中英文词语问“名词解释”等等的问题,既然是和课程有关,那在你学习课程视频的过程中都已经知道了答案,那再去“问”,那可能就是“明知故问”了。 另外一些常识性问题,也会有学生提问,“XXX是吗”、“XXX好吗”、“XXX对吗”,这种也是属于会被删帖/屏蔽/无效的范畴。</p>
<p>3、相同问题的重复发帖。一些可能就是纯粹自己想发的,但别人之前已经发过了,还有一些则是看到别人发了个问题回答的人很多,然后自己就想着也发相同的问题也可以收获很多回答。 本学期起,我们引入了AI智能管理,即使没有被删帖,重复发帖我们的AI系统也会将帖子自动判为无效帖。</p>
<p>4、请规范提问格式,以1个问号结尾,若使用多个问号结尾,平台将做删帖处理。同时也提醒其他学生注意此类帖,不要进行回答,提问被删除后,回答也会一并连同删除。 补充:近期我们发现有第三方刷帖行为,其提问格式为“请问XXXXXXXXX??”/“请问XXXXXXXXX。?”,即在正常的问题前面添加了“请问”,以及在结尾处添加了一个或多个问号,看到这类提问,请各位同学不要去回答,我们会每日清理此类重复刷帖。</p>
<p>5、1自问自答类型的提问。即提问中包含问题以及这个问题的答案。引导类型的提问,如回复点赞等。2使用同学姓名恶意制造提问/回答,提问者/回复者追加 3天(起)禁言。 欢迎各位同学看到这2类提问积极“举报”。 重要提醒:1看到此类提问请一定、一定、一定不要去回答,因为当这个提问被审核删除后,回答也会一并自动删除,则回答就会变成“无效”回答!!!2如有恶意举报行为一经查处,智慧树也会视情节轻重上报给学校教务处。</p>
<p>6、个人纬度短时间内使用相同句式连续提问的,经审核人员审核发现一律删帖处理。</p>
<p>7、回答方面,我们也看到了很多水帖,比如:“。。。。”、“不知道”、“不清楚”,还有一些回答完全是答非所问的。这些也都是审核人员会重点处理的。更新:近期发现有些“刷”回答的,其回答的内容根本不是该提问对应的回答,而是完全答非所问的“提问”刷在了回答板块内,欢迎举报此类回答,审核人员会进行删除并禁言处理。</p>
<p>温馨提示:不要为了“分”而“水”,小水小惩,屡教不改者我们会将名单提供给学校教务处,情节严重者将会永久禁言。</p>
<p>p.s.本文主要说的是被管理员删帖的那些事,部分涉及到“屏蔽”。被屏蔽是经过阿里的审核机制自动处理的。</p>
]]></content>
      <categories>
        <category>AimGraduate</category>
      </categories>
      <tags>
        <tag>智慧树</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]10043五年了,逆流留学的我们后悔了吗</title>
    <url>/2025/12/18/10043%E4%BA%94%E5%B9%B4%E4%BA%86-%E9%80%86%E6%B5%81%E7%95%99%E5%AD%A6%E7%9A%84%E6%88%91%E4%BB%AC%E5%90%8E%E6%82%94%E4%BA%86%E5%90%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="18级信通本留学经历安调-gap与海外找工"><a class="markdownIt-Anchor" href="#18级信通本留学经历安调-gap与海外找工"></a> 18级信通本留学经历：安调、GAP与海外找工</h1>
<p>楼主是18级信通本，当初是因为看重wlb以及异国恋感情原因，决定要去留学。在大二大三时出现了 <strong>PP10043</strong>，但是还是不死心，选择了弃保留学。</p>
<p>最近休假了，终于有空来写写这几年的感想和经历。这篇blog可能有些流水账，一方面是希望能给各位学弟学妹一些鼓励，一方面也是想客观表明目前政治环境下留学的风险与机遇以供参考。</p>
<p><strong>Blog由四部分构成：</strong></p>
<ol>
<li>我的经历综述</li>
<li>安调与GAP的反思与心态调节</li>
<li>海外找工经验与流水账</li>
</ol>
<hr />
<h2 id="三年经历快速回顾"><a class="markdownIt-Anchor" href="#三年经历快速回顾"></a> 三年经历快速回顾</h2>
<p>22年本科毕业后，我经历了：</p>
<ul>
<li><strong>（22.6-23.1）</strong> 加拿大学签 安全调查</li>
<li><strong>（25.3-至今）</strong> 加拿大学签境内续签 安全调查</li>
<li><strong>（25.10-至今）</strong> 加拿大PGWP 毕业工签超长审理</li>
<li><strong>（24.6）</strong> 美国J1实习签 长check后rej</li>
<li><strong>（24.11）</strong> 美国b1/2旅游签 当场rej</li>
</ul>
<p>之前发过飞榜，也有不少学弟学妹来咨询过（私密马赛我很久没有上论坛了，有一些没看到的pm请原谅），就不细说BG了。当初拿到了UofT, UBC, IC, UCL, GT, NUS, TUD等等offer，最终选择了 <strong>UofT ECE MEng</strong> 入读。</p>
<p>因为签证原因gap一年23fall入学，目前已毕业。这期间的经历如下：</p>
<ul>
<li><strong>加拿大：</strong> 拿到中厂offer x1（学签续签安调等待4个月后withdraw），M7大厂offer x1（等待pgwp），初创intern x2（项目没有coop）。</li>
<li><strong>美国：</strong> M7大厂intern x1（J1拒签后withdraw）。</li>
<li><strong>瑞士：</strong> intern x1。</li>
<li><strong>中国：</strong> 外企(M7 x2+中厂)intern x3+return offer x2，大厂intern x1， 香港RA x1。</li>
<li><strong>目前状态：</strong> 全职base联合国日内瓦总部工作。</li>
</ul>
<p>我不知道未来我会不会后悔，至少目前而言，我觉得这段经历带给我了许多煎熬（主要是签证），但是给了我许多当年决定留学时从未想过的人生体验与回报，更帮我不断地去思考“我是谁”“我想成为怎样的人”“我想要什么样的人生”。</p>
<hr />
<h2 id="gap-并不意味着人生完蛋但是真的很难熬"><a class="markdownIt-Anchor" href="#gap-并不意味着人生完蛋但是真的很难熬"></a> GAP 并不意味着人生完蛋，但是真的很难熬</h2>
<p>近些年，社交媒体上对于Gap year的态度越来越悲观，几近于gap=人生完蛋从此失业一条龙。而目前签证check（尤其是加拿大的无限期安调）导致的gap风险非常高。这让很多找我咨询的学弟学妹心生疑虑，担心职业生涯是否会受到影响。</p>
<p>先说我的结论： <strong>Depends on yourself</strong>。</p>
<p>经历了若干不可抗力和系统性风险带来的麻烦，我无法说我是幸运的；但是站在今日的时间戳上，我并不后悔五年前一意孤行的选择；甚至对本科后的gap存在一些感谢。</p>
<h3 id="心态与支持"><a class="markdownIt-Anchor" href="#心态与支持"></a> 心态与支持</h3>
<p>在22年7月毕业后发现进入无限期安全调查的时候，看到同学好友们都有了非常明确的未来方向时，说不焦虑是假的。第一次经历家里蹲，第一次感受到无所事事，真的快要陷入极端焦虑和崩溃中。很感谢我的父母与npy并没有责怪我或是逼迫我去找工/考研/去交了留位费的学校，而是给了我充分的精神支持：告诉我只要我想清楚了，能够为自己的选择负责，他们愿意支持。</p>
<p>在本科期间，我从来没有做过任何关于找工作的准备，一直在到处找老师做research，希望能去留学读phd。在崩溃情绪渡过后，我开始重新思考和进行职业规划。写了十多页的草稿进行推演后，列出了快20种可能的时间线与方案，开始了第二年重新申请，完全放弃科研，同时开始找实习。</p>
<h3 id="实习申请的波折"><a class="markdownIt-Anchor" href="#实习申请的波折"></a> 实习申请的波折</h3>
<p>只有足够坚定的心气才有可能支撑住自己在看似hopeless的前景里重新找到自己的路。当时最崩溃的除了加拿大学签，还有从0开始的找实习经历。</p>
<ul>
<li><strong>背景：</strong> 非在校生的身份，非寒暑假前大规模招聘的时间点，0开发背景。</li>
<li><strong>过程：</strong> 在经历n次非常shameful的失败面试后，终于拿到宇宙厂和一个欧企的实习机会。</li>
<li><strong>插曲：</strong> 我选择了欧企offer后，经历了接近半个月的手续期，被他们的法务部门通知不可以招我，因为我并非在校生。team的人都很好，hiring mgr和面试官轮番来安慰我和我解释道歉，但是当时真的快要疯了，我转回去狂舔宇宙厂的offer，则被告知已经找到其他candidate入职了。</li>
</ul>
<h3 id="峰回路转"><a class="markdownIt-Anchor" href="#峰回路转"></a> 峰回路转</h3>
<p>人生无常，大肠包小肠。在崩溃中过了元旦，突然收到了加拿大学签，整个人都活过来了，虽然没有租房没有买机票也甚至还没有交23 winter入学的学费，但是已经准备和等签群的小伙伴一起火速出发了。在临买机票前，我翻来覆去看刚刚安调时推演的方案，最终决定继续defer，继续申请实习和猛猛申请一下之前的梦校，就当买彩票了。我的npy对我的方案给了非常negative的评价但是并没有泼冷水，以及谢谢我亲爱的导师们愿意给我再提交一堆RL。</p>
<p>峰回路转的是，一个月后我拿到了某M7外企的R&amp;D intern，在实习期间又拿到了另一个M7外企的sde intern，实习期间非常开心，获得了很好的feedback和很高评价的return，接着又拿到了一个hk的ra，于是就这样忙忙碌碌度过了一整年，并且remote上了一个学期课。最终，在本科毕业后的第二年年初抵达了多伦多。</p>
<h3 id="留学咨询的初衷"><a class="markdownIt-Anchor" href="#留学咨询的初衷"></a> 留学咨询的初衷</h3>
<p>因为几乎操盘diy了我和npy所有可以申请的学校项目，研究/申请了美加欧新港英的很多很多学校与项目，并获得了不少好的结果，我收到了很多很多咨询，也感受到了帮助学弟学妹的乐趣。于是当时我也萌生了开设一个留学咨询机构的想法，从那时起到现在，我们主要针对半diy申请的同学提供个性化一对一辅导，帮助了不少来自北邮、西交利物浦、南大、上交、上财等学校的学弟学妹申请文书，其中包括了第一年失利第二年再战的，GPA普通的学弟学妹，也包括了top3年级排名顶尖的超级大佬。我们帮助他们申请到了包括但不限于 Stanford EE, NYU PhD 全奖，爱丁堡金数，GT CS, HKU MPhil，NUS CS, UofT ECE, 哥大CS 等等offer。</p>
<p><strong>不论是他们还是我自身的经历，给我留下的最大感触是：和别人不一样的pace并不意味着错误，只要一直在自己的时区里拥有清晰的目标不放弃，总会走到想要的彼岸。</strong></p>
<hr />
<h2 id="海外找工与身份"><a class="markdownIt-Anchor" href="#海外找工与身份"></a> 海外找工与身份</h2>
<h3 id="加拿大现状co-op与pr的选择"><a class="markdownIt-Anchor" href="#加拿大现状co-op与pr的选择"></a> 加拿大现状：Co-op与PR的选择</h3>
<p>先放dp。针对加拿大而言，身边及世界一下，非常非常想要留下的同学朋友基本上都找到工作了，无非是时间长短，工资高低，公司大小而已。但是除了过往就有full time工作经验的朋友，new grad市场确实非常艰难，需要有长期战斗的准备。这并不意味没有coop的加拿大留子就无法留下。但是呢，加拿大待遇并没有比国内大厂们的sp高多少，非大厂的话可能还低许多。所以也有很多非常牛的大佬果断选择回国工作。回国找工作的情况除了超级大包的大佬外，国央企的数据也很漂亮。总体来说，大家都过上了自己还比较满意的生活。</p>
<p>但是不得不说，job market是越来越严峻。22 fall与我同期拿offer没有gap的同学大多已然拿到pr，而且当年还有口罩时期特殊政策带来的不限时长实习政策，所以找工难度明显好不少；而我们这届因为oinp和bcpnp的政策收紧与改革，目前仍不明朗，大家都在纷纷学习法语刷雅思等等泡池子中。不再存在过去毕业即下卡的美梦了。</p>
<p>我在有coop的ubco ee和没有coop的uoft ece中选择了没有coop的项目。在bcpnp毕业即下卡的2023年，这个选择也是一个不太被理解的选择。</p>
<ul>
<li><strong>选项A：</strong> 带coop，费用为另一个项目1/3，毕业即下卡的项目。</li>
<li><strong>选项B：</strong> 算半个cash cow的无coop，需要入池打分拿pr的项目。</li>
<li><strong>抉择：</strong> 毕业证回国认证其实排名差不多的情况下，似乎无论如何都应该选择前者。我基于gap初期时那个对自身职业规划的分析与推演，意识到我需要的并非是立刻的pr，而是工作；找到喜欢的工作，pr自然来；否则有了pr我大概率还是要回国工作。对长期回报而非短期成果的认可促使我做出了这个选择。而在我还未毕业时，bcpnp的stem毕业即pr政策取消了，我只能说一声：阿门!</li>
</ul>
<h3 id="找工经验与美国签证波折"><a class="markdownIt-Anchor" href="#找工经验与美国签证波折"></a> 找工经验与美国签证波折</h3>
<p>那么没有coop的情况下能否找到工作和实习呢？答案是能的。具体不在这里展开了。核心就是：<strong>多尝试，多交流，多刷题。</strong></p>
<p>博主在第一年的summer term期间找到了两个多伦多startup的intern和美国M7的sde intern，美国的厂给了J1 sponsorship，我在经历了长check后，不出意外的出意外了，<strong>212f 10043 rej</strong>。因为10043的影响，我和在美国的npy已经两年多没见面了，这对我们而言确实也是一个很大的打击。我尝试了所有我能够做的方案去美国和npy见面，但是政策之下，我只能说“10043年代，或许不该太遥远的相爱”。此外，因为长check，时间已经来到7月份，我也没有时间再去寻找其他intern机会。</p>
<h3 id="瑞士的机遇与再次安调"><a class="markdownIt-Anchor" href="#瑞士的机遇与再次安调"></a> 瑞士的机遇与再次安调</h3>
<p>依然是前面说的，只要不放弃就依然会有希望。在收到J1 rej的消息后一周，我收到了来自瑞士的UN的intern offer，于是火速在20天内办理了一切手续，从多伦多飞到了日内瓦，开启了为期小半年的实习，再次进行远程上课，实习后获得了口头return。</p>
<p>回到多伦多后，享受了一下最后的校园生活，做了几门课的TA，选了一些并非本专业的课，参与了许多好玩的活动。并且及时办理了学签续签，因为之前的defer和安调，我的学签到期日在毕业前三个月。接着也顺利找到了一个wlb的德企offer。</p>
<p>但是随着毕业时间approaching，我的学签续签仍然没有下 – 没有valid的学签，申请pgwp后是无法在pgwp批准前合法工作的。我写信给当地MP，找学校immigration办公室顾问，和公司法务联系，给卡尼办公室和ircc部长写信，给IRCC写webform打电话等等，尝试了所有可能的方案，最后得出的结论是 – <strong>boom，我再一次进入安调了。</strong></p>
<p>在煎熬等待学签续签到8月份后，公司hiring mgr告诉我实在无法再等我了，他们必须重新开放招聘post。我于是艰难地决定离开加拿大申请境外PGWP，并接瑞士offer。工作期间我收到了另一家M7base加拿大的面试pass等待team match，于是我开始申请PGWP，而我的PGWP申请再次陷入了一个无底洞，从十月到今天，它还在background check中无法自拔。。。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>海外找工，努力和运气缺一不可。我不想唱衰海外市场，但是确实也无法看高这个市场。不谈美国，从职业发展机遇和待遇而言，目前国内的cs就业市场真的算是各国中最顶的存在了，尤其是对于算法而言。因此，更需要的还是深入挖掘自己真实的生活愿景和职业规划，“润”还是回都是不错的选择。</p>
<p>楼主不怎么看论坛内私信，如果要联系的话欢迎邮件：<br />
<code>wx010217 at gmail dot com</code><br />
看到基本上都会回。</p>
]]></content>
      <categories>
        <category>Insight</category>
      </categories>
  </entry>
  <entry>
    <title>[转载]从白月光到滤镜破碎</title>
    <url>/2025/12/28/%E4%BB%8E%E7%99%BD%E6%9C%88%E5%85%89%E5%88%B0%E6%BB%A4%E9%95%9C%E7%A0%B4%E7%A2%8E/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>人年纪越大越爱回忆从前，最近总想起从前的事，现在记录一下，防止老了忘记。<br>概括：从高中时深深迷恋男神，到大学的慢慢释怀，到工作后的滤镜破碎。<br>叠个甲，本人婚姻幸福，老公超棒，只想记录青春时的故事。</p>
<h2 id="一、我认识了一个理科学霸"><a href="#一、我认识了一个理科学霸" class="headerlink" title="一、我认识了一个理科学霸"></a>一、我认识了一个理科学霸</h2><p>认识cc是在高一上学期的一节选修课上，当时08年，山东省如火如荼的搞素质教育，作为本地级市最好的高中，我们首当其冲，应省里要求开了一些五花八门的与考试无关的选修课，每周五下午上。我和闺蜜Y选了走遍中国，上课内容无非就是老师给大家看点纪录片，讲讲中国各地的自然人文。对于我这种小学渣和我闺蜜这种大学渣自然是开心的，周五下午可以逍遥的玩耍了。</p>
<p>选修课跟大学差不多，位置随便坐，有一堂课我和Y到晚了，只剩第一排三个位置了，结果有个男生来得更晚，就坐在了我和Y旁边。他坐下便立马掏出题目来做，超级E人Y立马说，我能看看你的书吗？然后拿过那个男生的书，翻了两下跟我说，乖乖，这些什么题，我都看不懂，然后称赞cc，你肯定是大学霸。<br>我全程没有说话，只是看了cc两眼，他眉眼清秀，瘦瘦的，戴着眼镜，嗯，很理科学霸的长相，但是莫名的觉得亲切熟悉，很眼熟的感觉，但我确信自己没见过他。</p>
<p>后来直到选修课结束，我再也没碰见过他。</p>
<p>几个月以后，高一下学期，应该是4月底的样子，有一天我和初中时的好朋友K去别的班借书，在走廊上遇到了一个人，就是cc，他一下子认出了我，说是你，我也认出了他，正好我朋友K也认识他，说这是XXX，25班的。<br>我第一次知道了他的名字，最后一个字是聪，人如其名，他确实很聪明。然后我们互留了QQ号。</p>
<p>当天晚上他就在QQ上问我，周末要不要去打羽毛球，我高中的时候很害羞，从小到大受到的也是很保守的教育，对于一个刚认识的男同学的邀约，想都没想就拒绝了，其实自己内心对他也有好感的，现在想想当时干嘛不大大方方的去呢。</p>
<p>球没去打，但我心里却从此再没静下来过。<br>我开始四处搜寻他的信息，因为我们高中是全市最好的高中，大部分生源都来自最好的几所初中，又来自最好的几所小学，所以处处是熟人，想打听一个人从小到大的经历太容易了。<br>他是附小的，初中读的附中，他从五岁就开始学物理了，他爸他妈一个物理老师一个数学老师，在我们市的农业技术学院当老师，他家住3路车终点站，他小学就自学完了初中的数学，初中自学完了高中的数学，现在在自学高数，那天那本我和Y都看不懂的题目，就是高数。他考试数理化都是满分，偶尔数学考148是因为那天犯懒，大题步骤写得太简略。</p>
<p>在那样一个成绩比天大的环境中，一个文科生听到这些简直不敢相信，我考不及格的物理，会有人轻轻松松满分，后来那个小木块从斜坡滑下来的受力分析他给我讲了三遍，我还是没听懂。</p>
<h2 id="二、他的心不在高考上"><a href="#二、他的心不在高考上" class="headerlink" title="二、他的心不在高考上"></a>二、他的心不在高考上</h2><p>但让我心动的远不止这些，对于绝大部分高中生来说，拼尽全力能考个好大学就不错了。可他，是我认识的第一个“不愿意拼尽全力”的人。他把很多的课余时间都给了高数，因为他在准备数学竞赛，他甚至不怎么写化学作业，偶尔，他甚至会中午不去吃饭省下时间琢磨竞赛题。</p>
<p>后来熟悉了之后，我问他，你不怕这样影响高考吗？以你的能力，不搞竞赛好好学课本，top985肯定没问题，你为什么非要搞竞赛？他回答，数学是我的梦想，我从小就喜欢数学，上个好大学很重要，但不参加竞赛我会一辈子遗憾，我愿意为了竞赛赌。</p>
<p>那个时候竞赛全省一等奖是可以保送大学的，但二等奖是不可以的。</p>
<p>我又问他，你不怕最后是二等奖吗？<br>他说，所以我要拼尽全力拿一等奖。</p>
<p>一开始我对他是欣赏和羡慕，这之后又多了一份崇拜，我觉得他很纯粹，很酷，他敢拿高考做赌注，牺牲复习的时间来追梦，这是我想都不敢想的。<br>对于一个15岁的女孩来说，只能是深深的喜欢了。</p>
<p>我们那时候还讨论过以后选什么专业。<br>我：我想学金融，我想赚大钱。<br>他：我要学数学系，然后搞一辈子数学研究。<br>我：搞研究很难赚钱的吧？<br>他：我对赚钱没兴趣，我就想一辈子研究数学。</p>
<p>其实那时候就可以预见，我们价值观存在很深的分歧，我一直是一个很实际的人，我也有爱好，我从小就爱看书，我5岁的时候就认识一千多个字，看完了妈妈给我买的儿童版四大名著，小学的时候，我就不听课偷偷看书，茶花女，安娜卡列尼娜，葛朗台，岳飞传等等。我高一的时候，把所有理化生的课都拿来看书了，但我从未想过要学文学相关的专业，因为我知道不赚钱，我的梦想是赚很多钱，足够花了之后再追寻爱好。</p>
<p>我们高中是全市最好的，同学都来自重点初中，那个时候初中已经开始论学区了，所以同学们的家境普遍都比较好，很多官商背景的家庭，他家在我们学校应该算是偏下的水平，我家比他家好一点，勉强算个中等，我们都是普通家庭的孩子，但是他似乎没有什么赚钱的欲望。</p>
<h2 id="三、拧巴的青春期少女"><a href="#三、拧巴的青春期少女" class="headerlink" title="三、拧巴的青春期少女"></a>三、拧巴的青春期少女</h2><p>高二开学之后搬了新的教学楼，我们班和他们班离得近了，一条走廊，中间只隔两个班，而他们班正对着楼梯，意味着只要课间去厕所我就要从那里路过，这对我来说是天大的好消息。</p>
<p>开学没多久，有一次我和Y在走廊遇见他，Y主动跟他打招呼，他却一脸疑惑，问Y我认识你吗？Y立马说，你就光记得裴梓萱是吗？当时选修课上跟你说话的是我呀！他才恍然大悟，哦，那个是你呀，我没印象了。<br>时至今日，我仍旧想不明白，Y这样一个大美女他竟会不记得，Y后来走了艺术生，又去东航做了空姐，在她旁边我还能被记得？可能这就是所谓缘分吧，后来一个算命的也告诉我，我俩前世有缘，所以才会第一次见面就觉得熟悉亲切。</p>
<p>15岁的我，不知道为什么，拧巴得吓人。<br>明明每天都很期待在走廊上遇到他，却偏偏要在每次遇到的时候故作高冷，有时故意不理他，有时态度冷漠，现在真想穿越回去问自己，做个阳光可爱的美少女不好吗？</p>
<p>倒是他，每次都不吝于笑容灿烂，有的时候学小狗状跟我打招呼，他笑起来有深深的酒窝，很是好看，有一阵子常穿一件灰色卫衣，往后的许多年里，只要看见白衣少年四个字，我脑海里就浮现他当时的样子。<br>面上虽然拧巴，但该刷存在感也时也毫不含糊，我们高中没有校服，可以穿自己的衣服，所以那阵子我买了新衣服必定是要赶紧到他们班门口转一圈，有一次我穿了一件粉色的风衣，大家都说很好看，见了他我却高冷的假装路过甚至没有看他一眼，同学跟我说，他站在那里看了半天你的背影。</p>
<p>高二的秋天就在我的拧巴之中飞速而过，我的心思也完全不在学习上，上课看课外书，下课琢磨他。那阵子我读了很多很棒的书，每个月在亚马逊上买七八本书，当月全部读完，应该是我这辈子阅读密度最高的岁月。<br>cc只看到了每天吊儿郎当的我，我想他心里对我是有一些轻视的，他是根正苗红的优等生，学校里的风云人物。我们当时的学校氛围很微妙，不知怎么形成了一种隐形的阶级划分，表面上大家关系都很好，但学校里很多谈恋爱的小情侣，全都是好学生跟好学生，差学生跟差学生，引用我们班班花（也是校花）的一句话，“我要是考个小二本，人家大985的也不会搭理我呀。”听到她这话时我内心是很震惊的，她这般美貌还觉得自己会被人挑剔？<br>可能是山东这个省份很卷的缘故吧，从小我们所受的教育真的是唯读书论，在学校里，你所有的优点都会被抹杀掉，只有学习好是硬道理，好学生做错了事情老师也不会在意，差学生从头到脚就没有对的地方。</p>
<p>但我的处境比差学生还要难受，因为我曾经是好学生。<br>我继承了爸爸的文科基因，但偏偏我妈是个理科学霸，所以五岁妈妈就开始教我奥赛题。小学阶段靠着妈妈的努力，我在那个鸡娃并不普遍的年代，每每在数学竞赛中斩获嘉奖，给了妈妈和我自己一种错觉——我很厉害。<br>初中开始，我慢慢发现，有些数学题聪明同学做一遍就会了，我要做两遍才会，物理题更是。我记得当时学电学并联串联那个地方，有一种题目是考画电路图，这道题我会了，但你换换条件，我又不会做了。妈妈当时并未察觉我在物理上的迟钝，她只是说这么简单的东西，你怎么就学不会？我把书店里所有物理题/辅导书都买回来，那段时间我每天学习到半夜，我把我所能找到的有关的电路的题全部都做了，我终于攻克了电路题，我的物理开始频频高分，我以为自己又行了，但我的物理老师说你不适合学理科，我不以为然。</p>
<p>我初中的学校是一所炼狱般的学校，初一开始哪怕是平时的小测验，都要全班全年级排个名贴出来，我记得一次历史小测验我考了97，全班第一，全校第三，我妈妈看到的第一反应是，你以为自己考的很好吗？你那三分不应该扣。老师们也一个比一个卷，有同学课间一边上厕所一边背单词，被老师拿出来做典型案例大肆表扬，于是大家纷纷效仿。从初一开始，我每天早饭都是要边背书边吃的——被我妈要求的。<br>现在想来，我觉得好笑，初中到底有什么值得紧迫的？老师和家长把我们逼得像上甘岭战役似的。多背一篇课文真的对我以后的人生有那么大的益处吗？反而是他们觉得没什么用的闲书，让我觉得对我现在的人生还有很多助益。</p>
<p>刚毕业时我一个在统计局工作的大学好友，向我求助，说局长要她给买几本书，想去出差的时候无事翻翻，好友也是平时不爱读书的人，不知道买什么好，遂来问我，我当时也没想那么多，恰好我那阵子很喜欢台湾作家蒋晓云，我就推荐了几本蒋晓云的书给她。后来她告诉我，她领导看《百年好合—民国素人志》看哭了，五十多岁的男领导竟和我一样会为几十年前的小人物落泪，抑或是他在书里看到了自己？局长大力称赞好友的品味，后来也是处处关照她。<br>那时我才觉得，我这个在学生时代被老师打压的小爱好，其实是有人认可的，在我硕士毕业后，生活中不乏称赞我的人，但这称赞来得太晚，理科学不好的阴影始终深深笼罩我的学生时代，直到现在每当有人夸我很聪明有灵气，我内心第一反应依旧是惶恐，觉得自己德不配位。</p>
<p>扯远了，扯回来。<br>初中的知识如同在湖里行舟，我的发动机动力虽然一般，但靠着足够卷，也始终是全校前30名左右（我的初中是本市排名第二的重点初中）。初中的我确实是享尽了同学的羡慕和老师的夸赞。<br>不过，家长和学校双重高压还是在初四下学期压垮了我，最后一次模拟考，我的脑子像是坏掉了，数学题错一片，在此之前我的数学一直是满分。最后中考不出所料，我比平时的成绩差了60分左右，靠着血条够厚，我还是考上了本市最好的高中。</p>
<p>中考的致命打击，让本就厌学的我更加厌学。加上我高中母校放羊式的管理方式，我彻底放飞自我了。<br>我的高中自由到什么程度呢，恋爱是随便谈的，逃课是没人管的，作业不交也可以的，烫发染发做美甲都是可以的，我们班主任在学校里捡到过套套，他也只是在家长会的时候提醒家长们注意孩子的身心健康。<br>但我们高中是实打实的省重点，很多顶尖的学生是能够自律，按自己的计划去学习的，或者有的人可以边学边玩，像我这样被鸡娃鸡大的，就只能直线下滑。<br>中考的打击也让我妈醒悟过来，或许高压管理并不会让孩子一路优秀，所以我身上的所有枷锁都被拆除了。高一开学前我美美的烫了头发，开学后买很多漂亮衣服换着穿，自习课在操场上吹晚风用MP4听音乐，和好闺蜜Y、G到处乱窜。<br>高中的数理化难度本来就比初中上了强度，课堂上我就会有一些听不懂的东西，但此时我已对理科产生深深的厌恶，课下根本不会静下心来学习，我记得高一最后一次期末考试，我物理考了20+，数学70+（150的满分哦），年级排名1078（1500个人，如果按我初中时的成绩排名应该是200左右）。</p>
<p>这样的堕落，让我既快乐又不快乐。<br>快乐的是我终于不用再学习，不会有人因为我少考了一分就批评我，和同学们玩的也很开心，高二下学期世界杯那阵子，每天晚自习和不学习的同学一起看球是我此生难忘的美好回忆，我交了很多差生朋友，他们有很多的闪光点，没有精英式的傲慢，我们也不用攀比成绩，我好喜欢他们。<br>不快乐的是，不被主流群体接纳，老师觉得你是差学生，所以你在他们心里低人一等，好学生们更是会暗暗的看不起你，以前享受惯了优等生待遇的我，很难适应这种落差。</p>
<p>cc认识我的时候，正是我成绩最差的时候，后来他偶然听别人说了我初中时的状况，颇为惊讶的问我，你以前学习那么好吗？你现在怎么这样了？那目光有惊讶也有欣喜，我明白，他希望我是优秀的。</p>
<h2 id="四、他喜欢我or他不喜欢我"><a href="#四、他喜欢我or他不喜欢我" class="headerlink" title="四、他喜欢我or他不喜欢我"></a>四、他喜欢我or他不喜欢我</h2><p>cc是女生缘很好的人，据说全年级有二十几个女生明恋/暗恋他，具体有多少我也不知道，但如果你跟他从学校门口一起走到教室，一路上确实会有很多女生跟他打招呼，我不知道怎么会有那么多别的班的人认识他。<br>高二上学期，我前3个月的时间全都在思考一件事，他到底喜不喜欢我，我们之间是有一些隐隐的暧昧，但他女生缘这么好，真的会喜欢平平无奇的我吗？</p>
<p>好友Y和G每天被我拉着分析cc的每一个眼神和表情。<br>2009年10月31号那天罕见的下了一场大雪，大家都在操场上打雪仗，我素来喜静，却也拉着Y和G陪我去操场上散步，我知道cc这么爱热闹的人一定会在，我想被他的雪球砸中。<br>走到操场上，我假装和平时一样，兴高采烈的和Y、G聊天，余光却一直在搜索cc的身影，操场快走到头了，还没有看到他，心里颇为焦急，Y敏锐的察觉到了，跟G说，咱俩现在是陪衬。<br>就在这时，一个雪球啪砸中了我，一回头，正是cc，那一瞬间惊喜万分，脸上却嗔怒，你干嘛砸我？cc带着三分贱兮兮的笑容，伸出手里剩下的雪，说那你也砸我一下嘛。<br>我一言不发的扭头跑了，现在的我也不理解当时的自己怎么演技如此高超，心花怒放地同时可以把高冷演的这么好。</p>
<p>高二上学期，爸妈得知了有个渠道可以把我送到新加坡去读高中，在那里读一年语言学校，然后上高中，然后参加A-level考试，可以考新加坡本地或其他英联邦国家的大学，毕业之后新加坡绿卡很好拿，他们觉得那里没这么卷，或许对我更好。<br>我当时年纪小，认知不足，也不知道自己会不会喜欢那里，妈妈觉得好我就觉得应该没问题。于是爸妈开始大操大办这件事。</p>
<p>如果没有这件事，我可能永远不会有勇气跟cc表白，后来的事情可能也就都不会发生。<br>当时我以为自己很快就要离开中国了，以后可能就定居外国了，再也不会回来了，那阵子Y和G也鼓动我，你难道让你喜欢他这件事一辈子都埋在心里吗？</p>
<p>于是，在没有任何事先准备的情况下，2009年12月8号下午的那节体育课，我跟Y、G压操场的时候，我头脑一热，说我待会儿要去跟cc表白，G还特意帮我把凌乱的刘海梳了梳。<br>我回到教室给cc写了一封表白信，夹到先前问cc借的物理书里，打算下了课就去给他。<br>信的大致内容是：我还有一个多月就要去新加坡了，在我走之前，我想告诉你，我其实偷偷喜欢你很久了。<br>接下来的一节课是自习课，我整个人都很焦灼，cc看信了吗，他会怎么想？他喜欢我吗？他如果不喜欢我会不会因此而看轻我。</p>
<p>15岁的我自尊心太强，生怕自己被人看轻或取笑，开始后悔跟cc表白这件事，我觉得自尊是比感情重要很多的东西。<br>自习课下课就是放学了，我们学校都是走读的，没有住校的，晚自习也是自愿的，很多人是不来上晚自习的。<br>我决定一下课就飞奔去cc他们班，堵住他，也许他还没看到物理书里的信，我要赶在他回家之前拿回来。<br>结果，cc他们班居然空无一人，等了两分钟陆陆续续有人回来，原来他们是去上物理实验课了。</p>
<p>接下来的那个画面，我终生难忘，cc穿着那件灰色的卫衣，手里拿着物理课本和两节1号电池，笑嘻嘻朝我走来，我把他拽到无人的拐角处，他问我，你有事找我呀？语气里带着几分惊喜，可能因为我平常总是高冷。<br>我：我夹你物理书里的东西你看到了吗？<br>他：刚才我光忙着做实验了，没翻书，什么东西呀？<br>我听到他还没看，立马去抢他手里的书，想拿回来。<br>结果他比我敏捷，一下子拿起我那封信，说我现在要看。<br>我羞得立马转过身去，他很快读完了，说你不要害羞呀，喜欢一个人是很正常的呀。</p>
<p>接下来我们两个都不知道该说些什么，两个人都是低着头对着窗户，沉默了有一两分钟，他用带着一点犹豫和迟疑的语气问我，像你这样的女孩子肯定不能接受牵手吧？<br>天哪！如果搁现在，我肯定直接上去拉他的手，但那个时候我太害羞了，我心里悄悄地骂他，你这么问让我怎么说呀，我怎么好意思说可以，我只能低着头不说话。</p>
<p>那天后来发生了什么，我是以什么样的心情回家的，我完全不记得了。</p>
<p>如果故事到此，听起来是很美好的一个故事，只是后来发生的事情远超我的预期。<br>我那个时候并没有处理若即若离的暧昧关系的经验，15岁的感情太热烈纯粹，我又是爱憎极度分明的人，喜欢一个人就掏出自己全部的炙热。</p>
<h2 id="在我现在31岁的心智看来，男人其实是害怕炙热的感情的，尤其在他们没做好准备要负责任的时候。对于cc这样桀骜不驯，孤傲如寒剑的少年来说，炙热如火的感情不会让他更喜欢我，我应该努力发展自己，无论学习还是其他，做一株离他不远也不近的空谷幽兰，吸引他自己不舍得走掉。"><a href="#在我现在31岁的心智看来，男人其实是害怕炙热的感情的，尤其在他们没做好准备要负责任的时候。对于cc这样桀骜不驯，孤傲如寒剑的少年来说，炙热如火的感情不会让他更喜欢我，我应该努力发展自己，无论学习还是其他，做一株离他不远也不近的空谷幽兰，吸引他自己不舍得走掉。" class="headerlink" title="在我现在31岁的心智看来，男人其实是害怕炙热的感情的，尤其在他们没做好准备要负责任的时候。对于cc这样桀骜不驯，孤傲如寒剑的少年来说，炙热如火的感情不会让他更喜欢我，我应该努力发展自己，无论学习还是其他，做一株离他不远也不近的空谷幽兰，吸引他自己不舍得走掉。"></a>在我现在31岁的心智看来，男人其实是害怕炙热的感情的，尤其在他们没做好准备要负责任的时候。对于cc这样桀骜不驯，孤傲如寒剑的少年来说，炙热如火的感情不会让他更喜欢我，我应该努力发展自己，无论学习还是其他，做一株离他不远也不近的空谷幽兰，吸引他自己不舍得走掉。</h2><h2 id="五、数学竞赛班"><a href="#五、数学竞赛班" class="headerlink" title="五、数学竞赛班"></a>五、数学竞赛班</h2><p>要讲清楚我和cc的那段往事，就不得不引出另外几个人了，T和赵，还有贾老师。<br>贾老师是我们全市最厉害的数学老师，不教cc他们班，但学校为了让尖子生们冲竞赛拿奖，于是贾老师每周二晚上，每周六下午要在北楼的一间空教室里给他们讲竞赛题，自愿参加，也不收费。<br>这个竞赛班大概有二十来个人去，大部分都是学有余力，奔着去学点高数有意思的理科学霸，我的初中同学赵就是其中一个，他们是以很松弛的心态来上这个班。只有四五个人是奔着拿奖去的，其中最被贾老师看好的就是T和cc。<br>T身高185，瘦得惊人，晚饭喜欢买个夹饼带回教室边吃边做题，平时表情也多是呆萌呆萌的，和cc的喜好社交、桀骜不驯比，T显得非常沉稳甚至有点沉闷。T也是双教师的家庭背景，爸妈都是我们地市XX学院的数学老师。</p>
<p>自表白事件后，我和cc虽然没有说我们到底算什么关系，但却是实打实的更进了一步。<br>一个周二下午，我路过25班门口，cc问我，晚上你也来我们竞赛班听课吧？我轻轻的点头，心里炸开了花。<br>那天放学后，我第一个拎着书包冲出教室，想着赶紧回家吃饭然后赶回来去竞赛班找他。（我家离学校15分钟）<br>我几乎是小跑着下楼，就在我快下到1楼时，听闻头顶上传来一声裴梓萱，冬天天黑的早，楼梯上没有灯，我抬头什么都看不到，但心里感觉，一定是他。<br>我停下脚步，有个黑影追过来，裴梓萱，晚上的竞赛班你会来吗？<br>我：嗯嗯，我来。<br>我们相视一笑。</p>
<p>等我第二天听到Y的描述，更是美得冒泡。<br>原来昨天放学铃一响，我冲刺跑的同时他也飞速杀到我们班找我，怕我忘记晚上去，没找到我，就逮住Y问，裴梓萱呢？Y说她刚走了。于是他又冲下楼找我，楼梯上那声呼唤便来源于此。<br>他跑得可真快呀，我们教室就在2楼，我自以为是飞奔，没想到我还没下到2楼，他已经跑到我们班又跑到楼梯上了。</p>
<p>日后我因为觉得他疏忽我、不够在乎我，而跟他闹脾气，甚至最后走向决裂。现在写下这些文字的时候，我仿佛又回到了那个场景下，我突然觉得那些都不重要了，有过这样一个瞬间就足够了，在我年少的时候，有过那样一个傍晚，我喜欢的男孩，他虽然有竞赛重任在身，但还是那样迫不及待地想和我待在一起，哪怕在那个竞赛班里，我们能说话的时间加起来不到五分钟，但能坐在你旁边，我就是天底下最开心的人。如果时光能倒流，我一定会好好珍惜能坐在你身边的每个时刻，我不会再在意你喜欢我没有我喜欢你多这件事。</p>
<p>说回那个晚上，我在家里草草吃了几口饭就赶回学校，来到竞赛班的教室里。<br>教室里没什么人，大家用书占好位置就去吃饭了，都还没回来，我在教室后排找了个没人占的位置悄悄坐下，过会儿我的初中同学赵回来了，正好他就坐我前面，我们便聊了起来。<br>不一会儿，cc也回来了，他进了教室，绕了一圈，看到我坐在那里同赵聊天，就走掉了。他没同我说话，我自然也不好意思先叫他。<br>很快，他又回来了，手里还多了两瓶果粒橙，走到我桌子跟前，略带羞涩的放下一瓶就走了，又是一句话没说。<br>又过了几分钟，教室里人渐渐多起来，他这时候走到我跟前，略带羞涩的问我，你坐这里吗？<br>我抬起头，不解的看着他，他不好意思的指指第二排正中间两个座位，说那俩是我占的。<br>我方才明白，原来他一早给我站好了位置，于是悄悄地拎起书包，跟在他身后走过去。</p>
<p>那是2009年，回想起来我也觉得不可思议，那时候我们都这么羞涩的吗？多么简单一个事儿啊，我不好意思开口问他坐哪里，他进进出出好几趟才鼓起勇气叫我过去。<br>我能清晰地回忆起那天晚上的感觉，老师在台上讲着我听不懂的高数，我的心怦怦的为坐在我右边的男孩跳着，我偷偷的用余光看他，看他认真做题的侧脸，看他抢答时意气风发的样子，我在心里乞求上苍，能不能此刻来一场大地震，把我和他都砸死在这里，这样我就能永远和他在一起了。<br>多么稚气又纯真的想法，现在即使再爱一个人，我也不会希望和他一起死掉，但那个时候，我觉得只要能永远和他在一起，马上死掉也很幸福。<br>心里能有这样的期望，也说明了我那时候有多么想牢牢抓住他，而潜意识里也知道自己可能抓不住。</p>
<p>回家的路上，我牢牢地攥着那瓶果粒橙，那不是我第一次收到来自男孩的礼物，却是最兴奋的一次，我甚至舍不得喝，把它一股脑儿全浇到我家楼下的槐树上，边浇还边跟小树说，小树小树，你能帮我永远记住这瓶饮料的味道吗？<br>随着年龄渐长，后面谈恋爱收到的礼物越来越贵重，现在即使收到一个香奈儿包包，我也不会再有那股兴奋劲儿了，要不人人都说青春好。<br>这些事在别人眼中可能都是很小的事儿，听起来也有些无聊，甚至cc本人大概率也早就忘掉这些了，他后面有过那么多段感情，我也不是他的初恋，我只是他生命中一个不起眼的切片，但这些确实是我青春的第一口酸。<br>我大学和读研时谈的两段恋爱，分手后都淡忘了，内心再没有波澜，唯独cc，即使后来他变成了一个浑浑噩噩的人，我的记忆里也永远存留着那个意气风发的少年，他的孤傲，他的锋芒。</p>
<p>PS附图一张，2009/12/08表白事件第二天，我因为害羞不敢面对cc，放学的时候看见他直接跑掉了，晚上看到他在QQ上给我留的言，这张截图一直存在我的百度网盘里。</p>
<p><img src="https://pic1.imgdb.cn/item/69509eaf161224305eb31203.png" alt=""></p>
<h2 id="六、少年的心事"><a href="#六、少年的心事" class="headerlink" title="六、少年的心事"></a>六、少年的心事</h2><p>我们那届开始不再分尖子班，师资平均分配，cc他们班分到了比较差的数学老师，听说有几次讲到比较难的数学题，老师讲解的思路并不清晰，最后老师竟把cc叫上台讲题。<br>这是外人眼中的他，风光无两，也是我们不熟的时候，我眼里的他。</p>
<p>熟悉之后，我开始了解到，孤傲的少年，其实心一直悬在刀尖上。<br>他那在我看来惊世的天赋，放在天才堆里也只是泯然众人矣。<br>有次我鼓励他，天道酬勤，你为竞赛投入这么多心血，你一定可以的。他却苦笑着说，天道酬勤，可是名额只有40个，老天酬不酬得过来呀。</p>
<p>cc没跟任何人提起他想拿一等奖这事儿，别人问起，他都是说学着玩玩，无所谓拿不拿。但私下，他不止一次的，跟我透漏过自己的焦虑。<br>他告诉我，数学竞赛试卷是满分300，前100分是选择填空，后面200分是四道大题，一道50分。100+基本就能拿一等奖了，也就是说能做出来一道大题就差不多。<br>我做真题，有时候能做出一道大题，有时候不能，但T基本都能做出1-2道大题。他沮丧地跟我说，我们模拟考试，大多数时候T都比我考得好，我只有一次比他考得好。<br>除了鼓励，我也不知道该怎么安慰他。<br>T似乎是比他更有天赋，我深知勤奋是打败不了天赋的。</p>
<p>说到勤奋，T似乎也是更胜一筹，寒假cc和T等几个人去济南参加山大的竞赛培训，晚上下课之后他跑到网吧上网，告诉我，T真的不是人类，一天六个小时的高强度烧脑课程后，T下课后就买个面包接着去自习室做题了，而他的脑子已经烧短路了，只能出来网吧放松会儿。<br>他又问我，咱们高中每年都只有一个竞赛一等奖，我们这一届真的能出两个吗？</p>
<p>贾老师在网上搜寻了各省有价值的竞赛题，打印成了一个厚厚的大本，给cc和T一人一本，一个月后，T做完了三分之一，而cc只做了个开头。<br>更令人惊讶的是，T的成绩完全不受准备竞赛这事儿的影响，每次考试都是年级前20，有时候还能考到前5。我们那届最后的高考成绩全年级670以上的6个人，我不知道T到底有多高的智商，又付出了多少努力，可以如此完美的平衡。</p>
<p>插句题外话，对于T，我一直都是深深的佩服，不论当年还是后来，2020年T从莫斯科来北京参加一个学术交流会，我们在中关村约了个饭，聊起这些年他的种种，T一如往常的谦逊坦诚，我从没觉得自己多聪明多厉害，我只是喜欢天天和数学在一起的感觉。<br>T后来走上了cc理想中的人生道路，一直从事数学研究，每每在朋友圈分享自己的研究计划，当然我是一个字都看不懂的，哈哈。<br>T读大学之后，经常看到他在朋友圈分享自己的学习，带着面包和水杯，在自习室奋战24小时，我一开始也惊讶，学霸不都应该是低调的吗？不都是嘴上说着不学然后偷偷学的吗？T真的是个另类，他从不介意分享自己的勤奋，也从不介意分享自己的野心。<br>竞赛前他在QQ空间发说说，说自己想拿一等奖；大一时，他发说说，说四年后一定要拿到巴黎高师的offer；读研后，他说自己特别崇拜俄罗斯某个数学大牛，想follow他。他似乎从不怕公开自己的目标，也不怕实现不了被人打脸，不过后来，他真的全都实现了。<br>T唯一立了flag没实现的，是他喜欢一个女孩，他是高考后立了追那个女孩子的flag，后来追到了，但很快女孩就放弃了，“这不是我要的感觉”。T百思不得其解，不再打扰，但是每年都会发朋友圈祝她生日快乐，我记得前几年T还发过一条，大意是我这辈子不会喜欢别人了，如果哪天你愿意再给我机会，请告诉我，我随时等你的消息。</p>
<p>那时候我很年轻，也从没有过孤注一掷追求什么的经历，对于cc的焦灼很难有切实地理解。我上学早，他们普遍大我1-2岁，都把我当小孩儿看，我也确实不如大家懂事，在那样一个时期只有恋爱脑。<br>成年后的两次恋爱，每段故事开始的时候，我都是带着飞蛾扑火的热情扑向对方，事后看来，我觉得对方当时并没接住我的热情，他们是喜欢我的，但我总觉得自己的赤诚没人懂。<br>我闺蜜劝我，你不要这样，容易得手的就不会珍惜。我是死性不改的人，我会拉扯，但我不想，我又不是在跟hr谈薪资，爱情难道还要讨价还价，如果非要算计得失那不如结束，我心目中的感情，侠义是第一位的，你能两肋插刀，我就舍命相陪。</p>
<p>第三次恋爱我认识了我现在的老公，我俩一见钟情，见过第三面，他说让我搬到他那里去，我没有一丝一毫的顾虑。因为他工作忙，加班多，如果我们想每天见面，这是最好的办法。我的闺蜜们都说，刚认识就同居，你这样很危险。但我听不进去，我就想每天都能看到他。所幸，这一次扑火的飞蛾被人温柔的接住了，认识两个月的时候，我说我们结婚吧，他当时正在给我组装衣柜，一边拧螺丝一边说好啊。现在结婚六年多了，我们都觉得很幸福，也庆幸彼此都是简单直接的人。</p>
<h2 id="七、他喜欢粉色"><a href="#七、他喜欢粉色" class="headerlink" title="七、他喜欢粉色"></a>七、他喜欢粉色</h2><p>我还去过一次周六的竞赛班。<br>那天下午下课的时候已经六点多了，整个学校漆黑一片，不知道是哪位消息灵通的同学，说昨天半夜有个女生因为感情问题在学校里坠楼了，送去医院抢救了，现在生死未卜，地上的一大摊血迹还没清理呢。<br>周六学校没课，所以，我们应该是第一批知道这个消息的学生，大家都很震惊的讨论到底会是哪个班的，cc等几个男生更是兴奋的要去看那摊还没清理掉的血迹，二十多个人里就没几个女生，男孩子们兴致勃勃的一定要去看看，我害怕这种血腥的场面，就趁人不注意悄悄地溜走了。<br>等我回到家之后，又收到了cc的QQ留言，问我什么时候悄悄走了？他本来还想送送我的。</p>
<p>当时临近出国，我准备了一大本同学录给大家写，那个年代的人应该都懂，以前有多流行这个。<br>cc写完给我的时候，我一眼注意到最喜欢的颜色：粉色，忍不住笑出声。<br>高中的我狂爱粉色，十件衣服九件粉色，冬天的毛衣，大衣，珊瑚绒外套，羽绒服全是粉的，这不明显是在说我吗？<br>这简单两个字，粉色，够15岁的女孩开心一整个冬天。<br>cc真是撩妹高手，或者少女内心早就波涛汹涌，只需一个引子就能翻出惊涛骇浪。<br>（同学录现在还存在我家，cc在背面写了一大段话，我已经全然不记得写的什么，应该也是有些暧昧的，等过两天我老妈从沈阳回来，我让她拍个照发过来）</p>
<p>也是在那段时间，cc还约我去打过一次羽毛球，一开始我不太想去，因为确实不太会，后来他又叫上了一男一女两个朋友。<br>我们去的是师专羽毛球馆，门票是8元/人，买票的时候另外两位同学一人掏出10元，cc掏出一张20的，我没领会他的意思，直接从兜里掏出10元递给窗口，cc表情一怔，说你自己付钱呀，我还想请你来着。</p>
<p>那时候大约还有一些类似的片段，一点一滴给了我一种错觉——cc想跟我跟进一步。</p>
<p>当时离我去新加坡还有二十来天，我的两个好闺蜜Y和G在某天告诉我，她俩商量着在我走之前送我一份大礼——她俩想去替我告诉cc，你别看那个裴梓萱她天天那么害羞，你抱她一下她肯定不会躲开。<br>现在回想，觉得Y真的好勇敢，这个事情她和G讨论了好几天，本来想不告诉我就直接实行，后来又觉得还是得让我心里有个准备。<br>我和cc的关系中，从认识到后来，Y助攻了好几次。<br>有一次是因为什么，我们大家都把自己小时候的相册带到学校分享，那天我很想让cc看，但又不好意思自己拿去给他展示，聪明如Y，直接一把从我手里抢过去塞给cc，说你看裴梓萱小时候多可爱。我还要假装不乐意，大喊，WEY你个叛徒，你怎么拿给他看。<br>过后，Y说，刚才演得有点过了哈，请我吃方便面吧，我知道你想给他看。</p>
<p>于是在元旦放假前，Y和G真的在某个课间拦住了cc，说有秘密告诉他。</p>
<h2 id="八、矛盾的他"><a href="#八、矛盾的他" class="headerlink" title="八、矛盾的他"></a>八、矛盾的他</h2><p>整个高一我都在昏沉的堕落着，连我最喜欢的英语和语文也不学，一分钟都不想学习。<br>有一次被英语老师抽上台听写单词，几十个单词，我竟然一个都写不出来。<br>那会儿语文考试会考一篇课内的文言文阅读，再考一篇课外的文言文阅读，课外的那篇我往往可以拿满分，课内的却不能，因为我压根不背。飞飞问我课外的文言文到底咋学的，我真想不出来，我就是跟着感觉来答题的，非要说，可能因为有一阵子喜欢看诗经。<br>进入高二，我转变为清醒的堕落，具体表现为：开始认真学英语、语文以及数学，以及认真做所有科目的笔记。我心中有一个信念，虽然我现在不学习，但我以后肯定是要学的，所以我得写好笔记，将来才有东西可学呀。</p>
<p>cc有一次跑来借我的地理书和笔记，我想他也只是找个由头来跟我说话，不然干嘛放着那么多学霸的不借。<br>他看到我的课本和笔记大为震惊，大概他想象中像我这样的差生，应该是课本崭新或者布满涂鸦，但他打开只看到了工整的笔记，重点与难点用不同颜色的笔标注清晰，补充扩展的知识点也分条罗列。<br>cc：你的笔记怎么写的这么好？那你地理怎么考的那么差？<br>我：我记笔记是为了以后学。<br>cc：你怎么还要等以后学？现在高二都快过完一半了，你要等什么时候？你还打算学吗？<br>我：。。。。。。</p>
<p>直到我们决裂那天我才知道，他对我的吊儿郎当不满已久，这个时候我还未察觉他心里的鄙夷，事实上，到今天，我也无法完全理解他当时的心态，瞧不起我可以不来找我呀。</p>
<p>后来，赵跟我讲了一些事，我猜想，也许cc要的就是介于恋爱和朋友之间的状态。他从来没明确的表过态，却又不停的做出暧昧的举动，他会在我哭的时候，轻轻抚摸我的刘海安慰我，但转头又跟赵说Q白白净净的好可爱。<br>我真的适应不了所谓的暧昧关系，和男生我只能是两种关系，要么是恋爱，要么是朋友，介于两者之间的关系很奇怪。我是高敏感性格，容易内耗，我处理不好任何悬而未决的关系。</p>
<p>看到这里，前面吃糖的朋友是不是感觉自己被骗了，这个故事的A面确实是青涩的心动，B面却是残忍的人性。<br>那个时候他是学校的风云人物，女生崇拜的对象，他是这个小圈子里食物链顶端的人，两性关系中选择权更高的那个当然可以为所欲为，这个道理我19岁才明白。<br>不过有一点年轻的我们都想错了——以为高考决定人生的一切，他以为他会从此平步青云，我以为我这样不入流的人一辈子只有仰慕他的份儿。</p>
<p>写这篇其实不只是回忆青春时的朦胧情感，更是感慨人生的波谲云诡，多的不剧透了，继续慢慢往下写。</p>
<p>元旦之后，Y和G设计的那个拥抱，如期发生。但我对此记忆很浅，具体是哪天也不记得了，位置是在文化广场西侧的大树下，至于那天说了什么，愉快与否，已经全然忘记。<br>这个时间段，我们关系大约还是可以的，我记得我三天两头的给他写信，最长的一封足足写了六页纸，应该都是些很幼稚的话吧。<br>有两天中午，好像我跟他多聊了会，他觉得我耽误他时间了，反复跟我念叨“存天理，灭人欲”，现在想想，也许这话不只是对我说的，更是对他自己说的吧。</p>
<p>2010年1月9号，是个周六，一早他在QQ给我留言说今天下午因为贾老师有事暂停上课，我们出去走走吧。<br>收到此条消息的我，惊喜万分，因为我们两个还从来没在周末单独出去玩过。<br>他QQ上只简单说了两句就下线了，时间地点都不清楚，我再发就没人回了，等到中午，我只能给他打电话。<br>单纯的我并没想到，他不回消息也许是有什么麻烦，而电话直接打到他们家，更是引爆一个大雷。</p>
<h2 id="九、可怕的他爸"><a href="#九、可怕的他爸" class="headerlink" title="九、可怕的他爸"></a>九、可怕的他爸</h2><p>我妈从小对我学习要求严格，但其他方面相当纵容。<br>我不喜欢军训，觉得又晒又累，高中开学我妈就给我请了病假，军训完我才去上学。<br>刚开学给我调的座位我不喜欢，爸妈也是第一时间去班主任家送礼。也因此导致班主任一开始对我印象不太好，说我太娇气。</p>
<p>包括我和cc的事儿，我妈一早就知道的。<br>为了让我能更光鲜靓丽的出现在他面前，我妈甚至陪我逛街买衣服帮我搭配，在only试到一条牛仔裤，我妈非让我买小一号的，我说套不上秋裤了，我妈说你就不能冻着点，这样显腿细。我好像就是从那个冬天开始不穿秋裤的。<br>倒是我爸，一开始有几分反对，结果直接被我妈揭老底，你十五六岁就跟小翠去麦子地里约会你忘了，许你不许她？我爸不服，说这不是怕影响学习吗？我妈直接怼，人家学习那么好，你闺女不影响人家就不错了。我爸彻底败下阵来，不再过问此事。</p>
<p>我并不了解cc家是怎么样的氛围，我只觉得他考虑问题的时候特别喜欢装大人。<br>比如当他得知我要去新加坡的时候，第一反应是那岂不是要花家里很多钱，还劝我不要去。可是新加坡留学真的不贵，至少对于我家来说确实不构成负担，而且那边大学的奖学金很多，但他还是反复提到经济问题。<br>比如我说你等我从新加坡回来哦，他说明年你就不记得我了，我说怎么会，他一副你是小孩我不跟你争论的神情。</p>
<p>那天下午我们如约见面，见面后他显得心事重重的，说话情绪也不太对劲，我问他怎么了他也不说。那天聊了些啥我也不记得了，应该都是很幼稚的话题。<br>我当时应该有鼓动他高考完申请美国的大学，说你想搞科研肯定还是美帝环境更适合呀，他总是一副不相信的样子，说我想法天真不靠谱，不知道他是不相信我说的话，还是不相信自己能实现。他真的像一个信息闭塞又顽固的老头，听不进去别人的任何建议。</p>
<p>等我回到家，妈妈告诉我，我刚走不久，就有一个电话打到她手机上，是cc的爸爸，上来就是不客气的方言质问：聪聪是给你出去玩了白？<br>我妈：哈？<br>他爸一听是个大人，立马问：聪聪是给嫩闺女一起出去玩的白？<br>我妈反应贼快，直接说：啥？什么东西？你打错了吧？然后挂掉电话。<br>我妈跟我说，我才不想跟他讨论孩子的恋爱问题呢，早恋有什么错，早恋说明生理心理都健康，对异性没感觉就该去看病了。<br>我妈可真酷。</p>
<p>我和几个闺蜜的家长都算是比较开明的，我第一次知道，原来有家长是要监听孩子的电话的。<br>晚上我在QQ上问他，你爸爸是不是说你了？他是不是不让你出来呀？你迟到也是因为这个吧，你心不在焉也是因为这个吧，我是不是给你惹麻烦了。<br>但他插科打诨的根本就没回这句话，cc性格活泼，但却不爱表达自己内心，他什么都不说，那天到底发生了什么，我始终不知道。<br>（我对男生的理解不够透彻，有人能给我解答一下吗，为什么他就是不肯告诉我发生了什么）</p>
<p>因为这个事情，他好像失去了接电话的权利，后面他家所有电话都是他爸接，听到是男同学才会交给他。<br>再后来我了解到，他爸是一个专制、顽固、封建的家长，一个集网络上对山东人的刻板印象于一体的中年男人。<br>cc的内心是叛逆的，但某种程度上，他也继承了他爸的顽固，他后来许多的人生选择也印证了这一点。他看似反叛，其实他打心里也认同他爸说的那套，我当时年纪小并没理解这么深刻，只觉得他被管得好惨，现在想想，如果他真如他外表那般桀骜不驯，后来还会走上那条路吗？</p>
<h2 id="十、迟到的理解"><a href="#十、迟到的理解" class="headerlink" title="十、迟到的理解"></a>十、迟到的理解</h2><p>电话事件之后，我就不敢再给cc打电话了，有时候实在需要找他，我会先打给畅哥，让畅哥再转达。<br>畅哥，改改，和cc他们三个应该是类似三剑客之类的，关系很铁。<br>畅哥是个性情中人，也是为爱不顾一切的性格，我俩很投脾气。我们是因为cc才认识的，在我和cc的事件中，他一直站我，后来我和cc决裂，他俩的关系也因此疏远了。</p>
<p>年纪小的时候，很难注意到自己拥有的东西。<br>现在回头看，发现自己何其幸运，在和cc的整件事里，Y是亲闺蜜就不说了，畅哥和老赵一直是无条件站我，老赵在连整件事的来龙去脉都不清楚的时候，就坚定的告诉我，他嘴里说的关于你的我一点都不信，你们两个人之中如果有一个是虚伪的，那一定是他。畅哥前期一直是不停助攻，后期发现cc不对劲之后，又极力劝我放弃，不厌其烦的开导我。</p>
<p>据我现在分析当时的聊天记录，电话事件之后，他就开始疏远我，是我幼稚没听懂他的话里有话。<br>除了疏远，他对我的那一丝瞧不起也愈发明显。</p>
<p>我飞新加坡的机票是1月19号的，1月13号起我就正式办了休学，可以不用去上学了。<br>可我每天还是在下午快放学的时候跑去学校，找同学们玩，找他玩，要走了，我舍不得他们每一个人。那时候我完全是小孩子心态，根本不想太多，cc却说，如果我是你，我不会来学校找其他同学玩，你整得好像是从国外荣归故里似的。我反驳他，我只是来找大家玩玩，你怎么想这么多。他说，你真是跟正常人不一样。</p>
<p>好吧，人情世故上他确实是比我考虑得成熟，他也更要面子，怕被人议论，怕丢人，我现在能理解他了，但我依旧不赞同，人这辈子早晚是要变成一堆白骨的，我不管别人给我贴什么标签，我自己尽兴就好。在这一点上，我老公跟我的想法是高度一致的，除了那些留名历史的人，死了以后什么都是空的，难道世人会评价说这堆骨头比那堆骨头更高尚，更勤奋，更光荣？</p>
<p>1月15号晚上，他又神神秘秘的暗示我16号的竞赛班不要去，不肯直说，兜兜转转半天才说出来，因为我去了那两次竞赛班，跟他坐一起，被贾老师发现了，现在贾老师看他的眼神他觉得不对劲，说大人看穿小孩太容易了。其实他大可以直说，我也不想给他造成坏的影响，我肯定都会听他的呀。</p>
<p>然后他又告诉我，他觉得自己现在心不静，我还傻傻的问他，为什么不静？<br>他：每天上午大课间你跟我说完话，下一节的物理课我就听不进去课。<br>我：我也没说什么呀，你怎么就听不进去课呢。<br>他：哎，我只能尽量少想。<br>我：那我等你竞赛班放学，在学校门口等你，这个会影响你吗？如果有影响我就不去了。<br>他：这个不影响，但你坐我旁边，我想好好学很难。你可以去了解一下，年级前面那些，都是心无旁骛，清心寡欲，绝没有杂念的。<br>后面还有一些，总之，他一直在叹气，说现在特别害怕自己被任何东西吸引，还强调要存天理灭人欲，我完全没听懂，还跟他开玩笑，说你干脆出家吧。</p>
<p>现在看到这段对话，我很惊讶，这段对话我一点印象都没有了，可见当时我也完全没在意。<br>我怎么会这么幼稚，这么愚蠢，完全没理解他的心情，也没懂他的意思。<br>如果当时我的心智再成熟一点，我们也许不会走到那么难堪的地步。</p>
<p>我因为始终没从他口中听到一句确凿的“我喜欢你”或者“我想和你在一起”，内心很没有安全感，一直希望能从他这里获得更多的信息，来确认他是喜欢我的。<br>我太执著地寻求自己要的答案，我真的不是故意的，我只是没听懂，哪怕是当时幼稚的我，也不希望影响他的学习、他的竞赛，哪怕后来我们决裂，我都一直在祈祷，希望他拿一等奖。<br>此刻，我想穿越回去那一天跟他道个歉。</p>
<p>现在的裴梓萱，31岁的裴梓萱，她觉得这段对话甚至比一句轻飘飘的我喜欢你更能说明问题。<br>明明我去竞赛班的那两次，我都老老实实的坐着，上课一句话都没讲，听不懂我就自己趴着画画玩，余光偷瞄到他也是一直认真听讲，积极做题，抢答问题的，原来他的内心也是汹涌澎湃啊。<br>决裂后，我把聊天记录都存起来了，怕伤心一直没有再看，十六年后的今天，我才终于理解到那一刻他的心情，其实之前的很多年里，我都以为他从来没喜欢过我。</p>
<p>Ps.这段聊天记录我真的是这么些年来第一次回看，也让我自己挺震惊的，我得缓缓。毕竟2018年以前，我一直以为他不喜欢我。</p>
<h2 id="十一、去而又返的新加坡"><a href="#十一、去而又返的新加坡" class="headerlink" title="十一、去而又返的新加坡"></a>十一、去而又返的新加坡</h2><p>友情提醒，从这一章开始，可能大家会觉得后面发生的事逐渐离谱，但真的全都是我的经历，记忆或许有点差池，但绝无虚构，如果想写小说，我肯定是要美化下情节，再凝练下文字的，这个东西也不可能拿去投稿，所以大家就当流水账看吧。</p>
<p>在我去新加坡之前，大概还有两件小事值得记录一下。<br>一个是我跟cc在某个晚上爆发了一次争吵，起因大概也是我想验证他到底在不在乎我，而他只想学习。<br>我们是课间在校园里吵起来的，我实在想不起来当时说了啥，只记得他当时朝我蹦出一句，我比较喜欢你，但不是特别喜欢你。</p>
<p>这句话我记忆特别深刻。<br>我也不知道是不是他的真心话，但少女心哪里受得了这个，我立马爆哭，他本来是背对我的，听到我爆哭扭过头来，我一脸倔强的对上他强势的目光，这个时候上课铃响了，他脸上带着一丝无奈，欲走不走，我气狠狠的说了句，你赶紧走啊，省得又说我耽误你学习。他马上接了句，好，我走了。<br>然后就头也不回地走了，我坐在松树下面哭了很久，然后就回家了。</p>
<p>后来我们又是怎样和好的，我一点也不记得了，我太喜欢他了，我当时能原谅他做的任何事。</p>
<p>二是我的嫉妒心作祟，忍不住去找了18班的ZQQ。<br>ZQQ是cc初中时谈过的女朋友，也是cc的初恋，这是cc的同学告诉我的，我也跟cc求证过这一点。<br>当时我内心有很多疑问，也有很多不甘——为什么他以前可以光明正大的和她谈恋爱，为什么我不行。我想看看她到底是个怎样的女孩，我到底哪里不如她。<br>这件事最后cc也知道了，ZQQ还去找他了，他没责怪我，也没问我为什么，只是一脸问号的做了个搞笑的表情。<br>他当时心里应该是很烦的吧，现在看我这件事做的是相当幼稚，自己都觉得自己烦人，他那么忙，我还给他不停的惹麻烦。也许他心里的不满也在积累。</p>
<p>带着对故乡的满腔不舍，1月19号我到了北京，1月20号在首都国际机场飞新加坡，我清楚的记得爸爸送我和妈妈的场景，爸爸背一个巨大的黑色双肩包，如果我知道以后再没有机会跟爸爸一起出国，那次说什么也要等爸爸一起去。<br>本来最初是定的我们仨一起去，但爸爸的工作单位是我们当地的XX监狱（地级市的名字），涉及一些保密的东西，办签证周期会很长，就决定我和妈妈先来，爸爸可以等下次来看我。<br>提到爸爸的部分对我来说真的很难，这么多年了，他始终是我不能触碰的伤疤，想到他我没法不流泪。从小爸爸把我宠的无法无天，鲁西南重男轻女，但我是独生女，每次有人问爸爸要不要二胎，他都说有我就够了，说我比儿子好多了。我时常安慰自己，虽然我得到的父爱时间比别人短，但浓度足够高就该知足了。后面我的历任男朋友都会说我任性、大小姐脾气（连cc也说过），也是被爸爸惯出来的底气。</p>
<p>飞机落地的时候，妈妈和我都有些失望，新加坡似乎没有网络图片上那么美好，想象中的花园城市，也不过如此，新加坡给我的第一印象——热带版的青岛。<br>也许当时我们对发达国家的滤镜太重了，都没想过提前办旅游签去踩踩点，出境之前就办好了所有的入学手续，第二天我就被塞进了学校参加月考。<br>新加坡的这部分本来不想细说，但考虑到让大家更理解我后来的决定，还是再啰嗦一下。</p>
<p>新加坡的考试分O-level，A-level，相当于国内的中考和高考。<br>O-level是可以直接考专科的，考上以后读五年，拿专科文凭，因为新加坡当时很缺人，专科文凭就可以拿绿卡。<br>A-level是要先通过O-level考试考上高中，再读两年高中才能参加，A-level考试难度我当时理解是大于国内高考的，老师告诉我A-level的数学是包含一部分大学数学的，同时如果大学想读金融专业，那高中就要选修经济学，并且拿到B以上的成绩，我听完心里开始打鼓。</p>
<p>不管考高中还是考专科，O-level是肯定要考的，老师把我安进了O-level班开始上课。<br>很快我发现，这个班里分两种人，一种是家里很有钱来玩的，这类同学压根就不学习，寄希望于考运爆发能上个最差的专科；另一种是国内高考的失败者，这类同学年龄普遍较大，20-25岁之间，甚至有一些已经工作了，他们主要是觉得自己在国内混不出什么名堂，看中了新加坡的下限高。<br>新加坡一共三所本科，国立大学，南洋理工，管理大学，前两所很难考，国立大学要求高中成绩全A，南洋理工允许有一门B，后面一所门槛低一些，但似乎没什么名气；五所专科，最好的一所是新加坡理工学院，需要O-level考试六门都拿0分（0 means 90+）。</p>
<p>这时候我的难点就来了，国立大学和南洋理工，我知道我的斤两够不上，上个专科呢，我又不甘心。尤其是O-level班那个氛围，虽然我在国内也不学习，但真把我放到这样一个乌烟瘴气的环境，我一下子有些受不了。O-level的数理化难度大致于相当国内的中考，完全在我的舒适区，所以我和这帮开学已经几个月的同学一起考试，居然考到了A班，老师说我明年肯定能考上新加坡理工学院，跟我描绘后面的蓝图。<br>我开始问自己，真的以后要留在新加坡吗？这个印度人马来人占了三分之一的城市，遇到的华人也大多是说粤语或者闽南语，我的小学初中高中都在家里方圆三四公里的范围内，我从来没住过校，突然要我接受以后永远离开祖国吗？或者将来拿着这个专科学历回去？那些人是在国内混不上本科学历才来的，那我来又是为了什么呢？<br>专科毕业在新加坡确实可以过上一种下限比较高，但上限也很低的日子，我好像还不打算认命诶。</p>
<p>于是，我跟妈妈说，我想回去，我不想呆在这里了。</p>
<h2 id="十二、不后悔的决定"><a href="#十二、不后悔的决定" class="headerlink" title="十二、不后悔的决定"></a>十二、不后悔的决定</h2><p>我决定回来的时候，所有人都来劝我。<br>先是新加坡的老师们，他们也都是国内润过来的，他们说你不知道这里的生活有多好，文明富足，医疗发达等等；接着是我的大龄同学们，他们普遍是在国内没考上正经大学甚至被社会毒打过的人，纷纷劝我，这里专科毕业就能找到工作，虽说发不了财，但温饱无忧也不卷，多好呀。<br>就连我国内的朋友和老师，也都觉得我不应该放弃这个机会，但我去意已决，妈妈表示尊重我的意见。</p>
<p>现在回头看，我一点都不后悔这个决定，甚至很庆幸当时没留下。<br>十六年后的现在，我早已对发达国家祛魅，当时房东叔叔（也是润人）劝我，你不喜欢新加坡，那你可以入籍之后再移民去加拿大啊，那个地方女孩子去了都不想走的。现在加拿大已经变成加麻大或者印拿大，哈哈。现在祖国发展越来越好，每每想到自己生在华夏就觉得无比自豪，我们的祖先创造了五千年的悠久文明，我们的文化不是野蛮的盎撒人能比的。<br>有时我读到某句古诗会情不自禁流泪，我想我的根就在这里，我在别处再也找不到这样的文化共鸣。</p>
<p>决定回来当然也有一部分原因是因为cc，我舍不得他，但我没告诉他，年轻人的自尊心太强了。</p>
<p>爸爸开始给我办复学，刚刚办了休学，又要复学。<br>当时办休学的理由是精神病，校长当然不会痛快答应复学，爸爸拿他最喜欢的一幅画去送礼才搞定。现在想想，爸妈真的好娇纵我，虽然也批评我了，但还是义无反顾支持我的决定。尤其爸爸，他肯定想不到我现在变成了一个成熟冷静的成年人，周围的人都觉得我做事沉稳妥帖，可见父母的爱并不会真的宠坏孩子，而是会成为孩子一生的底气。</p>
<p>我1月26号落地北京，回来的事只暂时先告诉了cc，Y，畅哥。<br>回来之后的第一个周五，1月29号，cc跟我进行了一场长对话，我记忆中他对我说话很严厉，我当时很烦闷，觉得他完全不理解我，现在看他其实是想为我好的，想让我长大，但那种理性的没有温度的对话，让年轻的我委屈极了。</p>
<h2 id="十三、鸡同鸭讲"><a href="#十三、鸡同鸭讲" class="headerlink" title="十三、鸡同鸭讲"></a>十三、鸡同鸭讲</h2><p>那天cc跟我在QQ上聊了很多，我精简一下全部po上来。</p>
<p>我：我这样回来是不是很丢人呀？<br>他：你觉得呢？<br>我：我问你呢<br>他：。。。<br>我：你说呀<br>他：不好说<br>我：我感觉很不好意思，这学期还有四天就结束了，我下学期再去学校吧。<br>他：你能感觉得到。<br>我：什么意思？<br>他：大家都跟你告别了，你却回来了。你说呢<br>我：你这意思还是丢人啊，连你都觉得我丢人<br>他：这点没疑问，看来你脸皮还是挺厚的。<br>我：行了，我觉得咱俩没有说话的必要了，我是很丢人，但也丢不到你的人。<br>他：说实话，在别人看来可能没什么，却少不了猜忌。<br>我：我又没干什么见不得人的事儿。<br>他：你得换位思考，同学<br>我：那你说我应该怎么办？难道再回去吗？<br>他：你是一时冲动就决定回来了？<br>我：你以为回来很容易？我爸又送礼又找关系才搞定。<br>他：那你就应该好好学习<br>我：那边的东西可难吃了，我快饿死了。<br>他：有什么可吃的？<br>我：马来西亚口味的，印度的，比较多。我已经很烦很受打击了，如果你以打击我为乐趣的话，可以赶紧下线了。<br>他：你让我鼓励点什么呢？你觉着呢？<br>我：不用你锦上添花，可是你连雪中送炭都不会。<br>他：别人的安慰都很空虚。<br>我：死人都能让你气活。<br>他：多受点打击也不错，就看你怎么对待了。<br>我：我今天在家做数学题，有些不会的，也没人问。<br>他：坚持自己做，不去问。<br>我：做不出来，那都可难了。<br>他：这是最实用的方法，打上问号，做上一个小时。<br>我：你不给我讲没关系，我可以去问T啊，他人很好的。<br>他：随便你啦。<br>我：好，不会就得问。<br>他：专心给你说方法你还不听呵，我初中的时候还花一个月想一道题呢。<br>我：我又不参加数学竞赛，are u 明白？<br>他：方法问题，和内容无关。<br>我：你都不知道，在新加坡真让我活不下去。<br>他：我知道你待不下去，但没想到你这么快回来。<br>我：你这么乌鸦嘴啊<br>他：你想象的不是挺好的吗？<br>我：我想象的等于现实吗？<br>然后我跟他讲了O-level和A level的困境，考O不甘心，考A自己实力不够。<br>他：你都没学就怕了，你没下功夫，没有静心学习。<br>我：考A的有相当一部分是你这样的学霸。<br>他：一样学，怕什么，你还没学呢。<br>我：难道你觉得我水平和你一样？<br>他：你还是对自己没信心呀。<br>我：考O我有信心，但也太简单了。<br>他：学初中的你又嫌简单了。<br>我：可是考出来只能上专科啊。<br>他：那就是你事先没准备好。<br>我：行行行行，我幼稚行了吧，跟我说话你都屈尊。<br>他：你情绪还那么激动，我觉得你回来会很忏悔，认真反思呢。<br>我：我不后悔，一方面学习上不行，另一方面，我也发现，我离不开我妈，离不开家。<br>他：你回来就是因为生活上不适应？估计你也只能抱怨这一点吧。<br>我：你不就是觉得你自己厉害吗？你瞧不起我是吧。<br>他：我不是那种人，我觉得你应该想想自身哪里做的不对。<br>我：下学期学个样给你看看，那你说，我应该怎么办？<br>他：我是你我会写日记，表达自己的忏悔。<br>我：还有，我回来的事，我就告诉你和Y了，你先别告诉别人。<br>他：别人是谁？<br>我：除了你和Y以外的人。<br>他：呵呵，畅哥还以为我不知道呢，还跟我说呢。<br>我：啊？那岂不是大家都要知道了？<br>他：知道怎么了，早晚的事。<br>我：我现在真的想好好学习了，但我寒假里肯定会遇到很多不会的题。<br>他：你给我留言，留到我能看到的地方。<br>然后他发了一个贱贱的笑的表情。<br>我：我现在心情真的很不好，你可不可以不要再刺激我了。你再刺激我，我就去精神病院了<br>他：控制你的情绪，孩子。12点了，我得睡觉了。<br>我：下次不许再刺激我，哼<br>他：我说的对你应该挺有用的。<br>我：好好好，我万分感激！<br>他：去听听歌吧，转动命运之轮，安慰只能让自己发现不了自己的缺点。</p>
<p>把这段对话基本全发上来，是想让大家看看，那时我们的鸡同鸭讲。<br>我是玻璃心的小女孩，只想求抱抱求安慰，但他一直在教育我，很多话听起来确实难听，当时的我只觉得他肯定是不喜欢我，不然为什么这么严厉地对我。<br>而他大概是从小被严厉对待惯了，并不知道该如何对待女孩。<br>现在回头想想，他自己每天时间那么紧张，能抽出一个多小时来教育我，何尝不是一份“在乎”。在他的视角，肯定是觉得我幼稚、不懂事，不爱学习又害怕困难，可能他心里对我也挺失望的吧，觉得我像是扶不起来的烂泥，此时距离我们真正的分崩离析只有一步之遥了。</p>
<p>PS.好奇大家看了这段对话是什么感想</p>
<h2 id="附上那页珍贵的同学录"><a href="#附上那页珍贵的同学录" class="headerlink" title="附上那页珍贵的同学录"></a>附上那页珍贵的同学录</h2><p>这是我去新加坡之前他给我写的，蜗牛是他给自己起的外号，现在他的微信名还叫蜗牛。<br>我当时觉得他写的这段话是暗含着喜欢我的意思的，但是他又从不明说，所以天天猜来猜去。</p>
<p>我那时候很喜欢他的字，后来我们决裂后，我在某个中午偷偷溜进他们班偷了他的化学习题册，拿去复印，然后又悄悄放回去，那个复印件现在还在我家放着，哈哈，我那时候真是痴心不改啊。</p>
<p><img src="https://pic1.imgdb.cn/item/6950a3ae161224305eb3122d.png" alt=""></p>
<h2 id="十四、决裂"><a href="#十四、决裂" class="headerlink" title="十四、决裂"></a>十四、决裂</h2><p>接下来的寒假，我确实开始好好学习了。<br>因为我心里的那个deadline也到了，我再糊涂也知道还有一年零五个月就高考了，况且高二下学期还得花很多时间准备会考，我那前三个学期没怎么碰的物理化学生物，会考是要必须及格的呀。<br>cc和老赵还有T等几个人去了济南，参加山大的数学竞赛培训。</p>
<p>接下来又出现了一个令人迷惑的情节，本来寒假我俩也没怎么联系，cc去到济南却在QQ上跟我报备，跟我讲了他们培训的大致状况，说等回来跟我细讲。<br>莫说那个年纪，就是我现在这个年纪，一个异性来跟我报备，我都很难不多想，报备是个很微妙的东西。</p>
<p>cc直到过年之前才回来，2月13日是除夕，我忘记因为什么了，我那天给他打了个拜年电话，我当时的理解是，只是拜个年，问题不大吧。<br>cc的爸爸接了电话，他竟然很温和，没有生气，还问了我考试成绩，但我因为新加坡的事一个月没上学了也没复习期末考试，所以就说了一个平时跟我成绩差不多的同学的成绩，这个同学也就是中游水平，并没有多好的成绩，我高二上学期在班里也是中游水平，我觉得这样说问题不大。</p>
<p>晚上的时候，我们在qq上聊了起来，一些闲聊的废话略去，我只摘关键部分发上来。<br>我：你爸今天有没有说什么？他今天态度怎么这么温和？<br>他：我也不知道，他问我你是几班的。<br>我：他要来找我吗？<br>他：他懒得去。<br>我：他还问什么了？<br>他：他问你们班怎么样？说你考的不错。<br>我：他知道我学文科吗？<br>他：你考多少分？<br>我：我没来得及复习啊，你想想，我一个月没上学了。<br>他：呵呵呵呵呵<br>我：原来我跟xxx的成绩差不多，你可以去问她，我就说了她的分数。<br>他：哎，悲剧<br>他：你心态真稳。<br>我：你老是瞧不起我。<br>他：你的成绩可以查出来的。<br>我：你不知道我的考号呀。（因为素质教育，我们不许贴成绩单排名，正常只能私底下去找班主任看自己的成绩，看不到别人的。）<br>他：全校的我都能查到。你们班主任叫什么？<br>我：你是去找贾老师帮你查吗？<br>我：我不想让你爸知道我这次的成绩，我不想让他认为我是坏孩子。<br>他：你可真可爱呀，呵呵。你们班主任叫什么？<br>我：。。。。。。<br>他：说呀。<br>我：我一个月没上课了，一点没复习。你觉得这算真实成绩吗？<br>他：你们班主任叫啥？<br>他：你们班主任叫啥？<br>他：班主任<br>我：。。。。。。<br>他：你们班主任叫啥？<br>我：房xx<br>他：你们班主任到底叫什么？<br>我：房xx，满意了吧？？<br>他：真是他吗？<br>我：我骗你干嘛。（看到这里我觉得心寒，他竟然觉得我会骗他。）<br>他：不说成绩了，新年快乐呀。<br>我：我今天给你抽了个签，解签说你数学竞赛结果是好消息。<br>他：我讨厌别人夸我，无聊。<br>我：这不是夸你，我是真抽了这个签呀。<br>他：你真虚。<br>我：呵，那我怎么不去给别人抽签？我真是闲的来关心你。<br>他：T太厉害，我比不上，我离一等奖差得远，希望渺茫。我更喜欢听实话。<br>我：要我说实话，就是，既然觉得竞赛没希望，就别搞了，老老实实复习高考。<br>我：我觉得你很幼稚，在浪费时间做没用的。<br>他：至于我的真实水平，我也不知道自己是怎么样一个水平。<br>我：我觉得你应该以文化课优先。<br>他：那也比你强。<br>我：我知道你比我强，我只是觉得你可以更好。<br>他：是滴。<br>我：你厉害你厉害，我差，打击我你很快乐？<br>他：你就没好好学过呦。<br>他：其实你英语不算好。你这次英语分也不高。<br>我：哥，我课本后面的单词都没背，能多好。<br>他：和单词有什么关系？（现在回看，愚蠢的数学脑，英语的基石是单词量好伐）<br>我：行行行，全校我最差行了吧。<br>他：我觉得南开大学不错，北理工一般。<br>我：我觉得去北京肯定比天津更好，长远看。<br>他：我不太看得上北理工。（真是年少轻狂呵）<br>我：学破数学去吧。<br>他：我偏。</p>
<p>他爸有没有去查我的成绩，我并不知道，只是从这一天开始，他开始躲我。<br>QQ上对我隐身，却在群里发言，我很不解，我并没有纠缠他的意思，如果一开始他没有约我打球，他没有叫我去上竞赛班，他没有屡屡给我QQ留言，我会跟他走得这么近吗？</p>
<p>2月23号晚上，我决定跟他摊牌，大不了就老死不相往来，那也好过躲躲闪闪。<br>我：你不用再躲我了，你直接把我从QQ上删了不是更好。<br>他：。<br>我：你不用再躲我了，你直接把我从QQ上删了不是更好。<br>他：。<br>我：我真瞧不起你，一点男人样没有，不敢光明磊落的结束。结束挺好的，我也想安心学习。<br>他：您还高考呀？<br>我：我怎么不高考？<br>他：不过，您说的确实不关我的事。<br>我：现在就互删吧。<br>他：和您真的没什么好说的，您说话很空虚。<br>我：是我自己瞎了眼。<br>他：干嘛？大小姐，您可真任性。<br>我：耍我很有意思吗？你还需要再接着装吗？<br>他：我是很讨厌和你聊天，你说话很没谱。<br>我：那你一开始为什么要来找我聊天？玩弄我很有意思对不对？<br>他：额，我可没那么坏。<br>我：那你来招惹我干嘛？<br>他：我的梦想是一等奖，你总是安慰我鼓励我，说我可以。考不考上是你说了算的吗？<br>我：我鼓励你有错？<br>他：我喜欢泼冷水的话，您说话就像暖羊羊一样。<br>我：你肯定拿不了一等奖。<br>他：这话好。<br>我：我不过是欣赏你的才华才那么说。<br>他：我有才华？夸张了。<br>我：看来你配不上我的欣赏。<br>他：我想你应该问问别人对你的看法。<br>我：用不着，别人怎么看都不影响我是我。你这么讨厌我，应该早点把我拉黑。<br>他：你应该考虑到其他人，我们对你的印象真的不怎么样，你很虚伪，人品有问题。<br>我：那你为什么要跟我走那么近？<br>他：这很正常呀，同学的交往。<br>我：那你为什么叫我去上竞赛班？又是谁周六约我出去的？<br>他：高中是学习的地方，你这样根本学不下去，我真的害怕您耽误我学习。<br>我：你不来找我，我就能耽误你学习了？？<br>他：我找你怎么了？我天天谁都找，就是普通朋友啊<br>我：哦，所以就还是耍着我玩很好玩喽？<br>他：不敢不敢，您脾气这么大<br>我：你早这么想早说啊，难道我非得跟你联系？我会赖着你？<br>他：不好说，还真有可能。</p>
<p>对话就停在了这里，我就把他QQ删了。</p>
<p>时至今日，看完这段对话，我还是会血压飙升，这段对话把我的自尊撕得粉碎。<br>对我来说，这不单单是我喜欢的人不喜欢我，而是我从头到尾活成了一个笑话，你可以不喜欢我，但是从4月份刚认识约我打羽毛球开始，就是在耍我对吗？后来放学送我回家，叫我去上竞赛班，约我出去玩，全部都是带着这个女孩真好玩，我要把她当猴耍的心态是吗？<br>那个晚上，我甚至想去死，不是因为他不喜欢我，是我发现这竟是一场巨大的骗局，我的自尊心难以接受。</p>
<h2 id="十五、决裂之后"><a href="#十五、决裂之后" class="headerlink" title="十五、决裂之后"></a>十五、决裂之后</h2><p>跟他聊完之后，我想起他说的“我们对你印象不怎么样”，就直接去问了老赵，我想他也许知道点什么。<br>老赵是个正直的人，我问他，有没有人跟你说过我什么坏话？<br>赵：有的，但我并不认可。<br>我：他说我人品很差，虚伪。<br>赵：你们两个人之中，如果有一个人人品差，那一定是他不是你。<br>我：他说别人对我的印象都很差。<br>赵：可能是他自己臆想的，我没听到别人这么说过。我也从不这么认为，你只是天真一点，性格不稳重，但在我们眼里是可爱的小妹妹。<br>我：那为什么要这样说我？<br>赵：因为对每个人来说，最重要的是原则。<br>我：我没有原则？<br>赵：是你影响到了别人的原则。<br>我：？<br>赵：你影响他学习了，你不要听他说的，也不必把那些话当回事，他说的未必是他想的，反而是你在他心里有一定分量，才会影响他学习。<br>我：可是是他先来找我的啊？他要是不总是搞得那么暧昧，我会想多？<br>赵：他就是那个样，不把这样的事看得太重——他现在又看上了Q，26班的，前几天他跟我说觉得Q很可爱。<br>我：。。。。。<br>赵：我希望你能勇敢的站起来，他并不值得你看重。<br>赵：他的原则也是把谈恋爱当做人生的一部分，但不是重要的那一部分，所以他不在乎，但你在乎，他骗了你的心。<br>赵：我虽然对他有一些了解，但不多，这样的人不值得深交，我也不会跟他深交，你更不必在乎他。</p>
<p>畅哥听说这件事之后，第一反应是不信，他不信cc是这样的人，他说要去跟他谈谈。<br>结果cc直接选择无视畅哥，连畅哥也开始震惊，说没想到哥们一场，对他如此不了解。后来，他俩就很少联系了。</p>
<p>毕业之后，我们都联系的很少了，回想起来，很感谢老赵和畅哥在那个时候对我的关心和帮助。</p>
<p>接着往下写，2月28号是开学的日子，也是我们分班的日子。<br>不知是因为省里的要求，还是怎的，学校那时候扭扭捏捏，高一下学期就让我们每个人填写了自己是文倾向还是理倾向，却迟迟不肯分班，最后搞了个折中的分班——分教学班和行政班。<br>行政班，就是你从高一开始的班级，以后英语和语文还在这个班上，也还是原来的老师，你的大小事务还是归行政班的班主任管。<br>教学班，就是新分配的班级，把文倾向和理倾向的同学分开，给文科班配好的文科老师&amp;差的理科老师，理科班配好的理科老师&amp;差的文科老师，但总之，9门课都还是得学。</p>
<p>我的行政班是22班，新分的教学班是16班，原来22班想学文的都被我们班主任带到了16班，想学理的留在了22班；而cc原本的行政班是25班，他被分到的新教学班是22班。<br>而且，最戏剧的是，他们老师新排的座位里，他正好坐在我原来的位子上——也就是说，以后我们要共享一个座位，我英语语文课坐那里，其余时间他坐。<br>以前坐我左边的飞飞和坐我前面的小庞都留在了22班，排完座位后飞飞第一时间告诉我这个消息。我觉得上天真是最巧妙的小说家，我俩刚决裂就非得让我们再碰面吗？！</p>
<p>但我们都下了决心，坚决不再跟对方说话，甚至不会对视，每次英语语文课结束我都赶紧撤走，而他会等到上课铃响了才进来，走廊上遇见了也绝不瞅对方一眼。<br>直到有一天，我的语文书落在了桌洞里，我等到放学才回去拿，就是不想碰见他，没想到他迟迟不走，一直在座位上做题，我等了又等，忍无可忍直接上去拿。<br>我：起开，我要拿我的书。<br>他：你还学习？<br>我：士别三日，即更刮目相待。<br>他依旧一脸不信不屑的表情。<br>我拿起书就走。<br>这是我们最后一次面对面的对话。<br>他那个时候真的太骄傲了，包括我和他在内的所有人都没想到，最后我们都去了二本。</p>
<p>ps如果让我编故事，我都编不出来他最后去二本这个结局。</p>
<h2 id="十六、爸爸走了"><a href="#十六、爸爸走了" class="headerlink" title="十六、爸爸走了"></a>十六、爸爸走了</h2><p>关于高二下学期的记忆，只剩下两件事。<br>一个是我花了好几个月才走出cc给我的阴影，刚开学的时候，我天天都emo，妈妈还专门给我买了一颗小树，叫幸福树，妈妈说希望我快乐，妈妈还说，cc又不是皇帝，他说你不好你就不好吗？<br>Y和G也天天鼓励我，大美女Y用方言说，奶奶滴，这个熊cc，我想咧死他。G跟我说，你将来一定会遇到比他好的人的。我不相信，他都瞧不起我，比他好的人更瞧不起我呀。G那个时候就很成熟，说我真没看出来他有多好。<br>因为飞飞后来一直坐cc左边，所以，每次cc有什么新闻，哪怕我不想知道，她也会来告诉我，只是我渐渐不再有兴趣听。</p>
<p>大概到6月底，我感觉自己终于活过来了，天空重新蓝了，我也不再写些凄凄艾艾的博客。</p>
<p>二是为了会考，我不得不开始学物理化学生物。<br>有一阵子我像打了鸡血一样，天天熬夜背化学，整个课本被我背的滚瓜烂熟，甚至被化学老师拿到理科班做案例表扬，但那又有什么用，天生没有理科思维，化学我也最多考个八十几。<br>物化生占用了我很多时间，所以我完全没空补高一没学的那些政史地，也导致我高三开学后进入”别人复习我预习“的状态。</p>
<p>高二的暑假，爸妈带我去苏州杭州上海玩了一圈，那是我们一家三口最后的时光。我们在上海外滩留下了最后的合影，爸爸那时候还耿耿于怀于自己在官场上不能再升一下，妈妈一直劝他，现在就是最好的日子。<br>刚从上海回来没两天，有一天晚上我正在看《这个杀手不太冷》，刚好看到那句台词“人生总是如此痛苦吗？还是只有小时候这样“，这时妈妈接了一个电话，然后妈妈惊慌地跑过来跟我说，快换衣服，你爸爸出事了，你奇奇叔马上来接我们过去。<br>我：爸爸出什么事了？<br>妈妈：你二爷打过来的电话，他只说在医院抢救，让我们有个心理准备。<br>我那个时候大脑完全宕机了，怎么回事，爸爸今天中午还好好的，怎么出事了？</p>
<p>奇奇叔很快赶到，按二爷的指示往爸爸老家（某县某村）开，路上妈妈忍不住又给二爷打电话，到底出了什么事，为什么不让我们去医院，是死是活我要见他最后一面。<br>二爷可能是怕我和妈妈接受不了，始终不肯说。<br>妈妈又打给可可（堂哥），问可可，你跟我说实话，你三叔是不是没了？<br>可可甚至说不出一句完整的话，一直嚎啕大哭。他爹妈从小不要他，跟着我爷爷奶奶长大，爸爸和二爷一直很疼他。</p>
<p>其实人在面临最亲的人的突然去世的时候，第一反应不是悲痛，是茫然的感觉，我一直努力在脑子里反应，爸爸没了？爸爸没了？爸爸真没了？<br>等到我们到了老家，已经晚上十点，车子甚至开不到爷爷奶奶家门口，十里八村来看热闹的人站满了，我们只能走过去，那是我这辈子走过的最难走的路，那些农村的大爷大妈大叔大婶，用一种悲壮又怜悯的目光看着我，我害怕他们的目光，我也不知道前面有什么在等着我。<br>奶奶撕心裂肺的哭声响彻农村的黑夜，妈妈说，你爸爸肯定没了，不然奶奶不会这么哭。</p>
<p>原来爸爸中午参加了一个酒局，酒局过后，爸爸自己打车回单位，中途路过一个野水塘，可能是他觉得热或者其他原因，非要司机停车下来去游泳，当时水边还有一个钓鱼的老头，劝他不要下水，但他非要下水，他下水之后就没影子了，钓鱼老头不会游泳，立马喊人，但为时已晚。</p>
<p>爸爸是下午三点出事的，我们赶到老家那会儿，连尸体都还没捞上来。他跟正常溺水的人不一样，他嘴里一口水都没喝，他是憋死的，他也没飘上来，而是沉到了下面。</p>
<p>我28岁那年因为颈椎病开始学游泳，一开始我始终克服不了这个心理障碍，每次教练喊着憋气，我头埋入水中，就会忍不住想，爸爸当时在水里是什么心情？他最后一刻是不是知道自己要没了，他是不是舍不得离开我所以一直憋气，他那一刻会不会很恐惧？然后身体就会不自觉得发抖，完全没法正常。<br>甚至到了现在，我在水里游泳的时候，都会忍不住想，爸爸啊爸爸，你最后一刻到底在想什么？</p>
<p>我们家在县城的公检法系统里有点人脉，我爷爷和我二爷跟爸爸一个单位，都是xx监狱，我六爷爷（我爷爷亲弟弟）的亲家是副县长，我六爷爷家的大爷在民政局，二爷在公安局。当时他们花了很多时间调查这件事，查来查去真的查不到任何被害的证据，结论就是——真的是他自己进去游泳的。</p>
<p>爸爸要到冬天才满40周岁，他的生命被定格在了39岁。<br>我下个月就32岁了，从16岁到32岁，爸爸，你在我人生里缺席的岁月马上就要超过一半了。</p>
<p>这一part先这样吧，再写我情绪有点控制不了的。</p>
<h2 id="十七、真实的人生开始了"><a href="#十七、真实的人生开始了" class="headerlink" title="十七、真实的人生开始了"></a>十七、真实的人生开始了</h2><p>爸爸走了这件事，对我来说，我一直都没有真的接受。<br>到现在我都不喜欢去给爸爸上坟，我总觉得他不会躺在那个小坟包里，我不相信那里是他，他肯定是穿着一身飒爽的警服，威武的站在某个地方呢。<br>我所有朋友里，也只有几个知道爸爸不在了，大学四年，我都没把这件事告诉舍友或者同班同学，每次聊起父母，我都是神气活现的我爸怎样怎样，我总觉得他还在，甚至会在某一天出现。<br>只有偶尔受了委屈的时候，我才会想起来，爸爸不在了，他要是在，肯定不会让我受这样的委屈。</p>
<p>跟第二任男朋友吵架的时候，有一次我俩情绪都很失控，他朝我腰踢了一脚，我当时立马哭出来，哭着哭着又大笑，我笑自己命苦。要是爸爸在，他敢踢我吗？<br>爸爸性格极其刚硬，当兵去部队第一个月，就干翻了所有试图给他下马威的老兵，他这辈子没怕过谁，更不允许任何人欺负我，小学的时候，因为我想参加古诗比赛被老师讽刺了一句，爸爸立马找到校长那里，问他这个老师凭什么这样对孩子讲话？孩子能不能参加是一回事，老师凭什么讽刺孩子。</p>
<p>别人欺负我还好，最可怕的是来自家人的欺负。<br>爷爷，奶奶，大爷，二爷，堂哥，以及部分远亲。他们明目张胆，嚣张跋扈，我之前就想过，早晚有一天，我会把他们的嘴脸写出来。<br>他们本来就不喜欢我妈这个外来媳妇，更不喜欢我这个”婊孙妮子“，现在终于可以肆无忌惮了。<br>反而是爸爸的那帮拜把子兄弟，一次又一次，不厌其烦地帮我和妈妈。<br>我们家这些破事之后单独写吧，这里不再赘述。</p>
<p>我终于开始体验真实的人生。<br>妈妈性子软，想法纯真，之前被爸爸保护得太好，爸爸一走，所有大事小情妈妈一下子慌了神。再加上爸爸是经济支柱，所以我和妈妈开始陷入一种害怕的状态，既害怕没钱，也害怕遇到事。<br>我本来的愿望就是长大以后赚很多钱，从那之后更是了，我下定决心，一定要有钱，要强大，我要让所有人都不敢再欺负我，我要让妈妈不再有顾虑。</p>
<p>高三开始了。<br>同学们开始复习，但对我全是新知识，尤其是地理，老师讲的很快，很多细节不会再重复，我只能自己一点点揣摩以及课下单独问。<br>数学也不乐观，我做了很多题，但始终不开窍，我记得到高考前一个月，我才终于get到那种f(x)的题咋做。我每天时间分配给数学最多，但它始终不领我的情，最终高考只考了112。数学老师给我的评价是，“这个人你认识他，但他穿个马甲你又不认识了”。<br>后来到了我考研的时候也是如此，我每天上午给数学两个小时，晚上给数学两个小时，一天四五个小时学数学，结果考试做到第7道选择题我就被绊住了，能想象我在考场上的惊慌吗。可怜的英语被挤到下午最昏昏欲睡的时间段学，最后依旧考了83。考完研之后，我下决心，以后再也不参与任何有数学的考试，这玩意克我。</p>
<p>我整个高三心态还是很好的，比大多数人都好，因为我每一次考试都比上一次好，一直稳步上升。到2011年5月，大家都焦躁得不行，盼着快点高考，只有我希望能再多几个月就好了，我觉得自己还有好多没学完的。<br>高考前一个月，我发现我历史和政治的大题分数被固定住了，怎么都突破不了，不知道是不是因为自己基础薄弱，我当时很着急，找到历史老师问怎么办，闫老师说，你主要是差在思维上，思考得不够综合，你这样，你每天自己多做一套文综题，然后第二天课间来找我和政治老师，我们一道题一道题的给你分析思路。<br>我真的特别感谢闫老师，靠着最后一个月的努力，在高考前最后一次模拟考，我文综竟提高了40分。</p>
<p>最后我的高考成绩是568分，我特别知足。<br>当年文科一本线570，理科一本线567。<br>毕竟我只学了一年，而且智商也一般，已经实现了我对自己的预期。<br>高考后，我也很认真的想过要不要复读。我的自我评估是——有上升空间，但空间不大。我认为以我的智商，再多学一年也只能再多考30分左右，比一本线高30分，在山东也只能上个普通一本，青岛大学的好专业也够不上，211更是不可能，那何必呢，普通一本和普通二本有多大区别。</p>
<p>说回cc，2010年9月，高三刚开学，飞飞带来一个大瓜，cc要休学一个月——为了全力以赴准备竞赛。<br>他肯定是疯了，这摆明了是赌自己能拿一等奖然后保送啊。<br>与此同时，T一如往常的气定神闲，该上学上学，该复习复习，从他淡然的表情上看不出任何情绪。<br>10月17号，竞赛结束，cc回来了。<br>他嬉笑着跟飞飞说，完了肯定考砸了，一道大题都没做出来。<br>我是不信的，他一直是那种说着考砸了最后考满分的人。</p>
<p>命运的残忍再一次超出我的想象，T不只拿了一等奖，而且是全省第一名，力压省实验的一众英才，让我们学校狠狠的扬眉吐气了一把。清华北大的电话很快打过来，被T婉拒，他一心要读中科大的华罗庚数学班。<br>还有另一名在竞赛班不起眼的xx同学，竟然也获得了一等奖，我们这一届真的破纪录的出了两个一等奖，但没有他。<br>不明就里的同学们纷纷祝贺他拿了二等奖，我在走廊的这头，看他在人群中一如往常的嬉戏打闹，他笑得越肆意，我越能感到那种彻骨的悲凉。<br>Y问我，有没有一种他终于遭报应了的快感。<br>我摇摇头，他是伤害了我，可我也不愿意看到天上的星星陨落，星星离我很遥远，远到我可能一辈子都企及不了，但我希望他永远闪烁。</p>
<p>“他现在简直变了一个人，他上课看小说诶”，飞飞用夸张的语气跟我八卦，“而且他今天化学课上睡觉被老师拎起来罚站。你敢信吗？他上次模拟考数学才考128。”<br>听起来cc正在走上我的老路，不知他那个时候是否终于有一点能理解我中考考砸后的自暴自弃。<br>我很想去安慰鼓励他一下，又想，算了，在他眼里这么差劲的我，怎么配去鼓励他，他都那样贬低我了，还有什么脸面再跟他讲话。</p>
<p>12月，自主招生进行的如火如荼。<br>托了省重点的福，我们学校自主招生的名额特别多，连我这样的成绩也有资格参加，但我没去。<br>自主招生都是985、211，考过了也不过是能给你加10分20分，能加60分或者直接录取的本身都是顶尖的人才，就我这个成绩，加个20分我就能考上山大了？<br>cc报了三个学校，北航，山大，大连理工，最后，山大给他加20分，大连理工给他加10分。</p>
<p>高考前两天，学校给我们举行毕业典礼，那天大家都玩得很开心。学校要拍一个大家一起走出校门的镜头，我悄悄地在人群中找到cc，跟他保持一定的距离，看着他的背影离我越来越远。<br>我喜欢的男孩，他终于在我的视线中一点一点的消失，是不是此生都没有机会再见他了，我承认喜欢上他的时候是被他的光环吸引，可是此刻，命运给他的打击我也想陪他一起承担，我总觉得别人都不懂他的好，Y和G从头到尾都不喜欢他，我想我懂他的偏执、他的骄傲、他的破碎。</p>
<p>高考成绩出来之后，cc没有告诉任何人他的成绩，我问了很多人，只打听出他大约是595-600左右。他这个分数，算上加分也够不上山大或者大工。<br>他应该也想不到吧，他只比这个他曾经鄙夷的我多考了30分。</p>
<p>即便如此，这个时候我对他的滤镜也没碎，他还是那个让我心动的少年，是后来，后来发生的事彻底打碎了我心里的滤镜。</p>
<h2 id="十八、大学"><a href="#十八、大学" class="headerlink" title="十八、大学"></a>十八、大学</h2><p>cc报考徐州空军学院的消息传来的时候，我简直不敢相信——他居然没有复读，而且还要去军校！<br>别人我不知道，但他的梦想是数学系我非常确定，他从来没表达过一丝对军旅生活的向往，这不可能！很多年后我们聊起来这件事，证实了我的想法——他一点都不喜欢部队。<br>我猜，这件事大概率跟他爸有关，不肯复读可能是他已经完全碎掉，精神垮塌的人如何再拼搏？</p>
<p>老赵不如cc聪明，属于勤奋扎实型选手，高考考了636，加上自主招生加的30分，如愿去到西安交大王牌专业，苦读七年航空力学之后，毅然投身大上海，在私募基金混得风生水起。<br>畅哥比我还狠，高三也不学习，五百出头的成绩上了中外合办的二本，毕业后幡然醒悟，考上西南财大的金融硕士，在成都美女香车，好不快活。<br>曾经和cc关系比较近的几个尖子生，有人去了外经贸读金融，毕业后直奔美帝，成了财经新闻里那种金融分析师；有人继续追梦，在山大读基础科学，直博北大；有人去了上海交大医学院，化身白衣天使救死扶伤。后来，cc似乎都不愿再跟他们联系。</p>
<p>Y和G因为成绩不好都选择了走艺术生，大美女Y凭借盘靓条顺考了空乘专业，大二就去东航上班了，是我们中第一批富起来的人，我和G时不时能收到她送的国外小众品牌彩妆；G学了戏剧相关的专业，在天府之国过得活色生香，我真后悔当时没跟她一起去吃香喝辣。<br>我留在本省一所无趣的二本，读无趣的会计专业，周围的同学大多都来自山东农村，价值观普遍传统保守，时常让我觉得自己格格不入。</p>
<p>大一的冬天，我给cc发过一条短信，大意是你不要沮丧，你依旧是很优秀很厉害的那个你，好好努力，就算曲折一点，你也一定能实现自己想要的。<br>cc回过来，谢谢你的鼓励，我会加油的，你是哪位同学呀？<br>我回，你不用知道我是谁，希望你好好学习，不要忘记自己的梦想。<br>cc还问，真的谢谢你，不过，你到底是谁呀？</p>
<p>我没有再回复，我也是个骄傲的人，我始终没忘记他对我的轻视和讽刺，关心他鼓励他是因为我在乎他，但我的尊严不允许我暴露。<br>他在军校，手机的使用应该很受限制，所以大学四年，他的人人和QQ也没发多少状态。</p>
<p>后来，听说大一下学期cc和LXF在一起了。<br>LXF也是我们高中的，大学之后，当年喜欢他的女生们也作鸟兽散，毕竟，他的光环消失了，军恋又那么苦。<br>我向来不谈异地恋，因为我感性又怕寂寞，但如果是他，我想一个星期只能打一个电话也不是不能接受，可我不会拉下脸去找他，再来一遍也不会。</p>
<p>LXF是艺术生，我们那个年代学艺术的，大部分都是因为成绩不好想混个学上，真正热爱艺术的十不存一。我高三的时候也动过这个心思，当时有个新兴的艺术专业，叫戏剧影视文学，恰好也是我的兴趣点，当然我主要的心思还是觉得学艺术我就能考个985了，但被我们班主任劝退了，你好好学学能过一本线，去学什么艺术？那都是四百来分的人才考虑的，学艺术将来好找工作吗？考文化课才是正路。后来当我被所谓的互联网大厂裁员的时候，忍不住想，如果当时真学了戏剧影视文学，也不见得比现在差吧。</p>
<p>说来好笑，我一直以为cc那么鄙夷不好好学习这件事，谈恋爱肯定会找学霸，没想到他后来谈的女朋友们学习成绩好像都还不如我，命运真幽默啊。</p>
<p>我大学期间逃掉了所有能逃的课——不包括高数，高数我每堂必到，不是为了听课，是平时成绩占30%，这对我很重要，所幸每学期高数我都低分飘过，没挂过，有一学期我们班好像高数挂了接近一半的人，我自稳如泰山。<br>逃掉所有能逃的课是因为，反正我们这破二本也没有保研的机会，最后还不是得自己兢兢业业考研，那前三年就先爽着过吧，GPA算什么。<br>我好像一直是这个习惯，能玩就不学，大考在即的时候才肯下功夫。</p>
<p>考研的时候，我导师，也是我们会计学院的副院长，苦口婆心劝我，别考我喜欢的那个学校，理由一大堆，北京是热门城市，北京的211更是热门，经管类热度高门槛低，什么专业的都可以跨专业考，你这样很容易落空，你不如考首都经贸大学或者北京工商大学，好考一点。<br>我不，那俩不是211，我一定得上个211。<br>带着这种执念，我踏上了复习的路，现在我都很佩服自己那会儿的毅力，2014年已经是全民智能手机的时代了，我的很多同学为了考研把手机换成老人机，就是怕自己自习时忍不住玩，我没换，每天自习的时候手机就放在桌子上，但我真的可以做到一整天都不玩，只有晚上回宿舍后才会玩会儿。现在要是让我一整天不玩手机，我可能会疯。<br>我是会为了自己的执念不顾一切的。</p>
<p>后来有惊无险的考上了心仪的学校，开学前我终于做了我一直想做的事，给cc打电话。<br>你可能会问，这时候我为什么就能放下自尊先给他打电话了？<br>因为我要告诉他，我考上了，北京的，211。虽然含金量不如高考，但我也绝不是你想象中的不学无术之人。我终于能用有力的事实反驳掉他当年的质疑。这口气，我已经忍了好几年了。</p>
]]></content>
      <categories>
        <category>Youth</category>
      </categories>
      <tags>
        <tag>爱情</tag>
      </tags>
  </entry>
  <entry>
    <title>[转载]小登的北邮生活年度总结</title>
    <url>/2025/12/28/%E5%B0%8F%E7%99%BB%E7%9A%84%E5%8C%97%E9%82%AE%E7%94%9F%E6%B4%BB%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>这几天看着学长学姐的总结很开心</p>
<p>本月终于尘埃落定，把之前没写的都放进去，也算是了结了吧。如果还有下次的话，可以试试markdown形式，应该更好用</p>
<p>第一部分是对过去经历的片段回忆</p>
<p>第二部分是当下自己对ai的认识</p>
<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2>
<p>我生在不大不小的城镇，两个无聊但踏实的人，生出一个无聊但踏实的孩子。领着国家饭，全家从未设想过体制外生活。小时候培养，强调“腹有诗书气自华”，偏向文学而非数学，似乎是要个“君子”，而不是“工程师”，几分科举遗风。想来这也是小地方的朴素观念。从小在文化上的积累，和对于历史规律的体会，让我以后面对世界更加从容。不过也容易沉浸在自己的世界里，越走越远。</p>
<p>记得上初中时，也许是读了太多历史文化的书，成绩又比较突出，确实太呆了，与身边的同学有着模糊的“代沟”。恋爱，运动，周末，他们玩的很精彩，不过于我没什么关系。本来就是敏感内向的孩子，靠着为数不多的写作机会，抒发些内心的感受。</p>
<p>PS:追更学姐的帖子也让我想起了当年和现在的自己，多少带着点cc的影子。像个小大人操着心希望别人变好，却忽视了其他人的感受……</p>
<p>虽然说是区里最好的初中，却还是面对大锅饭喂不饱自己的问题，千方百计去搜罗市里中学的练习题，把每一份全市统考卷视若珍宝，想来和现在一样，去找国外的资源。人都是向上走的，需求也是越来越高，总是得不到满足。唏嘘！</p>
<p>对我来说，压力和受挫是次要的，痛苦的是做自己认为没有价值的事。正因为这些信息与高校接触的隔阂太大，高三一年重复枯燥的学习，让我深感无意义的痛苦。那时做新定义数学题、看新阅读篇目，已是难得的美事。回看高三下学期，因受不了课内重复，趁周末放假玩了700小时战地1。这当然是美好的回忆（战地一的历史氛围感非常对我胃口）。现在想来，若把这些时间放在更有价值的事情上（不是高考），大学生活或许会更顺利。轻视刷题最终让我在压力巨大的高考中失利，但绝不复读。</p>
<p>高考出分后曾戏谑说，与其去个外地中下九，不如读个师医公或者本省985，毕业回老家，进个体制，像爸妈一样安稳成家立业，一辈子也就过去了。</p>
<p>不过填报志愿想来是这辈子第一次可以自主决定未来的机会，我最终还是选择放手一搏。心里想着要是按着父母的想法，那我的人生真的就被高考毁了，而选择北邮，仍然还有接触到梦想里ee和cs的世界（虽然当时连c语言是什么都不知道）</p>
<p>选择北京，我从不后悔，这真是一座融合了历史与现代的城市，还有一年分明的四季，好喜欢，好想留下！只是前些阵子和其他专业的同学有过交流，似乎已经是两个世界的人了，不禁惘然！</p>
<h2 id="网络"><a class="markdownIt-Anchor" href="#网络"></a> 网络</h2>
<p>幸运的是，家里对上网没什么限制，虽会念叨营销号育儿经，但最终没狠下心。要是真的按着父母的认知来教育我的话，恐怕现在真的就是一个普普通通的大学生了吧。</p>
<p>感谢B站，让我在高中繁忙课业之余了解到大千世界的美好。有趣的是，我最初从跑鞋测评入坑b站，看似不正经，却锻炼了从营销号与优质创作者中筛选信息的能力，以及跨越并探索多个（购物）平台的能力。这些能力有着很好的可迁移性，让我快速搜集到不同领域的信息。</p>
<p>也感谢@数字游牧人，让我在学校第一次了解到程序员丰富而独特的生活，以及这个行业的种种精彩；感谢@就叫老张好了，让我在填志愿前看到IC从业现状与新工科毕业生未来；感谢@whynottv，mit读博那期视频里，“任尔东西南北风”，因热爱而all in的生活状态，让住在狭小出租屋的我从此有了憧憬，最终支撑我选择现在的方向……言之不尽</p>
<p>上一个帖子有uu回复说当个网红，起初有些郁闷，回头想想，其实也挺好。要是没有这些up主，我又会走向何方？不过实际来说，这方面赛道已经很拥挤了，没有亮眼的bg和颜值，哪里敢想那么多呢？只能说太高看我了。无论是技术大牛还是自媒体网红，没有高低贵贱之分，我想都有可学习之处，二者也不是对立关系。这是我的观点。</p>
<h2 id="认知"><a class="markdownIt-Anchor" href="#认知"></a> 认知</h2>
<pre><code>不少同学问过认知和信息获取的问题。一方面，认知需要循序渐进。我有过盲目听信营销号的经历，也看过所谓的低质内容。作为大学生，还是要建立自己的评判和审美标准。在这个信息泛滥的年代，品味和专注最为关键的。若真心愿意搜索，把兴趣偏好体现在日常刷的视频文字里，大数据很快会推送不同信息。多看多想，必然有所收获。
</code></pre>
<p>另一方面，看的再多，不如自己亲身体会。类比产品测评，看再多网上五花八门的视频文字，都比不上自己拿到实物后的比较。再如知乎上各路神仙给出的各种路线方法，看似都能够逻辑自洽，却只有亲自动手做起来，才能知道什么最适合自己。</p>
<h2 id="附录一"><a class="markdownIt-Anchor" href="#附录一"></a> 附录一</h2>
<p>下面给出我常用的平台和评价：</p>
<p>一.b站。高中时期的最爱，不过那个时候看的是半娱乐半科普性质视频。现在作为纯娱乐生活平台和youtube搬运平替。<br />
特别注意的是，近年来b站盈利性质加重，现在学习区充满了卖课的机构，搜网课最好还是直接看搬运的，观感更好（记得投币呀）。</p>
<p>二.小红书</p>
<p>plog平台</p>
<p>相比b站纯视频更快捷，信息密度更高，相比知乎观感更好，有一种短视频的感觉。<br />
1.生活，一搜就有，强大无需多言。<br />
2.琐碎，小道信息（最有特色的一集）。<br />
3.学习和就业方面的一些帖子。<br />
最近发现搭配上ai搜一搜，基本省去了信息整合的过程，这个功能点赞。</p>
<p>三.知乎</p>
<p>仰望星空</p>
<p>虽然山河日下，很多ai帖，广告帖，但整体用户素质比其他平台高很多，毕竟纯文字阅读已经删掉90%的人了。卧虎藏龙，各路神仙。在这里看到了许多文章，常常发觉自己的渺小。同时知乎上真的会有人用一大段文字，认真的回答你的疑问，感动！</p>
<p>1.学习和就业方面的计划，有不少质量很高的答案，也要注意适合自己的才是最好的。<br />
2.经济社会的内容（也有jianzheng的），看人“吵架”，锻炼批判思考能力。同时开阔眼界。<br />
3.专业技术，大佬云集</p>
<p>由知乎也可以引出很多其他的平台和网站。可以说b站是第一个认知上升的地方，知乎是第二个让我认知打开的地方。</p>
<p>其他：<br />
bry论坛<br />
欧易（吃瓜）<br />
boss直聘，offershow（吃瓜）<br />
豆包（一次性ai，功能齐全）</p>
<h2 id="教育"><a class="markdownIt-Anchor" href="#教育"></a> 教育</h2>
<pre><code>       本月看了2025最新的cs230，由ng和另一位教师教授（ng的口音非常舒服）。课程整体偏宏观，全面介绍了深度学习的各个方面，从模型训练到AI产品落地，到ai行业状况，北美就业形势，甚至是经济下行影响下社会风气的改变，并不高深，但很具启发性。第一节课ng就以从业者视角，在PPT上展示了cursor、windsurf、Claude，提到过对vibe coding的认识和影响。而课堂调查也显示，Stanford几乎所有学生都会vibe coding。
</code></pre>
<p>顶尖高校由业界大牛与资深教授授课，课程内容每年甚至每季度更新，同时建设专门网站，甚至是设计自动批改程序，配套线上资源。再看着cs230对学生的定位是“创业公司的首席技术官”。相比之下，看到电脑上还装着十年前就停止更新的devcpp，要求全员参加所谓的职业规划大赛，不禁惘然。</p>
<p>我不会奢望中国高校能够比肩世界top，但期待有一天，学生不再需要费尽周折地搜索自学路线、通过各种渠道获取彼岸国家的资源，能够真正获得有益的、个性化的教学，不用再为了水课和无意义的绩点消磨精力。应试教育固然很有性价比，多年下来，也带来了很大的副作用。身边很多雄心勃勃，天赋异禀的同龄人，习惯了遵规守矩的学习，面对大学自由的求学生活，不知何去何从。</p>
<p>教育改革，还有很长的路要走。也许我们这代人没有机会看到了，也许我们因10043已经无法赴美求学，也许一切都是妥协的结果，但，“I have a dream”。我真心不希望自己的孩子（如果有的话），再经受我所经历的折磨。凭借国内实力和人才数量，我相信这一天早晚会到来。这需要所有人的努力。</p>
<h2 id="附录二"><a class="markdownIt-Anchor" href="#附录二"></a> 附录二</h2>
<p>虽然日常生活中总会开玩笑说“离人很远了”，但我并非什么天才，不过是个“想得太多，做的太少”的普通学生。未来大概率也就是只“高不成低不就”的牛马。</p>
<p>常有被数学和代码支配的无力感；会在不确定的未来中迷茫；面对毫无意义的课内kpi焦虑；在就业与读研中45度躺平；一边看着超长的to do list一边拖延 ；因没有能谈心的朋友而感到孤单……</p>
<p>有时候看到情侣的日常，也会幻想着一场甜甜的恋爱，只可惜从小到大，自己面对异性的时候，总是像个人机（其实已经不如人机了）。就算拿着珍稀的数据集反复琢磨，也逃不掉过拟合的结局。而连文本信息都处理不好，更别提多模态能力了。而当提到自己研究领域的时候，却又突然两眼放光，侃侃而谈。这种人怎么会有吸引力呢？苦笑。不过冷静下来，其实只是想有一个可以倾诉的对象吧。（GPT，说的就是你！）</p>
<p>想来自己的教育经历，算是平平无奇吧。无论生活，情感，还是学习，留下了不少遗憾。以前同龄人里最落伍的&quot;保守派&quot;，如今却想去做最前沿的方向。那些年走过的弯路，做过的看似&quot;不务正业&quot;的事情，最终塑造了独一无二的自己。</p>
<h2 id="谈谈ai"><a class="markdownIt-Anchor" href="#谈谈ai"></a> 谈谈ai</h2>
<p>从成为deepseek最早的一批用户开始，便和ai结下了缘分。高考后选择来了以cs闻名的北邮，随后又选择了深度学习，算是一个入局者了。</p>
<p>还记得刚接触深度学习理论的时候，曾因为神经网络与人脑表面的相似，天真的以为这就是生命的奥秘。正如花书序言写到，深度学习领域本质仍是逻辑和数学。进一步学习之后，渐渐看到现代大模型理论是如何在一篇篇前人的论文上构建，简单的模型运行背后是一行行逻辑严密的代码，以及咆哮的显卡 ，增长的电费。虽然不再觉得大模型能够通往AGI，但它凝结了工业界的全部力量 ，已是现今文明能达到的最高峰。感慨不已！</p>
<h2 id="ai原住民"><a class="markdownIt-Anchor" href="#ai原住民"></a> ai原住民</h2>
<pre><code>    水群时学长偶然提到，“以前我们是互联网原住民”，现在你们是ai原住民”。是啊，22年到25年，恰是在高中与大学这个关键时期，我们见证了个人与ai行业的共同成长。高中时，还在打趣ai解不出来作业题。如今才刚上大学，已经完全离不开ai了。“等毕业的时候，说不定ai都能代替我工作了吧。”当然这也与软件受影响较大有关系。

    有时不禁觉得人类的教育，相对于ai的进步，世界的变化，真的太过缓慢。花费18年才称得上是成年人。培养一个博士，更是要35年。学校与市场脱节在所难免，平衡教学与就业对整个教育系统也是巨大挑战。“我们不会在课堂上教授具体知识了，因为它们一两年之内就会被淘汰。”技术会过时，规则会改变，保持一颗“崭新且聪明的头脑”更为重要。
</code></pre>
<p>话说回来，vibe coding这个话题网上讨论很多。从我自身的体会来说，现阶段纯vibe coding只是玩具，说程序员被取代也是个玩笑话。虽然各企业都在加快引进，但能否提供清晰的prompt和idea对效率影响极大，也是很有门槛的事情。</p>
<p>而与模型对话代替了传统的搜索引擎，也大大降低了知识的获取成本，以及学习和工作的门槛（还有水作业的成本）。对于我来说当然是重大利好。</p>
<h2 id="行业"><a class="markdownIt-Anchor" href="#行业"></a> 行业</h2>
<p>2025年仍然是ai市场火热的一年，英伟达虽是当之无愧的霸主，但也受各大公司自研芯片的威胁。Google，meta，openai等多个公司继续角逐，国产大模型积极跟进。摩尔线程，沐曦成为新兴的千亿巨头（真没想到能炒到这么高），智谱，minimax准备上市。12月，小米MiMo发布，姚顺雨27岁执掌腾讯ai，字节豆包全员信提薪。变化层出不穷，而ai泡沫的阴影始终伴随着这一切，虽然这个时代我已经见惯了奇迹，但当从旁观者变成入局者时，业内的每一次变动都变得与自己息息相关，才第一次亲身体会到：我们的未来与时代的脉搏紧密相连！</p>
<p>技术和规模的发展很快。当初clip256张v100已经被视为巨大工程，如今的显卡供不应求，千卡集群，万卡集群习以为常。近年来大环境寒气日益加重。我们毕业时不会再有高速发展的互联网行业，而未来35岁跳入体制的希望更是渺茫。即使是Stanford的课堂上，也要反复强调就业形势的严峻，以及ai泡沫的警示。与之对应的，是国内大厂给大模型顶尖开出一个又一个大包。北美市场的现状，会不会就是我们的未来？</p>
<p>然而反过来想，资本市场，泡沫总是有的，炒作永远不会停止。正如劳伦斯在结课时所说，2000年初的互联网泡沫破碎固然残酷，但20年过去了，“我们还站在这”，站在一个前所未有的高度。当初最终在危机中生存下来的公司，Amazon，google…如今都成了一方巨头，而互联网行业甚至比当年更加强大。在人几十年的生命周期里，注定是要经历危机与泡沫的，与其选择逃避，不如主动拥抱。选择更加落地的方向，做更实在的工作——这当然很难，但一想到未来的挑战，我常常激动不已。</p>
<p>说到这里，特别敬佩奋战在一线的前辈们，行业整体节奏极快，对学习的能力和体力都是很大的考验。17年的transformer，22年的chatgpt，过去短短几年，现在看来却好像是上个世纪的产物。而今ai行业趋向浮躁，鱼龙混杂，顶会水分加大，天价年薪层出不穷。ai的盈利点尚且不明确，危机感如影随形。他们经历过一轮又一轮的更迭，其中百味想必远超于我。</p>
<h2 id="未来"><a class="markdownIt-Anchor" href="#未来"></a> 未来</h2>
<p>大模型的边际效益递减，除了继续改进架构，扩大规模之外，一方面出现VLA，world model等新方向（不太了解），具身智能趋向稳定。另一方面在应用端，各种细分市场也在被逐渐重视挖掘。</p>
<p>各家的模型性能差距，对于普通用户来说已经微乎其微，如何利用企业自己已有的产品特点，帮助自家ai进行对应的用户推广和适配，可能会是更重要的事情。字节在这一点上真的是做的很好！作为原生多模态的模型，功能和性能俱佳，对一个普通用户来说体验已经很好！豆包手机也十分惊艳！</p>
<p>此外，在嵌入式系统上的小模型，我觉得也是一个方向，而且对于个人开发者来说更加利好。这方面已经有不少厂家在尝试了。而小米在人车家等硬件方向上构建的ai系统，我也十分期待！</p>
<h2 id="结尾"><a class="markdownIt-Anchor" href="#结尾"></a> 结尾</h2>
<p>人的一生会经历许多风口，错过本是常态，但只需抓住一个。也许这是性格使然，未知的事物总是对我有莫大的吸引力。有时候也羡慕家境好的同学，手握名校title和竞赛牌子的同学，有财富和天赋兜底，在学校里无忧的探索。但这期间逼出来自己身上的狠劲、勇气与反思的能力，亦远远超出了我的想象，我想这就是ai时代带来的影响，这是独属于我的人生财富！</p>
<p>回想起生日那天晚上，夜幕下，一个人独行于两侧灯火通明的大楼之间。返校时，学校空旷的大道上洒满了初雪……</p>
<p>这便是19岁最好的结语。</p>
<p>2025年12月27日</p>
<p>北京邮电大学沙河校区</p>
<p>2026，去做一个有趣的人吧！</p>
]]></content>
      <categories>
        <category>Insight</category>
      </categories>
  </entry>
</search>
