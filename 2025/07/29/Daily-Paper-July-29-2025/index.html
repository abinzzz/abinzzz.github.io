<!DOCTYPE html>

<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <!--
        hexo-theme-suka © SukkaW
        GitHub: https://github.com/SukkaW/hexo-theme-suka
    -->

    <!-- ### Resource Hint ### -->

    <!-- ## DNS Prefetch ## -->
    <meta http-equiv="x-dns-prefetch-control" content="on">

<!-- busuanzi -->

    <link rel="dns-prefetch" href="//busuanzi.ibruce.info">


<!-- comment -->


    <link rel="dns-prefetch" href="//disqus.com">
    <link rel="dns-prefetch" href="//robin02.disqus.com">






<!-- analytics -->







    <!-- ## Preload ## -->
    
    <!-- Busuanzi -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" as="script">







    <!-- ### Meta & Title & Info ### -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <meta name="renderer" content="webkit">

    <!-- Title -->
    <title>Daily Paper | July 29, 2025 | blog</title>

    <!-- Favicons -->
    <link rel="icon" type="image&#x2F;ico" href="/img/blog.ico">

    <!-- ### Import File ### -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spectre.css@0.5.3"><style>
    body {
        background-color: #f8f9fa;
    }

    a, a:visited {
        color: blue;
    }

    a:active, a:focus, a:hover {
        color: blue;
        opacity: .75;
    }

    #post-content a,
    #post-content a:hover,
    #post-content a:focus,
    #post-content a:visited {
        color: blue;
        opacity: 1;
    }

    

    .post-entry .card-body a {
        color: red;
    }

    .avatar {
        background: red;
    }

    .navbar-link,
    .navbar-link:visited,
    .timeline .timeline-item .timeline-icon.icon-lg {
        color: red;
    }

    .navbar-link:hover {
        color: red;
        opacity: .8;
    }

    #search-input .btn,
    #disqus_click_btn,
    #disqus-switch-to-direct,
    #disqus-loadmore-button {
        background: red;
        border-color: red;
        color: #fff;
    }

    #post-toc a.post-toc-link,
    #post-toc a.post-toc-link:visited,
    .share-menu.menu .menu-item>a {
        color: red;
    }

    .share-menu.menu .menu-item>a:hover,
    .share-menu.menu .menu-item>a:focus,
    .share-menu.menu .menu-item>a:visited {
        color: #50596c;
        background: #f8f9fa;
        opacity: .85;
    }
</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/style.min.css">








    <!-- Prettify Theme -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css"></noscript>





<script>
/*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
!function(t){"use strict";t.loadCSS||(t.loadCSS=function(){});var e=loadCSS.relpreload={};if(e.support=function(){var e;try{e=t.document.createElement("link").relList.supports("preload")}catch(t){e=!1}return function(){return e}}(),e.bindMediaToggle=function(t){var e=t.media||"all";function a(){t.addEventListener?t.removeEventListener("load",a):t.attachEvent&&t.detachEvent("onload",a),t.setAttribute("onload",null),t.media=e}t.addEventListener?t.addEventListener("load",a):t.attachEvent&&t.attachEvent("onload",a),setTimeout(function(){t.rel="stylesheet",t.media="only x"}),setTimeout(a,3e3)},e.poly=function(){if(!e.support())for(var a=t.document.getElementsByTagName("link"),n=0;n<a.length;n++){var o=a[n];"preload"!==o.rel||"style"!==o.getAttribute("as")||o.getAttribute("data-loadcss")||(o.setAttribute("data-loadcss",!0),e.bindMediaToggle(o))}},!e.support()){e.poly();var a=t.setInterval(e.poly,500);t.addEventListener?t.addEventListener("load",function(){e.poly(),t.clearInterval(a)}):t.attachEvent&&t.attachEvent("onload",function(){e.poly(),t.clearInterval(a)})}"undefined"!=typeof exports?exports.loadCSS=loadCSS:t.loadCSS=loadCSS}("undefined"!=typeof global?global:this);
</script>

    <!-- ### Site Verification ### -->
    


    <meta name="mobile-web-app-capable" content="yes"><meta name="application-name" content="blog"><meta name="msapplication-starturl" content="https://abinzzz.github.io"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="blog">

    <!-- ### The Open Graph & Twitter Card Protocol ### -->
    <meta property="og:title" content="Daily Paper | July 29, 2025 | blog"><meta property="og:site_name" content="blog"><meta property="og:type" content="article"><meta property="og:url" content="https://abinzzz.github.io/2025/07/29/Daily-Paper-July-29-2025/"><meta property="og:locale" content="zh-CN"><meta name="description" content="Table of Content  AlphaGo Moment for Model Architecture Discovery Group Sequence Policy Optimization GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING Step-3 is Large yet Afforda - ab - blog"><meta name="keywords" content="blog"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887c2c58cb8da5c8eb80c3.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887baf58cb8da5c8eb7ded.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887c4a58cb8da5c8eb8124.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887ce358cb8da5c8eb84e8.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887d4058cb8da5c8eb886f.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887dcf58cb8da5c8eb8fc2.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887e4458cb8da5c8eb9513.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887e9e58cb8da5c8eb984c.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/68887fa958cb8da5c8eba499.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/6888803858cb8da5c8ebaad7.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688880a258cb8da5c8ebb00f.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/6888811b58cb8da5c8ebb46a.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688882e958cb8da5c8ebc2bf.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/6888832d58cb8da5c8ebc456.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/6888839258cb8da5c8ebc931.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/6888843458cb8da5c8ebcdd9.png"><meta property="article:published_time" content="2025-07-29T07:20:03.000Z"><meta property="article:modified_time" content="2025-07-29T08:57:11.197Z"><meta property="og:updated_time" content="2025-07-29T08:57:11.197Z"><meta property="article:author" content="ab"><meta property="article:tag" content="blog"><meta name="twitter:card" content="summary">

    

    <!-- ### Canonical link ### -->
    <link rel="canonical" href="https://abinzzz.github.io/2025/07/29/Daily-Paper-July-29-2025/">

    <meta name="generator" content="Hexo 5.4.2">

    <!-- ### Analytics ### -->
    







    <!-- ### Structured Data ### -->
    



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "https://abinzzz.github.io/2025/07/29/Daily-Paper-July-29-2025/",
    "@type": "BlogPosting",
    "logo": "https://abinzzz.github.io/img/blog.ico",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://abinzzz.github.io/2025/07/29/Daily-Paper-July-29-2025/"
    },
    "headline": "Daily Paper | July 29, 2025 | blog",
    
    "image": {
        "@type": "ImageObject",
        "url": "https://abinzzz.github.io/img/blog.ico"
    },
    
    "datePublished": "2025-07-29T07:20:03.000Z",
    "dateModified": "2025-07-29T08:57:11.197Z",
    "author": {
        "@type": "Person",
        "name": "ab",
        "image": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/avatar.jpg"
        },
        "description": "Welcome to my blog!"
    },
    "publisher": {
        "@type": "Organization",
        "name": "blog",
        "logo": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/blog.ico"
        }
    },
    
    "potentialAction": {
        "@type": "SearchAction",
        "target": "https://abinzzz.github.io/search?s={search_term_string}",
        "query-input": "required name=search_term_string"
    },
    
    "keywords": "blog",
    "description": "Table of Content  AlphaGo Moment for Model Architecture Discovery Group Sequence Policy Optimization GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING Step-3 is Large yet Afforda - ab - blog"
}
</script>



    <!-- ### Custom Head ### -->
    
</head>

    <body>
            

            <!-- ### Main content ### -->
            <!-- ## Header ##-->
<header>
    <h1 class="header-title text-center"><a href="/">blog</a></h1>

    <p class="text-center header-slogan">
        
            
                Welcome to my blog!
            
        
    </p>

    <nav class="navbar-section text-center">
    
        <a href="/" class="navbar-link">首页</a>
    
    
        <a href="/archives/" class="navbar-link">归档</a>
    
    
        <a href="/search" class="navbar-link">搜索</a>
    
    
    
    
</nav>
</header>

            
    <!-- ## Post ## -->
    <div class="post-container">
    <div id="post-card" class="card">
        
        <div class="card-item-container">
            <div class="card-inner-cell">
                <!-- # Post Header Info # -->
                <div class="card-header">
                    
    <h1 class="card-title h3 mb-2">Daily Paper | July 29, 2025</h1>




<div class="post-header-info">
    <p class="post-header-info-left text-gray">
        <img class="author-thumb lazyload" data-src="/img/avatar.jpg" src="/img/suka-lazyload.gif" alt="ab's Avatar">
        <span>2025-07-29</span>
        
            <span class="suka-devide-dot"></span>
            <a class="category-link" href="/categories/Daily-Paper/">Daily Paper</a>
        
        
        
    </p>
    <div class="post-header-info-right">
        
            <div class="dropdown dropdown-right">
<a class="dropdown-toggle" tabindex="0">分享本文</a>
<ul class="menu share-menu">
    <!-- Share Weibo -->
    

    <!-- Share Twitter -->
    

    <!-- Share Facebook -->
    

    <!-- Share Google+ -->
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    

    <!-- QRCode -->
    
    <li class="menu-item">
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJQAAACUCAAAAABQV18IAAAB4klEQVR42u3ay27DMAxEUf//TydbQzA5l7YXIj3etEhS6RRQ9Bjq+G34HEYZZZRRF6gjedIGTu+TNtBnjBqDIp2eG15/jz6zvi77MWoUah145PWok6uBrNoz6luoq86y1+78k0Z9C0UW6QhM+zFqHipaKNf3yeJM2nm0SzBqe1S2oX/z52unGaO2RsnQAUx65ODwaupi1NaobCBmYUY2eCO0WtyNmoHKFtcMozqMQrO0D6NGoMJBJzZuZGOnJlkZ7hvVHqUQFXQEKO08jWqJqhR/KotsNTAzag6qEqaSCfFuAcqoWSj1hxEwmhxJSCsHulFtUeSPs87IYCdfFqPmoEhhh4SqlSJS+OUyahQqG4zkooQKzlRB3KhZKNU4Df7J4RUHHEa1RlUmQRJqZKErrjgY1RpVufygwg26oJeKkEa1Q5FCYmWQVwvhRs1DVcIO8nl8ietu6mJUC1TlMJAVLtUXJC0mGTUKpSY/OtmSi4HlcN+oVij1qIZIMZIcMIyag3pSxFaHAnIxunRwMKoNilyiUQssLXTjW0FGtUdVikOlIOzJLsGosShS9FaDW20qjfoWigxiUrhUQa9Rs1BZuEXDCxWKvLbJM2p7VGXBJUVrctlGBrFGtUXt9BhllFFGnZ4/5XCRIA+L6JsAAAAASUVORK5CYII=" alt="QRCode">
    </li>
    

</ul>
</div>
        
    </div>
</div>
                </div>
                <div class="card-body">
                    
                        
                        
                            <div id="post-toc"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#table-of-content"><span class="post-toc-number">1.</span> <span class="post-toc-text"> Table of Content</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#alphago-moment-for-model-architecture-discovery"><span class="post-toc-number">2.</span> <span class="post-toc-text"> AlphaGo Moment for Model Architecture Discovery</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#group-sequence-policy-optimization"><span class="post-toc-number">3.</span> <span class="post-toc-text"> Group Sequence Policy Optimization</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning"><span class="post-toc-number">4.</span> <span class="post-toc-text"> GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding"><span class="post-toc-number">5.</span> <span class="post-toc-text"> Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#back-to-the-features-dino-as-a-foundation-for-video-world-models"><span class="post-toc-number">6.</span> <span class="post-toc-text"> Back to the Features: DINO as a Foundation for Video World Models</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#gemini-25-pro-capable-of-winning-gold-at-imo-2025"><span class="post-toc-number">7.</span> <span class="post-toc-text"> Gemini 2.5 Pro Capable of Winning Gold at IMO 2025</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#learning-without-training-the-implicit-dynamics-of-in-context-learning"><span class="post-toc-number">8.</span> <span class="post-toc-text"> Learning without training : The implicit dynamics of in-context learning</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#checklists-are-better-than-reward-models-for-aligning-language-models"><span class="post-toc-number">9.</span> <span class="post-toc-text"> Checklists Are Better Than Reward Models For Aligning Language Models</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset"><span class="post-toc-number">10.</span> <span class="post-toc-text"> GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</span></a></li></ol></div>
                        
                    
                    <article id="post-content">
                        <!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#alphago-moment-for-model-architecture-discovery">AlphaGo Moment for Model Architecture Discovery</a></li>
<li><a href="#group-sequence-policy-optimization">Group Sequence Policy Optimization</a></li>
<li><a href="#gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning">GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING</a></li>
<li><a href="#step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding">Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</a></li>
<li><a href="#back-to-the-features-dino-as-a-foundation-for-video-world-models">Back to the Features: DINO as a Foundation for Video World Models</a></li>
<li><a href="#gemini-25-pro-capable-of-winning-gold-at-imo-2025">Gemini 2.5 Pro Capable of Winning Gold at IMO 2025</a></li>
<li><a href="#learning-without-training--the-implicit-dynamics-of-in-context-learning">Learning without training : The implicit dynamics of in-context learning</a></li>
<li><a href="#checklists-are-better-than-reward-models-for-aligning-language-models">Checklists Are Better Than Reward Models For Aligning Language Models</a></li>
<li><a href="#gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset">GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</a></li>
</ul>
<h2 id="alphago-moment-for-model-architecture-discovery"><a class="markdownIt-Anchor" href="#alphago-moment-for-model-architecture-discovery"></a> AlphaGo Moment for Model Architecture Discovery</h2>
<p><img src="https://pic1.imgdb.cn/item/68887c2c58cb8da5c8eb80c3.png" alt="" /><br />
The provided text describes ASI-ARCH, an AI system designed to autonomously discover and innovate neural network architectures, moving beyond traditional human-limited search methods. The system operates through three core modules: a Researcher that proposes novel designs, an Engineer that implements and evaluates them, and an Analyst that extracts insights from experiments. ASI-ARCH has successfully identified 106 state-of-the-art linear attention architectures, demonstrating a computational scaling law for scientific discovery in AI research. This breakthrough suggests that AI can significantly accelerate the pace of architectural innovation by continually learning and evolving its own designs, similar to how AlphaGo revealed new strategic principles in games.</p>
<p><img src="https://pic1.imgdb.cn/item/68887baf58cb8da5c8eb7ded.png" alt="" /></p>
<h2 id="group-sequence-policy-optimization"><a class="markdownIt-Anchor" href="#group-sequence-policy-optimization"></a> Group Sequence Policy Optimization</h2>
<p><img src="https://pic1.imgdb.cn/item/68887c4a58cb8da5c8eb8124.png" alt="" /></p>
<p>GSPO addresses critical stability and efficiency issues inherent in previous state-of-the-art RL algorithms like Group Relative Policy Optimization (GRPO), particularly when training gigantic and Mixture-of-Experts (MoE) LLMs.</p>
<p>The core innovation of GSPO lies in its sequence-level approach to importance ratio definition, clipping, rewarding, and optimization, contrasting with GRPO’s token-level methods. This fundamental change is theorized to align more closely with the basic principles of importance sampling, where rewards are granted to entire sequences. GSPO has demonstrated superior training stability, efficiency, and performance, notably resolving the instability challenges in MoE RL training without complex workarounds. These advancements have been instrumental in the “remarkable improvements in the latest Qwen3 models.” GSPO also offers potential for simplifying RL infrastructure by enabling direct use of likelihoods from inference engines.</p>
<h2 id="gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning"><a class="markdownIt-Anchor" href="#gepa-reflective-prompt-evolution-can-outperform-reinforcement-learning"></a> GEPA: REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING</h2>
<p><img src="https://pic1.imgdb.cn/item/68887ce358cb8da5c8eb84e8.png" alt="" /></p>
<p>This paper introduces GEPA (Genetic-Pareto), a novel prompt optimizer designed for compound AI systems. GEPA distinguishes itself by employing a multi-objective evolutionary search that incorporates natural language feedback from new system rollouts to iteratively refine prompts. Unlike greedy update methods, GEPA maintains a Pareto front of top-performing prompts, fostering diversity and robust generalization to avoid local optima. The authors demonstrate GEPA’s superior sample efficiency and performance against state-of-the-art optimizers like MIPROv2 and GRPO across various tasks, highlighting its ability to generate shorter, more effective prompts and adapt AI systems rapidly even with limited data or budget. The methodology involves reflective prompt mutation and Pareto-based candidate selection, as illustrated by the system’s iterative search process and sample prompt examples for tasks like HotpotQA and PUPA.</p>
<p><img src="https://pic1.imgdb.cn/item/68887d4058cb8da5c8eb886f.png" alt="" /></p>
<h2 id="step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding"><a class="markdownIt-Anchor" href="#step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding"></a> Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</h2>
<p><img src="https://pic1.imgdb.cn/item/68887dcf58cb8da5c8eb8fc2.png" alt="" /></p>
<p>Step-3 is a 321-billion-parameter Vision-Language Model (VLM) developed by StepFun Inc., specifically designed to minimize decoding costs for long-context reasoning tasks. It introduces a novel “model-system co-design” approach that focuses on hardware efficiency. Key innovations include the Multi-Matrix Factorization Attention (MFA) mechanism, which reduces KV cache size and computation while maintaining expressiveness, and Attention-FFN Disaggregation (AFD), a distributed inference system that decouples attention and Feed-Forward Network (FFN) layers.</p>
<p>Step-3 activates 38 billion parameters per token, more than comparable models like DeepSeek-V3 and Qwen3 MoE 235B, yet achieves significantly lower theoretical decoding costs. Its implementation on Hopper GPUs demonstrates a decoding throughput of up to 4,039 tokens per second per GPU, outperforming DeepSeek-V3 and setting a new Pareto frontier for LLM decoding efficiency. The paper argues that total or activated parameter count is a poor indicator of decoding costs, highlighting the critical role of hardware-aligned attention arithmetic intensity, MoE sparsity, and AFD in achieving cost-effectiveness.</p>
<p><img src="https://pic1.imgdb.cn/item/68887e4458cb8da5c8eb9513.png" alt="" /></p>
<h2 id="back-to-the-features-dino-as-a-foundation-for-video-world-models"><a class="markdownIt-Anchor" href="#back-to-the-features-dino-as-a-foundation-for-video-world-models"></a> Back to the Features: DINO as a Foundation for Video World Models</h2>
<p><img src="https://pic1.imgdb.cn/item/68887e9e58cb8da5c8eb984c.png" alt="" /></p>
<p>The paper introduces DINO-world, a novel generalist video world model designed to predict future frames in the latent space of DINOv2. This model addresses key challenges in training effective world models, such as the need for large-scale, annotated video data and the computational cost of pixel-based generative models. By leveraging a pre-trained image encoder (DINOv2) and training a future predictor on a massive, uncurated video dataset, DINO-world achieves superior performance in diverse video prediction benchmarks, including segmentation and depth forecasting, and demonstrates a strong understanding of intuitive physics. A significant advantage is its ability to be fine-tuned on observation-action trajectories for planning, making it suitable for controlling agents in simulated environments. DINO-world offers a more resource-efficient architecture compared to state-of-the-art pixel-based models, making it a promising step towards more generalist and adaptable AI agents.</p>
<p><img src="https://pic1.imgdb.cn/item/68887fa958cb8da5c8eba499.png" alt="" /></p>
<h2 id="gemini-25-pro-capable-of-winning-gold-at-imo-2025"><a class="markdownIt-Anchor" href="#gemini-25-pro-capable-of-winning-gold-at-imo-2025"></a> Gemini 2.5 Pro Capable of Winning Gold at IMO 2025</h2>
<p><img src="https://pic1.imgdb.cn/item/6888803858cb8da5c8ebaad7.png" alt="" /></p>
<p>A recent research paper, “Gemini 2.5 Pro Capable of Winning Gold at IMO 2025,” presents a significant breakthrough in the field of Large Language Models (LLMs) and their ability to solve highly complex mathematical problems, specifically those encountered in the International Mathematical Olympiad (IMO). The authors, Yichen Huang and Lin F. Yang, demonstrate that by employing a sophisticated “self-verification pipeline” with meticulous prompt engineering, Google’s Gemini 2.5 Pro model successfully solved 5 out of 6 problems from the newly released IMO 2025 competition. This performance level is unprecedented for LLMs on Olympiad-level mathematics and suggests a shift from mere pattern recognition or data retrieval to more genuine complex reasoning and proof construction capabilities. The methodology emphasizes rigorous, multi-step logical deduction and an iterative refinement process, indicating that optimal strategies are crucial for harnessing the full potential of powerful LLMs for complex reasoning tasks.</p>
<p><img src="https://pic1.imgdb.cn/item/688880a258cb8da5c8ebb00f.png" alt="" /></p>
<h2 id="learning-without-training-the-implicit-dynamics-of-in-context-learning"><a class="markdownIt-Anchor" href="#learning-without-training-the-implicit-dynamics-of-in-context-learning"></a> Learning without training : The implicit dynamics of in-context learning</h2>
<p><img src="https://pic1.imgdb.cn/item/6888811b58cb8da5c8ebb46a.png" alt="" /></p>
<p>This paper explores In-Context Learning (ICL) in Large Language Models (LLMs), a phenomenon where LLMs acquire new patterns from examples presented in the prompt without explicit weight updates. The authors propose that a transformer block, specifically the stacking of a self-attention layer with an MLP (Multi-Layer Perceptron), implicitly modifies the MLP layer’s weights based on the input context. They introduce the concept of a “contextual block” and demonstrate through theory and experimentation how context translates into a low-rank weight update of the MLP, effectively acting as an implicit fine-tuning mechanism. This implicit update is shown to resemble gradient descent, suggesting a form of implicit learning dynamics at inference time. The research offers a theoretical framework for understanding ICL beyond restrictive assumptions of prior work, although it acknowledges limitations to single transformer blocks and the initial output token.</p>
<h2 id="checklists-are-better-than-reward-models-for-aligning-language-models"><a class="markdownIt-Anchor" href="#checklists-are-better-than-reward-models-for-aligning-language-models"></a> Checklists Are Better Than Reward Models For Aligning Language Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688882e958cb8da5c8ebc2bf.png" alt="" /></p>
<p>The provided text introduces Reinforcement Learning from Checklist Feedback (RLCF), a novel method for aligning large language models (LLMs) to better follow user instructions. Unlike traditional reinforcement learning methods that use fixed criteria, RLCF employs dynamic, instruction-specific checklists to evaluate responses, generating more flexible and precise reward signals. This approach utilizes both AI judges and specialized verifier programs to score how well an LLM’s output satisfies each checklist item. The authors demonstrate that RLCF consistently improves performance across various benchmarks, highlighting its effectiveness in eliciting desirable behaviors in open-ended instruction-following tasks, even for models that haven’t been specifically instruction-tuned. The research also details the creation of “WildChecklists,” a large dataset of instructions and corresponding synthetically generated checklists, and explores the computational efficiency of the method.</p>
<p><img src="https://pic1.imgdb.cn/item/6888832d58cb8da5c8ebc456.png" alt="" /></p>
<h2 id="gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset"><a class="markdownIt-Anchor" href="#gpt-image-edit-15m-a-million-scale-gpt-generated-image-dataset"></a> GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</h2>
<p><img src="https://pic1.imgdb.cn/item/6888839258cb8da5c8ebc931.png" alt="" /></p>
<p>The “GPT-IMAGE-EDIT-1.5M” paper introduces a significant new public dataset designed to advance open-source research in instruction-guided image editing. This dataset comprises over 1.5 million high-quality triplets of {instruction, source image, edited image}. It was systematically constructed by leveraging the advanced capabilities of GPT-4o to unify and refine existing popular image-editing datasets (OmniEdit, HQ-Edit, and UltraEdit). The core methodology involves regenerating output images for enhanced visual quality and instruction alignment, and selectively rewriting prompts to improve semantic clarity.</p>
<p>Models fine-tuned on GPT-IMAGE-EDIT-1.5M, specifically FluxKontext, have achieved state-of-the-art performance among open-source methods across various benchmarks (e.g., 7.24@GEdit-EN, 3.80@ImgEdit-Full, 8.78@Complex-Edit). This significantly narrows the performance gap with leading proprietary models like GPT-4o. The release of this dataset aims to “catalyze further open research in instruction-guided image editing.”</p>
<p><img src="https://pic1.imgdb.cn/item/6888843458cb8da5c8ebcdd9.png" alt="" /></p>

                    </article>
                    


    <blockquote id="date-expire-notification" class="post-expired-notify">本文最后更新于 <span id="date-expire-num"></span> 天前，文中所描述的信息可能已发生改变</blockquote>
    <script>
    (function() {
        var dateUpdate = Date.parse("2025-07-29");
        var nowDate = new Date();
        var a = nowDate.getTime();
        var b = a - dateUpdate;
        var daysUpdateExpire = Math.floor(b/(24*3600*1000));
        if (daysUpdateExpire >= 120) {
            document.getElementById('date-expire-num').innerHTML = daysUpdateExpire;
        } else {
            document.getElementById('date-expire-notification').style.display = 'none';
        }
    })();
    </script>


<p class="post-footer-info mb-0 pt-0">本文发表于&nbsp;<time datetime="2025-07-29T07:20:03.000Z" itemprop="datePublished">2025-07-29</time>

</p>
<p class="post-footer-info mb-0 pt-2">

<span class="post-categories-list mt-2">

<a class="post-categories-list-item" href='/categories/Daily-Paper/'>Daily Paper</a>

</span>




</p>

                </div>
                <div class="post-nav px-2 bg-gray">
<ul class="pagination">
    <!-- Prev Nav -->
    

    <!-- Next Nav -->
    
        <li class="page-item page-next">
            <a href="/2025/07/27/Guide-to-Rebuttal/" rel="next">
                <div class="page-item-title"><i class="icon icon-forward" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">Guide to Rebuttal</div>
            </a>
        </li>
    
</ul>
</div>

                
                    <!-- # Comment # -->
                    
                        <div class="card-footer post-comment">
                            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
        this.page.url = 'https://abinzzz.github.io/2025/07/29/Daily-Paper-July-29-2025/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://abinzzz.github.io/2025/07/29/Daily-Paper-July-29-2025/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>
<script id="disqus-thread-script">
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//robin02.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

                        </div>
                    
                
            </div>
        </div>
    </div>
</div>

            <!-- ### Footer ### -->
            <footer class="text-center">
    <!-- footer copyright -->
    
        <p class="footer-copyright mb-0">Copyright&nbsp;©&nbsp;<span id="copyright-year"></span>
            <a class="footer-copyright-a" href="https://abinzzz.github.io">blog</a>
        </p>

    <!-- footer custom text -->
    <p class="footer-text mb-0">
    
    </p>
    <!-- footer develop info -->
    <p class="footer-develop mb-0">
        
    <!-- Busuanzi User Views -->
    <span id="busuanzi_container_site_uv" hidden>
        <span></span>
        <span id="busuanzi_value_site_uv"></span>
        <span>Viewers</span>
        
            <span>|</span>
        
    </span>




        
        Powered by&nbsp;<!--
         --><a href="https://hexo.io" target="_blank" class="footer-develop-a" rel="external nofollow noopener noreferrer">Hexo</a><span class="footer-develop-divider"></span>Theme&nbsp;-&nbsp;<!--
         --><a href="https://github.com/SukkaW/hexo-theme-suka" target="_blank" class="footer-develop-a" rel="external noopener">Suka</a>
    </p>
</footer>


        <!-- ### Import File ### -->
        <!-- ### Footer JS Import ### -->

<script>

    
window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 50
};

(function() {
    var copyrightNow = new Date().getFullYear();
    var copyrightContent = document.getElementById('copyright-year');
    var copyrightSince = 2023;
    if (copyrightSince === copyrightNow) {
        copyrightContent.textContent = copyrightNow;
    } else {
        copyrightContent.textContent = copyrightSince + ' - ' + copyrightNow;
    }
})();
console.log('\n %c Suka Theme (hexo-theme-suka) | © SukkaW | Verision 1.3.3 %c https://github.com/SukkaW/hexo-theme-suka \n', 'color: #fff; background: #444; padding:5px 0;', 'background: #bbb; padding:5px 0;');

</script>

<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@8.9.0" async></script>
    <script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" async></script>


<!-- Offset -->




<!-- Comment -->

    
        <script id="dsq-count-scr" src="https://robin02.disqus.com/count.js" async></script>

    


<!-- ### Custom Footer ### -->

    </body>

</html>