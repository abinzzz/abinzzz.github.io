<!DOCTYPE html>

<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <!--
        hexo-theme-suka © SukkaW
        GitHub: https://github.com/SukkaW/hexo-theme-suka
    -->

    <!-- ### Resource Hint ### -->

    <!-- ## DNS Prefetch ## -->
    <meta http-equiv="x-dns-prefetch-control" content="on">

<!-- busuanzi -->

    <link rel="dns-prefetch" href="//busuanzi.ibruce.info">


<!-- comment -->


    <link rel="dns-prefetch" href="//disqus.com">
    <link rel="dns-prefetch" href="//robin02.disqus.com">






<!-- analytics -->







    <!-- ## Preload ## -->
    
    <!-- Busuanzi -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" as="script">







    <!-- ### Meta & Title & Info ### -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <meta name="renderer" content="webkit">

    <!-- Title -->
    <title>Daily Paper | Aug 2, 2025 | blog</title>

    <!-- Favicons -->
    <link rel="icon" type="image&#x2F;ico" href="/img/blog.ico">

    <!-- ### Import File ### -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spectre.css@0.5.3"><style>
    body {
        background-color: #f8f9fa;
    }

    a, a:visited {
        color: blue;
    }

    a:active, a:focus, a:hover {
        color: blue;
        opacity: .75;
    }

    #post-content a,
    #post-content a:hover,
    #post-content a:focus,
    #post-content a:visited {
        color: blue;
        opacity: 1;
    }

    

    .post-entry .card-body a {
        color: red;
    }

    .avatar {
        background: red;
    }

    .navbar-link,
    .navbar-link:visited,
    .timeline .timeline-item .timeline-icon.icon-lg {
        color: red;
    }

    .navbar-link:hover {
        color: red;
        opacity: .8;
    }

    #search-input .btn,
    #disqus_click_btn,
    #disqus-switch-to-direct,
    #disqus-loadmore-button {
        background: red;
        border-color: red;
        color: #fff;
    }

    #post-toc a.post-toc-link,
    #post-toc a.post-toc-link:visited,
    .share-menu.menu .menu-item>a {
        color: red;
    }

    .share-menu.menu .menu-item>a:hover,
    .share-menu.menu .menu-item>a:focus,
    .share-menu.menu .menu-item>a:visited {
        color: #50596c;
        background: #f8f9fa;
        opacity: .85;
    }
</style><link rel="stylesheet" href="/css/style.min.css">








    <!-- Prettify Theme -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css"></noscript>





<script>
/*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
!function(t){"use strict";t.loadCSS||(t.loadCSS=function(){});var e=loadCSS.relpreload={};if(e.support=function(){var e;try{e=t.document.createElement("link").relList.supports("preload")}catch(t){e=!1}return function(){return e}}(),e.bindMediaToggle=function(t){var e=t.media||"all";function a(){t.addEventListener?t.removeEventListener("load",a):t.attachEvent&&t.detachEvent("onload",a),t.setAttribute("onload",null),t.media=e}t.addEventListener?t.addEventListener("load",a):t.attachEvent&&t.attachEvent("onload",a),setTimeout(function(){t.rel="stylesheet",t.media="only x"}),setTimeout(a,3e3)},e.poly=function(){if(!e.support())for(var a=t.document.getElementsByTagName("link"),n=0;n<a.length;n++){var o=a[n];"preload"!==o.rel||"style"!==o.getAttribute("as")||o.getAttribute("data-loadcss")||(o.setAttribute("data-loadcss",!0),e.bindMediaToggle(o))}},!e.support()){e.poly();var a=t.setInterval(e.poly,500);t.addEventListener?t.addEventListener("load",function(){e.poly(),t.clearInterval(a)}):t.attachEvent&&t.attachEvent("onload",function(){e.poly(),t.clearInterval(a)})}"undefined"!=typeof exports?exports.loadCSS=loadCSS:t.loadCSS=loadCSS}("undefined"!=typeof global?global:this);
</script>

    <!-- ### Site Verification ### -->
    


    <meta name="mobile-web-app-capable" content="yes"><meta name="application-name" content="blog"><meta name="msapplication-starturl" content="https://abinzzz.github.io"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="blog">

    <!-- ### The Open Graph & Twitter Card Protocol ### -->
    <meta property="og:title" content="Daily Paper | Aug 2, 2025 | blog"><meta property="og:site_name" content="blog"><meta property="og:type" content="article"><meta property="og:url" content="https://abinzzz.github.io/2025/08/02/Daily-Paper-Aug-2-2025/"><meta property="og:locale" content="zh-CN"><meta name="description" content="Table of Content  Persona Vectors: Monitoring and Controlling Character Traits in Language Models Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis SWE-Debate: Competitive Mul - ab - blog"><meta name="keywords" content="blog"><meta property="og:image" content="https://pic1.imgdb.cn/item/688dda6258cb8da5c8fd4fc2.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddc3458cb8da5c8fd5457.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddca358cb8da5c8fd5580.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddce658cb8da5c8fd5630.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddd5b58cb8da5c8fd5772.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddd9658cb8da5c8fd5823.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddde458cb8da5c8fd5902.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688dde3d58cb8da5c8fd5a03.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688dde7b58cb8da5c8fd5aba.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddfda58cb8da5c8fd6619.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688ddfb058cb8da5c8fd64c2.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de00c58cb8da5c8fd67ba.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de09358cb8da5c8fd6c29.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de0c158cb8da5c8fd6dcd.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de13058cb8da5c8fd7198.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de17c58cb8da5c8fd743b.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de1e158cb8da5c8fd77fa.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de25d58cb8da5c8fd7c6e.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de28a58cb8da5c8fd7e11.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de2f158cb8da5c8fd814e.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de50058cb8da5c8fd8f65.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de56e58cb8da5c8fd9117.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de63d58cb8da5c8fd93c6.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de68458cb8da5c8fd9487.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de6e558cb8da5c8fd9519.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de74a58cb8da5c8fd9571.png"><meta property="og:image" content="https://pic1.imgdb.cn/item/688de78158cb8da5c8fd9583.png"><meta property="article:published_time" content="2025-08-02T09:26:32.000Z"><meta property="article:modified_time" content="2025-08-03T09:40:11.804Z"><meta property="og:updated_time" content="2025-08-03T09:40:11.804Z"><meta property="article:author" content="ab"><meta property="article:tag" content="blog"><meta name="twitter:card" content="summary">

    

    <!-- ### Canonical link ### -->
    <link rel="canonical" href="https://abinzzz.github.io/2025/08/02/Daily-Paper-Aug-2-2025/">

    <meta name="generator" content="Hexo 5.4.2">

    <!-- ### Analytics ### -->
    







    <!-- ### Structured Data ### -->
    



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "https://abinzzz.github.io/2025/08/02/Daily-Paper-Aug-2-2025/",
    "@type": "BlogPosting",
    "logo": "https://abinzzz.github.io/img/blog.ico",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://abinzzz.github.io/2025/08/02/Daily-Paper-Aug-2-2025/"
    },
    "headline": "Daily Paper | Aug 2, 2025 | blog",
    
    "image": {
        "@type": "ImageObject",
        "url": "https://abinzzz.github.io/img/blog.ico"
    },
    
    "datePublished": "2025-08-02T09:26:32.000Z",
    "dateModified": "2025-08-03T09:40:11.804Z",
    "author": {
        "@type": "Person",
        "name": "ab",
        "image": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/avatar.jpg"
        },
        "description": "Welcome to my blog!"
    },
    "publisher": {
        "@type": "Organization",
        "name": "blog",
        "logo": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/blog.ico"
        }
    },
    
    "potentialAction": {
        "@type": "SearchAction",
        "target": "https://abinzzz.github.io/search?s={search_term_string}",
        "query-input": "required name=search_term_string"
    },
    
    "keywords": "blog",
    "description": "Table of Content  Persona Vectors: Monitoring and Controlling Character Traits in Language Models Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis SWE-Debate: Competitive Mul - ab - blog"
}
</script>



    <!-- ### Custom Head ### -->
    
</head>

    <body>
            

            <!-- ### Main content ### -->
            <!-- ## Header ##-->
<header>
    <h1 class="header-title text-center"><a href="/">blog</a></h1>

    <p class="text-center header-slogan">
        
            
                Welcome to my blog!
            
        
    </p>

    <nav class="navbar-section text-center">
    
        <a href="/" class="navbar-link">首页</a>
    
    
    <a href="/categories/" class="navbar-link">分类</a>
    
        <a href="/archives/" class="navbar-link">归档</a>
    
    
        <a href="/search" class="navbar-link">搜索</a>
    
    
    
    
</nav>
</header>

            
    <!-- ## Post ## -->
    <div class="post-container">
    <div id="post-card" class="card">
        
        <div class="card-item-container">
            <div class="card-inner-cell">
                <!-- # Post Header Info # -->
                <div class="card-header">
                    
    <h1 class="card-title h3 mb-2">Daily Paper | Aug 2, 2025</h1>




<div class="post-header-info">
    <p class="post-header-info-left text-gray">
        <img class="author-thumb lazyload" data-src="/img/avatar.jpg" src="/img/suka-lazyload.gif" alt="ab's Avatar">
        <span>2025-08-02</span>
        
            <span class="suka-devide-dot"></span>
            <a class="category-link" href="/categories/Daily-Paper/">Daily Paper</a>
        
        
        
    </p>
    <div class="post-header-info-right">
        
            <div class="dropdown dropdown-right">
<a class="dropdown-toggle" tabindex="0">分享本文</a>
<ul class="menu share-menu">
    <!-- Share Weibo -->
    

    <!-- Share Twitter -->
    

    <!-- Share Facebook -->
    

    <!-- Share Google+ -->
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    

    <!-- QRCode -->
    
    <li class="menu-item">
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJQAAACUCAAAAABQV18IAAAB20lEQVR42u3a247DIAyE4bz/S3dvqxTPDFFWAvPnZrU9wFeJk42vz4LPBQoUKFAD1CWeny8V7ydtRJ8B1QY1HHS3BquGK/jou7YfUK1Q947ur1eduslQtTfCgjoLpXAjKChQqpHR+6MFUU0IUOehqo3SLaKqk387JYBaHqUO9G/+fS2aAbU0yiYdzMBNNu7Xsy6glkYlgabbaNXEcIstqH4oNUgdyHWaBBrl4glqW1Q6oJNkmmvTHfpA9UapTlPIcDDPrOigtkTNJrkUWi2WSZIEVA+UGszp4ucOb/GiC6oFqjqAqcPebPAZBxegWqAUSCbiw0tL9ZotwAG1LUoFDi5xnwaojzZkUNui0kREMujdZ+TCC6oFKi2gUQGBK+xyPwpUb5RrPLkQTyYLqHNQM8WlaUGgCxhA9ULZS5yg4dkNvGwHVFuUS9bPJvTjCwNQLVEu6eWK5JPiijjBAWprVNJwktBPCgPjGwdQW6LS4MEN8DTZLxNooFqgkkJjl2BLE2VTiyeorVHuMJYEEMnFtdvcQfVCzQSdTxIij04JoNqi1KWSCxTcJAB1JspdGCWJjiiIBdUKlQajSWGhuzR6PcEBajmU2zRnD4BJsc3wf1AtUCs9oECBAvX1/AHRx8/vonQZTgAAAABJRU5ErkJggg==" alt="QRCode">
    </li>
    

</ul>
</div>
        
    </div>
</div>
                </div>
                <div class="card-body">
                    
                        
                        
                            <div id="post-toc"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#table-of-content"><span class="post-toc-number">1.</span> <span class="post-toc-text"> Table of Content</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#persona-vectors-monitoring-and-controlling-character-traits-in-language-models"><span class="post-toc-number">2.</span> <span class="post-toc-text"> Persona Vectors: Monitoring and Controlling Character Traits in Language Models</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis"><span class="post-toc-number">3.</span> <span class="post-toc-text"> Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#swe-debate-competitive-multi-agent-debate-for-software-issue-resolution"><span class="post-toc-number">4.</span> <span class="post-toc-text"> SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#swe-exp-experience-driven-software-issue-resolution"><span class="post-toc-number">5.</span> <span class="post-toc-text"> SWE-Exp: Experience-Driven Software Issue Resolution</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance"><span class="post-toc-number">6.</span> <span class="post-toc-text"> Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning"><span class="post-toc-number">7.</span> <span class="post-toc-text"> VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding"><span class="post-toc-number">8.</span> <span class="post-toc-text"> 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#viser-imperative-web-based-3d-visualization-in-python"><span class="post-toc-number">9.</span> <span class="post-toc-text"> Viser: Imperative, Web-based 3D Visualization in Python</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#userbench-an-interactive-gym-environment-for-user-centric-agents"><span class="post-toc-number">10.</span> <span class="post-toc-text"> UserBench: An Interactive Gym Environment for User-Centric Agents</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#three-loop-banana-integrals-with-four-unequal-masses"><span class="post-toc-number">11.</span> <span class="post-toc-text"> Three-loop banana integrals with four unequal masses</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective"><span class="post-toc-number">12.</span> <span class="post-toc-text"> On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#unveiling-super-experts-in-mixture-of-experts-large-language-models"><span class="post-toc-number">13.</span> <span class="post-toc-text"> Unveiling Super Experts in Mixture-of-Experts Large Language Models</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling"><span class="post-toc-number">14.</span> <span class="post-toc-text"> Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models"><span class="post-toc-number">15.</span> <span class="post-toc-text"> Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models</span></a></li></ol></div>
                        
                    
                    <article id="post-content">
                        <!-- omit in toc -->
<h2 id="table-of-content"><a class="markdownIt-Anchor" href="#table-of-content"></a> Table of Content</h2>
<ul>
<li><a href="#persona-vectors-monitoring-and-controlling-character-traits-in-language-models">Persona Vectors: Monitoring and Controlling Character Traits in Language Models</a></li>
<li><a href="#gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis">Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</a></li>
<li><a href="#swe-debate-competitive-multi-agent-debate-for-software-issue-resolution">SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution</a></li>
<li><a href="#swe-exp-experience-driven-software-issue-resolution">SWE-Exp: Experience-Driven Software Issue Resolution</a></li>
<li><a href="#falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance">Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance</a></li>
<li><a href="#vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning">VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning</a></li>
<li><a href="#3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding">3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding</a></li>
<li><a href="#viser-imperative-web-based-3d-visualization-in-python">Viser: Imperative, Web-based 3D Visualization in Python</a></li>
<li><a href="#userbench-an-interactive-gym-environment-for-user-centric-agents">UserBench: An Interactive Gym Environment for User-Centric Agents</a></li>
<li><a href="#three-loop-banana-integrals-with-four-unequal-masses">Three-loop banana integrals with four unequal masses</a></li>
<li><a href="#on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective">On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective</a></li>
<li><a href="#unveiling-super-experts-in-mixture-of-experts-large-language-models">Unveiling Super Experts in Mixture-of-Experts Large Language Models</a></li>
<li><a href="#trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling">Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling</a></li>
<li><a href="#compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models">Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models</a></li>
</ul>
<h2 id="persona-vectors-monitoring-and-controlling-character-traits-in-language-models"><a class="markdownIt-Anchor" href="#persona-vectors-monitoring-and-controlling-character-traits-in-language-models"></a> Persona Vectors: Monitoring and Controlling Character Traits in Language Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688dda6258cb8da5c8fd4fc2.png" alt="" /></p>
<p>Github Link:  <a target="_blank" rel="noopener" href="https://github.com/safety-research/persona_vectors">https://github.com/safety-research/persona_vectors</a>.<br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.21509">https://www.alphaxiv.org/abs/2507.21509</a></p>
<p>The paper introduces <strong>persona vectors</strong>, which are identified as linear directions within a language model’s activation space, representing distinct character traits like “evil,” “sycophancy,” or “propensity to hallucinate.” An <strong>automated pipeline</strong> generates these vectors from natural language descriptions, enabling the <strong>monitoring of personality shifts</strong> during a model’s deployment and <strong>prediction of behavioral changes</strong> during its training. The research demonstrates that these vectors can be used to <strong>mitigate undesirable persona shifts</strong> through “steering” interventions—either by subtracting the persona vector after finetuning or by applying <strong>preventative steering</strong> during the finetuning process itself. Additionally, the study shows that <strong>analyzing training data through the lens of persona vectors</strong> can help <strong>flag problematic datasets or individual samples</strong> that might induce unintended persona shifts, even those that traditional filtering methods miss.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddc3458cb8da5c8fd5457.png" alt="" /></p>
<h2 id="gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis"><a class="markdownIt-Anchor" href="#gaussian-variation-field-diffusion-for-high-fidelity-video-to-4d-synthesis"></a> Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</h2>
<p><img src="https://pic1.imgdb.cn/item/688ddca358cb8da5c8fd5580.png" alt="" /></p>
<p>Paper Link: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2507.23785">https://arxiv.org/abs/2507.23785</a><br />
Github Link: <a target="_blank" rel="noopener" href="https://github.com/ForeverFancy/gvfdiffusion">https://github.com/ForeverFancy/gvfdiffusion</a></p>
<p>The paper from the University of Science and Technology of China and Microsoft Research Asia introduces Gaussian Variation Field Diffusion (GVFDiffusion), a framework that enables high-fidelity 4D content generation from a single video input. This is achieved by creating a canonical 3D Gaussian Splatting representation and generating its temporal variations via a compact latent diffusion model, resulting in significantly faster generation times and improved quality compared to prior methods.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddce658cb8da5c8fd5630.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688ddd5b58cb8da5c8fd5772.png" alt="" /></p>
<h2 id="swe-debate-competitive-multi-agent-debate-for-software-issue-resolution"><a class="markdownIt-Anchor" href="#swe-debate-competitive-multi-agent-debate-for-software-issue-resolution"></a> SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution</h2>
<p><img src="https://pic1.imgdb.cn/item/688ddd9658cb8da5c8fd5823.png" alt="" /></p>
<p>Researchers from Shanghai Jiao Tong University and Huawei developed SWE-Debate, a multi-agent debate framework leveraging graph-guided localization to resolve software issues. The system achieved a 41.4% Pass@1 success rate on the SWE-Bench-Verified dataset and 81.67% file-level localization accuracy on the SWE-Bench-Lite dataset.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddde458cb8da5c8fd5902.png" alt="" /></p>
<h2 id="swe-exp-experience-driven-software-issue-resolution"><a class="markdownIt-Anchor" href="#swe-exp-experience-driven-software-issue-resolution"></a> SWE-Exp: Experience-Driven Software Issue Resolution</h2>
<p><img src="https://pic1.imgdb.cn/item/688dde3d58cb8da5c8fd5a03.png" alt="" /></p>
<p>SWE-Exp introduces an experience-enhanced framework that enables Large Language Model agents to learn from past software issue resolution attempts, achieving a Pass@1 score of 41.6% on the SWE-bench-Verified dataset. It systematically captures and reuses knowledge via a multi-faceted experience bank and a dual-agent architecture, transforming agents from memoryless explorers into strategic, experience-driven problem solvers.</p>
<p><img src="https://pic1.imgdb.cn/item/688dde7b58cb8da5c8fd5aba.png" alt="" /></p>
<h2 id="falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance"><a class="markdownIt-Anchor" href="#falcon-h1-a-family-of-hybrid-head-language-models-redefining-efficiency-and-performance"></a> Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance</h2>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/tiiuae/falcon-h1">https://github.com/tiiuae/falcon-h1</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.22448">https://www.alphaxiv.org/abs/2507.22448</a></p>
<p>The Falcon LLM Team at the Technology Innovation Institute introduces Falcon-H1, a series of hybrid-head language models that integrate Transformer attention with Mamba-2 SSMs, achieving strong performance across various tasks while demonstrating enhanced parameter and training efficiency. The models set new benchmarks for efficiency and capability, particularly in reasoning-intensive domains and long-context processing, often matching or exceeding larger models.</p>
<h2 id="vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning"><a class="markdownIt-Anchor" href="#vl-cogito-progressive-curriculum-reinforcement-learning-for-advanced-multimodal-reasoning"></a> VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning</h2>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/alibaba-damo-academy/VL-Cogito">https://github.com/alibaba-damo-academy/VL-Cogito</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.22607">https://www.alphaxiv.org/abs/2507.22607</a></p>
<p><img src="https://pic1.imgdb.cn/item/688ddfda58cb8da5c8fd6619.png" alt="" /></p>
<p>Researchers from Alibaba’s DAMO Academy and Fudan University developed VL-Cogito, a multimodal large language model, using a Progressive Curriculum Reinforcement Learning framework. This approach systematically enhances the model’s ability to perform complex multimodal reasoning and adaptively adjust its reasoning length, achieving competitive performance across diverse benchmarks in mathematics, science, and general understanding.</p>
<p><img src="https://pic1.imgdb.cn/item/688ddfb058cb8da5c8fd64c2.png" alt="" /></p>
<h2 id="3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding"><a class="markdownIt-Anchor" href="#3d-r1-enhancing-reasoning-in-3d-vlms-for-unified-scene-understanding"></a> 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding</h2>
<p><img src="https://pic1.imgdb.cn/item/688de00c58cb8da5c8fd67ba.png" alt="" /></p>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/AIGeeksGroup/3D-R1">https://github.com/AIGeeksGroup/3D-R1</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.23478">https://www.alphaxiv.org/abs/2507.23478</a></p>
<p>A generalist 3D Vision-Language Model, 3D-R1, combines cold-start initialization with reinforcement learning and dynamic view selection to enhance reasoning for unified scene understanding. It achieves state-of-the-art performance across seven distinct 3D vision-language tasks, demonstrating an average improvement of 10% over prior methods.</p>
<p><img src="https://pic1.imgdb.cn/item/688de09358cb8da5c8fd6c29.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688de0c158cb8da5c8fd6dcd.png" alt="" /></p>
<h2 id="viser-imperative-web-based-3d-visualization-in-python"><a class="markdownIt-Anchor" href="#viser-imperative-web-based-3d-visualization-in-python"></a> Viser: Imperative, Web-based 3D Visualization in Python</h2>
<p><img src="https://pic1.imgdb.cn/item/688de13058cb8da5c8fd7198.png" alt="" /></p>
<p>Project Link: <a target="_blank" rel="noopener" href="https://viser.studio/main/">https://viser.studio/main/</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.22885">https://www.alphaxiv.org/abs/2507.22885</a></p>
<p>Viser is a Python library that offers imperative, web-based 3D visualization, addressing the need for a versatile tool that bridges the gap between lightweight and domain-specific visualization solutions. The system provides comprehensive 3D scene and 2D GUI primitives, supports real-time data streaming, and has been adopted across various computer vision and robotics research areas, including as a foundational component for neural rendering frameworks.</p>
<p><img src="https://pic1.imgdb.cn/item/688de17c58cb8da5c8fd743b.png" alt="" /></p>
<h2 id="userbench-an-interactive-gym-environment-for-user-centric-agents"><a class="markdownIt-Anchor" href="#userbench-an-interactive-gym-environment-for-user-centric-agents"></a> UserBench: An Interactive Gym Environment for User-Centric Agents</h2>
<p><img src="https://pic1.imgdb.cn/item/688de1e158cb8da5c8fd77fa.png" alt="" /></p>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/SalesforceAIResearch/UserBench">https://github.com/SalesforceAIResearch/UserBench</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.22034">https://www.alphaxiv.org/abs/2507.22034</a></p>
<p>UserBench is an interactive Gym environment and benchmark that evaluates LLM-based agents on their ability to understand and align with user needs, particularly when instructions are underspecified, incremental, or indirect, using travel planning scenarios. Evaluations with leading LLMs revealed that models struggle significantly with user preference elicitation and making optimal, user-aligned decisions, even while demonstrating competence in tool use.</p>
<p><img src="https://pic1.imgdb.cn/item/688de25d58cb8da5c8fd7c6e.png" alt="" /></p>
<h2 id="three-loop-banana-integrals-with-four-unequal-masses"><a class="markdownIt-Anchor" href="#three-loop-banana-integrals-with-four-unequal-masses"></a> Three-loop banana integrals with four unequal masses</h2>
<p><img src="https://pic1.imgdb.cn/item/688de28a58cb8da5c8fd7e11.png" alt="" /></p>
<p>Researchers at the Bethe Center, Universität Bonn, constructed the first complete system of canonical differential equations for the master integrals of the three-loop banana diagram with four distinct unequal masses in D=2-2epsilon dimensions. This work identifies that the complex integrals can be expressed using known K3 periods and only two new fundamental iterated integrals, enabling full analytic results for precision calculations.</p>
<h2 id="on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective"><a class="markdownIt-Anchor" href="#on-the-expressiveness-of-softmax-attention-a-recurrent-neural-network-perspective"></a> On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective</h2>
<p><strong>The paper is similar to second-order flow matching.</strong></p>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/gmongaras/On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective">https://github.com/gmongaras/On-the-Expressiveness-of-Softmax-Attention-A-Recurrent-Neural-Network-Perspective</a></p>
<p>Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.23632">https://www.alphaxiv.org/abs/2507.23632</a></p>
<p><img src="https://pic1.imgdb.cn/item/688de2f158cb8da5c8fd814e.png" alt="" /></p>
<p>This paper, a preprint by <strong>Gabriel Mongaras</strong> and <strong>Eric C. Larson</strong> from Southern Methodist University, investigates the <strong>expressiveness of softmax attention</strong> within transformer architectures. The authors propose a novel <strong>recurrent neural network (RNN) perspective</strong> on softmax attention, demonstrating that <strong>linear attention</strong> can be understood as a <strong>first-order approximation</strong> of its more complex counterpart. They achieve this by deriving a recurrent form of softmax attention using a <strong>Taylor series expansion</strong> and then empirically evaluating this formulation against traditional softmax and various linear attention methods. The research also <strong>reinterprets the softmax denominator</strong> as either a gate or a norm, with experiments indicating that a <strong>vector norm</strong> most accurately replicates softmax’s behavior, ultimately aiming to explain why softmax attention consistently <strong>outperforms linear attention</strong> in various downstream tasks.</p>
<h2 id="unveiling-super-experts-in-mixture-of-experts-large-language-models"><a class="markdownIt-Anchor" href="#unveiling-super-experts-in-mixture-of-experts-large-language-models"></a> Unveiling Super Experts in Mixture-of-Experts Large Language Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688de50058cb8da5c8fd8f65.png" alt="" /></p>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/ZunhaiSu/Super-Experts-Profilling">https://github.com/ZunhaiSu/Super-Experts-Profilling</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.23279">https://www.alphaxiv.org/abs/2507.23279</a></p>
<p>Researchers from Tsinghua University and Meituan identified “Super Experts” (SEs) in Mixture-of-Experts Large Language Models, a tiny subset of experts (less than 0.5%) that are mechanistically responsible for inducing massive activations and crucial attention sinks. Removing these SEs leads to a catastrophic collapse in model performance, particularly for reasoning tasks, highlighting their indispensable role in maintaining core LLM capabilities.</p>
<p><img src="https://pic1.imgdb.cn/item/688de56e58cb8da5c8fd9117.png" alt="" /></p>
<h2 id="trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling"><a class="markdownIt-Anchor" href="#trae-agent-an-llm-based-agent-for-software-engineering-with-test-time-scaling"></a> Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling</h2>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/bytedance/trae-agent">https://github.com/bytedance/trae-agent</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.23370">https://www.alphaxiv.org/abs/2507.23370</a></p>
<p>Software issue resolution is a critical challenge in software engineering and has garnered increasing attention in recent years. With the rapid advancement of large language models (LLMs), substantial progress has been made in addressing real-world software engineering tasks. Recent studies have introduced ensemble reasoning techniques to enhance the performance of LLM-based issue resolution. However, existing prompting-based methods still face limitations in effectively exploring large ensemble spaces and lack the capacity for repository-level understanding, both of which constrain their overall effectiveness. In this paper, we propose Trae Agent, the first agent-based ensemble reasoning approach for repository-level issue resolution. Trae Agent formulates our goal as an optimal solution search problem and addresses two key challenges, i.e., large ensemble spaces and repository-level understanding, through modular agents for generation, pruning, and selection. We conduct extensive experiments using three leading LLMs on the widely-adopted SWE-bench benchmark, comparing Trae Agent against four state-of-the-art ensemble reasoning techniques. Experimental results demonstrate that Trae Agent consistently achieves superior performance, with an average improvement of 10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of 75.20%.</p>
<p><img src="https://pic1.imgdb.cn/item/688de63d58cb8da5c8fd93c6.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688de68458cb8da5c8fd9487.png" alt="" /></p>
<h2 id="compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models"><a class="markdownIt-Anchor" href="#compositional-discrete-latent-code-for-high-fidelity-productive-diffusion-models"></a> Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models</h2>
<p><img src="https://pic1.imgdb.cn/item/688de6e558cb8da5c8fd9519.png" alt="" /></p>
<p>Github Link: <a target="_blank" rel="noopener" href="https://github.com/lavoiems/DiscreteLatentCode">https://github.com/lavoiems/DiscreteLatentCode</a><br />
Paper Link: <a target="_blank" rel="noopener" href="https://www.alphaxiv.org/abs/2507.12318">https://www.alphaxiv.org/abs/2507.12318</a></p>
<p>Researchers at Mila, Université de Montréal, introduce Discrete Latent Codes (DLCs) as a conditioning representation for diffusion models, which enables state-of-the-art unconditional image generation on ImageNet (FID 1.59) and facilitates diverse, compositional image synthesis. The method also enables an efficient text-to-image pipeline that leverages pre-trained language models to generate DLCs, requiring significantly less training data than end-to-end models.</p>
<p><img src="https://pic1.imgdb.cn/item/688de74a58cb8da5c8fd9571.png" alt="" /></p>
<p><img src="https://pic1.imgdb.cn/item/688de78158cb8da5c8fd9583.png" alt="" /></p>

                    </article>
                    


    <blockquote id="date-expire-notification" class="post-expired-notify">本文最后更新于 <span id="date-expire-num"></span> 天前，文中所描述的信息可能已发生改变</blockquote>
    <script>
    (function() {
        var dateUpdate = Date.parse("2025-08-03");
        var nowDate = new Date();
        var a = nowDate.getTime();
        var b = a - dateUpdate;
        var daysUpdateExpire = Math.floor(b/(24*3600*1000));
        if (daysUpdateExpire >= 120) {
            document.getElementById('date-expire-num').innerHTML = daysUpdateExpire;
        } else {
            document.getElementById('date-expire-notification').style.display = 'none';
        }
    })();
    </script>


<p class="post-footer-info mb-0 pt-0">本文发表于&nbsp;<time datetime="2025-08-02T09:26:32.000Z" itemprop="datePublished">2025-08-02</time>

    , 最后修改于&nbsp;<time datetime="2025-08-03T09:40:11.804Z" itemprop="dateModified">2025-08-03</time>

</p>
<p class="post-footer-info mb-0 pt-2">

<span class="post-categories-list mt-2">

<a class="post-categories-list-item" href='/categories/Daily-Paper/'>Daily Paper</a>

</span>




</p>

                </div>
                <div class="post-nav px-2 bg-gray">
<ul class="pagination">
    <!-- Prev Nav -->
    
        <li class="page-item page-prev">
            <a href="/2025/08/03/Daily-Paper-Aug-3-2025/" rel="prev">
                <div class="page-item-title"><i class="icon icon-back" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">Daily Paper | Aug 3, 2025</div>
            </a>
        </li>
    

    <!-- Next Nav -->
    
        <li class="page-item page-next">
            <a href="/2025/08/02/The-Road-to-Diffusion-and-Flow-Matching-DDPM/" rel="next">
                <div class="page-item-title"><i class="icon icon-forward" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">The Road to Diffusion and Flow Matching | DDPM</div>
            </a>
        </li>
    
</ul>
</div>

                
                    <!-- # Comment # -->
                    
                        <div class="card-footer post-comment">
                            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
        this.page.url = 'https://abinzzz.github.io/2025/08/02/Daily-Paper-Aug-2-2025/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://abinzzz.github.io/2025/08/02/Daily-Paper-Aug-2-2025/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>
<script id="disqus-thread-script">
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//robin02.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

                        </div>
                    
                
            </div>
        </div>
    </div>
</div>

            <!-- ### Footer ### -->
            <footer class="text-center">
    <!-- footer copyright -->
    
        <p class="footer-copyright mb-0">Copyright&nbsp;©&nbsp;<span id="copyright-year"></span>
            <a class="footer-copyright-a" href="https://abinzzz.github.io">blog</a>
        </p>

    <!-- footer custom text -->
    <p class="footer-text mb-0">
    
    </p>
    <!-- footer develop info -->
    <p class="footer-develop mb-0">
        
    <!-- Busuanzi User Views -->
    <span id="busuanzi_container_site_uv" hidden>
        <span></span>
        <span id="busuanzi_value_site_uv"></span>
        <span>Viewers</span>
        
            <span>|</span>
        
    </span>




        
        Powered by&nbsp;<!--
         --><a href="https://hexo.io" target="_blank" class="footer-develop-a" rel="external nofollow noopener noreferrer">Hexo</a><span class="footer-develop-divider"></span>Theme&nbsp;-&nbsp;<!--
         --><a href="https://github.com/SukkaW/hexo-theme-suka" target="_blank" class="footer-develop-a" rel="external noopener">Suka</a>
    </p>
</footer>


        <!-- ### Import File ### -->
        <!-- ### Footer JS Import ### -->

<script>

    
window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 50
};

(function() {
    var copyrightNow = new Date().getFullYear();
    var copyrightContent = document.getElementById('copyright-year');
    var copyrightSince = 2023;
    if (copyrightSince === copyrightNow) {
        copyrightContent.textContent = copyrightNow;
    } else {
        copyrightContent.textContent = copyrightSince + ' - ' + copyrightNow;
    }
})();
console.log('\n %c Suka Theme (hexo-theme-suka) | © SukkaW | Verision 1.3.3 %c https://github.com/SukkaW/hexo-theme-suka \n', 'color: #fff; background: #444; padding:5px 0;', 'background: #bbb; padding:5px 0;');

(function() {
    'use strict';
    
    // 等待 DOM 加载完成
    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', initTocCollapse);
    } else {
        initTocCollapse();
    }
    
    function initTocCollapse() {
        const tocContainer = document.getElementById('post-toc');
        if (!tocContainer) {
            return;
        }
        
        // 找到所有有子目录的 level-1 和 level-2 项
        const tocItems = tocContainer.querySelectorAll('.post-toc-item.post-toc-level-1, .post-toc-item.post-toc-level-2');
        
        tocItems.forEach(function(item) {
            // 检查是否有子目录（包含 post-toc-child 的 ol）
            const hasChildren = item.querySelector('ol.post-toc-child') !== null;
            
            if (hasChildren) {
                // 添加标记类，用于 CSS 显示图标
                item.classList.add('toc-has-children');
                
                const link = item.querySelector('.post-toc-link');
                if (link) {
                    // 阻止默认的锚点跳转，改为展开/折叠
                    link.addEventListener('click', function(e) {
                        // 如果用户按住 Ctrl/Cmd 或中键点击，则跳转
                        if (e.ctrlKey || e.metaKey || e.button === 1) {
                            return; // 允许默认行为（跳转）
                        }
                        
                        e.preventDefault();
                        e.stopPropagation();
                        
                        // 切换展开/折叠状态
                        item.classList.toggle('toc-expanded');
                    });
                    
                    // 允许通过双击链接文本跳转
                    link.addEventListener('dblclick', function(e) {
                        const href = link.getAttribute('href');
                        if (href) {
                            window.location.hash = href;
                        }
                    });
                    
                    // 允许通过右键菜单跳转
                    link.addEventListener('contextmenu', function(e) {
                        // 允许默认的右键菜单
                        return true;
                    });
                }
            }
        });
    }
})();
        

</script>

<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@8.9.0" async></script>
    <script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" async></script>


<!-- Offset -->




<!-- Comment -->

    
        <script id="dsq-count-scr" src="https://robin02.disqus.com/count.js" async></script>

    


<!-- ### Custom Footer ### -->

    </body>

</html>