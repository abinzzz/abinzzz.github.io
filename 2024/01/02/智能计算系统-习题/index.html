
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <!--pjax：防止跳转页面音乐暂停-->
    <script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script> 
    <meta charset="utf-8">
    

    

    
    <title>
        智能计算系统:自制试题 |
        
        布洛戈</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });  第1章-绪论  判断题 (True&#x2F;False)  智能计算系统只能在大型数据中心中使用。（错） TensorFlow是一个用于机器学习的编程框架。（对） 所有智能计算系统必须包含CPU。（错） 神经网络是智能计算系统中">
<meta property="og:type" content="article">
<meta property="og:title" content="智能计算系统:自制试题">
<meta property="og:url" content="https://abinzzz.github.io/2024/01/02/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F-%E4%B9%A0%E9%A2%98/index.html">
<meta property="og:site_name" content="布洛戈">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });  第1章-绪论  判断题 (True&#x2F;False)  智能计算系统只能在大型数据中心中使用。（错） TensorFlow是一个用于机器学习的编程框架。（对） 所有智能计算系统必须包含CPU。（错） 神经网络是智能计算系统中">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-01-01T18:26:55.000Z">
<meta property="article:modified_time" content="2024-01-02T00:34:59.851Z">
<meta property="article:author" content="ab">
<meta property="article:tag" content="专业知识">
<meta name="twitter:card" content="summary">
    
        <link rel="alternate" href="/atom.xml" title="布洛戈" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
        
<link rel="stylesheet" href="https://unpkg.com/katex@0.16.7/dist/katex.min.css">

    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
    
        <img data-src="https://pbs.twimg.com/media/GBTN7RnW0AA6G9K?format=jpg&amp;name=medium" data-sizes="auto" alt="智能计算系统:自制试题" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>智能计算系统:自制试题</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-智能计算系统-习题" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2024/01/02/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F-%E4%B9%A0%E9%A2%98/" class="article-date-link">
        <time datetime="2024-01-01T18:26:55.000Z"
              itemprop="datePublished">2024-01-02</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><a class="article-category-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/">智能计算系统</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<p>第1章-绪论</p>
<h3 id="判断题-truefalse"><a class="markdownIt-Anchor" href="#判断题-truefalse"></a> 判断题 (True/False)</h3>
<ol>
<li>智能计算系统只能在大型数据中心中使用。（错）</li>
<li>TensorFlow是一个用于机器学习的编程框架。（对）</li>
<li>所有智能计算系统必须包含CPU。（错）</li>
<li>神经网络是智能计算系统中的一种核心技术。（对）</li>
<li>智能计算系统无法处理自然语言。（错）</li>
</ol>
<h3 id="fill-in-the-blank-questions-with-answers"><a class="markdownIt-Anchor" href="#fill-in-the-blank-questions-with-answers"></a> Fill-in-the-Blank Questions with Answers</h3>
<ol>
<li>
<p><strong>Question:</strong> 智能计算系统通常采用的两种主要技术是______和______。<br />
<strong>Answer:</strong> 深度学习, 机器学习</p>
</li>
<li>
<p><strong>Question:</strong> 在智能计算系统中，______起到了至关重要的作用。<br />
<strong>Answer:</strong> 神经网络</p>
</li>
<li>
<p><strong>Question:</strong> 智能计算系统中处理大量数据的主要挑战之一是______。<br />
<strong>Answer:</strong> 数据存储和处理速度</p>
</li>
<li>
<p><strong>Question:</strong> 智能计算系统的一个重要应用领域是______。<br />
<strong>Answer:</strong> 图像识别</p>
</li>
<li>
<p><strong>Question:</strong> TensorFlow和PyTorch是智能计算系统中常用的______。<br />
<strong>Answer:</strong> 编程框架</p>
</li>
</ol>
<h3 id="truefalse-questions-with-answers"><a class="markdownIt-Anchor" href="#truefalse-questions-with-answers"></a> True/False Questions with Answers</h3>
<ol>
<li>
<p><strong>Question:</strong> 智能计算系统不可能在医疗领域中找到应用。（错）<br />
<strong>Answer:</strong> 错误</p>
</li>
<li>
<p><strong>Question:</strong> 在智能计算系统中，数据预处理是不必要的。（错）<br />
<strong>Answer:</strong> 错误</p>
</li>
</ol>
<h3 id="short-answer-questions-with-answers"><a class="markdownIt-Anchor" href="#short-answer-questions-with-answers"></a> Short Answer Questions with Answers</h3>
<ol>
<li><strong>Question:</strong> 描述智能计算系统的主要特点。<br />
<strong>Answer:</strong> 智能计算系统主要特点包括能够处理大量数据、学习和适应、以及在各种任务中实现自动化和优化决策。</li>
</ol>
<p>第2章-神经网络基础</p>
<h3 id="fill-in-the-blank-questions"><a class="markdownIt-Anchor" href="#fill-in-the-blank-questions"></a> Fill-in-the-Blank Questions</h3>
<ol>
<li>神经网络中的基本计算单元被称为________。</li>
<li>________是连接输入层和输出层的网络，没有隐藏层。</li>
<li>在神经网络中，每个连接的强度被表示为________。</li>
<li>激活函数在神经网络中的作用是________。</li>
<li>________是神经网络中最常用的激活函数之一。</li>
<li>神经网络中的每个神经元对应于一个带权重的________。</li>
<li>神经网络通过________过程进行学习和调整权重。</li>
<li>反向传播算法是基于________法则工作的。</li>
<li>在神经网络训练过程中，用来度量预测值和实际值之间差距的函数称为________。</li>
<li>过拟合是指神经网络模型在训练集上表现________，但在新数据上表现不佳。</li>
<li>为了避免过拟合，可以使用________技术。</li>
<li>神经网络中，损失函数的一个常见选择是________。</li>
<li>________层是神经网络中介于输入层和输出层之间的层。</li>
<li>多层神经网络相较于单层网络，能够更好地近似________函数。</li>
<li>在神经网络中，________是一种有效的正则化技术。</li>
<li>________是一种在神经网络训练中常用的优化算法。</li>
<li>深度学习是一种涉及________层的神经网络的学习方法。</li>
<li>卷积神经网络(CNN)广泛应用于________领域。</li>
<li>循环神经网络(RNN)特别适用于处理________类型的数据。</li>
<li>神经网络的________是指网络能够逼近复杂函数和模式的能力。</li>
</ol>
<h3 id="answers"><a class="markdownIt-Anchor" href="#answers"></a> Answers</h3>
<ol>
<li>神经元2. 感知机3. 权重4. 引入非线性5. ReLU</li>
<li>线性组合7. 训练8. 链式求导9. 损失函数10. 过于优秀</li>
<li>正则化12. 均方误差(MSE)13. 隐藏14. 复杂的非线性15. Dropout</li>
<li>梯度下降17. 多个隐藏18. 图像处理19. 序列20. 表达能力</li>
</ol>
<h3 id="判断题"><a class="markdownIt-Anchor" href="#判断题"></a> 判断题</h3>
<ol>
<li>所有的激活函数都是线性函数。(对/错)</li>
<li>神经网络的训练过程不涉及权重的调整。(对/错)</li>
<li>单层神经网络无法解决非线性问题。(对/错)</li>
<li>反向传播算法仅适用于有监督学习。(对/错)</li>
<li>每一个神经元的输出都是其加权输入的线性组合。(对/错)</li>
<li>Dropout技术可以在训练时随机忽略某些神经元。(对/错)</li>
<li>在神经网络中，损失函数总是非负的。(对/错)</li>
<li>梯度下降算法总是保证找到全局最优解。(对/错)</li>
<li>深度学习一定比浅层学习更有效。(对/错)</li>
<li>循环神经网络不能处理时间序列数据。(对/错)</li>
</ol>
<h3 id="答案"><a class="markdownIt-Anchor" href="#答案"></a> 答案</h3>
<ol>
<li>错。激活函数通常是非线性的，以引入非线性特性。</li>
<li>错。神经网络的训练过程核心是通过调整权重来学习。</li>
<li>对。单层神经网络通常无法处理复杂的非线性问题。</li>
<li>错。反向传播算法也可以用于无监督学习，虽然它主要用于有监督学习。</li>
<li>错。神经元的输出通常是通过激活函数处理后的加权输入。</li>
<li>对。Dropout技术通过随机忽略神经元来防止过拟合。</li>
<li>对。损失函数衡量的是预测误差，通常是非负的。</li>
<li>错。梯度下降算法可能只找到局部最优解，特别是在复杂的非凸优化问题中。</li>
<li>错。深度学习在某些任务上比浅层学习更有效，但不是在所有情况下。</li>
<li>错。循环神经网络特别适合处理时间序列数据。</li>
</ol>
<h3 id="简答题"><a class="markdownIt-Anchor" href="#简答题"></a> 简答题</h3>
<ol>
<li>什么是神经网络中的激活函数？其作用是什么？</li>
<li>简述反向传播算法的基本原理及其重要性。</li>
<li>描述在神经网络中防止过拟合的常见方法。</li>
<li>为什么深度学习在某些任务上比浅层学习更有效？</li>
<li>说明循环神经网络（RNN）处理时间序列数据的优势。</li>
</ol>
<h3 id="解答"><a class="markdownIt-Anchor" href="#解答"></a> 解答</h3>
<ol>
<li>激活函数是神经网络中用于添加非线性的函数，使得网络能够学习和表示复杂的函数。它们帮助网络模拟复杂的决策边界。</li>
<li>反向传播算法是一种高效计算神经网络中所有权重梯度的方法。它通过链式法则反向传播误差，优化权重以减少损失。这对于训练复杂的深度学习网络至关重要。</li>
<li>防止过拟合的常见方法包括：使用正则化技术（如L1、L2正则化）、应用Dropout技术、增加训练数据、减小网络复杂度、使用早停法（early stopping）。</li>
<li>深度学习通过使用多个隐藏层可以学习数据的更高层次的抽象特征，使其在诸如图像和语音识别等复杂任务中比浅层学习更有效。</li>
<li>循环神经网络（RNN）适合处理时间序列数据，因为它们可以存储历史信息并利用这些信息进行当前的决策，这对于理解序列数据的时间依赖性非常重要。</li>
</ol>
<p>第3章-深度学习-上</p>
<h3 id="填空题"><a class="markdownIt-Anchor" href="#填空题"></a> 填空题</h3>
<ol>
<li>
<p><strong>Question</strong>: 在神经网络中，损失函数和______一起用于网络训练。<br />
<strong>Answer</strong>: 梯度下降</p>
</li>
<li>
<p><strong>Question</strong>: 神经网络防止过拟合的方法之一是______。<br />
<strong>Answer</strong>: 正则化</p>
</li>
<li>
<p><strong>Question</strong>: 在卷积神经网络中，权重共享主要减少______。<br />
<strong>Answer</strong>: 权重数量</p>
</li>
<li>
<p><strong>Question</strong>: 在CNN中，用于表达图像特征的工具称为______。<br />
<strong>Answer</strong>: 卷积模板</p>
</li>
<li>
<p><strong>Question</strong>: 卷积神经网络的一个关键特性是______连接。<br />
<strong>Answer</strong>: 局部</p>
</li>
<li>
<p><strong>Question</strong>: CNN中，______层用于分类。<br />
<strong>Answer</strong>: 全连接层</p>
</li>
<li>
<p><strong>Question</strong>: Softmax层在神经网络中用于将输出转化为______。<br />
<strong>Answer</strong>: 分类概率</p>
</li>
<li>
<p><strong>Question</strong>: 在CNN中，池化层主要用于______。<br />
<strong>Answer</strong>: 减小图像尺寸</p>
</li>
<li>
<p><strong>Question</strong>: 卷积运算在神经网络中实际上是计算______。<br />
<strong>Answer</strong>: 矩阵内积</p>
</li>
<li>
<p><strong>Question</strong>: 图像分类领域中具有重要影响的竞赛是______。<br />
<strong>Answer</strong>: ImageNet大规模视觉识别比赛</p>
</li>
<li>
<p><strong>Question</strong>: 用于避免神经网络过拟合的技术之一是______。<br />
<strong>Answer</strong>: Dropout</p>
</li>
<li>
<p><strong>Question</strong>: 在CNN中，ReLU函数用于______。<br />
<strong>Answer</strong>: 加速训练收敛</p>
</li>
<li>
<p><strong>Question</strong>: 在CNN中，卷积层和池化层一起构成______。<br />
<strong>Answer</strong>: 特征提取器</p>
</li>
<li>
<p><strong>Question</strong>: 神经网络中，通常用于输出层的激活函数是______。<br />
<strong>Answer</strong>: Softmax</p>
</li>
<li>
<p><strong>Question</strong>: 在卷积神经网络中，减少权重数量和计算量的层是______层。<br />
<strong>Answer</strong>: 池化</p>
</li>
<li>
<p><strong>Question</strong>: 图像处理中常用的CNN结构之一是______。<br />
<strong>Answer</strong>: VGG16</p>
</li>
<li>
<p><strong>Question</strong>: CNN中局部响应归一化(LRN)的主要目的是______。<br />
<strong>Answer</strong>: 增强模型泛化能力</p>
</li>
<li>
<p><strong>Question</strong>: 深度网络中防止梯度消失的策略之一是使用______。<br />
<strong>Answer</strong>: ReLU激活函数</p>
</li>
<li>
<p><strong>Question</strong>: 在CNN中，______用于减少参数数量和控制过拟合。<br />
<strong>Answer</strong>: 池化层</p>
</li>
<li>
<p><strong>Question</strong>: AlexNet中引入的，用于防止过拟合的技术是______。<br />
<strong>Answer</strong>: Dropout</p>
</li>
</ol>
<h3 id="判断题-2"><a class="markdownIt-Anchor" href="#判断题-2"></a> 判断题</h3>
<ol>
<li>
<p><strong>Question</strong>: 神经网络的激活函数可以是线性函数。(True/False)<br />
<strong>Answer</strong>: False. 激活函数通常是非线性的，如ReLU或Sigmoid。</p>
</li>
<li>
<p><strong>Question</strong>: 在CNN中，卷积层的主要功能是特征提取。(True/False)<br />
<strong>Answer</strong>: True. 卷积层主要用于提取输入数据的特征。</p>
</li>
<li>
<p><strong>Question</strong>: 池化层在神经网络中用于增加模型的计算复杂度。(True/False)<br />
<strong>Answer</strong>: False. 池化层实际上用于降低计算复杂度和防止过拟合。</p>
</li>
<li>
<p><strong>Question</strong>: 在深度学习中，更深的网络模型总是比浅层模型表现更好。(True/False)<br />
<strong>Answer</strong>: False. 更深的模型可能更容易过拟合或遇到梯度消失问题。</p>
</li>
<li>
<p><strong>Question</strong>: Dropout技术是通过在训练过程中随机丢弃神经元来防止过拟合。(True/False)<br />
<strong>Answer</strong>: True. Dropout技术通过随机丢弃神经元来减少模型对特定数据的依赖。</p>
</li>
<li>
<p><strong>Question</strong>: 卷积神经网络只能用于图像处理。(True/False)<br />
<strong>Answer</strong>: False. 虽然CNN在图像处理中非常有效，但它们也可用于其他类型的数据。</p>
</li>
<li>
<p><strong>Question</strong>: ReLU激活函数可以解决梯度消失问题。(True/False)<br />
<strong>Answer</strong>: True. ReLU函数有助于减轻梯度消失问题，尤其在深层网络中。</p>
</li>
<li>
<p><strong>Question</strong>: 在所有深度学习模型中，正则化是必需的。(True/False)<br />
<strong>Answer</strong>: False. 正则化是防止过拟合的一种手段，但并非所有情况都需要。</p>
</li>
<li>
<p><strong>Question</strong>: Softmax函数只在多类别分类问题中使用。(True/False)<br />
<strong>Answer</strong>: False. 虽然通常用于多类别分类，但也可用于其他类型的问题。</p>
</li>
<li>
<p><strong>Question</strong>: 卷积层中的滤波器数量与模型的复杂度无关。(True/False)<br />
<strong>Answer</strong>: False. 滤波器的数量直接影响模型的复杂度和学习能力。</p>
</li>
</ol>
<h3 id="简答题-2"><a class="markdownIt-Anchor" href="#简答题-2"></a> 简答题</h3>
<ol start="11">
<li>
<p><strong>Question</strong>: 简述卷积神经网络（CNN）的基本结构组成。<br />
<strong>Answer</strong>: 卷积神经网络主要由卷积层、池化层和全连接层组成。卷积层用于特征提取，池化层用于降低特征维度和计算量，全连接层则用于输出预测结果。</p>
</li>
<li>
<p><strong>Question</strong>: 什么是深度学习中的过拟合，以及如何防止？<br />
<strong>Answer</strong>: 过拟合是指模型在训练数据上表现良好，但在新数据上表现不佳的现象。防止方法包括增加数据集的大小、使用正则化技术、采用Dropout方法等。</p>
</li>
<li>
<p><strong>Question</strong>: 简述神经网络中梯度下降法的基本原理。<br />
<strong>Answer</strong>: 梯度下降法通过计算损失函数关于权重的梯度，并反向传播更新权重，从而最小化损失函数，以训练神经网络。</p>
</li>
<li>
<p><strong>Question</strong>: 如何理解卷积层中的局部连接和权重共享？<br />
<strong>Answer</strong>: 局部连接是指每个神经元只与输入数据的一个局部区域相连接。权重共享是指卷积层中的每个滤波器的权重在整个输入数据上共享，这减少了模型的复杂度和计算量。</p>
</li>
<li>
<p><strong>Question</strong>: 在神经网络中，为什么通常使用非线性激活函数？<br />
<strong>Answer</strong>: 非线性激活函数使得神经网络能够学习和模拟非线性关系。如果使用线性激活函数，无论网络有多少层，最终输出都是输入的线性组合，限制了网络的表达能力。</p>
</li>
</ol>
<h3 id="计算题"><a class="markdownIt-Anchor" href="#计算题"></a> 计算题</h3>
<ol>
<li>
<p><strong>Question</strong>: 假设有一个单层神经网络，输入层有3个神经元，输出层有2个神经元，没有激活函数。输入为[1, 2, 3]，权重矩阵为[[0.5, -0.6], [0.7, -0.8], [0.9, -0.1]]，偏置为[0.1, -0.1]，计算输出。<br />
<strong>Answer</strong>: 输出 = [1×0.5 + 2×0.7 + 3×0.9 + 0.1, 1×(-0.6) + 2×(-0.8) + 3×(-0.1) - 0.1] = [3.8, -3.0]</p>
</li>
<li>
<p><strong>Question</strong>: 对于简单的两层神经网络，输入x = [2, 3]，第一层权重为[[1, -1], [0, 1]]，偏置为[0, 2]，激活函数为ReLU，求第一层的输出。<br />
<strong>Answer</strong>: 第一层输出 = ReLU([2×1 + 3×0 + 0, 2×(-1) + 3×1 + 2]) = ReLU([2, 3]) = [2, 3]</p>
</li>
<li>
<p><strong>Question</strong>: 设有一个二分类问题的神经网络，其输出层使用Sigmoid激活函数。如果网络最后一层的输入为0.8，求输出层的输出。<br />
<strong>Answer</strong>: 输出层输出 = Sigmoid(0.8) = 1 / (1 + e^(-0.8)) ≈ 0.689</p>
</li>
<li>
<p><strong>Question</strong>: 在一个卷积神经网络中，假设输入图像大小为28x28，使用一个大小为3x3的卷积核，步长为1，无填充（padding），求卷积后的输出尺寸。<br />
<strong>Answer</strong>: 输出尺寸 = [(28 - 3) / 1 + 1] x [(28 - 3) / 1 + 1] = 26 x 26</p>
</li>
<li>
<p><strong>Question</strong>: 设有一个三层全连接神经网络，输入层有4个神经元，隐藏层有5个神经元，输出层有2个神经元。如果输入为[1, 0, 2, 1]，所有权重为1，所有偏置为0，激活函数为线性函数，计算输出层的输出。<br />
<strong>Answer</strong>: 隐藏层输出 = [1×1 + 0×1 + 2×1 + 1×1, …, 1×1 + 0×1 + 2×1 + 1×1] = [4, 4, 4, 4, 4]；输出层输出 = [4×1 + 4×1 + 4×1 + 4×1 + 4×1, 4×1 + 4×1 + 4×1 + 4×1 + 4×1] = [20, 20]</p>
</li>
</ol>
<p>3章-深度学习-下</p>
<p>第3章-编程框架使用</p>
<h3 id="question-1-pytorch-tensor-basics"><a class="markdownIt-Anchor" href="#question-1-pytorch-tensor-basics"></a> Question 1: PyTorch Tensor Basics</h3>
<p><strong>题目</strong>：在PyTorch中, 创建一个形状为3x4的张量 <code>A</code>, 并用从0到11的连续整数初始化。请写出创建这个张量的PyTorch代码。</p>
<p><strong>解答</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">A = torch.arange(<span class="number">0</span>, <span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h3 id="question-2-tensor-operations"><a class="markdownIt-Anchor" href="#question-2-tensor-operations"></a> Question 2: Tensor Operations</h3>
<p><strong>题目</strong>：给定一个形状为2x3的张量 <code>B</code>，其元素初始化为任意值。使用PyTorch求其转置张量 <code>B_transpose</code>。</p>
<p><strong>解答</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B_transpose = B.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="question-3-model-inference"><a class="markdownIt-Anchor" href="#question-3-model-inference"></a> Question 3: Model Inference</h3>
<p><strong>题目</strong>：在PyTorch框架中，假设已经有一个训练好的模型 <code>model</code> 和一个数据输入 <code>input_data</code>。写出如何使用这个模型进行推理的代码。</p>
<p><strong>解答</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(input_data)</span><br></pre></td></tr></table></figure>
<h3 id="question-4-loss-function"><a class="markdownIt-Anchor" href="#question-4-loss-function"></a> Question 4: Loss Function</h3>
<p><strong>题目</strong>：在使用PyTorch进行模型训练时，我们常用的损失函数之一是交叉熵损失（Cross Entropy Loss）。请写出在PyTorch中创建交叉熵损失函数 <code>criterion</code> 的代码。</p>
<p><strong>解答</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>
<h3 id="question-5-optimizer"><a class="markdownIt-Anchor" href="#question-5-optimizer"></a> Question 5: Optimizer</h3>
<p><strong>题目</strong>：给定一个PyTorch模型 <code>model</code>，请写出使用带有动量的随机梯度下降（SGD with momentum）优化器的代码，其中学习率设为0.01，动量设为0.9。</p>
<p><strong>解答</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<h3 id="question-1-tensor-transformation"><a class="markdownIt-Anchor" href="#question-1-tensor-transformation"></a> Question 1: Tensor Transformation</h3>
<p><strong>题目</strong>：使用PyTorch创建一个形状为 4x4 的矩阵，元素为从 1 到 16 的整数。然后，将此矩阵转换为一个 2x8 的矩阵。请写出相关的PyTorch代码。</p>
<h3 id="question-2-model-inference"><a class="markdownIt-Anchor" href="#question-2-model-inference"></a> Question 2: Model Inference</h3>
<p><strong>题目</strong>：给定一个使用PyTorch预先训练好的模型 <code>model</code> 和一个待推理的数据样本 <code>sample</code>。编写一个PyTorch代码段来对此样本进行模型推理，并输出结果。</p>
<h3 id="question-3-loss-computation"><a class="markdownIt-Anchor" href="#question-3-loss-computation"></a> Question 3: Loss Computation</h3>
<p><strong>题目</strong>：使用PyTorch定义一个交叉熵损失函数，并计算给定输入 <code>input</code> 和目标 <code>target</code> 的损失值。<code>input</code> 是一个包含三个类别得分的张量，<code>target</code> 是这三个类别的标签。请写出相关的PyTorch代码。</p>
<h3 id="question-4-backpropagation"><a class="markdownIt-Anchor" href="#question-4-backpropagation"></a> Question 4: Backpropagation</h3>
<p><strong>题目</strong>：在PyTorch中，给定一个简单的线性模型和损失函数，编写一个代码段来执行一次前向传播和反向传播过程。假设模型的输入是一个张量，输出是模型对输入的预测值。</p>
<h3 id="question-5-optimizer-step"><a class="markdownIt-Anchor" href="#question-5-optimizer-step"></a> Question 5: Optimizer Step</h3>
<p><strong>题目</strong>：定义一个PyTorch优化器，例如 SGD，用于优化一个简单的线性模型的参数。编写一个代码段来执行一次优化器的更新步骤。</p>
<p>以下是对上述计算题的规范解答：</p>
<h3 id="解答-1-tensor-transformation"><a class="markdownIt-Anchor" href="#解答-1-tensor-transformation"></a> 解答 1: Tensor Transformation</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 创建 4x4 矩阵</span></span><br><span class="line">matrix_4x4 = torch.arange(<span class="number">1</span>, <span class="number">17</span>).reshape(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 转换为 2x8 矩阵</span></span><br><span class="line">matrix_2x8 = matrix_4x4.view(<span class="number">2</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<h3 id="解答-2-model-inference"><a class="markdownIt-Anchor" href="#解答-2-model-inference"></a> 解答 2: Model Inference</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()  <span class="comment"># 设置为推理模式</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁用梯度计算</span></span><br><span class="line">    output = model(sample)  <span class="comment"># 对样本进行推理</span></span><br></pre></td></tr></table></figure>
<h3 id="解答-3-loss-computation"><a class="markdownIt-Anchor" href="#解答-3-loss-computation"></a> 解答 3: Loss Computation</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义交叉熵损失函数</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 计算损失</span></span><br><span class="line">loss = criterion(<span class="built_in">input</span>, target)</span><br></pre></td></tr></table></figure>
<h3 id="解答-4-backpropagation"><a class="markdownIt-Anchor" href="#解答-4-backpropagation"></a> 解答 4: Backpropagation</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line">loss = loss_function(output, target)</span><br><span class="line"><span class="comment"># 反向传播</span></span><br><span class="line">optimizer.zero_grad()  <span class="comment"># 清除之前的梯度</span></span><br><span class="line">loss.backward()        <span class="comment"># 计算梯度</span></span><br><span class="line">optimizer.step()       <span class="comment"># 更新参数</span></span><br></pre></td></tr></table></figure>
<h3 id="解答-5-optimizer-step"><a class="markdownIt-Anchor" href="#解答-5-optimizer-step"></a> 解答 5: Optimizer Step</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 SGD 优化器</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 执行一次优化步骤</span></span><br><span class="line">optimizer.zero_grad()  <span class="comment"># 清除之前的梯度</span></span><br><span class="line">loss.backward()        <span class="comment"># 计算当前梯度</span></span><br><span class="line">optimizer.step()       <span class="comment"># 更新模型参数</span></span><br></pre></td></tr></table></figure>
<p>第6章-深度学习处理器原理</p>
<h3 id="题目-1计算特征图尺寸"><a class="markdownIt-Anchor" href="#题目-1计算特征图尺寸"></a> 题目 1：计算特征图尺寸</h3>
<p>假设有一个输入特征图大小为 224x224，使用一个3x3的卷积核，步长为1，不使用填充（padding）。计算输出特征图的大小。</p>
<h4 id="解答-2"><a class="markdownIt-Anchor" href="#解答-2"></a> 解答：</h4>
<p>输出特征图大小 = (输入大小 - 卷积核大小 + 2 * 填充) / 步长 + 1<br />
= (224 - 3 + 2 * 0) / 1 + 1<br />
= 222x222</p>
<h3 id="题目-2计算参数数量"><a class="markdownIt-Anchor" href="#题目-2计算参数数量"></a> 题目 2：计算参数数量</h3>
<p>一个全连接层的输入节点数为 1024，输出节点数为 512。计算这个全连接层的参数数量（包括偏置项）。</p>
<h4 id="解答-3"><a class="markdownIt-Anchor" href="#解答-3"></a> 解答：</h4>
<p>参数数量 = 输入节点数 * 输出节点数 + 输出节点数<br />
= 1024 * 512 + 512<br />
= 524800</p>
<h3 id="题目-3计算操作数量"><a class="markdownIt-Anchor" href="#题目-3计算操作数量"></a> 题目 3：计算操作数量</h3>
<p>一个卷积层有32个3x3的卷积核，输入特征图的大小为 64x64x3（高x宽x通道数）。计算该卷积层需要的乘法操作总数。</p>
<h4 id="解答-4"><a class="markdownIt-Anchor" href="#解答-4"></a> 解答：</h4>
<p>乘法操作数 = 卷积核高度 * 卷积核宽度 * 输入通道数 * 输出特征图高度 * 输出特征图宽度 * 卷积核数量<br />
= 3 * 3 * 3 * 62 * 62 * 32<br />
= 1,095,936</p>
<h3 id="题目-4计算内存占用"><a class="markdownIt-Anchor" href="#题目-4计算内存占用"></a> 题目 4：计算内存占用</h3>
<p>一个深度学习模型的一个卷积层有64个卷积核，每个卷积核大小为3x3x3。假设每个参数占用4字节，计算这个卷积层的参数所占用的内存大小。</p>
<h4 id="解答-5"><a class="markdownIt-Anchor" href="#解答-5"></a> 解答：</h4>
<p>内存占用 = 卷积核高度 * 卷积核宽度 * 输入通道数 * 卷积核数量 * 参数大小<br />
= 3 * 3 * 3 * 64 * 4字节<br />
= 6,912字节</p>
<h3 id="题目-5计算数据重用次数"><a class="markdownIt-Anchor" href="#题目-5计算数据重用次数"></a> 题目 5：计算数据重用次数</h3>
<p>在一个3x3卷积操作中，输入特征图的大小为 7x7x1（无填充，步长为1），计算每个输入特征图数据点在卷积过程中的平均重用次数。</p>
<h4 id="解答-6"><a class="markdownIt-Anchor" href="#解答-6"></a> 解答：</h4>
<p>每个输入点在3x3的邻域内重用，因此在一次完整的卷积操作中，中心点会被重用9次。边缘和角点的重用次数少于中心点。平均重用次数 = 总重用次数 / 输入特征图中的数据点总数。<br />
总重用次数 = 5x5的输出特征图中每个点对应3x3的输入，共 5x5x9 = 225次。<br />
输入特征图中的数据点总数 = 7x7 = 49。<br />
平均重用次数 = 225 / 49 ≈ 4.59次。</p>
<p>第7章-深度学习处理器架构</p>
<h3 id="计算题一能效比计算"><a class="markdownIt-Anchor" href="#计算题一能效比计算"></a> 计算题一：能效比计算</h3>
<p><strong>题目</strong>：假设一个深度学习处理器的峰值性能为20 TFLOPS，功耗为150瓦特。计算其能效比（性能/功耗）。</p>
<p><strong>解答</strong>：</p>
<ul>
<li>能效比 = 性能 / 功耗</li>
<li>= 20 TFLOPS / 150 W</li>
<li>= 0.133 TFLOPS/W</li>
</ul>
<h3 id="计算题二指令级并行性能提升"><a class="markdownIt-Anchor" href="#计算题二指令级并行性能提升"></a> 计算题二：指令级并行性能提升</h3>
<p><strong>题目</strong>：若一个处理器核心支持4-way指令级并行，并假设指令之间没有依赖，理论上的性能提升是多少？</p>
<p><strong>解答</strong>：</p>
<ul>
<li>理论上，性能提升与指令级并行的数量成正比。</li>
<li>因此，性能提升 = 并行程度 = 4倍。</li>
</ul>
<h3 id="计算题三稀疏神经网络运算加速"><a class="markdownIt-Anchor" href="#计算题三稀疏神经网络运算加速"></a> 计算题三：稀疏神经网络运算加速</h3>
<p><strong>题目</strong>：一个处理器核心在处理稀疏神经网络时，只对非零元素进行计算。如果输入数据的稀疏度为70%，计算加速比是多少？</p>
<p><strong>解答</strong>：</p>
<ul>
<li>原始计算量 = 100%</li>
<li>实际计算量 = 100% - 70% = 30%</li>
<li>加速比 = 原始计算量 / 实际计算量</li>
<li>= 100% / 30%</li>
<li>= 3.33倍</li>
</ul>
<h3 id="计算题四权重存储需求"><a class="markdownIt-Anchor" href="#计算题四权重存储需求"></a> 计算题四：权重存储需求</h3>
<p><strong>题目</strong>：假设深度学习模型有1亿个参数，每个参数用32位浮点数表示。计算存储这些参数需要的内存大小。</p>
<p><strong>解答</strong>：</p>
<ul>
<li>每个参数大小 = 32位 = 4字节</li>
<li>总内存需求 = 参数数量 × 每个参数大小</li>
<li>= 1亿个 × 4字节</li>
<li>= 400 MB</li>
</ul>
<h3 id="计算题五矩阵乘法性能需求"><a class="markdownIt-Anchor" href="#计算题五矩阵乘法性能需求"></a> 计算题五：矩阵乘法性能需求</h3>
<p><strong>题目</strong>：一个深度学习模型进行的矩阵乘法操作需要2秒内完成。如果每次乘法操作需要10^12次浮点运算，计算所需的最小处理器性能。</p>
<p><strong>解答</strong>：</p>
<ul>
<li>总浮点运算次数 = 10^12</li>
<li>时间 = 2秒</li>
<li>性能需求 = 总浮点运算次数 / 时间</li>
<li>= 10^12次 / 2秒</li>
<li>= 0.5 TFLOPS</li>
</ul>

            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2024/01/02/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F-%E4%B9%A0%E9%A2%98/" data-id="cls1ihebh00mz986975vw3avg" data-title="智能计算系统:自制试题"
               class="article-share-link">分享</a>
            
            
            
            
    <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" rel="tag">专业知识</a></li></ul>


        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
            <div class="article-nav-link-wrap article-nav-link-left">
                
                    <img data-src="https://pbs.twimg.com/media/GBTN7RnW0AA6G9K?format=jpg&amp;name=medium" data-sizes="auto" alt="智能计算系统:课后题"
                         class="lazyload">
                
                <a href="/2024/01/02/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F-%E8%AF%BE%E5%90%8E%E9%A2%98/"></a>
                <div class="article-nav-caption">前一篇</div>
                <h3 class="article-nav-title">
                    
                        智能计算系统:课后题
                    
                </h3>
            </div>
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://pbs.twimg.com/media/GBTN7RnW0AA6G9K?format=jpg&amp;name=medium" data-sizes="auto" alt="Database:范式部分"
                         class="lazyload">
                
                <a href="/2023/12/30/Database-Review/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        Database:范式部分
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">323</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">31</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">367</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        <iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/74X2u8JMVooG2QbjRxXwR8?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accumulate/">Accumulate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AimGraduate/">AimGraduate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Competition/">Competition</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Future/">Future</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bug/">bug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/internship/SNN/">SNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/spikeBERT/">spikeBERT</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/spikingjelly/">spikingjelly</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/ItWorks-SNN/">ItWorks-SNN</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/boring-SNN/">boring-SNN</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS224N/">CS224N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS231N/">CS231N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/Missing-Semester-of-CS/">Missing Semester of CS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/reading/">reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/Database/">Database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/">ML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/NNDL/">NNDL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/OS/">OS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/SE/">SE</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/d2l/">d2l</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E6%99%BA%E8%83%BD%E4%BF%A1%E6%81%AF%E7%BD%91%E7%BB%9C/">智能信息网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/">智能计算系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/%E8%AF%AD%E9%9F%B3%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86/">语音信息处理</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/0/" style="font-size: 10px;">0</a> <a href="/tags/1/" style="font-size: 11.67px;">1</a> <a href="/tags/11-11/" style="font-size: 10px;">11.11</a> <a href="/tags/17/" style="font-size: 10px;">17</a> <a href="/tags/2/" style="font-size: 12.22px;">2</a> <a href="/tags/2-2/" style="font-size: 10px;">2-2</a> <a href="/tags/3/" style="font-size: 11.11px;">3</a> <a href="/tags/3-1/" style="font-size: 10px;">3-1</a> <a href="/tags/4/" style="font-size: 11.11px;">4</a> <a href="/tags/5/" style="font-size: 10.56px;">5</a> <a href="/tags/6/" style="font-size: 10px;">6</a> <a href="/tags/7/" style="font-size: 10px;">7</a> <a href="/tags/A4/" style="font-size: 10px;">A4</a> <a href="/tags/A6/" style="font-size: 10px;">A6</a> <a href="/tags/A9/" style="font-size: 11.11px;">A9</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/AI-Ethics/" style="font-size: 10px;">AI Ethics</a> <a href="/tags/Accumulate/" style="font-size: 17.78px;">Accumulate</a> <a href="/tags/Advanced-SQL/" style="font-size: 10px;">Advanced SQL</a> <a href="/tags/Advancing-Spiking-Neural-Networks-towards-Deep-Residual-Learning/" style="font-size: 11.11px;">Advancing Spiking Neural Networks towards Deep Residual Learning</a> <a href="/tags/Ai-Ethics/" style="font-size: 10px;">Ai Ethics</a> <a href="/tags/AimGraduate/" style="font-size: 13.89px;">AimGraduate</a> <a href="/tags/An-Overview-of-the-BLITZ-Computer-Hardware/" style="font-size: 10px;">An Overview of the BLITZ Computer Hardware</a> <a href="/tags/An-Overview-of-the-BLITZ-System/" style="font-size: 10px;">An Overview of the BLITZ System</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/Artificial-neural-networks/" style="font-size: 10px;">Artificial neural networks</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/BLIP/" style="font-size: 10px;">BLIP</a> <a href="/tags/BLIP-2/" style="font-size: 10px;">BLIP-2</a> <a href="/tags/BasciConception/" style="font-size: 10px;">BasciConception</a> <a href="/tags/BatchNorm/" style="font-size: 10px;">BatchNorm</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/Blitz/" style="font-size: 11.67px;">Blitz</a> <a href="/tags/CAS/" style="font-size: 10.56px;">CAS</a> <a href="/tags/CMU15-445/" style="font-size: 10px;">CMU15-445</a> <a href="/tags/CNN/" style="font-size: 11.67px;">CNN</a> <a href="/tags/CS224N/" style="font-size: 10px;">CS224N</a> <a href="/tags/CS231N/" style="font-size: 10px;">CS231N</a> <a href="/tags/CV/" style="font-size: 10.56px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 12.78px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/Chapter01/" style="font-size: 10px;">Chapter01</a> <a href="/tags/ComPetition/" style="font-size: 10px;">ComPetition</a> <a href="/tags/Container/" style="font-size: 10px;">Container</a> <a href="/tags/Convolutional-SNN-to-Classify-FMNIST/" style="font-size: 10px;">Convolutional SNN to Classify FMNIST</a> <a href="/tags/Cover-Letter/" style="font-size: 10px;">Cover Letter</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Database/" style="font-size: 15.56px;">Database</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 10.56px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Filter/" style="font-size: 10px;">Filter</a> <a href="/tags/Fine-Tuning/" style="font-size: 10px;">Fine-Tuning</a> <a href="/tags/Future/" style="font-size: 12.78px;">Future</a> <a href="/tags/GB/" style="font-size: 10px;">GB</a> <a href="/tags/GNN/" style="font-size: 10px;">GNN</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GiB/" style="font-size: 10px;">GiB</a> <a href="/tags/Git/" style="font-size: 10.56px;">Git</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoAbroad/" style="font-size: 16.11px;">GoAbroad</a> <a href="/tags/Graduate/" style="font-size: 10px;">Graduate</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/IC/" style="font-size: 10px;">IC</a> <a href="/tags/IELTS/" style="font-size: 10.56px;">IELTS</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 10px;">IntelliJ IDEA</a> <a href="/tags/Intermediate-SQL/" style="font-size: 10px;">Intermediate SQL</a> <a href="/tags/Introduction/" style="font-size: 10px;">Introduction</a> <a href="/tags/Introduction-to-SQL/" style="font-size: 10px;">Introduction to SQL</a> <a href="/tags/Introduction-to-the-Relational-Model/" style="font-size: 10px;">Introduction to the Relational Model</a> <a href="/tags/ItWorks/" style="font-size: 10px;">ItWorks</a> <a href="/tags/Jianfei-Chen/" style="font-size: 10px;">Jianfei Chen</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/LMUFORMER/" style="font-size: 10px;">LMUFORMER</a> <a href="/tags/Lab1/" style="font-size: 10px;">Lab1</a> <a href="/tags/Lab3/" style="font-size: 10px;">Lab3</a> <a href="/tags/Lab4/" style="font-size: 10px;">Lab4</a> <a href="/tags/LayerNorm/" style="font-size: 10px;">LayerNorm</a> <a href="/tags/Lec01/" style="font-size: 11.11px;">Lec01</a> <a href="/tags/Lec01s/" style="font-size: 10.56px;">Lec01s</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/Linux/" style="font-size: 11.67px;">Linux</a> <a href="/tags/M2/" style="font-size: 10.56px;">M2</a> <a href="/tags/MIT6-S081/" style="font-size: 12.22px;">MIT6.S081</a> <a href="/tags/ML/" style="font-size: 13.89px;">ML</a> <a href="/tags/MS-ResNet/" style="font-size: 10px;">MS-ResNet</a> <a href="/tags/Mac/" style="font-size: 10.56px;">Mac</a> <a href="/tags/Missing-Semester/" style="font-size: 10.56px;">Missing Semester</a> <a href="/tags/Monitor/" style="font-size: 10px;">Monitor</a> <a href="/tags/NLP/" style="font-size: 11.11px;">NLP</a> <a href="/tags/NNDL/" style="font-size: 17.22px;">NNDL</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Neural-Network-from-Shallow-to-Deep/" style="font-size: 10px;">Neural Network from Shallow to Deep</a> <a href="/tags/Neuromorphic-computing/" style="font-size: 10px;">Neuromorphic computing</a> <a href="/tags/Neuron/" style="font-size: 10px;">Neuron</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/OS/" style="font-size: 13.89px;">OS</a> <a href="/tags/PSN/" style="font-size: 10px;">PSN</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Qingyao-Ai/" style="font-size: 10.56px;">Qingyao Ai</a> <a href="/tags/RISC-V/" style="font-size: 10px;">RISC-V</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/Readme/" style="font-size: 10px;">Readme</a> <a href="/tags/ResNet/" style="font-size: 10.56px;">ResNet</a> <a href="/tags/Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" style="font-size: 10px;">Rethinking the performance comparison between SNNS and ANNS</a> <a href="/tags/SE/" style="font-size: 11.11px;">SE</a> <a href="/tags/SE-3-0/" style="font-size: 10px;">SE-3.0</a> <a href="/tags/SNN/" style="font-size: 12.22px;">SNN</a> <a href="/tags/SNN-vs-RNN/" style="font-size: 10px;">SNN vs RNN</a> <a href="/tags/SNNNLP/" style="font-size: 10px;">SNNNLP</a> <a href="/tags/SPIKEBERT/" style="font-size: 10px;">SPIKEBERT</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/Script/" style="font-size: 10px;">Script</a> <a href="/tags/Shell/" style="font-size: 10.56px;">Shell</a> <a href="/tags/Single-Fully-Connected-Layer-SNN-to-Classify-MNIST/" style="font-size: 10px;">Single Fully Connected Layer SNN to Classify MNIST</a> <a href="/tags/Spiking-Neural-Network-for-Ultra-low-latency-and-High-accurate-Object-Detection/" style="font-size: 10px;">Spiking Neural Network for Ultra-low-latency and High-accurate Object Detection</a> <a href="/tags/Spiking-neural-network/" style="font-size: 10.56px;">Spiking neural network</a> <a href="/tags/Spiking-neural-networks/" style="font-size: 10px;">Spiking neural networks</a> <a href="/tags/SpikingBERT/" style="font-size: 10px;">SpikingBERT</a> <a href="/tags/Surrogate-Gradient-Method/" style="font-size: 10px;">Surrogate Gradient Method</a> <a href="/tags/T1-fighting/" style="font-size: 10.56px;">T1 fighting</a> <a href="/tags/THU/" style="font-size: 10px;">THU</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/Terminal/" style="font-size: 10px;">Terminal</a> <a href="/tags/The-Thread-Scheduler-and-Concurrency-Control-Primitives/" style="font-size: 10px;">The Thread Scheduler and Concurrency Control Primitives</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/Undergraduate/" style="font-size: 10px;">Undergraduate</a> <a href="/tags/University/" style="font-size: 12.78px;">University</a> <a href="/tags/VSCode/" style="font-size: 10px;">VSCode</a> <a href="/tags/ViT/" style="font-size: 11.11px;">ViT</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 10.56px;">Yuxiao Dong</a> <a href="/tags/Zero/" style="font-size: 10px;">Zero</a> <a href="/tags/ai-ethics/" style="font-size: 10px;">ai ethics</a> <a href="/tags/alexnet/" style="font-size: 10px;">alexnet</a> <a href="/tags/arxiv/" style="font-size: 10px;">arxiv</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/bert/" style="font-size: 11.67px;">bert</a> <a href="/tags/blitz/" style="font-size: 10px;">blitz</a> <a href="/tags/boring/" style="font-size: 11.11px;">boring</a> <a href="/tags/bug/" style="font-size: 16.67px;">bug</a> <a href="/tags/cat/" style="font-size: 10px;">cat</a> <a href="/tags/chapter00/" style="font-size: 10px;">chapter00</a> <a href="/tags/chapter01/" style="font-size: 11.11px;">chapter01</a> <a href="/tags/chapter02/" style="font-size: 10px;">chapter02</a> <a href="/tags/chapter03/" style="font-size: 10px;">chapter03</a> <a href="/tags/chapter04/" style="font-size: 10.56px;">chapter04</a> <a href="/tags/chapter05/" style="font-size: 10.56px;">chapter05</a> <a href="/tags/chapter6/" style="font-size: 10px;">chapter6</a> <a href="/tags/chatgpt/" style="font-size: 10px;">chatgpt</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/chmod/" style="font-size: 10px;">chmod</a> <a href="/tags/chrome/" style="font-size: 10px;">chrome</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/code/" style="font-size: 11.11px;">code</a> <a href="/tags/coding/" style="font-size: 10px;">coding</a> <a href="/tags/commit/" style="font-size: 10px;">commit</a> <a href="/tags/competition/" style="font-size: 10px;">competition</a> <a href="/tags/conv2d/" style="font-size: 10px;">conv2d</a> <a href="/tags/copilot/" style="font-size: 10.56px;">copilot</a> <a href="/tags/courseinfo/" style="font-size: 10px;">courseinfo</a> <a href="/tags/cpu/" style="font-size: 10px;">cpu</a> <a href="/tags/cuda/" style="font-size: 10px;">cuda</a> <a href="/tags/d2l/" style="font-size: 13.33px;">d2l</a> <a href="/tags/database/" style="font-size: 13.89px;">database</a> <a href="/tags/dataloader/" style="font-size: 10px;">dataloader</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/deep-neural-network/" style="font-size: 10.56px;">deep neural network</a> <a href="/tags/delete/" style="font-size: 10px;">delete</a> <a href="/tags/discussion/" style="font-size: 10px;">discussion</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/dowhy/" style="font-size: 10.56px;">dowhy</a> <a href="/tags/dp/" style="font-size: 10.56px;">dp</a> <a href="/tags/echo/" style="font-size: 10px;">echo</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/embedding/" style="font-size: 10px;">embedding</a> <a href="/tags/explainer/" style="font-size: 10.56px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/file/" style="font-size: 10px;">file</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 12.22px;">github</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gpu/" style="font-size: 10.56px;">gpu</a> <a href="/tags/hacker/" style="font-size: 10px;">hacker</a> <a href="/tags/handout/" style="font-size: 10px;">handout</a> <a href="/tags/hexo/" style="font-size: 10.56px;">hexo</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/import/" style="font-size: 10px;">import</a> <a href="/tags/instructor/" style="font-size: 11.67px;">instructor</a> <a href="/tags/intern-00/" style="font-size: 10px;">intern-00</a> <a href="/tags/intern00/" style="font-size: 11.67px;">intern00</a> <a href="/tags/internship/" style="font-size: 18.89px;">internship</a> <a href="/tags/interview/" style="font-size: 10px;">interview</a> <a href="/tags/introduction/" style="font-size: 11.11px;">introduction</a> <a href="/tags/iterm2/" style="font-size: 10px;">iterm2</a> <a href="/tags/jmbook/" style="font-size: 10px;">jmbook</a> <a href="/tags/knowledge-distillaion/" style="font-size: 10px;">knowledge distillaion</a> <a href="/tags/l1/" style="font-size: 10px;">l1</a> <a href="/tags/l2/" style="font-size: 10px;">l2</a> <a href="/tags/l3/" style="font-size: 10px;">l3</a> <a href="/tags/lab1/" style="font-size: 10px;">lab1</a> <a href="/tags/lab2/" style="font-size: 10.56px;">lab2</a> <a href="/tags/lec01/" style="font-size: 10px;">lec01</a> <a href="/tags/linux/" style="font-size: 11.11px;">linux</a> <a href="/tags/llava/" style="font-size: 10px;">llava</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/loss/" style="font-size: 10px;">loss</a> <a href="/tags/lstm/" style="font-size: 10px;">lstm</a> <a href="/tags/mac/" style="font-size: 12.22px;">mac</a> <a href="/tags/memory/" style="font-size: 11.11px;">memory</a> <a href="/tags/mentor/" style="font-size: 10.56px;">mentor</a> <a href="/tags/mid/" style="font-size: 10.56px;">mid</a> <a href="/tags/ml/" style="font-size: 10px;">ml</a> <a href="/tags/mlp/" style="font-size: 10px;">mlp</a> <a href="/tags/mnist/" style="font-size: 10px;">mnist</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/mysqlclient/" style="font-size: 10px;">mysqlclient</a> <a href="/tags/neuromorphic-computing/" style="font-size: 10.56px;">neuromorphic computing</a> <a href="/tags/nndl/" style="font-size: 10.56px;">nndl</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/nvidia/" style="font-size: 10px;">nvidia</a> <a href="/tags/ohmyzsh/" style="font-size: 10px;">ohmyzsh</a> <a href="/tags/os/" style="font-size: 14.44px;">os</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/overview/" style="font-size: 10px;">overview</a> <a href="/tags/p1/" style="font-size: 10px;">p1</a> <a href="/tags/p2/" style="font-size: 11.11px;">p2</a> <a href="/tags/p3/" style="font-size: 10px;">p3</a> <a href="/tags/paper/" style="font-size: 19.44px;">paper</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/pku/" style="font-size: 10px;">pku</a> <a href="/tags/player/" style="font-size: 10px;">player</a> <a href="/tags/preparation/" style="font-size: 10px;">preparation</a> <a href="/tags/prml/" style="font-size: 11.67px;">prml</a> <a href="/tags/profile/" style="font-size: 10px;">profile</a> <a href="/tags/project/" style="font-size: 11.67px;">project</a> <a href="/tags/pycharm/" style="font-size: 10px;">pycharm</a> <a href="/tags/pytorch/" style="font-size: 13.89px;">pytorch</a> <a href="/tags/qemu/" style="font-size: 10px;">qemu</a> <a href="/tags/question/" style="font-size: 10px;">question</a> <a href="/tags/reading/" style="font-size: 10.56px;">reading</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/review/" style="font-size: 14.44px;">review</a> <a href="/tags/rf/" style="font-size: 10px;">rf</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/rsa/" style="font-size: 10px;">rsa</a> <a href="/tags/se/" style="font-size: 15px;">se</a> <a href="/tags/self-attention/" style="font-size: 10px;">self-attention</a> <a href="/tags/server/" style="font-size: 10px;">server</a> <a href="/tags/shap/" style="font-size: 10px;">shap</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/shell-vs-terminal/" style="font-size: 10px;">shell vs terminal</a> <a href="/tags/simple/" style="font-size: 10px;">simple</a> <a href="/tags/snn/" style="font-size: 11.11px;">snn</a> <a href="/tags/solution/" style="font-size: 10px;">solution</a> <a href="/tags/sora/" style="font-size: 10px;">sora</a> <a href="/tags/spike/" style="font-size: 10.56px;">spike</a> <a href="/tags/spikeBERT/" style="font-size: 10.56px;">spikeBERT</a> <a href="/tags/spikeBert/" style="font-size: 10px;">spikeBert</a> <a href="/tags/spikebert/" style="font-size: 10px;">spikebert</a> <a href="/tags/spikingjelly/" style="font-size: 12.22px;">spikingjelly</a> <a href="/tags/spikngjelly/" style="font-size: 10.56px;">spikngjelly</a> <a href="/tags/ssh/" style="font-size: 10.56px;">ssh</a> <a href="/tags/terminal/" style="font-size: 10px;">terminal</a> <a href="/tags/test/" style="font-size: 10px;">test</a> <a href="/tags/thu/" style="font-size: 10px;">thu</a> <a href="/tags/tips/" style="font-size: 10.56px;">tips</a> <a href="/tags/tool/" style="font-size: 18.33px;">tool</a> <a href="/tags/transformer/" style="font-size: 12.78px;">transformer</a> <a href="/tags/transformers/" style="font-size: 10px;">transformers</a> <a href="/tags/uml/" style="font-size: 10px;">uml</a> <a href="/tags/vit/" style="font-size: 10px;">vit</a> <a href="/tags/vscode/" style="font-size: 10.56px;">vscode</a> <a href="/tags/wakatime/" style="font-size: 10px;">wakatime</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/xv6/" style="font-size: 10px;">xv6</a> <a href="/tags/zero/" style="font-size: 10px;">zero</a> <a href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" style="font-size: 20px;">专业知识</a> <a href="/tags/%E4%B8%93%E7%A1%95/" style="font-size: 10px;">专硕</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E4%B8%AD%E7%A7%91%E9%99%A2/" style="font-size: 10px;">中科院</a> <a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 10px;">代理</a> <a href="/tags/%E5%85%AC%E9%80%89%E8%AF%BE/" style="font-size: 10px;">公选课</a> <a href="/tags/%E5%86%85%E5%AD%98/" style="font-size: 10.56px;">内存</a> <a href="/tags/%E5%86%99%E4%BD%9C%E5%BF%83%E5%BE%97/" style="font-size: 10px;">写作心得</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" style="font-size: 10px;">分布式训练</a> <a href="/tags/%E5%8A%A0%E5%88%86/" style="font-size: 10px;">加分</a> <a href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">动手学深度学习</a> <a href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/" style="font-size: 10px;">博弈论</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E6%8F%8F%E8%BF%B0%E7%94%9F%E6%88%90/" style="font-size: 10px;">图像描述生成</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" style="font-size: 10px;">基础优化方法</a> <a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">复习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 10px;">多模态</a> <a href="/tags/%E5%A4%A7%E4%B8%89%E4%B8%8A/" style="font-size: 10px;">大三上</a> <a href="/tags/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" style="font-size: 10px;">大作业</a> <a href="/tags/%E5%A4%A7%E5%88%9B/" style="font-size: 10px;">大创</a> <a href="/tags/%E5%A4%A7%E8%8B%B1%E8%B5%9B/" style="font-size: 10px;">大英赛</a> <a href="/tags/%E5%AD%A6%E7%A1%95/" style="font-size: 10px;">学硕</a> <a href="/tags/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/" style="font-size: 10.56px;">审稿意见</a> <a href="/tags/%E5%B0%8F%E4%BD%9C%E4%B8%9A/" style="font-size: 10px;">小作业</a> <a href="/tags/%E5%BC%BA%E5%BC%B1com/" style="font-size: 10px;">强弱com</a> <a href="/tags/%E5%BD%A2%E5%8A%BF%E4%B8%8E%E6%94%BF%E7%AD%96/" style="font-size: 10px;">形势与政策</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%80%80%E6%8F%A3%E7%9D%80%E4%B8%80%E5%AE%9A%E5%8F%AF%E4%BB%A5%E5%81%9A%E5%A5%BD%E7%9A%84%E7%A1%AE%E4%BF%A1/" style="font-size: 10px;">怀揣着一定可以做好的确信</a> <a href="/tags/%E6%82%84%E6%82%84%E8%AF%9D/" style="font-size: 10px;">悄悄话</a> <a href="/tags/%E6%83%85%E7%BB%AA%E7%9A%84%E7%A7%98%E5%AF%86/" style="font-size: 10px;">情绪的秘密</a> <a href="/tags/%E6%8F%90%E9%97%AE/" style="font-size: 10px;">提问</a> <a href="/tags/%E6%94%B9%E7%BB%B4%E5%BA%A6/" style="font-size: 10px;">改维度</a> <a href="/tags/%E6%95%99%E8%82%B2%E8%AE%B8%E5%8F%AF/" style="font-size: 10px;">教育许可</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 10px;">数据操作+预处理</a> <a href="/tags/%E6%98%BE%E5%8D%A1/" style="font-size: 10px;">显卡</a> <a href="/tags/%E6%98%BE%E5%AD%98/" style="font-size: 10.56px;">显存</a> <a href="/tags/%E6%99%BA%E6%85%A7%E6%A0%91/" style="font-size: 10px;">智慧树</a> <a href="/tags/%E6%99%BA%E8%83%BD%E4%BF%A1%E6%81%AF%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">智能信息网络</a> <a href="/tags/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" style="font-size: 13.89px;">智能计算系统</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 10.56px;">服务器</a> <a href="/tags/%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">期中复习</a> <a href="/tags/%E6%9C%9F%E6%9C%AB/" style="font-size: 10px;">期末</a> <a href="/tags/%E6%9C%B1%E8%80%81%E5%B8%88/" style="font-size: 10px;">朱老师</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9D%82%E9%A1%B9/" style="font-size: 11.67px;">杂项</a> <a href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" style="font-size: 10.56px;">李宏毅</a> <a href="/tags/%E6%9D%8E%E6%B2%90/" style="font-size: 10px;">李沐</a> <a href="/tags/%E6%A6%82%E8%AE%BA/" style="font-size: 10px;">概论</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/" style="font-size: 10px;">模型训练流程</a> <a href="/tags/%E6%AF%9B%E6%A6%82/" style="font-size: 12.78px;">毛概</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0/" style="font-size: 10.56px;">特征学习</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">环境搭建</a> <a href="/tags/%E7%94%A8%E4%BE%8B%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">用例模型</a> <a href="/tags/%E7%9F%A5%E8%A1%8C%E5%90%88%E4%B8%80/" style="font-size: 10px;">知行合一</a> <a href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">矩阵计算</a> <a href="/tags/%E7%AC%AC%E4%B8%89%E7%AB%A0/" style="font-size: 10px;">第三章</a> <a href="/tags/%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%BB%BA%E8%AE%AE%E4%B9%A6/" style="font-size: 10px;">系统开发建议书</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 10px;">线性代数</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3/" style="font-size: 10px;">脑机接口</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 10px;">脑机接口信号处理</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">自动求导</a> <a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" style="font-size: 10px;">虚拟机</a> <a href="/tags/%E8%A7%84%E5%88%99/" style="font-size: 10px;">规则</a> <a href="/tags/%E8%A7%A3%E5%8E%8B%E7%BC%A9/" style="font-size: 10px;">解压缩</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87/" style="font-size: 10px;">评测指标</a> <a href="/tags/%E8%AF%AD%E9%9F%B3%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86/" style="font-size: 10px;">语音信息处理</a> <a href="/tags/%E8%AF%BE%E5%A0%82%E8%AE%A8%E8%AE%BA/" style="font-size: 10px;">课堂讨论</a> <a href="/tags/%E8%AF%BE%E7%A8%8B/" style="font-size: 10px;">课程</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E6%A6%82%E8%A7%88/" style="font-size: 10px;">课程概览</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E8%A1%A8/" style="font-size: 10px;">课程表</a> <a href="/tags/%E8%AF%BE%E8%AE%BE/" style="font-size: 10px;">课设</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 11.11px;">调研</a> <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 10px;">贝叶斯</a> <a href="/tags/%E8%B4%A1%E7%8C%AE%E8%80%85/" style="font-size: 10px;">贡献者</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%A6%82%E8%A6%81%E8%AE%BE%E8%AE%A1/" style="font-size: 10px;">软件概要设计</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">软件生命周期模型</a> <a href="/tags/%E8%BE%93%E5%85%A5%E6%B3%95/" style="font-size: 10px;">输入法</a> <a href="/tags/%E9%87%8F%E5%8C%96/" style="font-size: 10px;">量化</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a> <a href="/tags/%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/" style="font-size: 10px;">需求分析</a> <a href="/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90%E5%BB%BA%E6%A8%A1/" style="font-size: 10px;">面向对象的需求分析建模</a> <a href="/tags/%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">领域模型</a>
        </div>
    </div>


    
        

    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">三月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">一月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">十一月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    

    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2024
                <span class="footer-info-sep"></span>
                ab
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    655.1k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    41:30
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">323</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">31</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">367</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

