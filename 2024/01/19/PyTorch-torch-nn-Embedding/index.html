<!DOCTYPE html>

<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <!--
        hexo-theme-suka © SukkaW
        GitHub: https://github.com/SukkaW/hexo-theme-suka
    -->

    <!-- ### Resource Hint ### -->

    <!-- ## DNS Prefetch ## -->
    <meta http-equiv="x-dns-prefetch-control" content="on">

<!-- busuanzi -->

    <link rel="dns-prefetch" href="//busuanzi.ibruce.info">


<!-- comment -->


    <link rel="dns-prefetch" href="//disqus.com">
    <link rel="dns-prefetch" href="//robin02.disqus.com">






<!-- analytics -->







    <!-- ## Preload ## -->
    
    <!-- Busuanzi -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" as="script">







    <!-- ### Meta & Title & Info ### -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <meta name="renderer" content="webkit">

    <!-- Title -->
    <title>PyTorch:torch.nn.Embedding() | blog</title>

    <!-- Favicons -->
    <link rel="icon" type="image&#x2F;ico" href="/img/blog.ico">

    <!-- ### Import File ### -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/spectre.css@0.5.3"><style>
    body {
        background-color: #f8f9fa;
    }

    a, a:visited {
        color: blue;
    }

    a:active, a:focus, a:hover {
        color: blue;
        opacity: .75;
    }

    #post-content a,
    #post-content a:hover,
    #post-content a:focus,
    #post-content a:visited {
        color: blue;
        opacity: 1;
    }

    

    .post-entry .card-body a {
        color: red;
    }

    .avatar {
        background: red;
    }

    .navbar-link,
    .navbar-link:visited,
    .timeline .timeline-item .timeline-icon.icon-lg {
        color: red;
    }

    .navbar-link:hover {
        color: red;
        opacity: .8;
    }

    #search-input .btn,
    #disqus_click_btn,
    #disqus-switch-to-direct,
    #disqus-loadmore-button {
        background: red;
        border-color: red;
        color: #fff;
    }

    #post-toc a.post-toc-link,
    #post-toc a.post-toc-link:visited,
    .share-menu.menu .menu-item>a {
        color: red;
    }

    .share-menu.menu .menu-item>a:hover,
    .share-menu.menu .menu-item>a:focus,
    .share-menu.menu .menu-item>a:visited {
        color: #50596c;
        background: #f8f9fa;
        opacity: .85;
    }
</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/style.min.css">








    <!-- Prettify Theme -->
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sukkaw/hexo-theme-suka@1.3.0/source/css/highlight/[theme-name].min.css"></noscript>





<script>
/*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
!function(t){"use strict";t.loadCSS||(t.loadCSS=function(){});var e=loadCSS.relpreload={};if(e.support=function(){var e;try{e=t.document.createElement("link").relList.supports("preload")}catch(t){e=!1}return function(){return e}}(),e.bindMediaToggle=function(t){var e=t.media||"all";function a(){t.addEventListener?t.removeEventListener("load",a):t.attachEvent&&t.detachEvent("onload",a),t.setAttribute("onload",null),t.media=e}t.addEventListener?t.addEventListener("load",a):t.attachEvent&&t.attachEvent("onload",a),setTimeout(function(){t.rel="stylesheet",t.media="only x"}),setTimeout(a,3e3)},e.poly=function(){if(!e.support())for(var a=t.document.getElementsByTagName("link"),n=0;n<a.length;n++){var o=a[n];"preload"!==o.rel||"style"!==o.getAttribute("as")||o.getAttribute("data-loadcss")||(o.setAttribute("data-loadcss",!0),e.bindMediaToggle(o))}},!e.support()){e.poly();var a=t.setInterval(e.poly,500);t.addEventListener?t.addEventListener("load",function(){e.poly(),t.clearInterval(a)}):t.attachEvent&&t.attachEvent("onload",function(){e.poly(),t.clearInterval(a)})}"undefined"!=typeof exports?exports.loadCSS=loadCSS:t.loadCSS=loadCSS}("undefined"!=typeof global?global:this);
</script>

    <!-- ### Site Verification ### -->
    


    <meta name="mobile-web-app-capable" content="yes"><meta name="application-name" content="blog"><meta name="msapplication-starturl" content="https://abinzzz.github.io"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="blog"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="blog">

    <!-- ### The Open Graph & Twitter Card Protocol ### -->
    <meta property="og:title" content="PyTorch:torch.nn.Embedding() | blog"><meta property="og:site_name" content="blog"><meta property="og:type" content="article"><meta property="og:url" content="https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/"><meta property="og:locale" content="zh-CN"><meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&amp;apos;$&amp;apos;, &amp;apos;$&amp;apos;]]}, messageStyle: &quot;none&quot; });   参考链接  EMBEDDING    正文  类定义 12345class torch.nn.Embedding(num_embeddings, embedding_dim,                          pa - ab - blog"><meta name="keywords" content="Accumulate, pytorch, embedding, blog"><meta property="article:published_time" content="2024-01-19T13:31:33.000Z"><meta property="article:modified_time" content="2024-01-19T14:23:56.244Z"><meta property="og:updated_time" content="2024-01-19T14:23:56.244Z"><meta property="article:author" content="ab"><meta property="article:tag" content="Accumulate, pytorch, embedding, blog"><meta name="twitter:card" content="summary">

    

    <!-- ### Canonical link ### -->
    <link rel="canonical" href="https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/">

    <meta name="generator" content="Hexo 5.4.2">

    <!-- ### Analytics ### -->
    







    <!-- ### Structured Data ### -->
    



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "url": "https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/",
    "@type": "BlogPosting",
    "logo": "https://abinzzz.github.io/img/blog.ico",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/"
    },
    "headline": "PyTorch:torch.nn.Embedding() | blog",
    
    "image": {
        "@type": "ImageObject",
        "url": "https://abinzzz.github.io/img/blog.ico"
    },
    
    "datePublished": "2024-01-19T13:31:33.000Z",
    "dateModified": "2024-01-19T14:23:56.244Z",
    "author": {
        "@type": "Person",
        "name": "ab",
        "image": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/avatar.jpg"
        },
        "description": "Welcome to my blog!"
    },
    "publisher": {
        "@type": "Organization",
        "name": "blog",
        "logo": {
            "@type": "ImageObject",
            "url": "https://abinzzz.github.io/img/blog.ico"
        }
    },
    
    "potentialAction": {
        "@type": "SearchAction",
        "target": "https://abinzzz.github.io/search?s={search_term_string}",
        "query-input": "required name=search_term_string"
    },
    
    "keywords": "Accumulate, pytorch, embedding, blog",
    "description": "MathJax.Hub.Config({ tex2jax: {inlineMath: [[&amp;apos;$&amp;apos;, &amp;apos;$&amp;apos;]]}, messageStyle: &amp;quot;none&amp;quot; });   参考链接  EMBEDDING    正文  类定义 12345class torch.nn.Embedding(num_embeddings, embedding_dim,                          pa - ab - blog"
}
</script>



    <!-- ### Custom Head ### -->
    
</head>

    <body>
            

            <!-- ### Main content ### -->
            <!-- ## Header ##-->
<header>
    <h1 class="header-title text-center"><a href="/">blog</a></h1>

    <p class="text-center header-slogan">
        
            
                Welcome to my blog!
            
        
    </p>

    <nav class="navbar-section text-center">
    
        <a href="/" class="navbar-link">首页</a>
    
    
    <a href="/categories/" class="navbar-link">分类</a>
    
        <a href="/archives/" class="navbar-link">归档</a>
    
    
        <a href="/search" class="navbar-link">搜索</a>
    
    
    
    
</nav>
</header>

            
    <!-- ## Post ## -->
    <div class="post-container">
    <div id="post-card" class="card">
        
        <div class="card-item-container">
            <div class="card-inner-cell">
                <!-- # Post Header Info # -->
                <div class="card-header">
                    
    <h1 class="card-title h3 mb-2">PyTorch:torch.nn.Embedding()</h1>




<div class="post-header-info">
    <p class="post-header-info-left text-gray">
        <img class="author-thumb lazyload" data-src="/img/avatar.jpg" src="/img/suka-lazyload.gif" alt="ab's Avatar">
        <span>2024-01-19</span>
        
            <span class="suka-devide-dot"></span>
            <a class="category-link" href="/categories/Accumulate/">Accumulate</a>
        
        
        
    </p>
    <div class="post-header-info-right">
        
            <div class="dropdown dropdown-right">
<a class="dropdown-toggle" tabindex="0">分享本文</a>
<ul class="menu share-menu">
    <!-- Share Weibo -->
    

    <!-- Share Twitter -->
    

    <!-- Share Facebook -->
    

    <!-- Share Google+ -->
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    

    <!-- QRCode -->
    
    <li class="menu-item">
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAACkCAAAAAA83tqdAAACLElEQVR42u3c0W7CQAxE0fz/T7evCGU91xui0vjy0kpAcpDw1jte9fj5B49DpEiRIr8AeRSP9+df37P6/f19Z68j9xU5G3n6pX252QpLXnuGI/cVKfKsYFY3XH7RT967gqX7ihRZvhh+kGqRpgUpUmQXQBqMasG/tbpFPgpZ/qFfNLOpgSAL/Ue6IJGPQ6aN2F0/P7pbFPkYJA6PQljQaZpvS9VEPgJZ3axqXFNIUC3mpKEWORfZbSxIAEVwqeEVORtJN/SkuMgGjoSsIkV2Fu0UVpHCaze9IkchSRNAF+0qvOo0KSJnI68MK9OwnSzey+uLFBkahFQUq0Igm7oy2Bc5DkkG56RoSLOSNmkiRZLFlwxB6cG61JAsQ1SRY5CpsaUFQ66X/jjE6YPIMcjOwaOdw3U7hSlyLpJcLAVO1aJOQ390mkXkOOSVRTt9iDQcQEN5kSOQKyC5GFnQU+NSPidyLJIGTN2Dmp0DoXj6IHIkkg4wu8OBTuAvcjay0yDQ8CoNl8jgSeRMZAd2JbQn6LIzFzkOSTdUO6FoCanCBZFjkSlw2jnA1LkWDlFFjkNWm/pOyF8NnVoFKnIkcjckrTb5aTOGnxM5EkkbjDRsrxqRnQ8kcjYyBaG7BUQDgWXRihyNJCE+fZ6GBAktUmQKSMmwnhQaHjyJFAkG6CSQTweV6OBe5GzkziCUbLCq68YCEzkWSYOkeADu6P+TGXRQROQo5Dc/RIoUKfIPH7+sDHfGtSzATgAAAABJRU5ErkJggg==" alt="QRCode">
    </li>
    

</ul>
</div>
        
    </div>
</div>
                </div>
                <div class="card-body">
                    
                        
                        
                            <div id="post-toc"><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="post-toc-number">1.</span> <span class="post-toc-text"> 参考链接</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#%E6%AD%A3%E6%96%87"><span class="post-toc-number">2.</span> <span class="post-toc-text"> 正文</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%B1%BB%E5%AE%9A%E4%B9%89"><span class="post-toc-number">2.1.</span> <span class="post-toc-text"> 类定义</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%8F%82%E6%95%B0"><span class="post-toc-number">2.2.</span> <span class="post-toc-text"> 参数</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%8F%98%E9%87%8F"><span class="post-toc-number">2.3.</span> <span class="post-toc-text"> 变量</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%BD%A2%E7%8A%B6"><span class="post-toc-number">2.4.</span> <span class="post-toc-text"> 形状</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="post-toc-number">2.5.</span> <span class="post-toc-text"> 示例</span></a></li></ol></li></ol></div>
                        
                    
                    <article id="post-content">
                        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
<h2 id="参考链接"><a class="markdownIt-Anchor" href="#参考链接"></a> 参考链接</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">EMBEDDING</a></li>
</ul>
<br>
<h2 id="正文"><a class="markdownIt-Anchor" href="#正文"></a> 正文</h2>
<h3 id="类定义"><a class="markdownIt-Anchor" href="#类定义"></a> 类定义</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.nn.Embedding(num_embeddings, embedding_dim, </span><br><span class="line">                         padding_idx=<span class="literal">None</span>, max_norm=<span class="literal">None</span>, norm_type=<span class="number">2.0</span>, scale_grad_by_freq=<span class="literal">False</span>, </span><br><span class="line">                         sparse=<span class="literal">False</span>, _weight=<span class="literal">None</span>, </span><br><span class="line">                         _freeze=<span class="literal">False</span>, device=<span class="literal">None</span>, </span><br><span class="line">                         dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>给一个编号，嵌入层就能返回这个编号对应的嵌入向量，嵌入向量反映了各个编号代表的符号之间的语义关系。</p>
<h3 id="参数"><a class="markdownIt-Anchor" href="#参数"></a> 参数</h3>
<ul>
<li><code>num_embeddings</code> (int): 嵌入字典的大小</li>
<li><code>embedding_dim</code> (int): 每个嵌入向量的大小</li>
<li><code>padding_idx</code> (int, 可选): 如果指定，padding_idx处的条目不会贡献梯度；因此，训练期间padding_idx处的嵌入向量不会更新。它保持为固定的“填充”。对于新构建的Embedding，padding_idx处的嵌入向量将默认为全零。</li>
<li><code>max_norm</code> (float, 可选): 如果给定，每个嵌入向量的范数大于max_norm时，将被重新标准化为范数max_norm。</li>
<li><code>norm_type</code> (float, 可选): 用于计算max_norm选项的p-范数的p。默认为2。</li>
<li><code>scale_grad_by_freq</code> (bool, 可选): 如果给定，这将按照小批量中单词的频率的倒数缩放梯度。默认为False。</li>
<li><code>sparse</code> (bool, 可选): 如果为True，权重矩阵的梯度将是一个稀疏张量。</li>
</ul>
<h3 id="变量"><a class="markdownIt-Anchor" href="#变量"></a> 变量</h3>
<ul>
<li><code>weight</code> (Tensor): 模块的可学习权重，形状为<code>(num_embeddings, embedding_dim)</code>，从<code>N(0,1)</code>初始化。</li>
</ul>
<h3 id="形状"><a class="markdownIt-Anchor" href="#形状"></a> 形状</h3>
<ul>
<li>输入: <code>(*)</code>, 包含要提取索引的任意形状的IntTensor或LongTensor</li>
<li>输出: <code>(*, H)</code>, 其中 * 是输入形状，<code>H = embedding_dim</code></li>
</ul>
<br>
<p>官方解释nn.embedding是什么：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A simple lookup table that stores embeddings of a fixed dictionary and size.</span><br><span class="line"></span><br><span class="line">This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.</span><br></pre></td></tr></table></figure>
<p>什么是simple lookup table？我没有训练过这个东西，到底哪来的word embedding？底下到底是word2vec、GloVe，还是什么pretrained的东西？</p>
<p><strong>答案其实很简单</strong>：都不是。实际上就是“随机”。我们再看一次这个文档，实际上，num_embeddings，第一个参数的意思就是，随便给定一个vocabulary size，比方说3，那么<code>nn.Embedding</code>就会帮你准备3个空位。第二个参数embedding_dim会直接帮你决定他帮你准备的随机的representation要有几个dimensions，你比如说5。</p>
<p>那么你可以想成实际上就是这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="number">0</span>: [<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>], <span class="comment"># 五个随机的floats来代表0这个token</span></span><br><span class="line"><span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>], <span class="comment"># 五个随机的floats来代表1这个token</span></span><br><span class="line"><span class="number">2</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>] <span class="comment"># 五个随机的floats来代表2这个token</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为什么是5个数字呢？因为你embedding_dim设成5，如果你设成384就会有384个随机数字对应到每一个id。</p>
<br>
<p>但是我想处理文字，又不是数字 - Tokenizer在干嘛？你可能接下来会感到困惑的点是…可是我想处理文字，又不是数字…所以…其实tokenizer就是在做这件事。假设你想要把&quot;你好吗&quot;这句话拿去配合什么东西训练，那么你就可能会有个tokenizer做这件事：{你: 0, 好:1, 吗:2}。你的文字input经过tokenizer之后就会变成一串数字，比方说&quot;你好好吗吗&quot;就会变成[0, 1, 1, 2, 2]，&quot;你吗吗好&quot;就会变成[0,2,2,1]。</p>
<p>然后经过<code>nn.Embedding</code>的时候他就把刚刚的随机数字塞进去。</p>
<p>所以&quot;你好好吗吗&quot;会被转成这样（就只是去查[0, 1, 1, 2, 2]）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="number">0</span>: [<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>],</span><br><span class="line"> <span class="number">1</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&quot;你吗吗好&quot;就会变成（就只是去查[0,2,2,1]）（我们这边先不管padding）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="number">0</span>: [<span class="number">.123123</span>,<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>],</span><br><span class="line">  <span class="number">2</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>],</span><br><span class="line">  <span class="number">2</span>: [<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>],</span><br><span class="line">  <span class="number">1</span>: [<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>更新参数：接下来你会有一个task可能是要训练model来分类什么东西，比方说听起来像不像脏话。那么，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>], </span><br><span class="line">[<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>], </span><br><span class="line">[<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>]]</span><br></pre></td></tr></table></figure>
<p>可能会对应到类别0（不像），</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">[<span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.123123</span>, <span class="number">.12312</span>, <span class="number">.123123</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>], </span><br><span class="line">[<span class="number">.789789</span>, <span class="number">.987987</span>, <span class="number">.98798</span>, <span class="number">.5789</span>, <span class="number">.7896</span>, <span class="number">.794</span>], </span><br><span class="line">[<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456456</span>,<span class="number">.456546</span>,<span class="number">.456456</span>,<span class="number">.42342</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>可能会对应到类比1（有点像）等等。</p>
<br>
<p><strong>Vocabulary Size的影响</strong>：你的第一个参数(num_embeddings)会影响到你有几个place holders可以用。刚刚我们设3，所以只有三个不同的tokens可以用。所以一旦传进去的index超过2(<strong>0,1,2三个参数</strong>)，就会出错（list out of range)。所以大部分的语言模型都会设一个很大的数字，像是80000，再搭配tokenizer。</p>
<br>
<h3 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 包含10个尺寸为3的张量的Embedding模块</span></span><br><span class="line">embedding = nn.Embedding(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 2个样本的批量，每个样本有4个索引</span></span><br><span class="line"><span class="built_in">input</span> = torch.LongTensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">9</span>]])<span class="comment">#torch.Size([2, 4])</span></span><br><span class="line">embedding(<span class="built_in">input</span>)<span class="comment">##torch.Size([2, 4,3])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 带padding_idx的示例</span></span><br><span class="line">embedding = nn.Embedding(<span class="number">10</span>, <span class="number">3</span>, padding_idx=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">input</span> = torch.LongTensor([[<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">5</span>]])<span class="comment">#torch.Size([1, 4])</span></span><br><span class="line">embedding(<span class="built_in">input</span>)<span class="comment">#torch.Size([1, 4],3)</span></span><br></pre></td></tr></table></figure>

                    </article>
                    


    <blockquote id="date-expire-notification" class="post-expired-notify">本文最后更新于 <span id="date-expire-num"></span> 天前，文中所描述的信息可能已发生改变</blockquote>
    <script>
    (function() {
        var dateUpdate = Date.parse("2024-01-19");
        var nowDate = new Date();
        var a = nowDate.getTime();
        var b = a - dateUpdate;
        var daysUpdateExpire = Math.floor(b/(24*3600*1000));
        if (daysUpdateExpire >= 120) {
            document.getElementById('date-expire-num').innerHTML = daysUpdateExpire;
        } else {
            document.getElementById('date-expire-notification').style.display = 'none';
        }
    })();
    </script>


<p class="post-footer-info mb-0 pt-0">本文发表于&nbsp;<time datetime="2024-01-19T13:31:33.000Z" itemprop="datePublished">2024-01-19</time>

</p>
<p class="post-footer-info mb-0 pt-2">

<span class="post-categories-list mt-2">

<a class="post-categories-list-item" href='/categories/Accumulate/'>Accumulate</a>

</span>



<span class="post-tags-list mt-2">

<a class="post-tags-list-item" href="/tags/Accumulate/" rel="tag">#&nbsp;Accumulate</a>

<a class="post-tags-list-item" href="/tags/pytorch/" rel="tag">#&nbsp;pytorch</a>

<a class="post-tags-list-item" href="/tags/embedding/" rel="tag">#&nbsp;embedding</a>

</span>


</p>

                </div>
                <div class="post-nav px-2 bg-gray">
<ul class="pagination">
    <!-- Prev Nav -->
    
        <li class="page-item page-prev">
            <a href="/2024/01/24/Mac%E4%B8%8B%E7%9A%84Terminal%E4%B8%8D%E6%AD%A3%E5%B8%B8%E6%98%BE%E7%A4%BA%E6%9C%BA%E5%99%A8%E7%9A%84%E5%90%8D%E5%AD%97/" rel="prev">
                <div class="page-item-title"><i class="icon icon-back" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">Mac下的Terminal不正常显示机器的名字</div>
            </a>
        </li>
    

    <!-- Next Nav -->
    
        <li class="page-item page-next">
            <a href="/2024/01/13/PyTorch-torch-cat/" rel="next">
                <div class="page-item-title"><i class="icon icon-forward" aria-hidden="true"></i></div>
                <div class="page-item-subtitle">PyTorch:torch.cat()和torch.stack()</div>
            </a>
        </li>
    
</ul>
</div>

                
                    <!-- # Comment # -->
                    
                        <div class="card-footer post-comment">
                            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
        this.page.url = 'https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://abinzzz.github.io/2024/01/19/PyTorch-torch-nn-Embedding/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>
<script id="disqus-thread-script">
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//robin02.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

                        </div>
                    
                
            </div>
        </div>
    </div>
</div>

            <!-- ### Footer ### -->
            <footer class="text-center">
    <!-- footer copyright -->
    
        <p class="footer-copyright mb-0">Copyright&nbsp;©&nbsp;<span id="copyright-year"></span>
            <a class="footer-copyright-a" href="https://abinzzz.github.io">blog</a>
        </p>

    <!-- footer custom text -->
    <p class="footer-text mb-0">
    
    </p>
    <!-- footer develop info -->
    <p class="footer-develop mb-0">
        
    <!-- Busuanzi User Views -->
    <span id="busuanzi_container_site_uv" hidden>
        <span></span>
        <span id="busuanzi_value_site_uv"></span>
        <span>Viewers</span>
        
            <span>|</span>
        
    </span>




        
        Powered by&nbsp;<!--
         --><a href="https://hexo.io" target="_blank" class="footer-develop-a" rel="external nofollow noopener noreferrer">Hexo</a><span class="footer-develop-divider"></span>Theme&nbsp;-&nbsp;<!--
         --><a href="https://github.com/SukkaW/hexo-theme-suka" target="_blank" class="footer-develop-a" rel="external noopener">Suka</a>
    </p>
</footer>


        <!-- ### Import File ### -->
        <!-- ### Footer JS Import ### -->

<script>

    
window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 50
};

(function() {
    var copyrightNow = new Date().getFullYear();
    var copyrightContent = document.getElementById('copyright-year');
    var copyrightSince = 2023;
    if (copyrightSince === copyrightNow) {
        copyrightContent.textContent = copyrightNow;
    } else {
        copyrightContent.textContent = copyrightSince + ' - ' + copyrightNow;
    }
})();
console.log('\n %c Suka Theme (hexo-theme-suka) | © SukkaW | Verision 1.3.3 %c https://github.com/SukkaW/hexo-theme-suka \n', 'color: #fff; background: #444; padding:5px 0;', 'background: #bbb; padding:5px 0;');

(function() {
    'use strict';
    
    // 等待 DOM 加载完成
    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', initTocCollapse);
    } else {
        initTocCollapse();
    }
    
    function initTocCollapse() {
        const tocContainer = document.getElementById('post-toc');
        if (!tocContainer) {
            return;
        }
        
        // 找到所有有子目录的 level-1 和 level-2 项
        const tocItems = tocContainer.querySelectorAll('.post-toc-item.post-toc-level-1, .post-toc-item.post-toc-level-2');
        
        tocItems.forEach(function(item) {
            // 检查是否有子目录（包含 post-toc-child 的 ol）
            const hasChildren = item.querySelector('ol.post-toc-child') !== null;
            
            if (hasChildren) {
                // 添加标记类，用于 CSS 显示图标
                item.classList.add('toc-has-children');
                
                const link = item.querySelector('.post-toc-link');
                if (link) {
                    // 阻止默认的锚点跳转，改为展开/折叠
                    link.addEventListener('click', function(e) {
                        // 如果用户按住 Ctrl/Cmd 或中键点击，则跳转
                        if (e.ctrlKey || e.metaKey || e.button === 1) {
                            return; // 允许默认行为（跳转）
                        }
                        
                        e.preventDefault();
                        e.stopPropagation();
                        
                        // 切换展开/折叠状态
                        item.classList.toggle('toc-expanded');
                    });
                    
                    // 允许通过双击链接文本跳转
                    link.addEventListener('dblclick', function(e) {
                        const href = link.getAttribute('href');
                        if (href) {
                            window.location.hash = href;
                        }
                    });
                    
                    // 允许通过右键菜单跳转
                    link.addEventListener('contextmenu', function(e) {
                        // 允许默认的右键菜单
                        return true;
                    });
                }
            }
        });
    }
})();
        

</script>

<script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@8.9.0" async></script>
    <script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@2.3/bsz.pure.mini.js" async></script>


<!-- Offset -->




<!-- Comment -->

    
        <script id="dsq-count-scr" src="https://robin02.disqus.com/count.js" async></script>

    


<!-- ### Custom Footer ### -->

    </body>

</html>