
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <!--pjax：防止跳转页面音乐暂停-->
    <script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script> 
    <meta charset="utf-8">
    

    

    
    <title>
        FL科研相关资源 |
        
        blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="FL相关论文库  链接   Categories 分类：  Artificial Intelligence 人工智能 (IJCAI, AAAI, AISTATS, ALT, AI) 联邦学习论文被以下顶级人工智能会议和期刊接受，包括：  IJCAI (International Joint Conference on Artificial Intelligence) AAAI (AAAI Con">
<meta property="og:type" content="article">
<meta property="og:title" content="FL科研相关资源">
<meta property="og:url" content="https://abinzzz.github.io/2024/07/05/FL%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="FL相关论文库  链接   Categories 分类：  Artificial Intelligence 人工智能 (IJCAI, AAAI, AISTATS, ALT, AI) 联邦学习论文被以下顶级人工智能会议和期刊接受，包括：  IJCAI (International Joint Conference on Artificial Intelligence) AAAI (AAAI Con">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img.shields.io/github/stars/liziniu/ReMax.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/yangjianxin1/LongQLoRA.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/ist-daslab/sparsefinetuning.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/prateeky2806/compeft.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/ytgui/SPT-proto.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/nikhil-ghosh-berkeley/loraplus.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/WooSunghyeon/dropbp.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/badge/Conference-SemEval">
<meta property="og:image" content="https://img.shields.io/github/stars/ngregoriade/Semeval2024-Shroom.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/github/stars/Ledzy/BAdam.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/badge/Conference-ICML">
<meta property="og:image" content="https://img.shields.io/github/stars/JingXuTHU/Random-Masking-Finds-Winning-Tickets-for-Parameter-Efficient-Fine-tuning.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/badge/Conference-ACL">
<meta property="og:image" content="https://img.shields.io/github/stars/gccnlp/Light-PEFT.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/badge/Conference-ICLR">
<meta property="og:image" content="https://img.shields.io/github/stars/LINs-lab/CapaBoost.svg?style=social&amp;label=Star">
<meta property="og:image" content="https://img.shields.io/badge/Conference-ACL">
<meta property="article:published_time" content="2024-07-05T08:07:48.000Z">
<meta property="article:modified_time" content="2024-07-16T12:45:26.690Z">
<meta property="article:author" content="ab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img.shields.io/github/stars/liziniu/ReMax.svg?style=social&amp;label=Star">
    
        <link rel="alternate" href="/atom.xml" title="blog" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
        
<link rel="stylesheet" href="https://unpkg.com/katex@0.16.7/dist/katex.min.css">

    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
    
        <img data-src="https://pbs.twimg.com/media/GO1SQD0W0AAmWnk?format=jpg&amp;name=medium" data-sizes="auto" alt="FL科研相关资源" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>FL科研相关资源</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-FL科研相关资源" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2024/07/05/FL%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/" class="article-date-link">
        <time datetime="2024-07-05T08:07:48.000Z"
              itemprop="datePublished">2024-07-05</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/paper/">paper</a><a class="article-category-link" href="/categories/paper/FL/">FL</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <h2 id="fl相关论文库"><a class="markdownIt-Anchor" href="#fl相关论文库"></a> FL相关论文库</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/youngfish42/Awesome-FL?tab=readme-ov-file">链接</a></li>
</ul>
<h2 id="categories-分类"><a class="markdownIt-Anchor" href="#categories-分类"></a> Categories 分类：</h2>
<h3 id="artificial-intelligence-人工智能-ijcai-aaai-aistats-alt-ai"><a class="markdownIt-Anchor" href="#artificial-intelligence-人工智能-ijcai-aaai-aistats-alt-ai"></a> Artificial Intelligence 人工智能 (IJCAI, AAAI, AISTATS, ALT, AI)</h3>
<p>联邦学习论文被以下顶级人工智能会议和期刊接受，包括：</p>
<ul>
<li>IJCAI (International Joint Conference on Artificial Intelligence)</li>
<li>AAAI (AAAI Conference on Artificial Intelligence)</li>
<li>AISTATS (Artificial Intelligence and Statistics)</li>
<li>ALT (International Conference on Algorithmic Learning Theory)</li>
<li>AI (Artificial Intelligence)</li>
</ul>
<h3 id="machine-learning-机器学习-neurips-icml-iclr-colt-uai-machine-learning-jmlr-tpami"><a class="markdownIt-Anchor" href="#machine-learning-机器学习-neurips-icml-iclr-colt-uai-machine-learning-jmlr-tpami"></a> Machine Learning 机器学习 (NeurIPS, ICML, ICLR, COLT, UAI, Machine Learning, JMLR, TPAMI)</h3>
<p>联邦学习论文被以下顶级机器学习会议和期刊接受，包括：</p>
<ul>
<li>NeurIPS (Annual Conference on Neural Information Processing Systems)</li>
<li>ICML (International Conference on Machine Learning)</li>
<li>ICLR (International Conference on Learning Representations)</li>
<li>COLT (Annual Conference on Computational Learning Theory)</li>
<li>UAI (Conference on Uncertainty in Artificial Intelligence)</li>
<li>Machine Learning</li>
<li>JMLR (Journal of Machine Learning Research)</li>
<li>TPAMI (IEEE Transactions on Pattern Analysis and Machine Intelligence)</li>
</ul>
<h3 id="data-mining-数据挖掘-kdd-wsdm"><a class="markdownIt-Anchor" href="#data-mining-数据挖掘-kdd-wsdm"></a> Data Mining 数据挖掘 (KDD, WSDM)</h3>
<p>联邦学习论文被以下顶级数据挖掘会议和期刊接受，包括：</p>
<ul>
<li>KDD (ACM SIGKDD Conference on Knowledge Discovery and Data Mining)</li>
<li>WSDM (Web Search and Data Mining)</li>
</ul>
<h3 id="secure-安全-sp-ccs-usenix-security-ndss"><a class="markdownIt-Anchor" href="#secure-安全-sp-ccs-usenix-security-ndss"></a> Secure 安全 (S&amp;P, CCS, USENIX Security, NDSS)</h3>
<p>联邦学习论文被以下顶级安全会议和期刊接受，包括：</p>
<ul>
<li>S&amp;P (IEEE Symposium on Security and Privacy)</li>
<li>CCS (Conference on Computer and Communications Security)</li>
<li>USENIX Security (Usenix Security Symposium)</li>
<li>NDSS (Network and Distributed System Security Symposium)</li>
</ul>
<h3 id="computer-vision-计算机视觉-iccv-cvpr-eccv-mm-ijcv"><a class="markdownIt-Anchor" href="#computer-vision-计算机视觉-iccv-cvpr-eccv-mm-ijcv"></a> Computer Vision 计算机视觉 (ICCV, CVPR, ECCV, MM, IJCV)</h3>
<p>联邦学习论文被以下顶级计算机视觉会议和期刊接受，包括：</p>
<ul>
<li>CVPR (Computer Vision and Pattern Recognition)</li>
<li>ICCV (IEEE International Conference on Computer Vision)</li>
<li>ECCV (European Conference on Computer Vision)</li>
<li>MM (ACM International Conference on Multimedia)</li>
<li>IJCV (International Journal of Computer Vision)</li>
</ul>
<h3 id="natural-language-processing-自然语言处理-acl-emnlp-naacl-coling"><a class="markdownIt-Anchor" href="#natural-language-processing-自然语言处理-acl-emnlp-naacl-coling"></a> Natural Language Processing 自然语言处理 (ACL, EMNLP, NAACL, COLING)</h3>
<p>联邦学习论文被以下顶级自然语言处理会议和期刊接受，包括：</p>
<ul>
<li>ACL (Annual Meeting of the Association for Computational Linguistics)</li>
<li>NAACL (North American Chapter of the Association for Computational Linguistics)</li>
<li>EMNLP (Conference on Empirical Methods in Natural Language Processing)</li>
<li>COLING (International Conference on Computational Linguistics)</li>
</ul>
<h3 id="information-retrieval-信息检索-sigir"><a class="markdownIt-Anchor" href="#information-retrieval-信息检索-sigir"></a> Information Retrieval 信息检索 (SIGIR)</h3>
<p>联邦学习论文被以下顶级信息检索会议和期刊接受，包括：</p>
<ul>
<li>SIGIR (Annual International ACM SIGIR Conference on Research and Development in Information Retrieval)</li>
</ul>
<h3 id="database-数据库-sigmod-icde-vldb"><a class="markdownIt-Anchor" href="#database-数据库-sigmod-icde-vldb"></a> Database 数据库 (SIGMOD, ICDE, VLDB)</h3>
<p>联邦学习论文被以下顶级数据库会议和期刊接受，包括：</p>
<ul>
<li>SIGMOD (ACM SIGMOD Conference)</li>
<li>ICDE (IEEE International Conference on Data Engineering)</li>
<li>VLDB (Very Large Data Bases Conference)</li>
</ul>
<h3 id="network-网络-sigcomm-infocom-mobicom-nsdi-www"><a class="markdownIt-Anchor" href="#network-网络-sigcomm-infocom-mobicom-nsdi-www"></a> Network 网络 (SIGCOMM, INFOCOM, MOBICOM, NSDI, WWW)</h3>
<p>联邦学习论文被以下顶级网络会议和期刊接受，包括：</p>
<ul>
<li>SIGCOMM (Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication)</li>
<li>INFOCOM (IEEE Conference on Computer Communications)</li>
<li>MobiCom (ACM/IEEE International Conference on Mobile Computing and Networking)</li>
<li>NSDI (Symposium on Networked Systems Design and Implementation)</li>
<li>WWW (The Web Conference)</li>
</ul>
<h3 id="system-系统-osdi-sosp-isca-mlsys-eurosys-tpds-dac-tocs-tos-tcad-tc"><a class="markdownIt-Anchor" href="#system-系统-osdi-sosp-isca-mlsys-eurosys-tpds-dac-tocs-tos-tcad-tc"></a> System 系统 (OSDI, SOSP, ISCA, MLSys, EuroSys, TPDS, DAC, TOCS, TOS, TCAD, TC)</h3>
<p>联邦学习论文被以下顶级系统会议和期刊接受，包括：</p>
<ul>
<li>OSDI (USENIX Symposium on Operating Systems Design and Implementation)</li>
<li>SOSP (Symposium on Operating Systems Principles)</li>
<li>ISCA (International Symposium on Computer Architecture)</li>
<li>MLSys (Conference on Machine Learning and Systems)</li>
<li>EuroSys (European Conference on Computer Systems)</li>
<li>TPDS (IEEE Transactions on Parallel and Distributed Systems)</li>
<li>DAC (Design Automation Conference)</li>
<li>TOCS (ACM Transactions on Computer Systems)</li>
<li>TOS (ACM Transactions on Storage)</li>
<li>TCAD (IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems)</li>
<li>TC (IEEE Transactions on Computers)</li>
</ul>
<h3 id="others-其他-icse-focs-stoc"><a class="markdownIt-Anchor" href="#others-其他-icse-focs-stoc"></a> Others 其他 (ICSE, FOCS, STOC)</h3>
<p>联邦学习论文被以下其他领域的顶级会议和期刊接受，包括：</p>
<ul>
<li>ICSE (International Conference on Software Engineering)</li>
<li>FOCS (IEEE Annual Symposium on Foundations of Computer Science)</li>
<li>STOC (Symposium on the Theory of Computing)</li>
</ul>
<h2 id="system"><a class="markdownIt-Anchor" href="#system"></a> System</h2>
<table>
<thead>
<tr>
<th>Title</th>
<th>Affiliation</th>
<th>Venue</th>
<th>Year</th>
<th>Materials</th>
</tr>
</thead>
<tbody>
<tr>
<td>DeTA: Minimizing Data Leaks in Federated Learning via Decentralized and Trustworthy Aggregation</td>
<td>IBM Research</td>
<td>EuroSys</td>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3627703.3650082">PUB</a></td>
</tr>
<tr>
<td>FLOAT: Federated Learning Optimizations with Automated Tuning</td>
<td>Virginia Tech</td>
<td>EuroSys</td>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3627703.3650081">PUB</a> <a target="_blank" rel="noopener" href="https://github.com/AFKD98/FLOAT/">CODE</a></td>
</tr>
<tr>
<td>Totoro: A Scalable Federated Learning Engine for the Edge</td>
<td>UCSC</td>
<td>EuroSys</td>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3627703.3629575">PUB</a></td>
</tr>
<tr>
<td>Dordis: Efficient Federated Learning with Dropout-Resilient Differential Privacy</td>
<td>HKUST</td>
<td>EuroSys</td>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2209.12528">PUB</a> <a target="_blank" rel="noopener" href="https://github.com/samuelgong/dordis">CODE</a></td>
</tr>
<tr>
<td>FLIGAN: Enhancing Federated Learning with Incomplete Data using GAN</td>
<td></td>
<td>EuroSys workshop</td>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3642968.3654813">PUB</a></td>
</tr>
<tr>
<td>ALS Algorithm for Robust and Communication-Efficient Federated Learning</td>
<td></td>
<td>EuroSys workshop</td>
<td>2024</td>
<td>[x]</td>
</tr>
<tr>
<td>FedRDMA: Communication-Efficient Cross-Silo Federated LLM via Chunked RDMA Transmission</td>
<td></td>
<td>EuroSys workshop</td>
<td>2024</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.00881">PUB</a></td>
</tr>
<tr>
<td>REFL: Resource-Efficient Federated Learning</td>
<td>QMUL</td>
<td>EuroSys</td>
<td>2023</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.01108">PUB</a> <a target="_blank" rel="noopener" href="https://github.com/ahmedcs/refl">CODE</a></td>
</tr>
<tr>
<td>A First Look at the Impact of Distillation Hyper-Parameters in Federated Knowledge Distillation</td>
<td></td>
<td>EuroSys workshop</td>
<td>2023</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3578356.3592590">PUB</a></td>
</tr>
<tr>
<td>Towards Practical Few-shot Federated NLP</td>
<td></td>
<td>EuroSys workshop</td>
<td>2023</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2212.00192">PUB</a></td>
</tr>
<tr>
<td>Can Fair Federated Learning Reduce the need for Personalisation?</td>
<td></td>
<td>EuroSys workshop</td>
<td>2023</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3578356.3592592">PUB</a></td>
</tr>
<tr>
<td>Gradient-less Federated Gradient Boosting Tree with Learnable Learning Rates</td>
<td></td>
<td>EuroSys workshop</td>
<td>2023</td>
<td><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3578356.3592579">PUB</a></td>
</tr>
<tr>
<td>Towards Robust and Bias-free Federated Learning</td>
<td></td>
<td>EuroSys workshop</td>
<td>2023</td>
<td>[x]</td>
</tr>
</tbody>
</table>
<h2 id="tuning"><a class="markdownIt-Anchor" href="#tuning"></a> Tuning</h2>
<table>
<thead>
<tr>
<th>Title of the Paper</th>
<th>Authors</th>
<th>Link</th>
<th>Skimming/In-depth Reading</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.07705">CPET: Effective Parameter-Efficient Tuning for Compressed Large Language Models</a></td>
<td>Weilin Zhao, Yuxiang Huang, Xu Han, Zhiyuan Liu, Zhengyan Zhang, <strong>Maosong Sun</strong></td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.07705">[Arxiv]</a></td>
<td>S</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/liziniu/ReMax"><img src="https://img.shields.io/github/stars/liziniu/ReMax.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.10505">ReMax: A Simple, Effective, and Efficient Method for Aligning Large Language Models</a></td>
<td>Ziniu Li, Tian Xu, Yushun Zhang, Yang Yu, Ruoyu Sun, Zhi-Quan Luo</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.10505">[ICML 2024]</a> <a target="_blank" rel="noopener" href="https://github.com/liziniu/ReMax">[Github]</a></td>
<td>S</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.10046">TRANSOM: An Efficient Fault-Tolerant System for Training LLMs</a></td>
<td>Baodong Wu, Lei Xia, Qingping Li, Kangyu Li, Xu Chen, Yongqiang Guo, Tieyao Xiang, Yuheng Chen, Shigang Li</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.10046">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.16776">DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection</a></td>
<td>Devleena Das, Vivek Khetan</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.16776">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/yangjianxin1/LongQLoRA"><img src="https://img.shields.io/github/stars/yangjianxin1/LongQLoRA.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.04879">LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models</a></td>
<td>Jianxin Yang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.04879">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/yangjianxin1/LongQLoRA">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/ist-daslab/sparsefinetuning"><img src="https://img.shields.io/github/stars/ist-daslab/sparsefinetuning.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.06927v2">Sparse Fine-tuning for Inference Acceleration of Large Language Models</a></td>
<td>Eldar Kurtic, Denis Kuznedelev, Elias Frantar, Michael Goin, Dan Alistarh</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.06927v2">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/ist-daslab/sparsefinetuning">[Github]</a> <a target="_blank" rel="noopener" href="https://github.com/neuralmagic/deepsparse/tree/main/research/mpt">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/prateeky2806/compeft"><img src="https://img.shields.io/github/stars/prateeky2806/compeft.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.13171">ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization</a></td>
<td>Prateek Yadav, Leshem Choshen, Colin Raffel, Mohit Bansal</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.13171">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/prateeky2806/compeft">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.13126">Towards Better Parameter-Efficient Fine-Tuning for Large Language Models: A Position Paper</a></td>
<td>Chengyu Wang, Junbing Yan, Wei Zhang, Jun Huang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.13126">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/ytgui/SPT-proto"><img src="https://img.shields.io/github/stars/ytgui/SPT-proto.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.10365">SPT: Fine-Tuning Transformer-based Language Models Efficiently with Sparsification</a></td>
<td>Yuntao Gui, Xiao Yan, Peiqi Yin, Han Yang, James Cheng</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.10365">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/ytgui/SPT-proto">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/nikhil-ghosh-berkeley/loraplus"><img src="https://img.shields.io/github/stars/nikhil-ghosh-berkeley/loraplus.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.12354">LoRA+: Efficient Low Rank Adaptation of Large Models</a></td>
<td>Soufiane Hayou, Nikhil Ghosh, Bin Yu</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.12354">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/nikhil-ghosh-berkeley/loraplus">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.15751">Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning</a></td>
<td>Yong Liu, Zirui Zhu, Chaoyu Gong, Minhao Cheng, Cho-Jui Hsieh, Yang You</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.15751">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/WooSunghyeon/dropbp"><img src="https://img.shields.io/github/stars/WooSunghyeon/dropbp.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.17812">DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping Backward Propagation</a></td>
<td>Sunghyeon Woo, Baeseong Park, Byeongwook Kim, Minjung Jo, Sejung Kwon, Dongsuk Jeon, Dongsoo Lee</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.17812">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/WooSunghyeon/dropbp">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.08822">LoRA-SP: Streamlined Partial Parameter Adaptation for Resource-Efficient Fine-Tuning of Large Language Models</a></td>
<td>Yichao Wu, Yafei Xiang, Shuning Huo, Yulu Gong, Penghao Liang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.08822">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.14608">Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</a></td>
<td>Zeyu Han, Chao Gao, Jinyang Liu, Jeff (Jun) Zhang, Sai Qian Zhang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.14608">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a href=""><img src="https://img.shields.io/badge/Conference-SemEval'24-blue" alt="Publish" /></a> <a target="_blank" rel="noopener" href="https://github.com/ngregoriade/Semeval2024-Shroom"><img src="https://img.shields.io/github/stars/ngregoriade/Semeval2024-Shroom.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.01210.pdf">AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for hallucination detection and analysis</a></td>
<td>Natalia Griogoriadou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.01210.pdf">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/ngregoriade/Semeval2024-Shroom">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/Ledzy/BAdam"><img src="https://img.shields.io/github/stars/Ledzy/BAdam.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.02827">BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models</a></td>
<td>Qijun Luo, Hengxu Yu, Xiao Li</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.02827">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/Ledzy/BAdam">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.08985">Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning</a></td>
<td>Yijiang Liu, Rongyu Zhang, Huanrui Yang, Kurt Keutzer, Yuan Du, Li Du, Shanghang Zhang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.08985">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a href=""><img src="https://img.shields.io/badge/Conference-ICML'24-blue" alt="Publish" /></a> <a target="_blank" rel="noopener" href="https://github.com/JingXuTHU/Random-Masking-Finds-Winning-Tickets-for-Parameter-Efficient-Fine-tuning"><img src="https://img.shields.io/github/stars/JingXuTHU/Random-Masking-Finds-Winning-Tickets-for-Parameter-Efficient-Fine-tuning.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.02596">Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning</a></td>
<td>Jing Xu, Jingzhao Zhang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.02596">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/JingXuTHU/Random-Masking-Finds-Winning-Tickets-for-Parameter-Efficient-Fine-tuning">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.02913">Zeroth-Order Fine-Tuning of LLMs with Extreme Sparsity</a></td>
<td>Wentao Guo, Jikai Long, Yimeng Zeng, Zirui Liu, Xinyu Yang, Yide Ran, Jacob R. Gardner, Osbert Bastani, Christopher De Sa, Xiaodong Yu, Beidi Chen, Zhaozhuo Xu</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.02913">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a href=""><img src="https://img.shields.io/badge/Conference-ACL'24%20Findings-blue" alt="Publish" /></a> <a target="_blank" rel="noopener" href="https://github.com/gccnlp/Light-PEFT"><img src="https://img.shields.io/github/stars/gccnlp/Light-PEFT.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.03792">Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning</a></td>
<td>Naibin Gu, Peng Fu, Xiyu Liu, Bowen Shen, Zheng Lin, Weiping Wang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.03792">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/gccnlp/Light-PEFT">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.17296">BlockLLM: Memory-Efficient Adaptation of LLMs by Selecting and Optimizing the Right Coordinate Blocks</a></td>
<td>Amrutha Varshini Ramesh, Vignesh Ganapathiraman, Issam H. Laradji, Mark Schmidt</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.17296">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.00066">Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead</a></td>
<td>Rickard Brüel-Gabrielsson, Jiacheng Zhu, Onkar Bhardwaj, Leshem Choshen, Kristjan Greenewald, Mikhail Yurochkin, Justin Solomon</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.00066">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a href=""><img src="https://img.shields.io/badge/Conference-ICLR'24-blue" alt="Publish" /></a> <a target="_blank" rel="noopener" href="https://github.com/LINs-lab/CapaBoost"><img src="https://img.shields.io/github/stars/LINs-lab/CapaBoost.svg?style=social&amp;label=Star" alt="Star" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01320">Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning</a></td>
<td>Haobo Song, Hao Zhao, Soumajit Majumder, Tao Lin</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01320">[Paper]</a> <a target="_blank" rel="noopener" href="https://github.com/LINs-lab/CapaBoost">[Github]</a></td>
<td></td>
</tr>
<tr>
<td><a href=""><img src="https://img.shields.io/badge/Conference-ACL'24%20PrivateNLP-blue" alt="Publish" /></a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01031">PocketLLM: Enabling On-Device Fine-Tuning for Personalized LLMs</a></td>
<td>Dan Peng, Zhihui Fu, Jun Wang</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01031">[Paper]</a></td>
<td></td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.05040">Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning</a></td>
<td>Yun-Da Tsai, Mingjie Liu, Haoxing Ren</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.05040">[Paper]</a></td>
<td></td>
</tr>
</tbody>
</table>
<p>CPET: Effective Parameter-Efficient Tuning for Compressed Large Language Models</p>
<ul>
<li><strong>机构</strong>: 清华大学 NLP Group, DCST, IAI, BNRIST</li>
<li><strong>问题</strong>：以前的模型在进行模型压缩时可能会导致知识丢失和性能下降，尤其是在大型语言模型（LLMs）上，这种压缩可能会影响模型在下游任务上的表现。</li>
<li><strong>优势</strong>：CPET模型的优势在于它结合了参数高效调整（PET）和模型压缩技术，通过知识继承和恢复策略来弥补压缩过程中可能导致的性能下降。</li>
<li>解决方案的<strong>关键</strong>在于引入了两种机制：(1) <strong>PET知识继承，使用在非压缩LLM上训练的PET模块作为初始化来学习压缩LLM上的PET模块</strong>；(2) 模型知识恢复，通过在压缩LLM中添加额外的知识恢复模块来弥补压缩过程中丢失的知识。</li>
</ul>
<p>ReMax: A Simple, Effective, and Efficient Method for Aligning Large Language Models</p>
<ul>
<li><strong>机构</strong>:
<ul>
<li>香港中文大学（深圳）数据科学学院</li>
<li>深圳大数据研究所</li>
<li>南京大学国家新型软件技术重点实验室</li>
<li><a target="_blank" rel="noopener" href="http://Polixir.ai">Polixir.ai</a></li>
<li>黄埔帕洲实验室（中国深圳国际工业与应用数学中心）</li>
</ul>
</li>
<li><strong>问题</strong>：以前的模型，特别是PPO，对于LLMs来说过于复杂，需要大量的计算资源和内存，且超参数调整繁琐，导致在有限的计算资源下难以应用。</li>
<li><strong>优势</strong>：ReMax模型之所以好，是因为它简化了实现，减少了超参数，降低了GPU内存使用，并缩短了训练时间。它利用了RLHF的三个特性：快速模拟、确定性转换和轨迹级奖励，这些在PPO中未被充分利用。</li>
<li><strong>关键</strong>：ReMax算法的关键是在REINFORCE算法的基础上引入了一种新的方差减少技术，并且去除了PPO算法中的价值模型部分，从而简化了算法，减少了内存消耗和训练时间。</li>
</ul>
<p>TRANSOM: An Efficient Fault-Tolerant System for Training LLMs</p>
<ul>
<li><strong>机构</strong>:
<ul>
<li>SenseTime，Huazhong University of Science and Technology</li>
<li>Beijing University of Posts and Telecommunications</li>
</ul>
</li>
<li><strong>问题</strong>：以前的模型在训练过程中容易受到硬件和软件故障的影响，导致训练任务中断，需要耗费大量时间和资源进行任务重启和恢复。此外，传统的方法在检查点保存和加载时效率较低，增加了整体训练时间</li>
<li><strong>优势</strong>：<br />
TRANSOM通过设计三个关键子系统（TOL、TEE、TCE），实现了高效的容错和恢复机制。这些机制显著提升了大规模LLMs训练的效率，减少了训练中断的时间和资源消耗。例如，GPT3-175B的预训练时间减少了28%，任务重启时间从数小时减少到12分钟，检查点保存和加载时间从平均200秒减少到不到10秒 。</li>
<li>论文中的解决方案之关键是设计了三个<strong>关键</strong>子系统：</li>
<li>
<ol>
<li>自动容错和恢复机制的训练管道（TOL）</li>
</ol>
</li>
<li>
<ol start="2">
<li>多维度度量自动异常检测系统（TEE）</li>
</ol>
</li>
<li>
<ol start="3">
<li>训练检查点异步访问自动容错和恢复技术（TCE）</li>
</ol>
</li>
</ul>
<p>DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection</p>
<ul>
<li><strong>机构</strong>:</li>
<li>Georgia Institute of Technology</li>
<li>Accenture Labs</li>
<li><strong>问题</strong>：以前的模型在微调过程中需要大量高质量数据，增加了数据获取和处理的成本。传统微调方法虽然能达到较好的性能，但在实际应用中往往面临数据不足的问题</li>
<li><strong>优势</strong>：DEFT-UCS通过无监督核心集选择方法，实现了在减少数据量的情况下高效微调预训练语言模型。实验结果表明，DEFT-UCS在多个文本编辑任务中，使用70%的训练数据可以达到与使用全部数据的传统方法相当的性能。</li>
<li><strong>关键</strong>：无监督核心集选择（UCS）方法。UCS通过K-Means聚类选择代表性数据子集，从而减少微调所需的数据量</li>
</ul>
<p>LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models</p>
<ul>
<li><strong>机构</strong>: Sun Yat-sen University</li>
<li><strong>问题</strong>：论文试图解决大型语言模型（如LLaMA2）在有限的训练资源下，如何有效地扩展其上下文长度的问题。当前许多模型在处理超出预定义上下文长度的输入时，性能显著下降，导致在处理长文本任务（如多文档问答、书籍总结等）时表现不佳。</li>
<li><strong>优势</strong>：它在单个32GB V100 GPU上高效地扩展了大型语言模型（LLaMA2）的上下文长度，同时保持了良好的性能。这一方法结合了位置插值（Position Interpolation）、QLoRA和Shift Short Attention的优点，实现了计算资源的节约和性能的提升。</li>
<li><strong>关键</strong>：结合了位置插值（Position Interpolation）、QLoRA和Shift Short Attention。位置插值用于扩展上下文长度，QLoRA通过量化预训练模型权重和添加可学习的低秩适配器来节省GPU内存，而Shift Short Attention通过分组计算注意力来进一步节省计算资源。</li>
</ul>
<p>Sparse Fine-tuning for Inference Acceleration of Large Language Models</p>
<ul>
<li><strong>机构</strong>：IST Austria</li>
<li><strong>问题</strong>：以前的模型在高稀疏度下微调时，容易出现训练不稳定的问题，导致准确性下降。此外，现有的量化方法在进一步压缩时（如到3比特）会导致准确性难以恢复，限制了推理速度的提升。</li>
<li><strong>优势</strong>：因为它能够在高效运行的同时保持高准确性。本文提出的SquareHead蒸馏方法能够在高稀疏度下进行微调，既能加速推理速度，又能保持模型的准确性，这使得模型在实践中更有用。</li>
<li><strong>关键</strong>：论文中解决方案的关键在于提出了一种基于L2的蒸馏方法SquareHead，通过这种方法在高稀疏度下进行微调时，能够有效地恢复模型的准确性。同时，展示了利用稀疏性实现推理加速的方法。</li>
</ul>
<p>ComPEFT: Compression for Communicating Parameter Efficient Updates via Sparsification and Quantization</p>
<ul>
<li><strong>研究机构</strong>:</li>
</ul>
<ol>
<li>University of North Carolina at Chapel Hill</li>
<li>IBM Research</li>
<li>Massachusetts Institute of Technology</li>
<li>University of Toronto</li>
<li>Vector Institute</li>
</ol>
<ul>
<li><strong>问题</strong>：以前的PEFT模型虽然在参数高效微调上表现良好，但在高延迟网络环境中传输较大模型时存在明显的通信成本问题。此外，传统压缩方法在不进行额外训练的情况下，通常会导致模型性能的显著下降。</li>
<li><strong>优势</strong>：ComPEFT模型好是因为它通过稀疏化和三值量化显著减少了PEFT模型的大小，同时在多个任务和模型上的性能都保持或有所提升。压缩后的模型在高延迟网络中的传输更为高效，且在少样本组合泛化能力上表现出色。</li>
<li><strong>关键</strong>：关键点在于稀疏化和三值量化相结合，使得任务向量在大幅度压缩的同时仍能保持高性能。特别是选择合适的标量常数（α）用于量化，有助于恢复或提高模型性能。</li>
</ul>
<p>SPT: Fine-Tuning Transformer-based Language Models Efficiently with Sparsification</p>
<ul>
<li><strong>机构</strong>:
<ul>
<li>The Chinese University of Hong Kong, Hong Kong SAR, China</li>
<li>Southern University of Science and Technology, China</li>
</ul>
</li>
<li><strong>问题</strong>：
<ul>
<li><strong>高内存消耗</strong>：存储多头注意力机制的权重需要大量内存。</li>
<li><strong>计算成本高</strong>：前馈网络的计算成本高，导致运行时间长。</li>
<li><strong>微调效率低</strong>：直接微调大型预训练模型需要更新大量参数，效率较低。</li>
</ul>
</li>
<li><strong>优势</strong>：SPT通过引入稀疏化技术，在不显著降低模型质量的情况下，减少了内存消耗和计算成本，显著提升了微调Transformer模型的效率</li>
<li><strong>关键</strong>：稀疏化技术：
<ul>
<li><strong>稀疏MHA</strong>：通过只计算和存储前L个注意力权重，减少了内存消耗。</li>
<li><strong>路由FFN</strong>：通过动态激活每个token的一部分模型参数，减少了计算成本。</li>
</ul>
</li>
</ul>
<p>LoRA+: Efficient Low Rank Adaptation of Large Models</p>
<ul>
<li><strong>机构</strong>: Simons Institute, UC Berkeley, Department of Statistics, UC Berkeley</li>
<li><strong>问题</strong>：以前的 LoRA 模型在处理大宽度模型时效果不佳，因为它为适配器矩阵 A 和 B 设置相同的学习率，导致特征学习效率低下，微调效果不理想。</li>
<li><strong>优势</strong>：LoRA+ 通过为 LoRA 适配器矩阵 A 和 B 设置不同的学习率，提高了特征学习效率，使得大宽度模型在微调时能够更有效地学习和适应新任务，从而在性能和速度上都有显著提升。</li>
<li><strong>关键</strong>：解决方案的关键是为 LoRA 适配器矩阵 A 和 B 设置不同的学习率，并通过缩放理论确定一个合适的固定比例。这种方法被称为 LoRA+，它在相同计算成本下提高了特征学习效率和模型性能。</li>
</ul>
<h2 id="llm"><a class="markdownIt-Anchor" href="#llm"></a> LLM</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/longtanle/awesome-federated-LLM-learning.git">链接</a></li>
</ul>

            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2024/07/05/FL%E7%A7%91%E7%A0%94%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90/" data-id="clyb7qvl70004vl697y369ieu" data-title="FL科研相关资源"
               class="article-share-link">分享</a>
            
            
            
            

        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
            <div class="article-nav-link-wrap article-nav-link-left">
                
                    <img data-src="https://pic.imgdb.cn/item/66894574d9c307b7e9783814.png" data-sizes="auto" alt="EuroSys:FLOAT"
                         class="lazyload">
                
                <a href="/2024/07/06/EuroSys-FLOAT/"></a>
                <div class="article-nav-caption">前一篇</div>
                <h3 class="article-nav-title">
                    
                        EuroSys:FLOAT
                    
                </h3>
            </div>
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://pbs.twimg.com/media/GO1SQD0W0AAmWnk?format=jpg&amp;name=medium" data-sizes="auto" alt="[转载]校招被裁后的心路历程"
                         class="lazyload">
                
                <a href="/2024/06/30/%E6%A0%A1%E6%8B%9B%E8%A2%AB%E8%A3%81%E5%90%8E%E7%9A%84%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        [转载]校招被裁后的心路历程
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">302</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">25</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">299</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        <iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/74X2u8JMVooG2QbjRxXwR8?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accumulate/">Accumulate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AimGraduate/">AimGraduate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Competition/">Competition</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Future/">Future</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/Application-Season/">Application Season</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/IELTS/">IELTS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/IELTS/">IELTS</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/IELTS/GoAbroad/">GoAbroad</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/bug/">bug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/internship/SNN/">SNN</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/FL/">FL</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/FL/Privacy/">Privacy</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/Multimudal/">Multimudal</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS224N/">CS224N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS231N/">CS231N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/Missing-Semester-of-CS/">Missing Semester of CS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/">ML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/d2l/">d2l</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/0/" style="font-size: 10px;">0</a> <a href="/tags/1/" style="font-size: 11.54px;">1</a> <a href="/tags/11-11/" style="font-size: 10px;">11.11</a> <a href="/tags/2/" style="font-size: 11.54px;">2</a> <a href="/tags/2-2/" style="font-size: 10px;">2-2</a> <a href="/tags/3/" style="font-size: 10.77px;">3</a> <a href="/tags/4/" style="font-size: 10px;">4</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/Accumulate/" style="font-size: 17.69px;">Accumulate</a> <a href="/tags/Advancing-Spiking-Neural-Networks-towards-Deep-Residual-Learning/" style="font-size: 11.54px;">Advancing Spiking Neural Networks towards Deep Residual Learning</a> <a href="/tags/AimGraduate/" style="font-size: 15.38px;">AimGraduate</a> <a href="/tags/An-Overview-of-the-BLITZ-Computer-Hardware/" style="font-size: 10px;">An Overview of the BLITZ Computer Hardware</a> <a href="/tags/An-Overview-of-the-BLITZ-System/" style="font-size: 10px;">An Overview of the BLITZ System</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/Artificial-neural-networks/" style="font-size: 10px;">Artificial neural networks</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/BLIP/" style="font-size: 10px;">BLIP</a> <a href="/tags/BLIP-2/" style="font-size: 10px;">BLIP-2</a> <a href="/tags/BasciConception/" style="font-size: 10px;">BasciConception</a> <a href="/tags/BatchNorm/" style="font-size: 10px;">BatchNorm</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/Blitz/" style="font-size: 12.31px;">Blitz</a> <a href="/tags/CAS/" style="font-size: 10.77px;">CAS</a> <a href="/tags/CMU15-445/" style="font-size: 10px;">CMU15-445</a> <a href="/tags/CNN/" style="font-size: 12.31px;">CNN</a> <a href="/tags/CS224N/" style="font-size: 10.77px;">CS224N</a> <a href="/tags/CS231N/" style="font-size: 10px;">CS231N</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 13.85px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/ComPetition/" style="font-size: 10px;">ComPetition</a> <a href="/tags/Competition/" style="font-size: 16.15px;">Competition</a> <a href="/tags/Container/" style="font-size: 10px;">Container</a> <a href="/tags/Convolutional-SNN-to-Classify-FMNIST/" style="font-size: 10px;">Convolutional SNN to Classify FMNIST</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 10.77px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Filter/" style="font-size: 10px;">Filter</a> <a href="/tags/Fine-Tuning/" style="font-size: 10px;">Fine-Tuning</a> <a href="/tags/Future/" style="font-size: 15.38px;">Future</a> <a href="/tags/GB/" style="font-size: 10px;">GB</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GiB/" style="font-size: 10px;">GiB</a> <a href="/tags/Git/" style="font-size: 10.77px;">Git</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoAbroad/" style="font-size: 16.92px;">GoAbroad</a> <a href="/tags/Graduate/" style="font-size: 10px;">Graduate</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/HMM/" style="font-size: 10px;">HMM</a> <a href="/tags/IELTS/" style="font-size: 13.08px;">IELTS</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 10px;">IntelliJ IDEA</a> <a href="/tags/Jianfei-Chen/" style="font-size: 10px;">Jianfei Chen</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/LMUFORMER/" style="font-size: 10px;">LMUFORMER</a> <a href="/tags/LayerNorm/" style="font-size: 10px;">LayerNorm</a> <a href="/tags/Lec01/" style="font-size: 11.54px;">Lec01</a> <a href="/tags/Lec01s/" style="font-size: 10.77px;">Lec01s</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/Linux/" style="font-size: 12.31px;">Linux</a> <a href="/tags/Listening/" style="font-size: 10px;">Listening</a> <a href="/tags/M2/" style="font-size: 10.77px;">M2</a> <a href="/tags/MIT6-S081/" style="font-size: 13.08px;">MIT6.S081</a> <a href="/tags/ML/" style="font-size: 15.38px;">ML</a> <a href="/tags/MS-ResNet/" style="font-size: 10px;">MS-ResNet</a> <a href="/tags/Mac/" style="font-size: 10.77px;">Mac</a> <a href="/tags/Missing-Semester/" style="font-size: 11.54px;">Missing Semester</a> <a href="/tags/Monitor/" style="font-size: 10px;">Monitor</a> <a href="/tags/NECCS/" style="font-size: 10px;">NECCS</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/Neuromorphic-computing/" style="font-size: 10px;">Neuromorphic computing</a> <a href="/tags/Neuron/" style="font-size: 10px;">Neuron</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/PSN/" style="font-size: 10px;">PSN</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Qingyao-Ai/" style="font-size: 10.77px;">Qingyao Ai</a> <a href="/tags/RISC-V/" style="font-size: 10px;">RISC-V</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/Reading/" style="font-size: 10px;">Reading</a> <a href="/tags/ResNet/" style="font-size: 10.77px;">ResNet</a> <a href="/tags/Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" style="font-size: 10px;">Rethinking the performance comparison between SNNS and ANNS</a> <a href="/tags/SNN/" style="font-size: 13.08px;">SNN</a> <a href="/tags/SNN-vs-RNN/" style="font-size: 10px;">SNN vs RNN</a> <a href="/tags/SPIKEBERT/" style="font-size: 10px;">SPIKEBERT</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/Script/" style="font-size: 10px;">Script</a> <a href="/tags/Shell/" style="font-size: 10.77px;">Shell</a> <a href="/tags/Single-Fully-Connected-Layer-SNN-to-Classify-MNIST/" style="font-size: 10px;">Single Fully Connected Layer SNN to Classify MNIST</a> <a href="/tags/Spiking-Neural-Network-for-Ultra-low-latency-and-High-accurate-Object-Detection/" style="font-size: 10px;">Spiking Neural Network for Ultra-low-latency and High-accurate Object Detection</a> <a href="/tags/Spiking-neural-network/" style="font-size: 10.77px;">Spiking neural network</a> <a href="/tags/Spiking-neural-networks/" style="font-size: 10px;">Spiking neural networks</a> <a href="/tags/SpikingBERT/" style="font-size: 10px;">SpikingBERT</a> <a href="/tags/Surrogate-Gradient-Method/" style="font-size: 10px;">Surrogate Gradient Method</a> <a href="/tags/T1-fighting/" style="font-size: 10.77px;">T1 fighting</a> <a href="/tags/THU/" style="font-size: 10px;">THU</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/Terminal/" style="font-size: 10px;">Terminal</a> <a href="/tags/The-Thread-Scheduler-and-Concurrency-Control-Primitives/" style="font-size: 10px;">The Thread Scheduler and Concurrency Control Primitives</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/Undergraduate/" style="font-size: 10px;">Undergraduate</a> <a href="/tags/University/" style="font-size: 13.08px;">University</a> <a href="/tags/VSCode/" style="font-size: 10px;">VSCode</a> <a href="/tags/ViT/" style="font-size: 10px;">ViT</a> <a href="/tags/Vim/" style="font-size: 10px;">Vim</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 10.77px;">Yuxiao Dong</a> <a href="/tags/alexnet/" style="font-size: 10px;">alexnet</a> <a href="/tags/anygpt/" style="font-size: 10px;">anygpt</a> <a href="/tags/arxiv/" style="font-size: 10px;">arxiv</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/bert/" style="font-size: 12.31px;">bert</a> <a href="/tags/blip2/" style="font-size: 10px;">blip2</a> <a href="/tags/bug/" style="font-size: 16.92px;">bug</a> <a href="/tags/cat/" style="font-size: 10px;">cat</a> <a href="/tags/chapter00/" style="font-size: 10px;">chapter00</a> <a href="/tags/chatgpt/" style="font-size: 10px;">chatgpt</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/chmod/" style="font-size: 10px;">chmod</a> <a href="/tags/chrome/" style="font-size: 10px;">chrome</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/code/" style="font-size: 10.77px;">code</a> <a href="/tags/coding/" style="font-size: 10px;">coding</a> <a href="/tags/commit/" style="font-size: 10px;">commit</a> <a href="/tags/competition/" style="font-size: 10px;">competition</a> <a href="/tags/conv2d/" style="font-size: 10px;">conv2d</a> <a href="/tags/copilot/" style="font-size: 10.77px;">copilot</a> <a href="/tags/cpu/" style="font-size: 10px;">cpu</a> <a href="/tags/cuda/" style="font-size: 10.77px;">cuda</a> <a href="/tags/d2l/" style="font-size: 14.62px;">d2l</a> <a href="/tags/database/" style="font-size: 10px;">database</a> <a href="/tags/dataloader/" style="font-size: 10px;">dataloader</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/deep-neural-network/" style="font-size: 10.77px;">deep neural network</a> <a href="/tags/delete/" style="font-size: 10px;">delete</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/dowhy/" style="font-size: 10.77px;">dowhy</a> <a href="/tags/dp/" style="font-size: 10px;">dp</a> <a href="/tags/echo/" style="font-size: 10px;">echo</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/embedding/" style="font-size: 10px;">embedding</a> <a href="/tags/explainer/" style="font-size: 10.77px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/file/" style="font-size: 10px;">file</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 13.08px;">github</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gpu/" style="font-size: 11.54px;">gpu</a> <a href="/tags/hexo/" style="font-size: 10.77px;">hexo</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/import/" style="font-size: 10px;">import</a> <a href="/tags/instructor/" style="font-size: 12.31px;">instructor</a> <a href="/tags/intern-00/" style="font-size: 10px;">intern-00</a> <a href="/tags/intern00/" style="font-size: 12.31px;">intern00</a> <a href="/tags/interns/" style="font-size: 10px;">interns</a> <a href="/tags/internship/" style="font-size: 19.23px;">internship</a> <a href="/tags/interview/" style="font-size: 10px;">interview</a> <a href="/tags/introduction/" style="font-size: 10px;">introduction</a> <a href="/tags/iterm2/" style="font-size: 10px;">iterm2</a> <a href="/tags/knowledge-distillaion/" style="font-size: 10px;">knowledge distillaion</a> <a href="/tags/linux/" style="font-size: 11.54px;">linux</a> <a href="/tags/llava/" style="font-size: 10px;">llava</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/loss/" style="font-size: 10px;">loss</a> <a href="/tags/lr/" style="font-size: 10px;">lr</a> <a href="/tags/lstm/" style="font-size: 10px;">lstm</a> <a href="/tags/mac/" style="font-size: 13.08px;">mac</a> <a href="/tags/memory/" style="font-size: 12.31px;">memory</a> <a href="/tags/mentor/" style="font-size: 10.77px;">mentor</a> <a href="/tags/ml/" style="font-size: 10px;">ml</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/mysqlclient/" style="font-size: 10px;">mysqlclient</a> <a href="/tags/neuromorphic-computing/" style="font-size: 10.77px;">neuromorphic computing</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/nvidia/" style="font-size: 10px;">nvidia</a> <a href="/tags/ohmyzsh/" style="font-size: 10px;">ohmyzsh</a> <a href="/tags/olive/" style="font-size: 10px;">olive</a> <a href="/tags/os/" style="font-size: 12.31px;">os</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/paper/" style="font-size: 20px;">paper</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/pku/" style="font-size: 10px;">pku</a> <a href="/tags/player/" style="font-size: 10px;">player</a> <a href="/tags/preparation/" style="font-size: 10px;">preparation</a> <a href="/tags/prml/" style="font-size: 12.31px;">prml</a> <a href="/tags/profile/" style="font-size: 10px;">profile</a> <a href="/tags/project/" style="font-size: 13.85px;">project</a> <a href="/tags/prompt/" style="font-size: 10px;">prompt</a> <a href="/tags/pycharm/" style="font-size: 10px;">pycharm</a> <a href="/tags/python/" style="font-size: 10.77px;">python</a> <a href="/tags/pytorch/" style="font-size: 16.15px;">pytorch</a> <a href="/tags/qemu/" style="font-size: 10px;">qemu</a> <a href="/tags/question/" style="font-size: 10px;">question</a> <a href="/tags/reading/" style="font-size: 10px;">reading</a> <a href="/tags/register/" style="font-size: 10px;">register</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/rsa/" style="font-size: 10px;">rsa</a> <a href="/tags/se/" style="font-size: 10px;">se</a> <a href="/tags/self-attention/" style="font-size: 10px;">self-attention</a> <a href="/tags/server/" style="font-size: 10px;">server</a> <a href="/tags/shap/" style="font-size: 10px;">shap</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/shell-vs-terminal/" style="font-size: 10px;">shell vs terminal</a> <a href="/tags/softmax/" style="font-size: 10px;">softmax</a> <a href="/tags/sora/" style="font-size: 10px;">sora</a> <a href="/tags/spike/" style="font-size: 10.77px;">spike</a> <a href="/tags/spikeBERT/" style="font-size: 10.77px;">spikeBERT</a> <a href="/tags/spikeBert/" style="font-size: 10px;">spikeBert</a> <a href="/tags/spikebert/" style="font-size: 10px;">spikebert</a> <a href="/tags/spikingjelly/" style="font-size: 13.08px;">spikingjelly</a> <a href="/tags/spikngjelly/" style="font-size: 10.77px;">spikngjelly</a> <a href="/tags/ssh/" style="font-size: 10.77px;">ssh</a> <a href="/tags/sta/" style="font-size: 10px;">sta</a> <a href="/tags/terminal/" style="font-size: 10px;">terminal</a> <a href="/tags/thu/" style="font-size: 10px;">thu</a> <a href="/tags/tips/" style="font-size: 10.77px;">tips</a> <a href="/tags/tittle/" style="font-size: 10px;">tittle</a> <a href="/tags/tmux/" style="font-size: 10px;">tmux</a> <a href="/tags/tool/" style="font-size: 18.46px;">tool</a> <a href="/tags/transformer/" style="font-size: 13.85px;">transformer</a> <a href="/tags/transformers/" style="font-size: 10px;">transformers</a> <a href="/tags/vit/" style="font-size: 10px;">vit</a> <a href="/tags/vscode/" style="font-size: 10.77px;">vscode</a> <a href="/tags/wakatime/" style="font-size: 10px;">wakatime</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/xv6/" style="font-size: 10px;">xv6</a> <a href="/tags/yeild/" style="font-size: 10px;">yeild</a> <a href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" style="font-size: 18.46px;">专业知识</a> <a href="/tags/%E4%B8%93%E7%A1%95/" style="font-size: 10px;">专硕</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E4%B8%AD%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AE%BE%E8%AE%A1%E5%A4%A7%E8%B5%9B/" style="font-size: 10px;">中国大学生计算机设计大赛</a> <a href="/tags/%E4%B8%AD%E7%A7%91%E9%99%A2/" style="font-size: 10px;">中科院</a> <a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 10px;">代理</a> <a href="/tags/%E5%85%AC%E9%80%89%E8%AF%BE/" style="font-size: 10px;">公选课</a> <a href="/tags/%E5%86%85%E5%AD%98/" style="font-size: 10.77px;">内存</a> <a href="/tags/%E5%86%99%E4%BD%9C%E5%BF%83%E5%BE%97/" style="font-size: 10px;">写作心得</a> <a href="/tags/%E5%86%99%E4%BD%9C%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">写作技巧</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" style="font-size: 10px;">分布式训练</a> <a href="/tags/%E5%8A%A0%E5%88%86/" style="font-size: 10px;">加分</a> <a href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">动手学深度学习</a> <a href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/" style="font-size: 10px;">博弈论</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" style="font-size: 10px;">基础优化方法</a> <a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">复习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 10px;">多模态</a> <a href="/tags/%E5%A4%A7%E4%B8%89%E4%B8%8A/" style="font-size: 10px;">大三上</a> <a href="/tags/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" style="font-size: 10px;">大作业</a> <a href="/tags/%E5%A4%A7%E5%88%9B/" style="font-size: 10px;">大创</a> <a href="/tags/%E5%A4%A7%E8%8B%B1%E8%B5%9B/" style="font-size: 10px;">大英赛</a> <a href="/tags/%E5%AD%A6%E7%A1%95/" style="font-size: 10px;">学硕</a> <a href="/tags/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/" style="font-size: 10.77px;">审稿意见</a> <a href="/tags/%E5%BC%BA%E5%BC%B1com/" style="font-size: 10px;">强弱com</a> <a href="/tags/%E5%BD%A2%E5%8A%BF%E4%B8%8E%E6%94%BF%E7%AD%96/" style="font-size: 10px;">形势与政策</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%82%84%E6%82%84%E8%AF%9D/" style="font-size: 10px;">悄悄话</a> <a href="/tags/%E6%94%B9%E7%BB%B4%E5%BA%A6/" style="font-size: 10px;">改维度</a> <a href="/tags/%E6%95%99%E8%82%B2%E8%AE%B8%E5%8F%AF/" style="font-size: 10px;">教育许可</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 10px;">数据操作+预处理</a> <a href="/tags/%E6%98%BE%E5%AD%98/" style="font-size: 10.77px;">显存</a> <a href="/tags/%E6%99%BA%E6%85%A7%E6%A0%91/" style="font-size: 10px;">智慧树</a> <a href="/tags/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">智能计算系统</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 10.77px;">服务器</a> <a href="/tags/%E6%9C%9F%E6%9C%AB/" style="font-size: 10px;">期末</a> <a href="/tags/%E6%9C%B1%E8%80%81%E5%B8%88/" style="font-size: 10px;">朱老师</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 10px;">朴素贝叶斯</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9D%82%E9%A1%B9/" style="font-size: 12.31px;">杂项</a> <a href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" style="font-size: 10.77px;">李宏毅</a> <a href="/tags/%E6%9D%8E%E6%B2%90/" style="font-size: 10px;">李沐</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">环境搭建</a> <a href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">矩阵计算</a> <a href="/tags/%E7%A7%91%E8%BD%AF/" style="font-size: 10px;">科软</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 10px;">线性代数</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a> <a href="/tags/%E7%BB%A7%E6%89%BF/" style="font-size: 10px;">继承</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3/" style="font-size: 10px;">脑机接口</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 10px;">脑机接口信号处理</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">自动求导</a> <a href="/tags/%E8%8A%82%E8%83%BD%E5%87%8F%E6%8E%92/" style="font-size: 11.54px;">节能减排</a> <a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" style="font-size: 10px;">虚拟机</a> <a href="/tags/%E8%A7%84%E5%88%99/" style="font-size: 10px;">规则</a> <a href="/tags/%E8%A7%A3%E5%8E%8B%E7%BC%A9/" style="font-size: 10px;">解压缩</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%AF%AD%E4%B9%89%E7%A9%BA%E9%97%B4/" style="font-size: 10px;">语义空间</a> <a href="/tags/%E8%AF%BE%E7%A8%8B/" style="font-size: 10px;">课程</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E6%A6%82%E8%A7%88/" style="font-size: 10px;">课程概览</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E8%A1%A8/" style="font-size: 10px;">课程表</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 10.77px;">调研</a> <a href="/tags/%E8%B4%A1%E7%8C%AE%E8%80%85/" style="font-size: 10px;">贡献者</a> <a href="/tags/%E8%BE%93%E5%85%A5%E6%B3%95/" style="font-size: 10px;">输入法</a> <a href="/tags/%E9%87%8F%E5%8C%96/" style="font-size: 10px;">量化</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a> <a href="/tags/%E9%B8%BF%E9%9B%81%E6%9D%AF/" style="font-size: 10px;">鸿雁杯</a>
        </div>
    </div>


    
        

    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">十月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">九月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">八月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">七月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">六月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">五月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">四月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">三月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">一月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">十一月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    

    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2024
                <span class="footer-info-sep"></span>
                ab
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    723.4k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    45:39
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">302</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">25</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">299</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

