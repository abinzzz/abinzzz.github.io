
    <!DOCTYPE html>
    <html lang="zh-CN"
            
          
    >
    <head>
    <!--pjax：防止跳转页面音乐暂停-->
    <script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script> 
    <meta charset="utf-8">
    

    

    
    <title>
        DAC:EDGE-LLM |
        
        blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CUbuntu%20Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
    
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/v4-font-face.min.css">

    
<link rel="stylesheet" href="/css/loader.css">

    <meta name="description" content="基本信息 标题: EDGE-LLM: Enabling Efficient Large Language Model Adaptation on Edge Devices via Layerwise Unified Compression and Adaptive Layer Tuning &amp; Voting 作者: Zhongzhi Yu, Zheng Wang, Yuhan Li, H">
<meta property="og:type" content="article">
<meta property="og:title" content="DAC:EDGE-LLM">
<meta property="og:url" content="https://abinzzz.github.io/2024/07/16/DAC-EDGE-LLM/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="基本信息 标题: EDGE-LLM: Enabling Efficient Large Language Model Adaptation on Edge Devices via Layerwise Unified Compression and Adaptive Layer Tuning &amp; Voting 作者: Zhongzhi Yu, Zheng Wang, Yuhan Li, H">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.imgdb.cn/item/6696933cd9c307b7e97a0333.png">
<meta property="article:published_time" content="2024-07-16T11:06:35.000Z">
<meta property="article:modified_time" content="2024-07-17T00:47:43.018Z">
<meta property="article:author" content="ab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/6696933cd9c307b7e97a0333.png">
    
        <link rel="alternate" href="/atom.xml" title="blog" type="application/atom+xml">
    
    
        <link rel="shortcut icon" href="/images/favicon.ico">
    
    
        
<link rel="stylesheet" href="https://unpkg.com/typeface-source-code-pro@1.1.13/index.css">

    
    
<link rel="stylesheet" href="/css/style.css">

    
        
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

    
    
        
<link rel="stylesheet" href="https://unpkg.com/katex@0.16.7/dist/katex.min.css">

    
    
    
    
<script src="https://unpkg.com/pace-js@1.2.4/pace.min.js"></script>

    
        
<link rel="stylesheet" href="https://unpkg.com/wowjs@1.1.3/css/libs/animate.css">

        
<script src="https://unpkg.com/wowjs@1.1.3/dist/wow.min.js"></script>

        <script>
          new WOW({
            offset: 0,
            mobile: true,
            live: false
          }).init();
        </script>
    
<meta name="generator" content="Hexo 5.4.2"></head>

    <body>
    
<div id='loader'>
  <div class="loading-left-bg"></div>
  <div class="loading-right-bg"></div>
  <div class="spinner-box">
    <div class="loading-taichi">
      <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="http://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
      <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="#ff6e6b" />
      <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z" fill="#fd0d00" />
      <path d="M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95" fill="#fd0d00" />
    </svg>
    </div>
    <div class="loading-word">Loading...</div>
  </div>
</div>
</div>

<script>
  const endLoading = function() {
    document.body.style.overflow = 'auto';
    document.getElementById('loader').classList.add("loading");
  }
  window.addEventListener('load', endLoading);
  document.getElementById('loader').addEventListener('click', endLoading);
</script>


    <div id="container">
        <div id="wrap">
            <header id="header">
    
    
        <img data-src="https://pic.imgdb.cn/item/66965670d9c307b7e9fb2b6f.png" data-sizes="auto" alt="DAC:EDGE-LLM" class="lazyload">
    
    <div id="header-outer" class="outer">
        <div id="header-title" class="inner">
            <div id="logo-wrap">
                
                    
                    
                        <a href="/" id="logo"><h1>DAC:EDGE-LLM</h1></a>
                    
                
            </div>
            
                
                
            
        </div>
        <div id="header-inner">
            <nav id="main-nav">
                <a id="main-nav-toggle" class="nav-icon"></a>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/">首页</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/archives">归档</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/about">关于</a>
                    </span>
                
                    <span class="main-nav-link-wrap">
                        <span class="main-nav-icon"></span>
                        <a class="main-nav-link" href="/friend">友链</a>
                    </span>
                
            </nav>
            <nav id="sub-nav">
                
                    <a id="nav-rss-link" class="nav-icon" href="/atom.xml"
                       title="RSS 订阅"></a>
                
                
            </nav>
            <div id="search-form-wrap">
                <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://abinzzz.github.io"></form>
            </div>
        </div>
    </div>
</header>

            <div id="content" class="outer">
                <section id="main"><article id="post-DAC-EDGE-LLM" class="h-entry article article-type-post"
         itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
    <div class="article-inner">
        <div class="article-meta">
            <div class="article-date wow slideInLeft">
    <a href="/2024/07/16/DAC-EDGE-LLM/" class="article-date-link">
        <time datetime="2024-07-16T11:06:35.000Z"
              itemprop="datePublished">2024-07-16</time>
    </a>
</div>

            
    <div class="article-category wow slideInLeft">
        <a class="article-category-link" href="/categories/paper/">paper</a><a class="article-category-link" href="/categories/paper/FL/">FL</a>
    </div>


        </div>
        <div class="hr-line"></div>
        

        <div class="e-content article-entry" itemprop="articleBody">
            
                <h2 id="基本信息"><a class="markdownIt-Anchor" href="#基本信息"></a> 基本信息</h2>
<p><strong>标题</strong>:<br />
EDGE-LLM: Enabling Efficient Large Language Model Adaptation on Edge Devices via Layerwise Unified Compression and Adaptive Layer Tuning &amp; Voting</p>
<p><strong>作者</strong>:<br />
Zhongzhi Yu, Zheng Wang, Yuhan Li, Haoran You, Ruijie Gao, Xiaoya Zhou, Sreenidhi Reedy Bommu, Yang (Katie) Zhao, Yingyan (Celine) Lin</p>
<p><strong>作者单位</strong>:</p>
<ul>
<li>Georgia Institute of Technology</li>
<li>University of Minnesota, Twin Cities</li>
<li>University of California, Santa Barbara</li>
</ul>
<p><strong>会议</strong>:<br />
61st ACM/IEEE Design Automation Conference (DAC ’24), June 23–27, 2024, San Francisco, CA, USA</p>
<p><strong>DOI</strong>:<br />
<a target="_blank" rel="noopener" href="https://doi.org/10.1145/3649329.3658473">https://doi.org/10.1145/3649329.3658473</a></p>
<p><strong>代码仓库</strong>:<br />
<a target="_blank" rel="noopener" href="https://github.com/GATECH-EIC/Edge-LLM">https://github.com/GATECH-EIC/Edge-LLM</a></p>
<h2 id="论文二十问"><a class="markdownIt-Anchor" href="#论文二十问"></a> 论文二十问</h2>
<h3 id="1-论文试图解决什么问题"><a class="markdownIt-Anchor" href="#1-论文试图解决什么问题"></a> 1. 论文试图解决什么问题？</h3>
<p>论文试图解决大型语言模型（LLMs）在边缘设备（如边缘GPU和智能手机）上的高效适配问题，具体来说，是减少计算和内存开销，使得这些模型能够在资源有限的设备上进行连续和隐私保护的推理和调整。</p>
<h3 id="2-这是否是一个新的问题"><a class="markdownIt-Anchor" href="#2-这是否是一个新的问题"></a> 2. 这是否是一个新的问题？</h3>
<p>这不是一个全新的问题，但随着LLMs规模的增加和对隐私保护需求的提高，这个问题变得越来越重要。现有的调优技术在计算和内存开销上仍然存在显著不足，因此需要新的方法来应对这些挑战。</p>
<h3 id="3-这篇文章要验证一个什么科学假设"><a class="markdownIt-Anchor" href="#3-这篇文章要验证一个什么科学假设"></a> 3. 这篇文章要验证一个什么科学假设？</h3>
<p>本文要验证的科学假设是，通过层级统一压缩（LUC）和自适应层调优与投票机制，可以在计算和内存资源有限的边缘设备上实现高效的LLM适配，同时保持模型的性能。</p>
<h3 id="4-有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员"><a class="markdownIt-Anchor" href="#4-有哪些相关研究如何归类谁是这一课题在领域内值得关注的研究员"></a> 4. 有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</h3>
<p>相关研究主要包括参数高效调优（PET）、内存高效调优（MET）和压缩-再调优技术。PET方法减少需要训练的参数数量，但在内存开销上仍有不足；MET方法通过减少反向传播深度来降低内存占用；压缩-再调优技术则通过先压缩模型来减少计算和数据移动开销。值得关注的研究员包括LoRA提出者（Hu et al.）和QLoRA提出者（Dettmers et al.）。</p>
<h3 id="5-论文中提到的解决方案之关键是什么"><a class="markdownIt-Anchor" href="#5-论文中提到的解决方案之关键是什么"></a> 5. 论文中提到的解决方案之关键是什么？</h3>
<p>解决方案的关键包括：</p>
<ol>
<li><strong>层级统一压缩（LUC）：</strong> 基于对LLMs不同层级对量化和剪枝敏感性的实证观察，生成层级压缩策略，以优化计算和内存效率。</li>
<li><strong>自适应层调优与投票机制：</strong> 动态选择不同层进行调优，并通过多层输出投票机制来提高模型的推理准确性。</li>
</ol>
<h3 id="6-论文中的实验是如何设计的"><a class="markdownIt-Anchor" href="#6-论文中的实验是如何设计的"></a> 6. 论文中的实验是如何设计的？</h3>
<p>实验设计包括对比不同调优方法（如LoRA、部分调优、LST）在MMLU和WikiText-2数据集上的性能，评估Edge-LLM框架在不同量化和剪枝策略下的表现。此外，还模拟了硬件加速器的性能，以评估硬件调度模块的效率。</p>
<h3 id="7-用于定量评估的数据集是什么代码有没有开源"><a class="markdownIt-Anchor" href="#7-用于定量评估的数据集是什么代码有没有开源"></a> 7. 用于定量评估的数据集是什么？代码有没有开源？</h3>
<p>用于定量评估的数据集包括MMLU和WikiText-2。代码已开源，链接为<a target="_blank" rel="noopener" href="https://github.com/GATECH-EIC/Edge-LLM">https://github.com/GATECH-EIC/Edge-LLM</a>。</p>
<h3 id="8-论文中的实验及结果有没有很好地支持需要验证的科学假设"><a class="markdownIt-Anchor" href="#8-论文中的实验及结果有没有很好地支持需要验证的科学假设"></a> 8. 论文中的实验及结果有没有很好地支持需要验证的科学假设？</h3>
<p>是的，实验结果表明，Edge-LLM在相同资源约束下，相比基准方法取得了更高的准确性和显著的内存开销减少，验证了提出的LUC和自适应层调优与投票机制的有效性。</p>
<h3 id="9-这篇论文到底有什么贡献"><a class="markdownIt-Anchor" href="#9-这篇论文到底有什么贡献"></a> 9. 这篇论文到底有什么贡献？</h3>
<p>论文的主要贡献包括：</p>
<ol>
<li>提出了一个综合性的LLM调优框架Edge-LLM，从算法和硬件角度解决了边缘设备上的计算和内存开销问题。</li>
<li>开发了层级统一压缩（LUC）和自适应层调优与投票机制，提高了调优的效率和模型性能。</li>
<li>实验验证了Edge-LLM框架在不同数据集上的优越性，并开源了相关代码。</li>
</ol>
<h3 id="10-下一步呢有什么工作可以继续深入"><a class="markdownIt-Anchor" href="#10-下一步呢有什么工作可以继续深入"></a> 10. 下一步呢？有什么工作可以继续深入？</h3>
<p>未来工作可以包括：</p>
<ol>
<li>扩展Edge-LLM框架以支持更多类型的边缘设备和更大规模的LLMs。</li>
<li>探索更多的量化和剪枝策略，以进一步优化计算和内存效率。</li>
<li>研究如何在保持高效性的同时，进一步提高模型的推理准确性和适应性。</li>
</ol>
<h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h2>
<p>大型语言模型（LLMs）在边缘设备上的高效适配对于需要持续且隐私保护的适配和推理的应用至关重要。然而，现有的调优技术由于高计算和内存开销而不足。为此，我们引入了一种<strong>计算和内存高效的LLM调优框架</strong>，称为Edge-LLM，以促进在边缘设备上进行经济高效的LLM适配。具体来说，Edge-LLM具有三个核心组件：（1）层级统一压缩（LUC）技术，通过生成层级修剪稀疏性和量化位宽策略来减少计算开销，（2）自适应层调优和投票机制，通过减少反向传播深度来降低内存开销，（3）互补硬件调度策略，处理由LUC和自适应层调优引入的不规则计算模式，从而实现高效的计算和数据移动。大量实验表明，与传统调优方法相比，Edge-LLM实现了2.92倍的速度提升和4倍的内存开销减少，同时任务准确性相当。我们的代码已在 <a target="_blank" rel="noopener" href="https://github.com/GATECH-EIC/Edge-LLM">https://github.com/GATECH-EIC/Edge-LLM</a> 上开源。</p>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<p>近年来，大型语言模型（LLMs）如GPT-4在各类应用中表现出色，改变了人类生活。顺应这一趋势，开发高效的调优技术以支持需要持续和隐私保护适配的应用变得越来越重要。然而，LLMs庞大的模型规模使得在边缘设备（如边缘GPU和智能手机）上直接进行LLM适配变得困难重重。这主要有两个挑战：(1) 在计算LLM的<strong>前向和后向传递时遇到的过高计算开销</strong>，(2) 在调优过程中<strong>存储庞大模型权重和激活值</strong>带来的繁琐内存开销。正如最近的研究所示，LLMs通常在前沿的GPU上进行调优（例如，使用40GB或80GB的GPU内存），需要超过一天的GPU时间来完成。即使是最先进的高效调优方法，在边缘设备上有效调优相对较小规模的LLMs（如LLaMA-7B）仍然是不现实的。</p>
<p>尽管一些现有的努力试图解决上述挑战，但每种方法都有其缺点。(1) 为了减少计算开销，常见的方法是先压缩目标LLM以减少模型规模。然而，如何在保持LLM适应性的同时有效减少其冗余仍然是一个未充分探索的问题。(2) 为了减轻内存开销，现有方法主要集中在缩短反向传播深度。不幸的是，减少的反向传播深度导致LLM中只有一部分块被更新，限制了可实现的性能。</p>
<p>在本文中，我们开发了一个综合解决方案来解决上述内存和计算挑战，实现有效的LLM适配。具体而言，我们做出了以下贡献：</p>
<ul>
<li>我们提出了一个名为Edge-LLM的综合框架，从算法和硬件的角度解决LLM适配的内存和计算挑战，使其能够在内存和计算资源有限的边缘设备上实现有效的LLM适配。</li>
<li>在算法方面，我们从两个方向实现这一目标，每个方向主要集中在上述挑战之一：(1) 为了减少<strong>计算开销</strong>，我们提出了一种基于LLM层级对<strong>量化和修剪</strong>敏感性实证观察的低成本层级统一压缩（LUC）方法。(2) 为了减少内存开销，我们引入了一种<strong>自适应层调优和投票机制</strong>。在自适应层调优中，我们建议有选择地更新目标LLM的不同部分，并通过直接连接当前更新部分的输出到最终层来减少内存占用。此外，在自适应层投票中，我们利用目标LLM不同部分的输出进行投票，以获得优化的输出。</li>
<li>在硬件方面，为了更好地处理由提出的算法引入的不规则计算模式（即不同层级的量化位宽、层级修剪稀疏性和LLM段的更新），我们进一步将一个互补的硬件调度模块集成到Edge-LLM中。硬件调度模块包括一个搜索空间和搜索策略，考虑潜在的卸载策略、计算计划和张量放置，旨在更好地将理论上的计算开销减少转化为硬件效率的提高。</li>
<li>实验结果和消融研究验证了我们提出的Edge-LLM框架的有效性。具体而言，与在相同资源约束下调优的基线方法相比，Edge-LLM在MMLU得分上提高了0.70%至1.29%，在WikiText-2上的困惑度与LoRA调优相当，但每次迭代的延迟降低了2.92倍，内存开销减少了4倍。</li>
</ul>
<h2 id="2background-and-motivation"><a class="markdownIt-Anchor" href="#2background-and-motivation"></a> 2.Background and Motivation</h2>
<h3 id="21-efficient-tuning-techniques"><a class="markdownIt-Anchor" href="#21-efficient-tuning-techniques"></a> 2.1 Efficient Tuning Techniques</h3>
<p><img src="https://pic.imgdb.cn/item/6696933cd9c307b7e97a0333.png" alt="" /><br />
<strong>图1展示了在Alpaca数据集上使用LoRA和QLoRA对LLaMA-7B进行调优时的内存占用情况</strong>。现有的内存高效调优（MET）技术通过减少反向传播深度，从而减少需要存储的激活数来实现内存占用的最小化。这些技术要么通过部分调优只调优最后几层，要么通过侧调优在每个适配器模块与最终输出之间添加旁路连接。虽然在调优过程中减少内存占用是非常理想的，但现有的MET技术在LLM调优中仍面临着精度和内存占用之间的不满意权衡。具体而言，对于部分调优，现有方法需要调优目标LLM的80%以上的层才能达到满意的任务精度，而侧调优由于偏置优化，难以达到与最先进的PET技术相媲美的任务精度。</p>
<p>压缩-再调优是一系列新兴的高效调优技术，其动机是由于LLM调优中的计算开销主要由LLM骨干网络的前向和后向传递所主导。因此，一些先驱性工作提出在调优前压缩LLM骨干网络，以减少计算和数据移动开销。然而，现有的最先进的压缩-再调优技术主要旨在提高调优速度，忽视了极端的内存开销（例如，最先进的压缩-再调优方法仍需使用具有40GB内存的A100 GPU才能在Llama-70B模型上实现有效调优）。这一忽视限制了压缩-再调优技术在资源受限的边缘设备上调优LLM的有效性。</p>
<h3 id="22-memory-overhead-during-tuning"><a class="markdownIt-Anchor" href="#22-memory-overhead-during-tuning"></a> 2.2 Memory Overhead During Tuning</h3>
<p>为了更好地理解现有调优技术所需的内存与边缘设备可用内存之间的差距，我们对LLaMA-7B模型使用LoRA（最先进的PET技术之一）和QLoRA（最先进的压缩-再调优技术之一）进行了内存需求分析。图1显示，LoRA的内存开销主要来自存储LLM的<strong>骨干权重和反向传播的激活</strong>。即使QLoRA将LLM骨干压缩到4-bit，并使整体内存占用减少了41.2%，与LoRA相比，调优所需的内存仍然比常用的边缘设备（如8GB的TX2和12GB的Quest Pro）可用内存高出1.48倍至2.22倍。</p>
<h3 id="23-opportunities-for-efficient-llm-tuning"><a class="markdownIt-Anchor" href="#23-opportunities-for-efficient-llm-tuning"></a> 2.3 Opportunities for Efficient LLM Tuning</h3>
<p>为了应对现有调优方法的上述限制，我们识别了改进这些方法以开发有效LLM调优框架的潜在机会。</p>
<p>一方面，为了进一步减少计算开销，我们识别出现有压缩-再调优技术中用于减少模型冗余的成功实践与采用的原始压缩技术之间的不匹配。具体而言，以往的研究观察到深度学习模型在不同维度（如位宽和稀疏性）和不同层次上表现出冗余，而现有的压缩-再调优技术通常采用统一压缩方法，仅从一个维度减少冗余。</p>
<p>另一方面，为了进一步减少内存开销，根据我们在第2.1节中的分析，我们总结出提高可实现的精度-内存权衡的关键在于能够以有限的反向传播深度更新LLM中的所有层。受用于高效模型推理的早退出机制的启发，我们假设LLM中早期层的输出可以为预测提供有意义的信息。因此，可以从早退出层开始反向传播，并仍然有效地更新模型。在这种情况下，由于反向传播可以从多个早退出层开始，更新LLM所有层所需的反向传播深度可以最小化。</p>
<h2 id="3-edge-llm算法"><a class="markdownIt-Anchor" href="#3-edge-llm算法"></a> 3 Edge-LLM算法</h2>
<h3 id="31-概述"><a class="markdownIt-Anchor" href="#31-概述"></a> 3.1 概述</h3>
<p>受第2.3节中提到的机会启发，我们介绍了Edge-LLM框架的算法设计，以便在计算和内存开销有限的情况下，实现高效的LLM适配。正如图2所示，我们提出的Edge-LLM调优算法结合了两个关键要素，每个要素都利用了减少计算和内存开销的机会。具体来说：(1) 为了减少计算开销，我们提出了LUC技术来减少目标LLM的冗余。该技术基于我们对LLM层级对量化和修剪敏感性的实证观察。基于上述观察，我们在LUC中开发了一种低成本的基于均方误差（MSE）的识别器，以生成层级压缩策略（例如，层级位宽和修剪稀疏分配），旨在改善LUC在压缩-再调优框架中相对于现有压缩技术的准确性-效率权衡（见第3.2节）。(2) 为了减少内存开销，我们提出了一种自适应层调优方案，该方案在前向传递过程中通过跳跃连接动态地将所选层（每次迭代可能不同）的输出连接到最终分类层。在反向传播过程中，只有所选层的前几个层接收梯度更新。由于选择更新的层因不同输入而异，这种方法确保了所有层都能有效更新，同时最小化了内存开销。通过引入跳跃连接减少了反向传播的深度，从而实现了效率。此外，在推理过程中，我们引入了一种投票机制，以提高自适应层调优的LLM的准确性。该方法利用自适应调优LLM从多个层生成合理输出的能力。因此，每个层生成的logits，通过投票过程确定最终输出（见第3.3节）。</p>
<h3 id="32-层级统一压缩luc"><a class="markdownIt-Anchor" href="#32-层级统一压缩luc"></a> 3.2 层级统一压缩（LUC）</h3>
<h5 id="llm层级敏感性观察"><a class="markdownIt-Anchor" href="#llm层级敏感性观察"></a> LLM层级敏感性观察</h5>
<p>在先前的模型压缩研究中，一个普遍的理解是模型的不同层对不同压缩技术表现出不同的敏感性。然而，LLM中不同层对不同压缩技术的敏感性仍是一个未解的问题。为了解决这个问题，我们首先探讨了目标LLM对修剪和量化的层级敏感性。具体来说，我们对预训练的LLaMA-7B模型的每一层应用不同的量化位宽和修剪稀疏度。通过比较从WikiText数据集获得的相同输入的压缩层和原始层输出的平均MSE，我们观察到，如图3所示，LLM中只有一小部分层对压缩表现出高敏感性。</p>
<h5 id="我们的假设和提出的luc"><a class="markdownIt-Anchor" href="#我们的假设和提出的luc"></a> 我们的假设和提出的LUC</h5>
<p>基于上述观察，我们假设高敏感性（即高MSE）是由于相应层的冗余有限，因此需要较低的压缩比率。为此，我们提出以下映射函数，将层级MSE映射到层级量化位宽和修剪稀疏度。对于量化，给定一个具有L层的LLM M，表示为C={l0, l1, …, lL-1}，基本量化位宽为B，层li的量化敏感性（即原始层输出和B位量化层输出之间的MSE）为s_quant，我们定义层lj的优化量化位宽b_j为：<br />
[ b_j = B + 1(s_quant_j \ge \frac{\sum_{i=0}^{L-1} s_quant_i}{L}) ]<br />
其中1(.)为指示函数。对于修剪，给定目标总体修剪稀疏度P，我们定义层lj的修剪稀疏度p_j为：<br />
[ p_j = P \times \frac{L \times s_prune_j}{\sum_{i=0}^{L-1} s_prune_i} ]<br />
其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>p</mi></msub><mi>r</mi><mi>u</mi><mi>n</mi><msub><mi>e</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">s_prune_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是层lj的修剪敏感性。</p>
<h3 id="33-自适应层调优与投票"><a class="markdownIt-Anchor" href="#33-自适应层调优与投票"></a> 3.3 自适应层调优与投票</h3>
<p>在此组件中，我们的目标是通过减少内存开销来实现有效调优，从而使调优过程适应内存容量有限的边缘设备。为此，我们识别的主要挑战是，在限制的反向传播深度下，实现目标LLM的所有层的高效更新，正如在第2.3节中分析的那样。</p>
<p>在Edge-LLM中，我们通过构建一组退出层T = {t0, t1, …, tT-1}来缓解这一挑战。每个退出层ti连接到目标LLM中的第lCeil((i+1)×L/T)层的输出，作为最终输出层。需要注意的是，T代表可选择的退出层的数量，L表示目标LLM的总层数，确保T &lt; L。在每次调优迭代中，我们随机选择一个ti ∈ T作为唯一使用的退出层，并更新以下层集合：<br />
[ {lCeil((i+1)×L/T)-m, lCeil((i+1)×L/T)-m+1, …, lCeil((i+1)×L/T), ti} ]<br />
每个层都配备有LoRA适配器。这里，m = Ceil(L/T)表示在此配置中具有未冻结可训练参数的层数。</p>
<p>此外，通过上述自适应层调优，调优后的LLM可以从所有退出层t ∈ T生成输出。尽管直接使用最终输出层tT-1可以实现有竞争力的性能，但拥有多个可用的退出层提供了在推理时通过自适应组合不同层的输出来进一步提高性能的机会。为此，我们提出了一种投票机制，通过基于所有退出层的输出进行预测来提高性能。具体来说，受关于后softmax概率与预测置信度关系的现有研究结果的启发，我们通过选择所有退出层中具有最高后softmax概率的索引来确定最终输出。具体来说，给定一个输出概率矩阵M，其中每个元素m(i,j)表示层ti的索引j的输出概率。我们首先找到M中最大值的位置（imax, jmax）= argmaxi,j(m(i,j))，然后生成最终输出o = jmax。</p>
<h2 id="5-评估"><a class="markdownIt-Anchor" href="#5-评估"></a> 5 评估</h2>
<h3 id="51-评估设置"><a class="markdownIt-Anchor" href="#51-评估设置"></a> 5.1 评估设置</h3>
<ul>
<li><strong>数据集：</strong> 使用两个常用的基准数据集，包括MMLU和WikiText。</li>
<li><strong>模型：</strong> LLaMA-7B。</li>
<li><strong>算法基准：</strong> 包括最先进的PET技术LoRA、最先进的MET技术LST、最先进的压缩技术Sparse-GPT和LLM-QAT，以及我们提出的七种方法的变体。</li>
<li><strong>硬件基准：</strong> 用于Transformer训练的最先进的systolic加速器。</li>
<li><strong>算法实现：</strong> 我们分别使用LLM-QAT和Sparse-GPT作为量化和修剪技术，并按照相关设置对模型进行调优。</li>
<li><strong>硬件配置：</strong> 加速器的DRAM设置为8GB LPDDR4，片上SRAM设置为1MB，与最先进的边缘设备一致，其他硬件配置遵循基准训练加速器的设计。</li>
<li><strong>评估方法：</strong> 我们使用最先进的Scale-Sim模拟器来模拟基准加速器及应用我们技术后的加速器。</li>
</ul>
<h3 id="52-算法评估"><a class="markdownIt-Anchor" href="#52-算法评估"></a> 5.2 算法评估</h3>
<p>为了评估我们提出的方法的性能，我们首先在常用的MMLU数据集上将我们的方法与现有基准方法（包括部分调优、LST和LoRA调优）进行比较。如表1所示，我们的方法在保持相同计算效率的情况下，精度比基准方法提高了0.70%到1.29%，内存使用减少了4倍。为了进一步验证Edge-LLM中的关键要素，我们首先在WikiText-2数据集上单独评估LUC的困惑度，与两种最先进的压缩技术（包括SparseGPT和LLM-QAT）和两种变体进行比较：（1）Uniform：在所有层使用相同的量化位宽和修剪稀疏度；（2）Random：随机分配我们生成的层级修剪稀疏度和量化位宽。如表2所示，在类似资源限制下，我们提出的方法比Uniform基准的困惑度低1.28到2.49，在相同效率下比Random基准的困惑度低0.50到1.68，展示了我们提出的LUC的有效性。</p>
<h3 id="53-硬件评估"><a class="markdownIt-Anchor" href="#53-硬件评估"></a> 5.3 硬件评估</h3>
<p>我们基于用于Transformer训练的基准systolic加速器设计对提出的技术进行评估，并进行了适当修改以支持提出的技术：</p>
<ol>
<li>由于提出的自适应层调优可以自然地在基准加速器上运行，因此无需修改基准加速器；</li>
<li>对于LUC，我们做了以下修改：将基准更新为在DRAM和SSD上存储压缩权重。为了简化设计，我们没有修改计算核心的稀疏性，而是使用了简单的时空灵活精度MAC单元。我们应用提出的硬件调度搜索方法来找到最佳的算法到硬件的映射。Scale-Sim模拟结果显示，自适应层调优可以实现2.24倍的加速；修剪和自适应层调优可以实现2.37倍的加速；结合LUC（4-bit/5-bit）和自适应层调优可以分别实现3.38倍和2.92倍的总体加速。</li>
</ol>

            
        </div>
        <footer class="article-footer">
            <a data-url="https://abinzzz.github.io/2024/07/16/DAC-EDGE-LLM/" data-id="clyobo00c0000td690lw0f2ob" data-title="DAC:EDGE-LLM"
               class="article-share-link">分享</a>
            
            
            
            

        </footer>
    </div>
    
        
    <nav id="article-nav" class="wow fadeInUp">
        
            <div class="article-nav-link-wrap article-nav-link-left">
                
                    <img data-src="https://pic.imgdb.cn/item/66a4abfed9c307b7e97fc78a.png" data-sizes="auto" alt="KDD:FedBiOT"
                         class="lazyload">
                
                <a href="/2024/07/16/KDD-FedBiOT/"></a>
                <div class="article-nav-caption">前一篇</div>
                <h3 class="article-nav-title">
                    
                        KDD:FedBiOT
                    
                </h3>
            </div>
        
        
            <div class="article-nav-link-wrap article-nav-link-right">
                
                    <img data-src="https://pic.imgdb.cn/item/66964c1cd9c307b7e9ec08b4.png" data-sizes="auto" alt="Arxiv:SPT"
                         class="lazyload">
                
                <a href="/2024/07/16/Arxiv-SPT/"></a>
                <div class="article-nav-caption">后一篇</div>
                <h3 class="article-nav-title">
                    
                        Arxiv:SPT
                    
                </h3>
            </div>
        
    </nav>


    
</article>











</section>
                
                    <aside id="sidebar">
    <div class="sidebar-wrap wow fadeInRight">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">299</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">23</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">299</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
    
        <iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/74X2u8JMVooG2QbjRxXwR8?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Accumulate/">Accumulate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AimGraduate/">AimGraduate</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Competition/">Competition</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Future/">Future</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/">GoAbroad</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/Application-Season/">Application Season</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoAbroad/IELTS/">IELTS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/bug/">bug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/internship/">internship</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/internship/SNN/">SNN</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/FL/">FL</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/paper/FL/Privacy/">Privacy</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/Multimudal/">Multimudal</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/">project</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS224N/">CS224N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/CS231N/">CS231N</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/project/Missing-Semester-of-CS/">Missing Semester of CS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/">专业知识</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/ML/">ML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/d2l/">d2l</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a></li></ul>
        </div>
    </div>


    
        
    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/0/" style="font-size: 10px;">0</a> <a href="/tags/1/" style="font-size: 11.54px;">1</a> <a href="/tags/11-11/" style="font-size: 10px;">11.11</a> <a href="/tags/2/" style="font-size: 11.54px;">2</a> <a href="/tags/2-2/" style="font-size: 10px;">2-2</a> <a href="/tags/3/" style="font-size: 10.77px;">3</a> <a href="/tags/4/" style="font-size: 10px;">4</a> <a href="/tags/AI/" style="font-size: 10px;">AI</a> <a href="/tags/Accumulate/" style="font-size: 17.69px;">Accumulate</a> <a href="/tags/Advancing-Spiking-Neural-Networks-towards-Deep-Residual-Learning/" style="font-size: 11.54px;">Advancing Spiking Neural Networks towards Deep Residual Learning</a> <a href="/tags/AimGraduate/" style="font-size: 15.38px;">AimGraduate</a> <a href="/tags/An-Overview-of-the-BLITZ-Computer-Hardware/" style="font-size: 10px;">An Overview of the BLITZ Computer Hardware</a> <a href="/tags/An-Overview-of-the-BLITZ-System/" style="font-size: 10px;">An Overview of the BLITZ System</a> <a href="/tags/Anything/" style="font-size: 10px;">Anything</a> <a href="/tags/Artificial-neural-networks/" style="font-size: 10px;">Artificial neural networks</a> <a href="/tags/Attention/" style="font-size: 10px;">Attention</a> <a href="/tags/BLIP/" style="font-size: 10px;">BLIP</a> <a href="/tags/BLIP-2/" style="font-size: 10px;">BLIP-2</a> <a href="/tags/BasciConception/" style="font-size: 10px;">BasciConception</a> <a href="/tags/BatchNorm/" style="font-size: 10px;">BatchNorm</a> <a href="/tags/Benchmark/" style="font-size: 10px;">Benchmark</a> <a href="/tags/Blitz/" style="font-size: 12.31px;">Blitz</a> <a href="/tags/CAS/" style="font-size: 10.77px;">CAS</a> <a href="/tags/CMU15-445/" style="font-size: 10px;">CMU15-445</a> <a href="/tags/CNN/" style="font-size: 12.31px;">CNN</a> <a href="/tags/CS224N/" style="font-size: 10.77px;">CS224N</a> <a href="/tags/CS231N/" style="font-size: 10px;">CS231N</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/Causal-Analysis-Churn/" style="font-size: 13.85px;">Causal Analysis Churn</a> <a href="/tags/Causal-Reasoning/" style="font-size: 10px;">Causal Reasoning</a> <a href="/tags/ComPetition/" style="font-size: 10px;">ComPetition</a> <a href="/tags/Competition/" style="font-size: 16.15px;">Competition</a> <a href="/tags/Container/" style="font-size: 10px;">Container</a> <a href="/tags/Convolutional-SNN-to-Classify-FMNIST/" style="font-size: 10px;">Convolutional SNN to Classify FMNIST</a> <a href="/tags/DIY/" style="font-size: 10px;">DIY</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/DeepFM/" style="font-size: 10px;">DeepFM</a> <a href="/tags/English/" style="font-size: 10.77px;">English</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Filter/" style="font-size: 10px;">Filter</a> <a href="/tags/Fine-Tuning/" style="font-size: 10px;">Fine-Tuning</a> <a href="/tags/Future/" style="font-size: 15.38px;">Future</a> <a href="/tags/GB/" style="font-size: 10px;">GB</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GiB/" style="font-size: 10px;">GiB</a> <a href="/tags/Git/" style="font-size: 10.77px;">Git</a> <a href="/tags/GitHub/" style="font-size: 10px;">GitHub</a> <a href="/tags/GoAbroad/" style="font-size: 16.92px;">GoAbroad</a> <a href="/tags/Graduate/" style="font-size: 10px;">Graduate</a> <a href="/tags/HKU/" style="font-size: 10px;">HKU</a> <a href="/tags/HMM/" style="font-size: 10px;">HMM</a> <a href="/tags/IELTS/" style="font-size: 13.08px;">IELTS</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 10px;">IntelliJ IDEA</a> <a href="/tags/Jianfei-Chen/" style="font-size: 10px;">Jianfei Chen</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/LMUFORMER/" style="font-size: 10px;">LMUFORMER</a> <a href="/tags/LayerNorm/" style="font-size: 10px;">LayerNorm</a> <a href="/tags/Lec01/" style="font-size: 11.54px;">Lec01</a> <a href="/tags/Lec01s/" style="font-size: 10.77px;">Lec01s</a> <a href="/tags/Lime/" style="font-size: 10px;">Lime</a> <a href="/tags/Linux/" style="font-size: 12.31px;">Linux</a> <a href="/tags/Listening/" style="font-size: 10px;">Listening</a> <a href="/tags/M2/" style="font-size: 10.77px;">M2</a> <a href="/tags/MIT6-S081/" style="font-size: 13.08px;">MIT6.S081</a> <a href="/tags/ML/" style="font-size: 15.38px;">ML</a> <a href="/tags/MS-ResNet/" style="font-size: 10px;">MS-ResNet</a> <a href="/tags/Mac/" style="font-size: 10.77px;">Mac</a> <a href="/tags/Missing-Semester/" style="font-size: 11.54px;">Missing Semester</a> <a href="/tags/Monitor/" style="font-size: 10px;">Monitor</a> <a href="/tags/NECCS/" style="font-size: 10px;">NECCS</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/NTU/" style="font-size: 10px;">NTU</a> <a href="/tags/Neuromorphic-computing/" style="font-size: 10px;">Neuromorphic computing</a> <a href="/tags/Neuron/" style="font-size: 10px;">Neuron</a> <a href="/tags/OCR/" style="font-size: 10px;">OCR</a> <a href="/tags/PSN/" style="font-size: 10px;">PSN</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Qingyao-Ai/" style="font-size: 10.77px;">Qingyao Ai</a> <a href="/tags/RISC-V/" style="font-size: 10px;">RISC-V</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ReadMemory/" style="font-size: 10px;">ReadMemory</a> <a href="/tags/Reading/" style="font-size: 10px;">Reading</a> <a href="/tags/ResNet/" style="font-size: 10.77px;">ResNet</a> <a href="/tags/Rethinking-the-performance-comparison-between-SNNS-and-ANNS/" style="font-size: 10px;">Rethinking the performance comparison between SNNS and ANNS</a> <a href="/tags/SNN/" style="font-size: 13.08px;">SNN</a> <a href="/tags/SNN-vs-RNN/" style="font-size: 10px;">SNN vs RNN</a> <a href="/tags/SPIKEBERT/" style="font-size: 10px;">SPIKEBERT</a> <a href="/tags/STGgameAI/" style="font-size: 10px;">STGgameAI</a> <a href="/tags/Script/" style="font-size: 10px;">Script</a> <a href="/tags/Shell/" style="font-size: 10.77px;">Shell</a> <a href="/tags/Single-Fully-Connected-Layer-SNN-to-Classify-MNIST/" style="font-size: 10px;">Single Fully Connected Layer SNN to Classify MNIST</a> <a href="/tags/Spiking-Neural-Network-for-Ultra-low-latency-and-High-accurate-Object-Detection/" style="font-size: 10px;">Spiking Neural Network for Ultra-low-latency and High-accurate Object Detection</a> <a href="/tags/Spiking-neural-network/" style="font-size: 10.77px;">Spiking neural network</a> <a href="/tags/Spiking-neural-networks/" style="font-size: 10px;">Spiking neural networks</a> <a href="/tags/SpikingBERT/" style="font-size: 10px;">SpikingBERT</a> <a href="/tags/Surrogate-Gradient-Method/" style="font-size: 10px;">Surrogate Gradient Method</a> <a href="/tags/T1-fighting/" style="font-size: 10.77px;">T1 fighting</a> <a href="/tags/THU/" style="font-size: 10px;">THU</a> <a href="/tags/TUM/" style="font-size: 10px;">TUM</a> <a href="/tags/Tai-Jiang-Mu/" style="font-size: 10px;">Tai-Jiang Mu</a> <a href="/tags/Terminal/" style="font-size: 10px;">Terminal</a> <a href="/tags/The-Thread-Scheduler-and-Concurrency-Control-Primitives/" style="font-size: 10px;">The Thread Scheduler and Concurrency Control Primitives</a> <a href="/tags/Transformer/" style="font-size: 10px;">Transformer</a> <a href="/tags/Undergraduate/" style="font-size: 10px;">Undergraduate</a> <a href="/tags/University/" style="font-size: 13.08px;">University</a> <a href="/tags/VSCode/" style="font-size: 10px;">VSCode</a> <a href="/tags/ViT/" style="font-size: 10px;">ViT</a> <a href="/tags/Vim/" style="font-size: 10px;">Vim</a> <a href="/tags/Yuxiao-Dong/" style="font-size: 10.77px;">Yuxiao Dong</a> <a href="/tags/alexnet/" style="font-size: 10px;">alexnet</a> <a href="/tags/anygpt/" style="font-size: 10px;">anygpt</a> <a href="/tags/arxiv/" style="font-size: 10px;">arxiv</a> <a href="/tags/author/" style="font-size: 10px;">author</a> <a href="/tags/bert/" style="font-size: 12.31px;">bert</a> <a href="/tags/blip2/" style="font-size: 10px;">blip2</a> <a href="/tags/bug/" style="font-size: 16.92px;">bug</a> <a href="/tags/cat/" style="font-size: 10px;">cat</a> <a href="/tags/chapter00/" style="font-size: 10px;">chapter00</a> <a href="/tags/chatgpt/" style="font-size: 10px;">chatgpt</a> <a href="/tags/chatgpt-prompt/" style="font-size: 10px;">chatgpt prompt</a> <a href="/tags/chmod/" style="font-size: 10px;">chmod</a> <a href="/tags/chrome/" style="font-size: 10px;">chrome</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/code/" style="font-size: 10.77px;">code</a> <a href="/tags/coding/" style="font-size: 10px;">coding</a> <a href="/tags/commit/" style="font-size: 10px;">commit</a> <a href="/tags/competition/" style="font-size: 10px;">competition</a> <a href="/tags/conv2d/" style="font-size: 10px;">conv2d</a> <a href="/tags/copilot/" style="font-size: 10.77px;">copilot</a> <a href="/tags/cpu/" style="font-size: 10px;">cpu</a> <a href="/tags/cuda/" style="font-size: 10.77px;">cuda</a> <a href="/tags/d2l/" style="font-size: 14.62px;">d2l</a> <a href="/tags/database/" style="font-size: 10px;">database</a> <a href="/tags/dataloader/" style="font-size: 10px;">dataloader</a> <a href="/tags/debug/" style="font-size: 10px;">debug</a> <a href="/tags/deep-neural-network/" style="font-size: 10.77px;">deep neural network</a> <a href="/tags/delete/" style="font-size: 10px;">delete</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/dowhy/" style="font-size: 10.77px;">dowhy</a> <a href="/tags/dp/" style="font-size: 10px;">dp</a> <a href="/tags/echo/" style="font-size: 10px;">echo</a> <a href="/tags/email/" style="font-size: 10px;">email</a> <a href="/tags/embedding/" style="font-size: 10px;">embedding</a> <a href="/tags/explainer/" style="font-size: 10.77px;">explainer</a> <a href="/tags/fee/" style="font-size: 10px;">fee</a> <a href="/tags/file/" style="font-size: 10px;">file</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 13.08px;">github</a> <a href="/tags/gpt/" style="font-size: 10px;">gpt</a> <a href="/tags/gpu/" style="font-size: 11.54px;">gpu</a> <a href="/tags/hexo/" style="font-size: 10.77px;">hexo</a> <a href="/tags/imap/" style="font-size: 10px;">imap</a> <a href="/tags/import/" style="font-size: 10px;">import</a> <a href="/tags/instructor/" style="font-size: 12.31px;">instructor</a> <a href="/tags/intern-00/" style="font-size: 10px;">intern-00</a> <a href="/tags/intern00/" style="font-size: 12.31px;">intern00</a> <a href="/tags/interns/" style="font-size: 10px;">interns</a> <a href="/tags/internship/" style="font-size: 19.23px;">internship</a> <a href="/tags/interview/" style="font-size: 10px;">interview</a> <a href="/tags/introduction/" style="font-size: 10px;">introduction</a> <a href="/tags/iterm2/" style="font-size: 10px;">iterm2</a> <a href="/tags/knowledge-distillaion/" style="font-size: 10px;">knowledge distillaion</a> <a href="/tags/linux/" style="font-size: 11.54px;">linux</a> <a href="/tags/llava/" style="font-size: 10px;">llava</a> <a href="/tags/llm/" style="font-size: 10px;">llm</a> <a href="/tags/loss/" style="font-size: 10px;">loss</a> <a href="/tags/lr/" style="font-size: 10px;">lr</a> <a href="/tags/lstm/" style="font-size: 10px;">lstm</a> <a href="/tags/mac/" style="font-size: 13.08px;">mac</a> <a href="/tags/memory/" style="font-size: 12.31px;">memory</a> <a href="/tags/mentor/" style="font-size: 10.77px;">mentor</a> <a href="/tags/ml/" style="font-size: 10px;">ml</a> <a href="/tags/model-evaluation/" style="font-size: 10px;">model evaluation</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/mysqlclient/" style="font-size: 10px;">mysqlclient</a> <a href="/tags/neuromorphic-computing/" style="font-size: 10.77px;">neuromorphic computing</a> <a href="/tags/note/" style="font-size: 10px;">note</a> <a href="/tags/nvidia/" style="font-size: 10px;">nvidia</a> <a href="/tags/ohmyzsh/" style="font-size: 10px;">ohmyzsh</a> <a href="/tags/olive/" style="font-size: 10px;">olive</a> <a href="/tags/os/" style="font-size: 12.31px;">os</a> <a href="/tags/outlook/" style="font-size: 10px;">outlook</a> <a href="/tags/paper/" style="font-size: 20px;">paper</a> <a href="/tags/photo/" style="font-size: 10px;">photo</a> <a href="/tags/pku/" style="font-size: 10px;">pku</a> <a href="/tags/player/" style="font-size: 10px;">player</a> <a href="/tags/preparation/" style="font-size: 10px;">preparation</a> <a href="/tags/prml/" style="font-size: 12.31px;">prml</a> <a href="/tags/profile/" style="font-size: 10px;">profile</a> <a href="/tags/project/" style="font-size: 13.85px;">project</a> <a href="/tags/prompt/" style="font-size: 10px;">prompt</a> <a href="/tags/pycharm/" style="font-size: 10px;">pycharm</a> <a href="/tags/python/" style="font-size: 10.77px;">python</a> <a href="/tags/pytorch/" style="font-size: 16.15px;">pytorch</a> <a href="/tags/qemu/" style="font-size: 10px;">qemu</a> <a href="/tags/question/" style="font-size: 10px;">question</a> <a href="/tags/reading/" style="font-size: 10px;">reading</a> <a href="/tags/register/" style="font-size: 10px;">register</a> <a href="/tags/regression/" style="font-size: 10px;">regression</a> <a href="/tags/rnn/" style="font-size: 10px;">rnn</a> <a href="/tags/rsa/" style="font-size: 10px;">rsa</a> <a href="/tags/se/" style="font-size: 10px;">se</a> <a href="/tags/self-attention/" style="font-size: 10px;">self-attention</a> <a href="/tags/server/" style="font-size: 10px;">server</a> <a href="/tags/shap/" style="font-size: 10px;">shap</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/shell-vs-terminal/" style="font-size: 10px;">shell vs terminal</a> <a href="/tags/softmax/" style="font-size: 10px;">softmax</a> <a href="/tags/sora/" style="font-size: 10px;">sora</a> <a href="/tags/spike/" style="font-size: 10.77px;">spike</a> <a href="/tags/spikeBERT/" style="font-size: 10.77px;">spikeBERT</a> <a href="/tags/spikeBert/" style="font-size: 10px;">spikeBert</a> <a href="/tags/spikebert/" style="font-size: 10px;">spikebert</a> <a href="/tags/spikingjelly/" style="font-size: 13.08px;">spikingjelly</a> <a href="/tags/spikngjelly/" style="font-size: 10.77px;">spikngjelly</a> <a href="/tags/ssh/" style="font-size: 10.77px;">ssh</a> <a href="/tags/sta/" style="font-size: 10px;">sta</a> <a href="/tags/terminal/" style="font-size: 10px;">terminal</a> <a href="/tags/thu/" style="font-size: 10px;">thu</a> <a href="/tags/tips/" style="font-size: 10.77px;">tips</a> <a href="/tags/tittle/" style="font-size: 10px;">tittle</a> <a href="/tags/tmux/" style="font-size: 10px;">tmux</a> <a href="/tags/tool/" style="font-size: 18.46px;">tool</a> <a href="/tags/transformer/" style="font-size: 13.85px;">transformer</a> <a href="/tags/transformers/" style="font-size: 10px;">transformers</a> <a href="/tags/vit/" style="font-size: 10px;">vit</a> <a href="/tags/vscode/" style="font-size: 10.77px;">vscode</a> <a href="/tags/wakatime/" style="font-size: 10px;">wakatime</a> <a href="/tags/writing/" style="font-size: 10px;">writing</a> <a href="/tags/xv6/" style="font-size: 10px;">xv6</a> <a href="/tags/yeild/" style="font-size: 10px;">yeild</a> <a href="/tags/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86/" style="font-size: 18.46px;">专业知识</a> <a href="/tags/%E4%B8%93%E7%A1%95/" style="font-size: 10px;">专硕</a> <a href="/tags/%E4%B8%AD%E4%BB%8B/" style="font-size: 10px;">中介</a> <a href="/tags/%E4%B8%AD%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AE%BE%E8%AE%A1%E5%A4%A7%E8%B5%9B/" style="font-size: 10px;">中国大学生计算机设计大赛</a> <a href="/tags/%E4%B8%AD%E7%A7%91%E9%99%A2/" style="font-size: 10px;">中科院</a> <a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 10px;">代理</a> <a href="/tags/%E5%85%AC%E9%80%89%E8%AF%BE/" style="font-size: 10px;">公选课</a> <a href="/tags/%E5%86%85%E5%AD%98/" style="font-size: 10.77px;">内存</a> <a href="/tags/%E5%86%99%E4%BD%9C%E5%BF%83%E5%BE%97/" style="font-size: 10px;">写作心得</a> <a href="/tags/%E5%86%99%E4%BD%9C%E6%8A%80%E5%B7%A7/" style="font-size: 10px;">写作技巧</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" style="font-size: 10px;">分布式训练</a> <a href="/tags/%E5%8A%A0%E5%88%86/" style="font-size: 10px;">加分</a> <a href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">动手学深度学习</a> <a href="/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/" style="font-size: 10px;">博弈论</a> <a href="/tags/%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" style="font-size: 10px;">基础优化方法</a> <a href="/tags/%E5%A4%8D%E4%B9%A0/" style="font-size: 10px;">复习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/" style="font-size: 10px;">多模态</a> <a href="/tags/%E5%A4%A7%E4%B8%89%E4%B8%8A/" style="font-size: 10px;">大三上</a> <a href="/tags/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" style="font-size: 10px;">大作业</a> <a href="/tags/%E5%A4%A7%E5%88%9B/" style="font-size: 10px;">大创</a> <a href="/tags/%E5%A4%A7%E8%8B%B1%E8%B5%9B/" style="font-size: 10px;">大英赛</a> <a href="/tags/%E5%AD%A6%E7%A1%95/" style="font-size: 10px;">学硕</a> <a href="/tags/%E5%AE%A1%E7%A8%BF%E6%84%8F%E8%A7%81/" style="font-size: 10.77px;">审稿意见</a> <a href="/tags/%E5%BC%BA%E5%BC%B1com/" style="font-size: 10px;">强弱com</a> <a href="/tags/%E5%BD%A2%E5%8A%BF%E4%B8%8E%E6%94%BF%E7%AD%96/" style="font-size: 10px;">形势与政策</a> <a href="/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/" style="font-size: 10px;">快捷键</a> <a href="/tags/%E6%82%84%E6%82%84%E8%AF%9D/" style="font-size: 10px;">悄悄话</a> <a href="/tags/%E6%94%B9%E7%BB%B4%E5%BA%A6/" style="font-size: 10px;">改维度</a> <a href="/tags/%E6%95%99%E8%82%B2%E8%AE%B8%E5%8F%AF/" style="font-size: 10px;">教育许可</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E9%A2%84%E5%A4%84%E7%90%86/" style="font-size: 10px;">数据操作+预处理</a> <a href="/tags/%E6%98%BE%E5%AD%98/" style="font-size: 10.77px;">显存</a> <a href="/tags/%E6%99%BA%E6%85%A7%E6%A0%91/" style="font-size: 10px;">智慧树</a> <a href="/tags/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">智能计算系统</a> <a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 10.77px;">服务器</a> <a href="/tags/%E6%9C%9F%E6%9C%AB/" style="font-size: 10px;">期末</a> <a href="/tags/%E6%9C%B1%E8%80%81%E5%B8%88/" style="font-size: 10px;">朱老师</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 10px;">朴素贝叶斯</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">机器学习</a> <a href="/tags/%E6%9D%82%E9%A1%B9/" style="font-size: 12.31px;">杂项</a> <a href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" style="font-size: 10.77px;">李宏毅</a> <a href="/tags/%E6%9D%8E%E6%B2%90/" style="font-size: 10px;">李沐</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 10px;">环境搭建</a> <a href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">矩阵计算</a> <a href="/tags/%E7%A7%91%E8%BD%AF/" style="font-size: 10px;">科软</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 10px;">线性代数</a> <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">线性回归</a> <a href="/tags/%E7%BB%A7%E6%89%BF/" style="font-size: 10px;">继承</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3/" style="font-size: 10px;">脑机接口</a> <a href="/tags/%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 10px;">脑机接口信号处理</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/" style="font-size: 10px;">自动求导</a> <a href="/tags/%E8%8A%82%E8%83%BD%E5%87%8F%E6%8E%92/" style="font-size: 11.54px;">节能减排</a> <a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" style="font-size: 10px;">虚拟机</a> <a href="/tags/%E8%A7%84%E5%88%99/" style="font-size: 10px;">规则</a> <a href="/tags/%E8%A7%A3%E5%8E%8B%E7%BC%A9/" style="font-size: 10px;">解压缩</a> <a href="/tags/%E8%AE%A1%E7%BD%91/" style="font-size: 10px;">计网</a> <a href="/tags/%E8%AF%AD%E4%B9%89%E7%A9%BA%E9%97%B4/" style="font-size: 10px;">语义空间</a> <a href="/tags/%E8%AF%BE%E7%A8%8B/" style="font-size: 10px;">课程</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E6%A6%82%E8%A7%88/" style="font-size: 10px;">课程概览</a> <a href="/tags/%E8%AF%BE%E7%A8%8B%E8%A1%A8/" style="font-size: 10px;">课程表</a> <a href="/tags/%E8%B0%83%E7%A0%94/" style="font-size: 10.77px;">调研</a> <a href="/tags/%E8%B4%A1%E7%8C%AE%E8%80%85/" style="font-size: 10px;">贡献者</a> <a href="/tags/%E8%BE%93%E5%85%A5%E6%B3%95/" style="font-size: 10px;">输入法</a> <a href="/tags/%E9%87%8F%E5%8C%96/" style="font-size: 10px;">量化</a> <a href="/tags/%E9%99%B6%E7%93%B7/" style="font-size: 10px;">陶瓷</a> <a href="/tags/%E9%B8%BF%E9%9B%81%E6%9D%AF/" style="font-size: 10px;">鸿雁杯</a>
        </div>
    </div>


    
        

    <div class="widget-wrap wow fadeInRight">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">十月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">九月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">八月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">七月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">六月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">五月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">四月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">三月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">一月 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">十一月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">十月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">九月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">八月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">七月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li></ul>
        </div>
    </div>


    
</aside>

                
            </div>
            <footer id="footer" class="wow fadeInUp">
    

    <div style="width: 100%; overflow: hidden"><div class="footer-line"></div></div>
    <div class="outer">
        <div id="footer-info" class="inner">
            
            <div>
                <span class="icon-copyright"></span>
                2020-2024
                <span class="footer-info-sep"></span>
                ab
            </div>
            
                <div>
                    基于&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;
                    Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" target="_blank">Reimu</a>
                </div>
            
            
                <div>
                    <span class="icon-brush"></span>
                    711.6k
                    &nbsp;|&nbsp;
                    <span class="icon-coffee"></span>
                    44:32
                </div>
            
            
                <div>
                    <span class="icon-eye"></span>
                    <span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                    &nbsp;|&nbsp;
                    <span class="icon-user"></span>
                    <span id="busuanzi_container_site_uv">总访客量&nbsp;<span id="busuanzi_value_site_uv"></span></span>
                </div>
            
        </div>
    </div>
</footer>

        </div>
        <nav id="mobile-nav">
    <div class="sidebar-wrap">
        <div class="sidebar-author">
            <img data-src="/avatar/avatar.jpg" data-sizes="auto" alt="ab" class="lazyload">
            <div class="sidebar-author-name">ab</div>
            <div class="sidebar-description"></div>
        </div>
        <div class="sidebar-state">
            <div class="sidebar-state-article">
                <div>文章</div>
                <div class="sidebar-state-number">299</div>
            </div>
            <div class="sidebar-state-category">
                <div>分类</div>
                <div class="sidebar-state-number">23</div>
            </div>
            <div class="sidebar-state-tag">
                <div>标签</div>
                <div class="sidebar-state-number">299</div>
            </div>
        </div>
        <div class="sidebar-social">
            
                <div class=icon-github>
                    <a href=https://github.com/abinzzz itemprop="url" target="_blank"></a>
                </div>
            
        </div>
        <div class="sidebar-menu">
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">首页</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/archives"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">归档</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/about"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">关于</div>
                </div>
            
                <div class="sidebar-menu-link-wrap">
                    <a class="sidebar-menu-link-dummy" href="/friend"></a>
                    <span class="sidebar-menu-icon"></span>
                    <div class="sidebar-menu-link">友链</div>
                </div>
            
        </div>
    </div>
</nav>

        
<script src="https://unpkg.com/jquery@3.7.0/dist/jquery.min.js"></script>


<script src="https://unpkg.com/lazysizes@5.3.2/lazysizes.min.js"></script>


<script src="https://unpkg.com/clipboard@2.0.11/dist/clipboard.min.js"></script>



    
<script src="https://unpkg.com/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>



    
<script src="https://unpkg.com/busuanzi@2.3.0/bsz.pure.mini.js"></script>






<script src="/js/script.js"></script>
















    </div>
    <div class="site-search">
        <div class="algolia-popup popup">
            <div class="algolia-search">
                <span class="algolia-search-input-icon"></span>
                <div class="algolia-search-input" id="algolia-search-input"></div>
            </div>

            <div class="algolia-results">
                <div id="algolia-stats"></div>
                <div id="algolia-hits"></div>
                <div id="algolia-pagination" class="algolia-pagination"></div>
            </div>

            <span class="popup-btn-close"></span>
        </div>
    </div>
    <!-- hexo injector body_end start -->
<script src="/js/insertHighlight.js"></script>
<!-- hexo injector body_end end --></body>
    </html>

